from gensim.models import Word2Vec
from gensim.models import Doc2Vec
from nltk import word_tokenize
from scipy import spatial
import operator
import sys



#Get the most similar words/phrases from the input file based on the doc2vec model
def main(argv):
	DIM = argv[1]
	filename = argv[2]
	#print indexes
	model_name = 'doc2vec_model_'+str(DIM)
	model = Doc2Vec.load(model_name)

	#for index in range(int(str(indexes))):
	#docvec = model.docvecs[filename]
	docvec = model.docvecs[0]
	doc = open(filename,'r').readlines()[0].replace('\n','')
	#print "document"+str(index)
	print doc
	print ""
	words = word_tokenize(doc.decode('utf8'))
	Sim_Dict = {}
	for word in words:
		try:
			wordvec = model[word]
			Sim_Dict[word] = 1 - spatial.distance.cosine(docvec,wordvec)
		except:
			pass
	sorted_dict = sorted(Sim_Dict.items(), key=operator.itemgetter(1),reverse=True)
	print "significant words:"
	for item in sorted_dict[:20]:
		print item
	print ""

if __name__ == "__main__":
	main(sys.argv)


