Recovering key biological constituents through sparse representation of gene expression Motivation: Large-scale RNA expression measurements are generating enormous quantities of data. During the last two decades, many methods were developed for extracting insights regarding the interrelationships between genes from such data. The mathematical and computational perspectives that underlie these methods are usually algebraic or probabilistic. Results: Here, we introduce an unexplored geometric view point where expression levels of genes in multiple experiments are interpreted as vectors in a high-dimensional space. Specifically, we find, for the expression profile of each particular gene, its approximation as a linear combination of profiles of a few other genes. This method is inspired by recent developments in the realm of compressed sensing in the machine learning domain. To demonstrate the power of our approach in extracting valuable information from the expression data, we independently applied it to large-scale experiments carried out on the yeast and malaria parasite whole transcriptomes. The parameters extracted from the sparse reconstruction of the expression profiles, when fed to a supervised learning platform, were used to successfully predict the relationships between genes throughout the Gene Ontology hierarchy and proteinprotein interaction map. Extensive assessment of the biological results shows high accuracy in both recovering known predictions and in yielding accurate predictions missing from the current databases. We suggest that the geometrical approach presented here is suitable for a broad range of high-dimensional experimental data.High-throughput technologies have come to play a central role in biological and biomedical research in the last decade. Advances in large-scale technologies on a genome-wide scale produce enormous amounts of data . Yet, a major goal of functional genomics is the quest for a comprehensive description of the functions and interactions of all genes and proteins in a genome. To whom correspondence should be addressed. Data such as large-scale gene expression are usually represented by a matrix, where n genes are examined in d experimental conditions. Here, we view such data as a set of n points (vectors) in d-dimensional space, each of which represents the profile of a given gene over d different experimental conditions. Many known methods that have yielded meaningful biological insights in fact seek geometric or algebraic features of these vectors. For example, analyzing the angles between vectors amounts to a correlation-based analysis. Similarly, the direction in space along which these points are most spread out correspond to singular value decomposition (SVD) and its principal component analysis implementation . These are powerful tools in providing biological inference . In general, methods and disciplines developed toward extracting information from expression data include pairwise properties (e.g. correlation, variance, entropy-based distance) , clustering , Bayesian networks , information theory, ordinary differential equations and other sophisticated distance measures. In this study, we applied a different approach to gene expression data analysis. The geometric principle that underlies it is very natural and different from existing methods, though it is close in spirit, and inspired by recent advances in compressive sensing and sparse signal recovery . A simple probabilistic consideration implies the following geometric claim: given a set of n randomly chosen points in the d-dimensional space, it is very unlikely that a linear subspace Y exists where more than dim(Y ) points of the chosen points reside very close to Y (see Section 3). In this study, we present a natural, yet unexplored, approach for the seemingly exhausted problem of gene expression analysis. Adopting a sparse signals reconstruction mindset, we recover a support set of genes for each gene in a genome. Geometrically, we uncovered linear subspaces that are overpopulated with expression profiles in the multidimensional space of the experiments set. We could verify the robustness and significance of the sparse reconstructions using measures intrinsic to the method and data. Formally, we are interested in subsets S of our n-point set that (nearly) resides on a subspace of dimension strictly smaller than S. Having found such sets, several immediate questions suggest themselves: (i) are these findings robust? (ii) If they are robust, can we directly interpret their biological meaning? (iii) Can such representation uncover meaningful structures? (iv) Does the method generalize? In this article, we answer these questions by considering gene expression alone and testing datasets coming from the transcriptomes of the budding yeast Saccharomyces cerevisiae and the malaria parasite Plasmodium falciparum. A conceptually new method that we call SPARCLE (SPArse ReCovery of Linear combinations of Expression) is introduced. It is inspired by the plausible assumption that expression data, when considered over a broad range of experimental conditions, encodes profound layers of systematic (yet hidden) behaviors. We further confirmed the stability and robustness of SPARCLE results for entire transcriptomes under perturbations to the data. Extracting features from the geometric parameters of SPARCLEs results, and training AdaBoost, a machine learning platform, to exhaustively reveal pairwise associations between gene function [represented by Gene Ontology (GO) annotations and by the proteinprotein interaction (PPI) map] confirmed the principal information encoded by the geometric-based representation. The generality of the method is confirmed by applying it to both the knowledge-rich yeast model and the poorly annotated malaria parasite proteome.To demonstrate the utility of SPARCLE on gene expression data, we analyzed two very large experimental datasets: from the yeast S.cerevisiae and from the malaria parasite P.falciparum composed of 170 and 208 experiments and covering 6254 and 4365 genes, respectively. While the SPARCLE methodology is not restricted by the type or source of data, we used mRNA expression measurements from, which constitute a microarray compendium of chemostat cultures of S.cerevisiae that cover 55 unique growth conditions, including nutrient-limiting substrates,growth rate, aeration, pH and temperature. This dataset was divided randomly into two equal-sized sets of d = 85 experiments covering n = 6254 yeast genes. Our matrix has full row rank d = 85 and linear algebra implies that the smallest support (of a solution to P 0 ) will never exceed d. Indeed, the coefficient vectors obtained were considerably sparser with an average support size of 67 . Thus, our goal of achieving a short compact linear representation is achieved. To ensure robustness, half of the experiments (85) were not used for such representation, and were reserved for the purpose of cross-validation and evaluation. Random partitions of the data into two parts were performed five times with essentially identical results (see Section 3). Following this new geometrical representation of the data and confirming its stability to perturbations , we turned to extracting valuable biological information for the entire proteomes. The first functional test was based on searching enrichment in GO annotations. For 10 of the genes, significant enrichment of functional annotation could be found among their set of supporting genes retrieved by SPARCLE. An example is the gene MEP1 for which many of the support members share annotations (Supplementary). The statistical enrichments of GO annotations for a sample of gene supports are shown (Supplementary). Furthermore, MEP1 is interconnected with several of the support gene products, as reflected by the connected graph of the PPI network . However, for most genes (90), an immediate biological interpretation could not be retrieved from the support set. Typically, the objective gene and its support gene products are isolated in a PPI network graph (examples are shown in). As SPARCLE results proved meaningful and robust by the cross-validation test (; Supplementary), we expect the method to capture hidden information. To this end, we used SPARCLE results as input for a machine learning procedure . Specifically, we trained the AdaBoost framework to classify whether each pair of genes has a reported PPI or not, using information that is only extracted from the input data itself (i.e. the expression matrix) and the SPARCLE analysis (see Section 3). Together, the results of SPARCLE, with the Page: 659 655661a set of genes and their assigned coefficient. For each pair of genes, a feature vector was constructed from the properties of their representing sets. The feature vector also included another high-dimensional analysis, i.e. distances of each profile from the convex hull of the others. Other features were obtained directly from the input data (see Section 3). Features in the illustration: I, co-occurrence in supports; II, gene is coefficient in gene js support; III, gene js coefficient in gene is support; IV, Pearsons correlation of the expression profiles. (B) Prediction of PPI, as represented by the STRING database, by supervised learning from SPARCLE results (SPARCLE+AB). Accuracy is traded off with coverage by applying certainty thresholds on the classifier output. Other methods for predicting genes interrelationships are as follows: Pearsons correlation of the expression profiles (Correlations), and a transitive correlations method (SPath, see Section 2). (C) Prediction of associations for the GO Slim annotations, covering CC ontology. For detailed analyses of accuracy coverage tradeoff, see Supplementary(GO slim) and(PPI). input expression data, were condensed into feature vectors for each pair of genes . We tested whether functional information that is encoded in the yeast PPI map can be successfully recovered. Using a confidence threshold for the classification, accurate performance can be traded off in exchange for providing lower coverage of the data. The results of the supervised learning were exceptionally good . For 50 coverage of the high-confidence predictions, an accuracy of 78 was reached. Even for 100 coverage, the accuracy reaches 70 . Recall that the yeast unfiltered PPI map still exhibits a high false positive (FP) rate . The combined protocol of the unsupervised SPARCLE method and supervised learning platform (based on SPARCLE feature vector,) was then tested for the task of recovering the GO associations between genes, with the three functional branches covering MF, CC and BP . Specifically, gene pairs were classified as sharing, or not sharing, similar GO annotations. For comparison, we compare the prediction results to other correlation-based methods (and C). While the GO hierarchical database covers different descriptive resolutions (Supplementary), our protocol exhibited accurate predictions at all resolution levels (Supplementary Figs S3S5). For example, with 20 coverage at high GO resolution, the accuracy reached 97.6, 91 and 99 for CC, BP and MF, respectively (SPARCLE+AB;C and Supplementary Figs S3S5). For 100 coverage, we still achieved 6572 accuracy for all ontology branches at low resolution (SPARCLE+AB,C), and 7389 for the more specific terms of the high resolution of GO annotations (SPARCLE+AB; Supplementary Figs S3S5). An additional perspective on the SPARCLE+AB method is retrieved from the tradeoff of sensitivity and 1specificity as presented by the receiver operating characteristic curves. In all tests (for PPI, GO low and high levels and GO Slim), when SPARCLE+AB and Correlation+AB are compared a higher sensitivity is measured for the same specificity (data not shown). Next, we tested whether our inference method happens to do well on the yeast as a model system. Indeed, the yeast genome is extremely rich in annotations and currently 88 of its genes are associated with some informative GO annotation. Similarly, the quality and density of the yeast interactome exceed those of any other model system. We thus repeated the entire protocol for a set of 208 experiments measuring 4365 P.falciparum genes expression levels, from cells exposed to 30 anti-malaria drugs. Note that only 5 of the malaria genes are reviewed by SwissProt, 65 of the proteins are annotated as putative and only 46 of the genes are associated with some GO annotations (often at a low resolution, Supplementary). The SPARCLE-based protocol again demonstrated high predictive power (F; Supplementary).Finally, we systematically tested the novel knowledge gained from the above-described protocols (Figs 3 and 4; Supplementary Figs S3S5). To this end, we randomly sampled pairs of yeast genes which were annotated as unrelated and yet which we predicted to be related (FP) and, for comparison, pairs of genes which were annotated as unrelated and predicted to be unrelated (TNs). We manually examined each such pair of genes for functional connections. Remarkably, we verified our predictions for interrelations in 80 of all FP samples, yet could only detect relations in about a third of the TN set (Supplementary). While this manual inspection cannot be considered to stand on solid statistical ground, it provides support for the relevance of SPARCLE-based properties, when they are fed into a machine-learning platform to empower functional inference.The value of the information retrieved by the SPARCLE approach was demonstrated by using its results as a basis for machine learning classification of gene associations. A systematic and comprehensive evaluation, ranging from PPI networks and going through all resolution levels of the GO annotation database, covering the immensely explored yeast transcriptome and the poorly annotated malaria-parasite genome, revealed the large potential of using such a poorly studied geometric approach to extract principal insights from gene expression data. Many approaches aim to develop a systematic way to unravel hidden structure in data. Most studies that looked for biologicalcoherence in gene expression data applied clustering (at different levels of sophistication), revealing the existence of some hidden structure in the data. In the current research, comparisons to clustering results were not carried out, as our goal here is quite different. The high performance of SPARCLE-based AdaBoost learning should be considered as evidence for the principal information that is embedded in the geometric properties of the data. Therefore, a critical comparison was performed to evaluate the information that is embedded in correlation (a form of geometric representation, see below). We show that the correlation performed very poorly on the malaria data and somewhat better on the yeast data. In addition, by combining the AdaBoost learning protocol with the correlation (Correlation+AB), we isolated the contribution of the AdaBoost learning itself. SPARCLE+AB outperformed these other approaches for the entire range of accuracy and coverage (and 4; Supplementary Figs S3S7). Several aspects of our approach differ from common practices, and should be elaborated. Most of the activity in the machinelearning area can be viewed as a modern-day approach to the classical questions of statistics. The data at hand is considered as being sampled from some distribution and the question is to get as accurate as possible a description of that distribution. Our approach is different. When data items are (or can be naturally viewed as) points in space, it is possible to utilize any unexpected geometric properties that this set of points (corresponding to data items) has. In fact, many successful existing methods in machine learning can be viewed from this perspective. Thus, if S is a generic set of N points in d-dimensional space and if N is subexponential in d, then we do not expect to see any pairs of points (even nearly) in the same direction from the origin. If the set of points that is your dataset violates this statement, you can conclude that it has a geometrically nontrivial structure. This structural property is very likely a reflection of an interesting (albeit not necessarily interpretable) property in the domain from which the dataset came. This is our interpretation of correlation analysis, one of the most reliable workhorses of bioinformatics. Likewise, a generic point set in Euclidean space is not expected to be stretched in any special directions in space. Therefore, if your dataset, viewed geometrically, is stretched in certain directions it tells you something that can often be used to discover interesting phenomena. This is our interpretation of SVD analysis. Correlations and stretch are only two of the numerous properties that one may consider in a point set in Euclidean space. Our work considers another very basic property that we know not to exist in generic sets: (nearly) linearly dependent sets of points of cardinality that is substantially smaller than the dimension of the host space. When such an unexpected property of the dataset is discovered, two questions suggest themselves: (i) is this phenomenon only coincidental? and (ii) how can this geometric property of the data help us learn something about the system which it represents? In this study, we confirm the robustness of this Page: 661 655661 
