Bioimage informatics Fast and robust optical flow for time-lapse microscopy using super-voxels Motivation: Optical flow is a key method used for quantitative motion estimation of biological structures in light microscopy. It has also been used as a key module in segmentation and tracking systems and is considered a mature technology in the field of computer vision. However, most of the research focused on 2D natural images, which are small in size and rich in edges and texture information. In contrast, 3D time-lapse recordings of biological specimens comprise up to several terabytes of image data and often exhibit complex object dynamics as well as blurring due to the point-spread-function of the microscope. Thus, new approaches to optical flow are required to improve performance for such data. Results: We solve optical flow in large 3D time-lapse microscopy datasets by defining a Markov random field (MRF) over super-voxels in the foreground and applying motion smoothness constraints between super-voxels instead of voxel-wise. This model is tailored to the specific characteristics of light microscopy datasets: super-voxels help registration in textureless areas, the MRF over super-voxels efficiently propagates motion information between neighboring cells and the background subtraction and super-voxels reduce the dimension-ality of the problem by an order of magnitude. We validate our approach on large 3D time-lapse datasets of Drosophila and zebrafish development by analyzing cell motion patterns. We show that our approach is, on average, 10 faster than commonly used optical flow implementations in the Insight Tool-Kit (ITK) and reduces the average flow end point error by 50 in regions with complex dynamic processes, such as cell divisions. Availability: Source code freely available in the Software section atAutomated computational techniques are essential for the quantitative analysis of cellular dynamics using time-lapse light microscopy. For example, to quantitatively reconstruct the development of large multi-cellular organisms such as entire Drosophila and zebrafish embryos, tens of thousands of cells need to be segmented and tracked at high spatial resolution . Such analyses are of fundamental importance to understanding the development of biological tissues, to reconstructing functional defects in mutants and disease models and to quantitatively dissecting the mechanisms underlying the cellular building plan of entire complex organisms . However, many computational challenges are encountered when performing key tasks, such as image registration, cell segmentation and cell tracking, in complex microscopy datasets . Optical flow computation is one of the central tasks used to perform quantitative motion estimation of biological structures in time-lapse light microscopy, from the subcellular level to the tissue scale . Optical flow is defined as the vector field capturing the motion of brightness patterns between adjacent volumes in time (; since our examples are 3D images, we use the term volume to refer to the datasets used in optical flow computation. However, our approach and code work also for 2D images). On the cellular level, optical flow information can theoretically be obtained from single-cell tracking data. However, comprehensive and accurate cell tracking in complex multicellular organisms is currently an open research problem . Here, optical flow methods can be useful for analyses of group dynamics, which do not require single-cell resolution, or, conversely, as the first module in a larger cell tracking framework. In this latter scenario, the flow information informs the tracking algorithm and helps improving results for regions exhibiting complex or fast cell dynamics. Optical flow computation has been the object of decades of research, and it is considered a mature technology in many computer vision applications . However, most approaches have been tested in relatively small 2D natural images, which are dense and rich in edges and texture information. The Middlebury database used as a benchmark in the computer vision community is a good example of these types of images. Fluorescence microscopy volumes of biological structures are qualitatively very different from natural images . They are sparse (in datasets similar to, 8095 of voxels are background; throughout the text, we use the term voxel to generically refer to each intensity value in a dataset independent of the dimensionality of the data) and contain relatively textureless objects, which typically appear blurred To whom correspondence should be addressed. The Author 2012. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited. owing to the point spread function of the microscope and the characteristics of commonly used fluorescent labeling strategies. Moreover, neighboring objects with similar appearance and multiple motions in the same volume are very common. Finally, microscopy volumes tend to be much larger than natural images, which demands computationally efficient approaches. Here, we present a new algorithm for optical flow estimation tailored to large fluorescence light microscopy 3D time-lapse datasets as the one shown in. The key idea is to define a model that takes into account the specific characteristics of time-lapse microscopy data. In particular, we define a Markov random field (MRF) over super-voxels to improve registration in textureless areas, propagate motion information efficiently between neighboring structures and speed up computations by reducing the complexity of the problem.We evaluate our approach in scanned light-sheet microscopy datasets. Light-sheet microscopy provides exceptionally high imaging speeds while minimizing the energy load on thebiological specimen, and has thus emerged as an essential tool for life sciences. This combination of capabilities is invaluable for live imaging applications and enables quantitative imaging of cellular dynamics throughout the development of complex organisms such as entire Drosophila and zebrafish embryos (in the Supplementary Material). Light-sheet microscopes often produce terabytes of image data per specimen, which need to be analyzed with efficient computational approaches. We tested our approach in two different biological model systems using previously published datasets of Drosophila and zebrafish . Two videos are included in the Supplementary Material to show the complete results of the optical flow estimation and how it allows analyzing different motion patterns for different groups of cells. Each volume of the Drosophila dataset consists of 602 1386 110 voxels (179 MB in UINT16), and each pair of time points was processed in 3 min with our method (all Central Processing Unit (CPU) running times reported in this article were determined on a workstation with Intel Xeon X5690 CPU with 3.47 GHz clock rate). In total, we processed 50 time points (9 GB of data) following a cell division wave in early development. Each volume of the zebrafish dataset consists of 1064 1034 500 voxels (379 MB in UINT16), and each pair of time points was processed in 9 min with our method. In total, we processed 220 time points (83 GB of image data) to follow epiboly and the formation of the body axis. Additional evaluation of the proposed and baseline methods using synthetic data is provided in the Supplementary Material. We simulate fluorescent nuclei images with different types of motion (linear, cell division and Brownian), different signal-to-noise ratios, different cell densities and different photobleaching settings to show that our method is applicable to different types of fluorescence microscopy techniques and cell dynamics.We developed and tested a new model for optical flow tailored to microscopy volumes, in which a large fraction of the objects are textureless and similar in appearance. Moreover, the information in the volume tends to be sparse because many voxels do not contain any information and cellular dynamics can be very variable. A key idea in our approach is to generate a volume partition graph over the foreground voxels, and to perform optical flow directly on that model instead of computing it at the voxel level. This model is tailored to the specific characteristics of time-lapse light microscopy datasets, as it provides the regularization needed to solve optical flow robustly for these types of volumes. At the same time, our method reduces the complexity of the problem by an order of magnitude, which is an invaluable advantage when working with large 3D datasets. In Section 4.1, we showed that the method might fail in some extreme cases for $1 of the nuclei, when neighboring nuclei move in opposite directions. In those scenarios, we are left only with the data term to determine the correct flow. Thus, a possible future direction would be to use different features or point descriptors in the volume intensity to increase robustness of the data term . It is also possible to constrain the flow field to a diffeomorphism, as two objects cannot originate from the same source point. Finally, if a faster implementation is required, it is straightforward to parallelize the computation of the data term in Equation (3) for each super-voxel using GPU technology. At the moment, this operation takes $40 of the time for each function evaluation in the quasi-Newton method, and it is thus a primary candidate for code optimization. 
