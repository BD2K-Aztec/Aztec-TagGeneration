Data and text mining A linear programming model for protein inference problem in shotgun proteomics Motivation: Assembling peptides identified from tandem mass spectra into a list of proteins, referred to as protein inference, is an important issue in shotgun proteomics. The objective of protein inference is to find a subset of proteins that are truly present in the sample. Although many methods have been proposed for protein inference, several issues such as peptide degeneracy still remain unsolved. Results: In this article, we present a linear programming model for protein inference. In this model, we use a transformation of the joint probability that each peptide/protein pair is present in the sample as the variable. Then, both the peptide probability and protein probability can be expressed as a formula in terms of the linear combination of these variables. Based on this simple fact, the protein inference problem is formulated as an optimization problem: minimize the number of proteins with non-zero probabilities under the constraint that the difference between the calculated peptide probability and the peptide probability generated from peptide identification algorithms should be less than some threshold. This model addresses the peptide degeneracy issue by forcing some joint probability variables involving degenerate pep-tides to be zero in a rigorous manner. The corresponding inference algorithm is named as ProteinLP. We test the performance of ProteinLP on six datasets. Experimental results show that our method is competitive with the state-of-the-art protein inference algorithms. Availability: The source code of our algorithm is available at: https:// sourceforge.net/projects/prolp/.Protein identification using tandem mass spectrometry (MS/MS) is the most widely used tool for detecting proteins from biological samples. In a typical shotgun proteomics experiment , proteins in a sample are first digested into peptides, and the resulting mixture of peptides is subjected to mass spectrometry to generate tandem mass spectra. After spectra acquisition, the peptide that generates each spectrum is identified with peptide identification algorithms. From these putative peptide identifications, the proteins that are present in the sample are detected with protein inference algorithms. Computationally, the input for the protein inference problem is a bipartite graph: the left is a set of identified peptides and the right is the set of candidate proteins that have at least one constituent peptide. The inference problem considered here is to find a subset of proteins that are truly present in the sample. However, such protein inference problem is only partially solved since several technical challenges still remain unconquered. One of the most challenging problems is the peptide degeneracy issue, which arises when a single peptide can be mapped to multiple proteins. The performance of protein inference algorithms mainly depends on our capability of assigning these degenerate/shared peptides to proteins that really generate them. To date, there are already many protein inference algorithms available in the literature . The reader can refer to a recent survey for details. Here, we shall discuss briefly how these methods tackle the peptide degeneracy issue and present our research motivation. Existing protein inference algorithms solve the peptide degeneracy problem in quite different ways. Generally, they fall into two categories, as listed in the subsequent sections. Inference algorithms in the first category solve the peptide degeneracy problem with some simple rules or assumptions in an implicit manner. One typical example is the widely used two-peptide rule, which regards all candidate proteins that have at least two matching peptides as true positives (TPs). The underlying assumption is that degenerate peptides should belong to all proteins that they can match. In contrast, IDPicker formulates the protein inference problem as a set covering problem and solves it with a greedy algorithm. In the greedy selection procedure, proteins that can match the maximal number of uncovered peptides are selected in an iterative manner. The underlying assumption is that each degenerate peptide should be assigned to one protein only. Inference algorithms in the second category treat the peptide degeneracy issue explicitly in terms of conditional probability. Briefly, they either model the conditional probability of one protein being present given a peptide or model the conditional To whom correspondence should be addressed. probability of one peptide being present given a protein. ProteinProphet , one of the most widely used protein inference methods, learns degenerate peptide weight using an EM-like algorithm. In fact, such degenerate peptide weight corresponds to the probability of one protein being present conditional on the presence of a given peptide. Alternatively, MSBayesPro utilizes the concept of peptide detectability, which is defined as the probability of detecting a peptide in a standard sample by a standard proteomics routine if its parent protein is expressed. Fido models the probability with which a sample peptide is generated from a protein containing it with a constant probability. HSM considers five types of mechanisms that a peptide can be generated by a protein, i.e. the conditional probability that one peptide is present has five possible values. The attempts of treating the peptide degeneracy problem rigorously in the second category have obtained promising results; however, they still have some limitations. First, ProteinProphet employs an EM-like iterative procedure to estimate protein probabilities. This method is described procedurally rather than derived from a well-defined optimization model. In contrast, MSBayesPro, HSM and Fido derive their models from clear, explicitly stated statistical assumptions. However, they formulate the protein inference problem as a combinatorial optimization problem. This means that they may generate different inference results from the same dataset when obtaining the optimal solution is too time-consuming. Second, Fido and HSM use a very small set of parameters to approximate all possible values that the conditional probability can take. Such a simplification makes it possible to create efficient accompanying algorithms, but it may also limit the capability of achieving better inference performance. In contrast, there are no such limitations in ProteinProphet and MSBayesPro. Unfortunately, the conditional probabilities in ProteinProphet are calculated using a formula that has not been rigorously justified. The peptide detectability values in MSBayesPro are predicted using a complex model trained on other datasets. Finally, existing methods involve many parameters that are not easy to specify. For example, Fido needs to have a grid search in order to find good values for its three parameters. The aforementioned observations motivate our research. In this article, we take a step further toward completely solving the protein inference problem with particular emphasis on peptide degeneracy. To that end, we present a linear programming (LP) model for protein inference, which is built on two simple probability equations. We first introduce the joint probability that both a protein and its constituent peptide are present in the sample. To obtain a linear model, we use a mathematical transformation of this joint probability as the variable. The marginal probability of a peptide being present can be expressed as a formula in terms of the linear combination of these variables. If we assume that the marginal probability of each identified peptide being present is known, the protein inference problem could be formulated as the following optimization problem: minimize the number of proteins of non-zero probabilities while the calculated peptide probability should be as close to its known value as possible. We show that this optimization problem actually can be written as a LP problem, which has only one parameter that is easy to specify and has a clear interpretation. This new protein inference algorithm is named as ProteinLP. Experimental results on six datasets show that our ProteinLP algorithm is a competitive and complementary approach for protein inference. The main contributions of the work described in this article can be summarized as follows:To our knowledge, our work is the first LP formulation for the protein inference problem. Our method guarantees to find the optimal solution. Instead of using conditional probability, our model is the first attempt of addressing the peptide degeneracy problem with the joint probability. It greatly simplifies the model without sacrificing the discrimination power.The rest of this article is organized as follows. In Section 2, we describe our method in detail. Section 3 presents the experimental results and Section 4 concludes the article.We evaluate the performance of different methods by creating a curve, which plots the number of TPs as a function of q-value. An identified protein is labeled as a TP if it is present in the corresponding protein reference set or target protein sequence database1 is the joint probability that peptide i and protein j are both present in the sample. In the model, the linear program has two kinds of constraints: column constraints and row constraints. The row constraints require that for each peptide i, the difference between the observed peptide probability and the calculated peptide probability should be no greater than a threshold. The column constraints can shrink some protein probabilities to 0 and as a FP otherwise. Given a certain probability threshold t, suppose there are T t TPs and F t FPs, the false discovery rate (FDR) is estimated as FDR t F t =F t T t . The corresponding q-value is defined as the minimal FDR that a protein is reported: q t min t 0 t FDR t 0. The curve is produced by varying the probability threshold t. The probabilities of top-scoring proteins in the several methods are all equal to one, and the order of these proteins in the output file is random. Thus, we skip these proteins with same probabilities and start from the one with a different score when calculating the q-value.plots the number of TPs identified by four methods at different q-values. Some important observations are summarized as follows. First, none of these four methods can always achieve the best performance over all datasets. Throughout six datasets, our method is stable and never performs the worst. Globally,, Fido, ProteinProphet (PP) and MSBayesPro (MSB). Because people are particularly interested in the performance of different algorithms when the q-value or FDR is very small, we only plot the curve up to 0.05 along the x-axis for yeast, DME and HumanMD datasets. Fido has a minimum non-zero q-value of 0.08 on yeast dataset, which is40.05. To plot the curve of Fido within the slot of, we use the maximal number of TPs achieved at q-value 0.08 as the value of y-axis at q-value 0.05. Note that such an operation overestimates the actual performance of Fido on the yeast data. Since the maximum q-value for HumanEKC is 50.04, we choose 0.03 as the maximal value of x-axis. We cannot set the q-value range very small for 18 mixtures and Sigma49 datasets since the probabilities of top-scoring proteins in the several algorithms are all equal to one, hence we have to ship these proteins with same probabilities and then calculate the q-value of the first appearing protein with a different probability ProteinLP is approximately (or tied with other algorithms) the best inference algorithm on four datasets (yeast, DME, HumanMD and HumanEKC) and the second best on 18 mixture data. Locally, it beats ProteinProphet five times, outperforms both MSBayesPro and Fido four times. Second, ProteinLP has the largest number of TPs among the highest ranking proteins when q-value 0 (i.e. 0 FPs) on three datasets: DME, HumanMD and HumanEKC. Other three algorithms can also achieve such a property on some datasets. The number of these datasets is 1, 0 and 2 for ProteinProphet, MSBayesPro and Fido, respectively. Finally, the experimental results from simple 18 mixture to complex human data show the trend that ProteinLP is more powerful on processing the MS data generated from real samples. To compare the capability of different methods in tackling the peptide degeneracy issue, we present the identification results of four methods when inferring proteins containing a high-scoring degenerate peptide in. For each dataset, we count the number of TPs and FPs identified by ProteinProphet, MSBayesPro, Fido and ProteinLP with the same number of reported proteins. Then, we divide the identified proteins into two classes: degenerate proteins, which contain a high-scoring degenerate peptide and simple proteins which do not contain any such degenerate peptide. From, we have the following observations. First, ProteinProphet and ProteinLP can identify more degenerate proteins than MSBayesPro and Fido in most cases. This is because both ProteinProphet and ProteinLP tend to assign a degenerate peptide to the parent protein with more identified peptides. As a result, some degenerate proteins will have much higher probability than other proteins. In contrast, MSBayesPro and Fido do not have such a tendency. When we let different methods report the same number of proteins, ProteinProphet and ProteinLP will return more degenerate proteins since these proteins are ranked more front by these two methods. Second, MSBayesPro can always report the least number of FP degenerate proteins on 18 mixtures, Sigma49 and yeast at the cost of identifying less TP degenerate proteins. All four methods report zero FP degenerate proteins on HumanMD and HumanEKC datasets. Third, ProteinLP is able to identify more TP degenerate proteins than the other three methods on DME, HumanMD and HumanEKC datasets. Our method never reports the most FP degenerate proteins. Moreover, ProteinLP identifies the least number of FP degenerate proteins on DME dataset. Overall, MSBayesPro is more powerful in controlling the false discovery rate with respect to degenerate proteins, whereas our method offers a reasonable trade-off between TP and FP rates. Using the same set of identified proteins in, we also plot two groups of Venn diagrams to further check the overlap and difference among (degenerate) proteins identified by different inference algorithms in supplementary Figures S3 and S4. These figures show that the set of proteins identified from the same dataset by different methods can vary significantly. Moreover, ProteinLP can always report some additional (degenerate) proteins that have never been identified by the other three methods on all datasets except Sigma49. This fact further confirms that ProteinLP can serve as a strong and complementary approach for protein inference. ProteinLP requires only one parameter:. We choose 0 as the default setting. To test the effect of this parameter, we run ProteinLP over a rough grid of that ranges from 0 to 0.9. We omit parameter value of 1.0 since all the protein probabilities are zero under this parameter setting. We use the number of TPs at certain q-value threshold as the performance metric to assess the effect of different parameters. We choose 0.3 as the q-value threshold for 18 mixtures and Sigma49 and 0.01 for all the other four datasets, respectively. As shown in, the performance of our method is sensitive to different parameter specifications, and 0 is not the best choice. To address the parameter selection problem, we develop an entropy-based approach for setting a proper value automatically (see supplementary Section 2 for details).For the six datasets, we count the number of true positives and false positives identified by ProteinProphet (PP), MSBayesPro (MSB) and Fido and ProteinLP (PLP) among their top-k ranked proteins, where k is 31, 43, 538, 175, 124 and 196 for 18 mixtures, Sigma49, yeast, DME, HumanMD and HumanEKC datasets, respectively. The value of k is determined according to the number of proteins with probability of 1.0 reported by ProteinProphet. We divide the identified proteins into two classes: degenerate proteins are proteins that share a high-scoring (! 0:90) peptide with another protein and simple proteins do not share such a peptide with any other protein.To solve the peptide degeneracy problem, we need to know which protein really generates the degenerate/shared peptide. The most natural idea is to model or infer the conditional probability of one peptide (protein) being present given a protein (peptide). However, we may still need the protein probability as the variable in the mathematical formulation besides the conditional probability. This will lead to a hard optimization problem that cannot be optimally solved. In fact, the joint probability that both a protein and its constituent peptide are present in the sample can also provide similar discrimination information for assigning a degenerate peptide to the right protein. Therefore, the main advantage of ProteinLP over other methods is the use of joint probability as the variable, which avoids modeling the protein probability and the conditional probability simultaneously so that the optimization formulation is greatly simplified. In the future work, we plan to incorporate some supplementary information such as proteinprotein interactions into the LP model to help solving the degeneracy issue. For example, if we know that there is an interaction between two proteins, then it can be expected that the existence of one protein may lead to the presence of another protein. To utilize such interaction information, we can introduce a linear constraint on the probability difference between two interacting proteins to enforce their coexistence. 
