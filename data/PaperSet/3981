Sequence analysis Reptile: representative tiling for short read error correction Motivation: Error correction is critical to the success of next-generation sequencing applications, such as resequencing and de novo genome sequencing. It is especially important for high-throughput short-read sequencing, where reads are much shorter and more abundant, and errors more frequent than in traditional Sanger sequencing. Processing massive numbers of short reads with existing error correction methods is both compute and memory intensive, yet the results are far from satisfactory when applied to real datasets. Results: We present a novel approach, termed Reptile, for error correction in short-read data from next-generation sequencing. Reptile works with the spectrum of k-mers from the input reads, and corrects errors by simultaneously examining: (i) Hamming distance-based correction possibilities for potentially erroneous k-mers; and (ii) neighboring k-mers from the same read for correct contextual information. By not needing to store input data, Reptile has the favorable property that it can handle data that does not fit in main memory. In addition to sequence data, Reptile can make use of available quality score information. Our experiments show that Reptile outperforms previous methods in the percentage of errors removed from the data and the accuracy in true base assignment. In addition, a significant reduction in run time and memory usage have been achieved compared with previous methods, making it more practical for short-read error correction when sampling larger genomes. Availability: Reptile is implemented in C++ and is available through the link: http://aluru-sun.High-throughput sequencing is profoundly changing the way genetics data are collected, stored and processed . The advantages of the new technology have led to revitalization of old techniques and discovery of novel uses, with growing applications in resequencing, de novo genome assembly, metagenomics and beyond . New technology inevitably comes with challenges. For many next-generation sequencers, the advantage of deeper and cheaper To whom correspondence should be addressed. coverage comes at the cost of shorter reads with higher error rates compared with the Sanger sequencing they replace. Genome assembly, the de novo inference of a genome without the aid of a reference genome, is challenging. Sanger reads, typically 7001000 bp in length, are long enough for overlaps to be reliable indicators of genomic co-location, which are used in the overlap-layout-consensus approach for genome assembly. However, this approach does poorly with the much shorter reads of many next-generation sequencing platforms (e.g. 35100 bp for Illumina Genome Analyzer II). In this context, de Bruijn graph and string graph based formulations that reconstruct the genome as a path in a graph perform better due to their more global analysis and ability to naturally accommodate paired read information. As a result, they have become de facto models for building short-read genome assemblers, e.g. ALLPATHS , Velvet , ABySS and Yaga . Error correction has long been recognized as a critical and difficult part of these graph-based assemblers. It also has significant impact in other next-generation sequencing applications such as resequencing. We give a brief review of several well-known error correction methods. Alignment-based error correction methods, such as MisEd for Sanger reads, require refined multiple read alignments and assume unusually isolated bases to be read errors. Like the Sanger-motivated assembly algorithms, these approaches do not adapt well to short reads. Hence,proposed the spectral alignment problem (SAP): in a given dataset, a kmer is considered solid if its multiplicity exceeds a threshold, and insolid otherwise. Reads containing insolid kmers are corrected using a minimum number of edit operations so that they contain only solid kmers post-correction. Similar approaches have been adapted and used by others . To overcome the typically long run times of SAP-based approaches,proposed SHREC, a method based on a generalized suffix tree constructed from short-read data using both forward and reverse complementary strands. SHREC compares the multiplicity of a substring, represented by a node in the suffix tree, with its expected frequency of occurrence calculated analytically, assuming uniform sampling of the genome and uniformly distributed sequencing errors. The nodes with observed counts that deviate beyond a tolerable threshold from their expected values are considered erroneous. An erroneous node is corrected to a sibling when applicable, and all its descendants are transferred to the selected sibling. Well-engineered code is necessary to cope with the largePage: 2527 25262533We evaluated Reptile on several Illumina/Solexa datasets and compared the results with SHREC version 2.0, a recent high-quality short-read error correction method that is itself shown to give superior results over prior k-spectrum approaches. We omitted evaluation on simulated data because simulations with random errors or synthetic genomes do not accurately reflect actual short-read sequencing errors , and could even be misleading. Our test datasets are Illuminagenerated short reads of well-characterized, Sanger assembled bacterial genomes. Knowledge of the genomes is needed for determining the accuracy of the error correction methods. The six experimental datasets, downloaded from the sequence read archive at NCBI, are listed in. Datasets D1 (Accession Number: SRX000429), D2 (SRR001665_1), D5 (SRR022918_1) and D6 (SRR034509_1) are Illumina reads from the E.coli str. K-12 substr (NC_000913) genome (4.64 Mbp); datasets D3 (SRR006332) and D4 are Illumina reads from the Acinetobacter sp. ADP1 (NC_005966) genome (3.6 Mb). The first four datasets are generated by Solexa 1G Genome Analyzer, where each read has the same length 36 bp. The latter two datasets are generated using the more recent Illumina Genome Analyzer II, with read lengths of 47 bp in D5 and 101 bp in D6. D1 has high coverage and low error rate. D2 has typical coverage and low error rate. D3 has high coverage and high error rate. D4 is derived from D3 by randomly selecting short reads amounting to 40 coverage. This is done for evaluating performance on a low coverage, high error rate dataset. Both D5 and D6 have higher error rates. In addition, 13.9 of the reads in D6 contain ambiguous nucleotides, denoted by character N. Since SHREC cannot process non-ACGT characters, we eliminated all reads with ambiguous bases, even though Reptile has no such limitation. The number of discarded reads is indicated in column 5,. Similar to, we evaluated error correction results with the aid of RMAP (v2.05) , which maps short reads to a known genome by minimizing mismatches. We allowed up to five mismatches per read in the first four datasets Page: 2531 25262533Error rate is estimated by mapping the reads to the corresponding genome using RMAP, and finding mismatches based on uniquely mapped reads.and allowed up to 10 mismatches (default value of RMAP) in D5 and fifteen mismatches in D6 since the reads are longer in the latter two datasets. Reads that could not be mapped to the genome, or that map to multiple locations, are discarded. The mismatches between uniquely mapped reads and the genome are considered read errors. Quality of the datasets varied as shown in, with the percentage of reads that are uniquely mapped ranging from 62.5 to 96.7. The large percentage of unmappable reads, the higher error rates as well as the large percentage of reads with ambiguous bases indicate that D5 and D6 have lower quality than D1 to D4. Since the goal of error correction is to identify and correct each erroneous nucleotide, we assess the quality of error correction at the base level. A true positive (TP) is any erroneous base that is changed to the true base, a false positive (FP) is any true base changed wrongly, a true negative (TN) is any true base left unchanged, and a false negative (FN) is any erroneous base left unchanged. Then Sensitivity = TP/(TP + FN) and Specificity = TN/(TN + FP). Note that these definitions are different from those used by, which target read-level error detection (whether a read is flagged as containing an error or not). This is a less stringent measure because any read containing errors was classified as TP provided at least one of its errors was detected and irrespective of whether they were accurately corrected or not. We propose two additional measures for assessing the quality of error correction: @BULLET Erroneous base assignment (EBA): let n e denote the number of erroneous bases that are correctly identified but changed to a wrong base. Then, EBA = n e /(TP+n e ) reflects how well we are able to correct an erroneous base to the true base after a sequencing error has been identified. A lower value of EBA indicates a more accurate base assignment. @BULLET Gain: (TP FP)/(TP + FN). This measures the percentage of errors effectively removed from the dataset, which is equivalent to the number of errors before correction minus the number of errors after correction divided by the number of errors before correction. Clearly, Gain should approach one for the best methods, but may be negative for methods that actually introduce more errors than they correct.The proposed error correction algorithm is conservative because it avoids changing bases unless there is a compelling underrepresentation of a tile compared with its d-mutant tiles. Actual errors in read r cannot be corrected if r occurs in a very low coverage region of the genome or there exist multiple candidate d-mutant tiles, probably because of genome repetition. On the other hand, a tile may be miscorrected if it contains a minor variant of a highly repetitive element in the genome or it traverses a low coverage region that is similar to other regions with normal coverage. Our method is not unique in being challenged by non-uniform coverage on repetitive genomes. Error correction for highly repetitive genomes is essential for successfully assembling larger eukaryotic genomes but none of the existing methods successfully addresses this problem, including Reptile. Short-read mapping provides a reasonable method to evaluate error correction methods in well-assembled, low repetition genomes. Nevertheless, it is not possible to unambiguously determine all errors. There are natural polymorphisms among bacterial lines, and some presumed polymorphisms may be unrecognized assembly errors. Furthermore, the mapping software chooses among alternative mappings by invoking parsimony, but there is some chance that the true number of errors is less than the minimum. Lastly, mapping software cannot map reads that contain more than a constant number of substitutions, typically just two, with full sensitivity, although we considered 5 here and tested as many as 15 with similar results. Despite these limitations, we believe that most errors are correctly identified, and this approach can provide a fair comparison of error correction methods. We and others have found that sequence quality scores provide valuable information. Our use of quality scores probably helped us account for the error patterns in nextgeneration sequencing data without explicitly modeling them. However, it has been observed that high quality scores may be too optimistic and low quality scores too pessimistic in estimating sequencing errors in Solexa data. Since quality scores may not be precise measures of misread probabilities, the current version of Reptile uses quality score information in a very simple manner, but can be modified to make more sophisticated use of quality scores if warranted. Finally, although quality scores are needed to run Reptile, it can be run effectively without scores by setting all quality scores and the threshold Q c to the same value. There remain several additional challenges in next-generation sequencing error correction. One challenge is to distinguish errors from polymorphisms, for example, single nucleotide polymorphisms (SNPs). Reptile could accommodate SNP prediction with modification in the tile correction stage (Algorithm 1), where ambiguities may indicate polymorphisms. Another challenge is the growing read length of upcoming high-throughput sequencers. Currently, we define tiles as concatenations of two kmers. it might prove useful to extend the tile definition to more than two kmers in order to address error correction in much longer reads. 
