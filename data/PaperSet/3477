Structural bioinformatics PconsD: ultra rapid, accurate model quality assessment for protein structure prediction Clustering methods are often needed for accurately assessing the quality of modeled protein structures. Recent blind evaluation of quality assessment methods in CASP10 showed that there is little difference between many different methods as far as ranking models and selecting best model are concerned. When comparing many models, the computational cost of the model comparison can become significant. Here, we present PconsD, a fast, stream-computing method for distance-driven model quality assessment that runs on consumer hardware. PconsD is at least one order of magnitude faster than other methods of comparable accuracy. Availability: The source code for PconsD is freely available atPredicting the 3D structure of protein from its sequence remains one of the yet unsolved problems of molecular biology. Recent improvements in the field allow for constructing more accurate models of protein structures, be it through relying on homologous structures, folding proteins ab initio or by combining multiple approaches. Regardless of the approach chosen, there is a need for a method of discriminating good (native-like) models from the mispredicted ones. This is the role of Model Quality Assessment Programs (MQAPs). The most successful approaches to MQAP problem is the use of clustering methods, as introduced by the Pcons method in CASP5 . They are based on the premise that among different models of the same protein, the one that is most similar to the others is most likely to be correct. It is widely assumed that if a sufficiently accurate model generation method is used, most of the predictions will tend to cluster near the correct fold . Consequently, the largest cluster of protein models is most likely to contain models of native-like fold, and cluster centroid is the most likely candidate for the most accurate structure in the ensemble. Most of clustering-based MQAPs rely on repeated pairwise structural superposition to find a largest subset of residues superimposable between models in question within a certain threshold. This approach is a computationally relatively expensive process, which renders clustering approaches unfeasible for model ensembles larger than some thousand proteins. An alternative to rigid superposition is comparing the inter-residue distance matrices of the models. This approach has been successfully used for quality assessment, both in terms of similarity of predictions to the native structure and predicting the quality of models . Authors postulate that this approach is capable of capturing the interactions relevant for protein structure better than rigid C superposition, as it accounts both for the local proximity of relevant residues (distances close to each other in the sequence space) and the general fold of the protein (long-range distances). Although avoiding the computational expense of repeated superposition, distance matrix comparison still requires 0:5 m n 2 operations for computing the distances and 0:25 m 2 n 2 operations for their comparison, when given m models of n residues each. In this work, we introduce PconsD, a new model quality assessment program, which uses a massively parallel, OpenCLbased streaming approach, which attempts to alleviate the scaling issues and provide an efficient platform for future development in distance-driven quality assessment.PconsD has been blindly benchmarked in model quality assessment category of CASP10 experiment. According to CASP assessors, PconsD is at least as good a model classifier as other clustering MQAP methods and comparable with compound methods [methods combining multiple approaches to quality assessment, such as Pcomb , ModFoldclust2 , MUFOLD-QA (, both as far as distinguishing good models from bad ones, and as far as selecting best model in the ensemble are concerned, see. PconsD selected more good models (with less than two GDT-TS points loss to the best model in the ensemble) than Pcons (one of state-of-art clustering methods) or Pcomb (the best MQAP in CASP10 in terms of picking best models). It also picked fewer poor models than Pcons (410 GDTTS points loss to the best model in ensemble). The slightly worse performance in terms of average GDT-TS is due to prediction targets on which clustering did not work sufficiently well (i.e. difficult, free-modeling targets). PconsD seemed to be slightly less suitable for ranking models, when considering the Pearson correlation coefficient with superposition-based metrics, such as GDT-TS, but it still performs better in this category than MUFOLD-QA. The main strength of PconsD lies in its outstandingly short prediction time. The prediction performance and scaling have been assessed on a set of up to 250 000 models (55 GB of PDB files) of PTS EIIA type-2 domain from Escherichia coli (pdbid: 1a3a:A), produced by ab initio folding protocol implemented by ROSETTA . The benchmark results show that PconsD for non-trivial task sizes is at least an order of magnitude faster than Pcons, which is already almost two orders of magnitude faster than the navenave clustering using TM-score, thanks to aggressive optimization ,. PconsD scales linearly with the amount of models, until it needs to perform problem domain partitioning, on which moment it starts scaling quadratically. On the Nvidia GTX 560 used for testing PconsD, the running time with 10 8 contacts (5000 models of 143 residues each, 1000 of 300 residues and so forth) is 51 min. 
