Gene expression Estimating classification probabilities in high-dimensional diagnostic studies Motivation: Classification algorithms for high-dimensional biological data like gene expression profiles or metabolomic fingerprints are typically evaluated by the number of misclassifications across a test dataset. However, to judge the classification of a single case in the context of clinical diagnosis, we need to assess the uncertainties associated with that individual case rather than the average accuracy across many cases. Reliability of individual classifications can be expressed in terms of class probabilities. While classification algorithms are a well-developed area of research, the estimation of class probabilities is considerably less progressed in biology, with only a few classification algorithms that provide estimated class probabilities. Results: We compared several probability estimators in the context of classification of metabolomics profiles. Evaluation criteria included sparseness biases, calibration of the estimator, the variance of the estimator and its performance in identifying highly reliable classifications. We observed that several of them display artifacts that compromise their use in practice. Classification probabilities based on a combination of local cross-validation error rates and monotone regression prove superior in metabolomic profiling. Availability: The source code written in R is freely available atDiagnosis, prognosis and prediction of treatment response based on transcriptomic, proteomic or metabolomic profiles is a well developed field . A plethora of classification algorithms have been proposed and critically compared . It very much depends on the classification problem at hand, whether an almost error-free classifier can be developed or whether classification errors are unavoidable regardless of what algorithm is chosen. In the latter case, it is natural that a clinician asks for the reliability of an individual diagnosis before moving on to treatment decisions. Classification algorithms are typically evaluated by the frequency of misclassifications in cross-validation or on an independent test set. These performances are averages over many predicted cases. They say little about the reliability of an individuals diagnosis. The case To whom correspondence should be addressed. might be easier or more difficult to diagnose than the average in the test set. For each case, every class is assigned a value p j , which is an estimated probability that the case belongs to that class, given the profiling data. In microarray-based classification, the performance of classification algorithms has been analyzed and compared in great detail . However, little attention has been given to the usefulness of probability estimates and this is even more true for metabolomic analyses. In fact, only relatively few classification algorithms estimate class probabilities and in the majority of clinical papers on the performance of classifiers, case-specific probabilities are not shown. A class probability estimator is most useful, if it flags incorrect classifications as low confidence classifications. In other words: if a classifier produces confident class probabilities close to one, these should be correct classifications. In this article, we compare class probability estimators in the context of high-dimensional data-based diagnosis. We briefly review a selection of class probability estimators including those that are most frequently used in the context of gene expression analysis like Naive Bayes estimators or binary regression. In addition, we discuss alternative approaches from different fields of application like text categorization and digit recognition and adapt them to metabolomics analysis. We complement the pool of methods by a novel approach based on smooth local error rates. The approaches are compared on a recently published metabolomics dataset of patients with various types of kidney disease. We found that artifacts can compromise the utility of some frequently used methods. A widely observed problem is the dependence of classification probabilities on the number of features used in a diagnostic signature. The more features are used by a classifier, the more confident the classification probabilities, even in cases where the classification is incorrect. Moreover, class probabilities need to be estimated from test data or cross-validated classification scores since training scores display a better but unrealistic separation of classes. This overfitting phenomenon can greatly affect class probabilities. In our comparative metabolomics study, class probabilities derived from local error rates proved to be the method of choice.We compared the class probability estimators in the context of a recently published metabolomic profiling study on kidney diseases . The dataset comprised 168 urine samples measured using 1D nuclear magnetic resonance (NMR) spectroscopy. 54 samples were obtained from patients with autosomal polycystic kidney disease. The challenge is to separate them from samples taken from healthy volunteersfrom patients 3 months after renal transplantation). More details on the composition of cases in the study can be found in. NMR 1D spectra were split into 701 equally sized buckets and globally normalized to the signal of the CH 2 group of creatinine to ensure sample to sample comparability. Furthermore, compatibility across metabolites was ensured by applying the glog transformation . For full details of sample preparation and data preprocessing see. We learned a shrunken centroid classifier aiming at the separation of ADPKD patients and healthy controls. Across all patients, we observe a classification performance of 76 correct classification in cross-validation.resolves this classification performance further. The ticks on the x-axis show the cross-validated classification scores s(x j ) from ADPKD patients (top) and healthy donors (bottom). In line with the global performance of only 76, one can observe that there is no perfect separation of the two groups. Scores between 0.96 and +0.86 can be observed in both classes. The separating hyperplane lies in the middle of these points. It assigns 41 of them to the ADPKD class and 40 to the healthy donor class. Confined to this range of scores, the classifier has a performance of 71 correct classifications. These diagnoses should be flagged unreliable. However, scores 0.86 are only found among ADPKD patients and hence reliably indicate that a patient suffers from ADPKD. Identifying this group of patients boils down to estimating ADPKD probabilities for all patients. The y-axis exemplarily shows such estimates obtained using a local error frequency approach. All patients with a score 0.93 receive probabilities close to one indicating their reliable classification as ADPKD positives. Patients with scores between 0.97 and +0.22 obtain probabilities between 0.2 and 0.8 flagging them as problematic classifications. We next compare the six CPF estimators, Naive Bayes (NB), Compound Bayes (CB), binary regression (BReg) and the local error frequency methods (LEF(Bin), LEF(Smooth), LEF(Adapt)), with respect to several criteria including modification of classification performance, sparseness bias, calibration and the performance in identifying reliable classifications. 
