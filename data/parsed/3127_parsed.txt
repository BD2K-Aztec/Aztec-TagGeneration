ms reduce an ultrafast technique for reduction of big mass_spectrometry data for high_throughput processing motivation modern proteomics_studies utilize high_throughput mass_spectrometers which can produce data at an astonishing rate these big mass_spectrometry ms datasets can easily reach peta scale level creating storage and analytic problems for large_scale systems_biology studies each spectrum consists of thousands of peaks which have to be processed to deduce the peptide however only a small percentage of peaks in a spectrum are useful for peptide deduction as most of the peaks are either noise or not useful for a given spectrum this redundant processing of non useful peaks is a bottleneck for streaming high_throughput processing of big ms data one way to reduce the amount of computation required in a high_throughput environment is to eliminate non useful peaks existing noise removing algorithms are limited in their data reduction capability and are compute intensive making them unsuitable for big_data and high_throughput environments in this paper we introduce a novel low complexity technique based on classification quantization and sampling of ms peaks results we present a novel data reductive strategy for analysis of big ms data our algorithm called ms reduce is capable of eliminating noisy peaks as well as peaks that do not contribute to peptide deduction before any peptide deduction is attempted our experiments have shown up to speed up over existing state of the art noise elimination algorithms while maintaining comparable high_quality matches using our approach we were able to process a million spectra in just under an hour on a moderate server availability_and the developed tool and strategy has been made available to wider proteomics and parallel_computing community and the code can be found at https github com pcdslab msreducemass spectrometry ms is an analytical_chemistry technique which is used for determining the type and amount of constituents of a mixture ms has found its application in the field of biomedical_research among all the applications of ms in biology and medicine protein identification and quantization has proved to be the most widely used ms based proteomics is very frequently used for profiling of exosomes toxicological screening k evolutionary_biology and numerous other applications wide_variety of computational_techniques such as estimation of false_positive protein quantification from large_datasets phosphopeptide filtering phosphorylation_site assignments spectrum to peptide matching and denovo peptide_identification are required to make this ms data useful with the introduction of modern mass_spectrometers such as thermo orbitrap thousands of spectra can be generated in just a single run of experiment an ms spectrum consists of mass to charge ratio and associated intensities for each peak depicting their abundance in the sample under consideration on an average total number of peaks for one spectrum may range up to and for k human proteins the number of distinct peaks that need to be compared is close to million assuming that there is no redundancy this number is just for a single human_proteome and with projects like peptide atlas the number of distinct human observations are close to which makes the total number of peaks equal to note that this number does not include other species distinct experimental_conditions or novel post_translational which exponentially increases the number of peaks that needs to be processed the current computational_analysis techniques have not been designed for such massive datasets the current peptide_identification techniques e g assume that each peak that is encountered is useful in making peptide deductions this leads to processing much more number of peaks than are necessary to make a peptide deduction the processing of peaks that are noise and or do not contribute in deduction of peptides makes the processing of these large_datasets time consuming we assert that in order to process big ms data we should be able to eliminate noisy peaks and the peaks that do not contribute to peptide deduction before an in depth analysis of the spectra this will clearly result in faster processing of the ms_ms and will save overhead for peptide searches by reducing the number of peaks to be analyzed only processing the peaks that are useful rather than performing intensive per peakcomputations will result in tremendous time and space advantages to the best of authors knowledge there is no algorithm available which can perform the noise removal function without performing an in depth analysis on spectra further we are not aware of any procedure that can eliminate non noisy and yet non essential peaks that do not contribute to peptide deduction in this paper we introduce a novel algorithm called msreduce for ultrafast reduction of ms_ms data in pre_processing stage the proposed algorithm is a low complexity procedure based on random_sampling approximate classification and quantization making it highly scalable with increasing number of spectra further user_defined reduction ratio makes it suitable for a variety and sizes of ms datasets our experiments show peptide deduction accuracy of up to with reduction in the data size of up to our results also indicate that we are able to process spectra in under h on a sequential machine making it highly_efficient for big datasets comparable reduction tools took over days for the same dataset on a similar machine analysis of high_throughput ms based proteomics_data is an essential task in systems_biology data from multiple experiments can scale from million to a billion spectra and this data volume can easily reach tera to peta byte level the big_data from modern mass_spectrometers creates scaling problems for existing software_designed for much smaller datasets although these algorithms are useful for interpretation of simple spectra the search and match routine becomes computationally_intractable for complex peptides the big_data volume that one gets from these high_throughput machines is enormous and low scalability of conventional tools cannot keep up with the rate of data generation hence dimensionality_reduction techniques that can reduce the number of peaks that needs to be processed are essential for fast and efficient processing of ms data for system wide studies in this paper we presented a novel dimensionality_reduction technique called ms reduce for pre_processing big ms datasets to our knowledge the proposed_strategy is first attempt at data reduction of ms data for high_throughput environments our low_computational strategy is based on classification quantization and sampling of ms data peaks an approximate classification of spectra followed by a quantization step results in binning of peaks each quantum of a spectrum contains peaks within a particular intensity range then a random_sampling step is performed on these bins to obtain the peaks which form the final reduced spectrum our strategy is linear in time complexity with increasing number of spectra which is confirmed by our experiments we also show that msreduce can process up to a million spectra in min as compared to the de_noising algorithm which processes the same number of spectra in about days we performed rigorous testing of the algorithm using experimental_datasets and compared its performance with two of the existing algorithms the implemented software will be available for free academic use at the authors webpages 
