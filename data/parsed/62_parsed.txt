ace adaptive cluster expansion for maximum_entropy graphical_model inference downloaded from motivation graphical_models are often employed to interpret patterns of correlations observed in data through a network of interactions between the variables recently ising potts models also known as markov_random have been productively applied to diverse problems in biology including the prediction of structural contacts from protein sequence_data and the description of neural_activity patterns however inference of such models is a challenging computational_problem that cannot be solved exactly here we describe the adaptive cluster expansion ace method to quickly and accurately infer ising or potts models based on correlation data ace avoids overfit ting by constructing a sparse network of interactions sufficient to reproduce the observed correlation data within the statistical error expected due to finite sampling when convergence of the ace algorithm is slow we combine it with a boltzmann machine_learning algorithm bml we illustrate this method on a variety of biological and artificial datasets and compare it to state of the art approximate_methods such as gaussian and pseudo likelihood inference results we show that ace accurately reproduces the true parameters of the underlying model when they are known and yields accurate statistical descriptions of both biological and artificial data models inferred by ace more accurately describe the statistics of the data including both the constrained low order correlations and unconstrained higher_order correlations compared to those obtained by faster gaussian and pseudo likelihood methods these alternative_approaches can recover the structure of the interaction_network but typically not the correct strength of interactions resulting in less accurate generative_models availability_and the ace source_code user_manual and tutorials with the example data and filtered correlations described herein are freely_available on github at https interpreting patterns of correlations in data is a fundamental problem across scientific_disciplines a common approach to this problem is to infer a simple graphical_model that explains the statistics of the data through a network of effective interactions between the variables which may then be used to generate new predictions the goal of this approach is to disentangle the direct_interactions between variables from their correlations which arise through a combination of direct and indirect_effects here we focus on a particular family of undirected graphical_models referred to as potts models in the language of statistical physics which have recently been applied to study a wide_variety of biological_systems applications include inference of the effective_connectivity of populations of neurons and their patterns of firing_activity based on data from multi electrode recordings and the prediction of protein contact residues and the fitness_effects of mutations based on the analysis of multiple_sequence msas unfortunately the inference of potts models from data is challenging the computational time required for naive potts inference algorithms scales exponentially with the system size rendering the problem intractable for realistic systems of interest various approximations have been employed to combat this problem including gaussian and mean field inference perturbative expansions and pseudo likelihood methods these approximate_methods can successfully capture the general structure of the network of interactions recovering in particular contact residues in the threedimensional structure of protein_families but the resulting models typically give a less accurate statistical description of the data alternately algorithms based on iterative rounds of monte_carlo are capable of inferring models that accurately reproduce the observed correlations but they are typically slow to converge here we describe an extension of the adaptive cluster expansion ace method originally devised for binary ising variables to more general potts variables taking multiple categorical values we also describe new computational_methods for faster inference including a monte_carlo learning procedure and the optional incorporation of prior_knowledge about the structure of the interaction graph the algorithm has been successfully_applied to real_data with as many as several hundred variables including studies of neural_activity in the retina and prefrontal_cortex human_immunodeficiency hiv fitness based on protein msa data and lattice protein models below we illustrate the application of this method to both real and artificial datasets we show that models inferred by ace give an excellent reconstruction of the statistics of the data they also accurately recover considering sampling limitations true underlying model_parameters when they are known and can achieve comparable_performance to state of the art methods for predicting structural contacts in protein_family data we compare these results to those obtained using other approximate inference methods focusing in particular on pseudolikelihood methods potts models have been successfully_applied to study a variety of biological_systems however the computational difficulty of the inverse potts problem i e the inference of a potts model from correlation data has presented a barrier to their use here we presented ace a flexible easy to use method for solving the inverse potts problem which can be applied to analyze a wide_variety of real and synthetic data we also provide tools for automatically generating correlation data from multiple_sequence msa making the analysis of this type of data even more accessible here we have adapted the complexity of the inferred potts models to the level of the sampling in the data this is achieved by regrouping less frequently observed potts states into a unique state according to a threshold on entropy or frequency then by a sparse inference procedure that omits interactions that are unnecessary for reproducing the statistics of the data to within the error bounds due to finite sampling on artificial data we verified that compression of the number of potts states allows for a faster and more precise inference of the uncompressed model_parameters while reducing overfitting the methods of compression that we describe here can also be applied to other inference methods including for example the dca and plmdca approaches discussed above a topic of future study in addition as described above ace yields sparser models when sampling is poor leading to more robust inference this method allows for the simple construction of models from various types of data which can then be used to predict the evolution of experimental_systems and their response to perturbations previous work has demonstrated promising applications of such models in a variety of different biological_contexts in neuroscience the analysis of multi electrode recordings has led to models that identify cell assemblies which are thought of as basic units of neural computation and memory here we show the top predicted contacts with true predictions in orange and false predictions in blue other contact residues in the crystal_structure are shown in gray for true_positives and other contact residues close contacts are darkly shaded and further contacts are lightly shaded the upper and lower triangular parts of the contact_map give predictions for the inferred model with strong regularization no compression c and weak regularization high compression c b respectively b precision number of true predictions divided by the total number of predictions as a function of the number of contact predictions for close contact residues that are widely separated on the protein_backbone i j results using ace compare favorably with those from dca and are competitive with those from plmdca 
