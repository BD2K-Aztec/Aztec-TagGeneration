structural_bioinformatics protein fold_recognition using geometric kernel data fusion motivation various approaches based on features extracted from protein_sequences and often machine_learning have been used in the prediction of protein_folds finding an efficient technique for integrating these different protein features has_received in particular kernel methods are an interesting class of techniques for integrating heterogeneous data various methods have been proposed to fuse multiple kernels most techniques for multiple_kernel focus on learning a convex linear combination of base kernels in addition to the limitation of linear_combinations working with such approaches could cause a loss of potentially useful information results we design several techniques to combine kernel matrices by taking more involved geometry inspired means of these matrices instead of convex linear_combinations we consider various sequence_based protein features including information extracted directly from position_specific and local sequence_alignment we evaluate our methods for classification on the scop pdb d benchmark_dataset for protein fold_recognition the best overall accuracy on the protein fold_recognition test_set obtained by our methods is this is an improvement over the results of the best existing approach moreover our computational_model has been developed by incorporating the functional domain_composition of proteins through a hybridization model it is observed that by using our proposed hybridization model the protein fold recognition_accuracy is further improved to furthermore we investigate the performance of our approach on the protein_remote problem by fusing multiple string kernels availability_and the matlab_code used for our proposed geometric kernel fusion frameworks are publicly_available atknowledge on functions of proteins can be provided by information about their tertiary_structure hence determining this structure is among the most essential objectives in molecular_biology cell_biology proteomics and bioinformatics structural_information also provides a much better understanding of proteinprotein_interaction furthermore this information is potentially useful for drug_design studies unfortunately experimentally identifying the d structure of proteins is expensive_and by contrast recent development in genome_sequencing has tremendously increased the number of protein_coding because there is much slower growth in information on d structure there is an increasing gap between the protein_sequence and protein_structure information despite these problems knowledge about protein_folds can be useful in determining its structural_properties because of the limitation of homology modelling_methods when there is no sequence_similarity to homologous_proteins of known structure the taxonomic approach is usually considered as a trustworthy alternative this approach is based on the assumption that the number of protein domain folds is restricted promising results are reported using taxonomic approaches but they are still far from tackling the classification of protein_folds completely so fold_recognition or protein threading is still among the most challenging tasks in bioinformatics in many bioinformatics tasks it is worthwhile to consider several representations of the data which will not always be vectors in particular we should be able to deal with them using the same algorithm regardless whether they are represented as binary vectors real vectors on different scales sequences graph data etc various approaches based on features extracted from protein_sequence and often machine_learning have been used to tackle the fold_recognition problem several informative fold data_sources can be constructed based on various representative models of protein features pfs such as primary structural_information local pairwise_sequence based feature spaces physicochemical_properties of constituent amino_acids and sequence_evolution information more attention needs to be paid to finding an efficient and cost_effective technique for integrating these different discriminatory data_sources for protein fold classification nevertheless to deal with biological data there are not only a lot of issues in machine_learning but also a lot of difficulties in data analysis full integration and decision integration are common techniques for fusing protein fold data_sources in particular full integration is a fast and easy way to fuse data_sources however because of heterogeneity of the to whom correspondence should be addressed the author published_by this is an open_access the terms of the creative_commons http creativecommons org_licenses which permits non commercial re use distribution and reproduction in any medium provided the original_work for commercial re use please_contact permissions_oup com biological data combining data_sources at the data level is not always feasible in practice by contrast fusing data_sources at decision level such as in the ensemble learning framework is considered as an intuitive manner to deal with heterogeneous data various decision based integration approaches have been proposed for protein fold classification in addition to limitations of using ad_hoc ensemble learning the computational_cost of decision based_approaches increases corresponding to the number of data_sources the heterogeneous_biological data_sources can also be integrated intelligently using partial integration such as kernelbased data fusion using kernel methods is an elegant and versatile strategy because it decouples the original data from the machine_learning by using a representation of the data as a kernel_matrix the main idea behind kernel methods is rather than using original data directly to use only a kernel_matrix symmetric positive definite spd kernel matrices are the non linear extension of covariance correlation matrices and encode the similarity between samples in their respective input space this implies that the heterogeneous data binary vectors real vectors on different scales graph data can all be replaced by appropriately scaled kernel matrices which all have the same size and thus that the data heterogeneity disappears then other algorithms such as classification clustering and prioritization can access the same data which is currently not possible constructing the same representation for all datasets and integrating these representations systematically is the main intuition behind kernel fusion methods in the simplest scenario we can compute kernel matrices separately for each data source and then average them together the standard approach for combining kernel matrices is to take the weighted arithmetic average there are several methods for obtaining a valid and fitting kernel by tuning the kernel matrices weights gonen finding such weights from training data and replacing the single kernel by a linear combination of weighted base kernels is usually referred to as multiple_kernel mkl these weights can also be interpreted as their corresponding importance in the fused kernel during the past_decades several mkl methods have been proposed in the literature and are shown to yield good results in various applications in particular in bioinformatics applications most of these approaches try to learn a linear combination of base kernels which can be interpreted as the concatenation of the base kernel feature_space or an or combination of the individual kernels the kernel integration problem is often reduced to a convex_optimization in addition to the limitation of linear_combinations solving this optimization_problem is only possible for a small number of kernels and small number of data_points furthermore because this type of averaging is often sensitive to deal with complementary and noisy kernels it is not appropriate for biological data in fact going with such approaches could cause a loss of potentially useful latent information in the data recent biological_applications have demonstrated that even using uniformly weighted kernel integration can boost the generalization capability of the decision function by contrast the results obtained by using such averaging of the kernel matrices are comparable with the results of the best existing mkl approaches in general applications hence using the uniformly weighted_average of the base kernels can be considered as a reliable and computationally more scalable alternative uniformly weighted kernel integration can also be considered as the arithmetic mean am of kernel matrices which is always a generator of a valid mercer kernel similar to the am other types of means of spd matrices such as the harmonic mean hm log euclidean mean logem and geometric mean gm result in spd kernels in this study we propose and develop several new techniques that combine the mercer kernel matrices through other types of averaging than convex linear combination such averaging of the base kernels can be interpreted as a kind of fusion that expresses the non linear relationship between the individual kernels in particular we focus on taking the matrix gm of base kernels however computing the gm of a general number of spd matrices is a challenge in fact for a general number of spd matrices a proper definition of a gm with some natural properties has only recently been developed we present two methods for computing the gm the first approach is focused on computing the actual gm using the definition of the karcher mean the second however only computes a rough approximation of the actual gm using a proposed heuristic_method based on arithmetic geometric harmonic agh mean we show in the second section that it is a computationally scalable method for computing an approximate gm we also consider the behaviour of combining kernels by taking hm and log em where this last one can be seen as a consensus between the am and gm moreover our computational_model has been developed by incorporating the functional_domain information through the hybridization model experimental_results on the scop pdb d benchmark_dataset demonstrate that our integration technique can effectively improve the accuracy of the state of the art kernel fusion model in this study we enhance the fold_recognition results on the scop pdb d benchmark_dataset through a novel kernel data fusion framework based on the gm of kernel matrices gfk we present two methods karcher kf and agh kf for computing the gm where the second one is a computationally scalable method that computes an approximate gm the experimental_results demonstrate that the gm of kernel matrices can effectively improve the accuracy of the state_ofthe kernel fusion model in addition we obtain similar results using the logem which is a more cost_effective technique for integrating different pfs our meta predictor is developed by incorporating the available knowledge on functions of protein_domains into our kernel data fusion framework giving a promising total accuracy of understanding the relationship between primary and tertiary_structure in proteins is one of the main objectives of protein sequence_analysis this relation is still elusive but our results suggest that combining the evolutionary and secondary structural_information could be crucial to elucidate such a latent link this claim is investigated on the newer scop database version where our new methods again have good performance in addition by incorporating the available functional_domain information using our fungeofold model nearly exact protein fold_recognition for folds is achieved furthermore the limitation of convex linear_combinations in dealing with fusion of different pfs that carry complementary information is considered our proposed fusion frameworks by contrast can be used to detect these features with complementary information which provides an insightful approach for fusing different features of other problems in bioinformatics 
