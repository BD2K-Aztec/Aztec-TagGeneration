dixa a data infrastructure for chemical safety_assessment motivation the field of toxicogenomics the application of omics_technologies to risk_assessment of compound toxicities has expanded in the last decade partly driven by new legislation aimed at reducing animal_testing in chemical risk_assessment but mainly as a result of a paradigm change in toxicology towards the use and integration of genome_wide data many research groups worldwide have generated large_amounts of such toxicogenomics data however there is no centralized repository for archiving and making these data and associated tools for their analysis easily available results the data infrastructure for chemical safety_assessment dixa is a robust and sustainable infrastructure storing toxicogenomics data a central data_warehouse is connected to a portal with links to chemical_information and molecular and phenotype data dixa is publicly_available through a_user new data can be readily deposited into dixa using guidelines and templates available online analysis descriptions and tools for interrogating the data are available via the dixa portal availability_and http www dixa fp euduring the last decade technology developments as well as new legislation ethical_considerations and concerns about the reliability and relevance of traditional animal_experimentation for toxicity_testing have led to the expansion of the field of toxicogenomics many projects worldwide have generated large_amounts of toxicogenomics data but so_far there is no centralized repository collecting curating and maintaining all these data to make sure data are easily_accessible and do not disappear over time we developed the data infrastructure for chemical safety_assessment dixa a database and web_interface providing access to toxicogenomics datasets and analysis while several toxicogenomics projects made their data already available via public_databases e g arrayexpress geo expression atlas data from other projects are more difficult to access moreover toxicogenomics data are generally deposited in isolation not as structured sets there are several reasons for this among others non comparable experimental_designs different technology platforms and different data pre_processing furthermore available metadata for public data_sources are often insufficient for data reuse dixa aims to overcome these drawbacks by defining standard workflows for data pre_processing and standard formats for metadata annotation these standards are applied to the dixa data through servicing moreover dixa integrates_information from toxicology chemistry and human disease databases alongside the original data helping interpretation of data analysis results and increasing the relevance for evaluating toxicity combining data_sets from different sources centrally can provide_important about experimental_design and mechanistic interpretations when all relevant data for a study are available in a public repository a remaining challenge is to integrate these data in order to get a better understanding of the entire biological system data from different platforms and different technologies are very heterogeneous in terms of experimental_conditions species noise levels time scales and linearity of response as a consequence integrating data from different sources requires new data analysis methodologies here we describe dixa a database providing access to toxicogenomics data from different sources and data analysis tools 
