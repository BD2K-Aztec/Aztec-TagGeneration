data_and optimized data fusion for k means laplacian clustering motivation we propose a novel algorithm to combine multiple kernels and laplacians for clustering analysis the new algorithm is formulated on a rayleigh quotient objective_function and is solved as a bi level alternating minimization procedure using the proposed algorithm the coefficients of kernels and laplacians can be optimized automatically results three variants of the algorithm are proposed the performance is systematically validated on two real_life data fusion applications the proposed optimized kernel laplacian clustering oklc algorithms perform significantly better than other methods moreover the coefficients of kernels and laplacians optimized by oklc show some correlation with the rank of performance of individual data source though in our evaluation the k values are predefined in practical studies the optimal cluster number can be consistently estimated from the eigenspectrum of the combined kernel laplacian matrix availability the matlab_code of algorithms implemented in this paper is downloadable fromclustering is a fundamental problem in unsupervised_learning and a number of different algorithms and methods have emerged over the years k means km and spectral clustering are two popular_methods for clustering analysis k means is proposed to cluster attribute based data into k numbers of clusters with the minimal distortion another well known method spectral clustering sc is also widely_adopted in many applications unlike km sc is specifically developed for graphs where the data samples are represented as vertices connected by non negatively weighted undirected edges the problem of clustering on graphs belongs to whom correspondence should be addressed present_address department of medicine institute for genomics and systems_biology the university of chicago to another paradigm than the algorithms based on the distortion measure the goal of graph_clustering is to find partitions on the graph such that the edges between different groups have a very low weight von to model this different objective_functions are adopted and the typical criteria include the ratiocut the normalized cut and many others to solve these objectives the discrete constraint of the clustering indicators is usually relaxed to real values thus the approximated solution of spectral clustering can be obtained from the eigenspectrum of the graph laplacian matrix many investigations e g have shown the connection between km and sc moreover in practical_applications the weighted similarity matrix is often used interchangeably as the kernel_matrix in km or the adjacency_matrix in sc recently a new algorithm kernel laplacian kl clustering is proposed to combine a kernel and a laplacian simultaneously in clustering analysis this method combines the objectives of km and sc in a quotient trace maximization form and solves the problem by eigen decomposition kl is shown to empirically outperform km and sc on real_datasets this straightforward idea is useful to solve many practical problems especially those pertaining to combine attribute based data with interaction based networks for example in web analysis and scientometrics the combination of text_mining and bibliometrics has become a standard approach in clustering science or technology fields toward the detection of emerging fields or hot topics in bioinformatics proteinprotein_interaction and expression data are two of the most important sources used to reveal the relevance of genes and proteins with complex_diseases conventionally the data are often transformed into similarity matrices or interaction graphs then consequently clustered by km or sc in kl the similarity based kernel_matrix and the interactionbased laplacian matrix are combined which provides a novel approach to combine heterogeneous data_structures in clustering analysis our preliminary_experiments show that when using kl to combine a single kernel and a single laplacian its performance strongly depends on the quality of the kernel and the laplacian which results in a model_selection problem to determine the optimal settings of the kernel and the laplacian to perform model_selection on unlabeled data is non trivial because it is difficult to evaluate the models to tackle the new problem we propose a novel algorithm to incorporate multiple kernels and laplacians in kl clustering our recent work proposes a method to integrate_multiple kernel matricesclustering submitted for publication the main contribution of the present work lies in the additive combination of multiple kernels and laplacians moreover the coefficients assigned to the kernels and the laplacians are optimized automatically this article_presents the mathematical derivations of the additive integration form of kernels and laplacians the optimization of coefficients and clustering are achieved via a solution based on bi level alternating minimization we validate the proposed algorithm on heterogeneous datasets taken from two real applications where the advantage and reliability of the proposed method are systematically compared and demonstrated we implement the proposed oklc models to integrate_multiple kernels and laplacians on disease data and journal set data to compare the performance we also apply six popular ensemble clustering_methods mentioned in relevant work to combine the partitions of individual kernels and laplacians as a consolidated partition these six methods are cspa hgpa mcla qmi eacal and adacvote as shown in tables and the performance of oklc algorithms is better than all the compared methods and the improvement is significant on disease data the best performance is obtained by oklc model which uses sparse coefficients to combine nine text_mining kernels and nine laplacians to identify disease_relevant clusters ari nmi on journal data all three oklc models perform comparably well the best one seems coming from oklc model ari nmi which optimizes the non sparse coefficients on the four kernels and four laplacians to evaluate whether the combination of kernel and laplacian indeed improve the clustering performance we first systematically compared the performance of all the individual data_sources using km and sc as shown in supplementary_material on disease data the best km performance ari nmi and sc ari nmi performance are obtained on lddb text_mining profile next we enumerate all the paired combinations of a single kernel and a single laplacian for clustering the integration is based on equation and the value is set to so the objectives of km and sc are combined averagely the performance of all paired combinations is presented in supplementary_material as shown the best kl clustering performance is obtained by integrating the lddb kernel with ko laplacian ari nmi moreover we also found that the integration performance varies_significantly by the choice of kernel and laplacian which proves our previous point that the kl performance is highly dependent on the quality of kernel and laplacian using the proposed oklc algorithm there is no need to enumerate all the possible paired combinations oklc combines all the kernels and laplacians and optimizes their coefficients in parallel yielding a comparable_performance with the best paired combination of a single kernel and a single laplacian in two confusion matrices of disease data for a single run are depicted the values on the matrices are normalized according to r ij c j t i where t i is the total number of genes belonging in disease i and c j is the number of these t i genes that were clustered to belong to class j first it is worth noting that oklc reduces the number of misclustered genes on breast_cancer nr cardiomyopathy nr and muscular_dystrophy nr among the misclustered genes in lddb five genes tsg dbc cttn slc a ar in breast_cancer two genes in cardiomyopathy cox csrp and two genes in muscular_dystrophy sepn col a are correctly clustered in oklc model second there are several diseases where consistent misclustering occurs in both methods such as diabetes nr and neuropathy nr the intuitive confusion matrices correspond to the numerical evaluation results as shown the quality of clustering obtained by oklc model ari nmi is higher than lddb the performance of individual data_sources of journal data is shown in supplementary_material the best km ari nmi is obtained on the idf kernel and the best sc ari nmi is obtained on the cross citation laplacian to combine the four kernels with four laplacians we evaluate all the paired combinations and show the performance in supplementary_material the best performance is obtained by integrating the idf kernel with the cross citation laplacian ari nmi as shown the integration of lexical similarity information and citation based laplacian indeed improves the performance in the confusion matrices also normalized of journal data for a single run are illustrated we compare the best individual data source idf with kernel km figure on the left with the oklc model in the confusion matrix of idf km journals belonging to agriculture science nr are misclustered to environment ecology nr journals are misclustered to pharmacology and toxicology nr in oklc the number of agriculture journals misclustered to environment ecology is reduced to and the number to pharmacology and toxicology is reduced to on other journal clusters the performance of the two models is almost equivalent we also investigated the performance of combining only multiple kernels or multiple laplacians on the disease dataset we combined the nine kernels and the nine laplacians for clustering respectively using all the compared methods inbetween the ranks of weights and the ranks of performance on both datasets the correlations of disease kernels disease laplacians journal kernels and journal laplacians are respectively and in some relevant work the average spearman_correlations are mostly around therefore the optimal weights obtained in our experiments are generally consistent with the rank of performance as a spectral_clustering the optimal cluster number of oklc can be estimated by checking the plot of eigenvalues von to demonstrate this we investigated the dominant eigenvalues of the optimized combination of kernels and laplacians in we compare the difference of three oklc models with the pre defined k set as equal to the number of class_labels in practical research one can predict the optimal cluster number by checking the elbow of the eigenvalue plot as shown in the elbow in disease data is quite obvious at the number of in journal data the elbow is more likely to range from to all the three oklc models show a similar trend on the eigenvalue plot moreover in supplementary_material we also compare the eigenvalue curves using different k values as input as shown the eigenvalue plot is quite stable with respect to the different inputs of k which means the optimized kernel and laplacian coefficients are quite independent with the k value this advantage enables a reliable prediction about the optimal cluster number by integrating_multiple data_sources to investigate the computational time we benchmark oklc algorithms with other clustering_methods on the two datasets as shown in when optimizing the coefficients oklc algorithm models and spends longer time than the other methods to optimize the coefficients on the laplacians andthe kernels however the proposed algorithm is still efficient considering the fact that the proposed algorithm yields much better performance and more enriched information the ranking of the individual sources than other methods it is worth spending extra computational_complexity on a promising algorithm the reported values are averaged from repetitions the cpu time is evaluated on matlab v windows xp installed on a laptop computer with intel core duo ghz and g memory and different experimental_settings the proposed oklc algorithms perform significantly better than other methods moreover the coefficients of kernels and laplacians optimized by oklc show strong correlation with the rank of performance of individual data source though in our evaluation the k values are predefined in practical studies the optimal cluster number can be consistently estimated from the eigenspectrum of the combined kernel laplacian matrix the proposed oklc algorithm demonstrates the advantage of combining and leveraging information from heterogeneous data_structures and sources it is potentially useful in bioinformatics and many other application areas where there is a surge of interest to integrate similarity based information and interaction based relationships in statistical_analysis and machine_learning 
