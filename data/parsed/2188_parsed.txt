data_and high_dimensional bolstered error estimation motivation in small sample settings bolstered error estimation has been shown to perform better than cross_validation and competitively with bootstrap with regard to various criteria the key issue for bolstering performance is the variance setting for the bolstering kernel heretofore this variance has been determined in a non parametric manner from the data although bolstering based on this variance setting works well for small feature_sets results can deteriorate for high_dimensional feature spaces results this article computes an optimal kernel variance depending on the classification rule sample_size model and feature_space both the original number and the number remaining after feature_selection a key point is that the optimal variance is robust relative to the model this allows us to develop a method for selecting a suitable variance to use in real_world applications where the model is not known but the other factors in determining the optimal kernel are known availability companion website atthroughout most of the history of pattern_recognition the number of features was much smaller than the numbers currently being generated in high_throughput biology less than years_ago in two studies on feature_selection most cases considered involved features and the maximum number considered was the advent_of technologies has radically altered the landscape in conjunction with large_numbers of features bioinformatics is confronted by small_sample often which forces one to train and test on the same data where bias variance braga and lack of correlation with the true error can severely degrade error estimation performance can degrade even further in the presence of feature_selection recent_articles have pointed_out the difficulty in establishing performance advantages for proposed classification rules two statistically grounded sources of overoptimism have been highlighted i applying a classification rule to numerous datasets and then reporting only the results on the dataset for which the designed classifier possesses the lowest estimated error to whom correspondence should be addressed and ii applying multiple classification rules to a dataset and comparing the classification rules according to the estimated errors of the designed classifiers in both cases optimism is a result of inaccurate error estimation a good error estimator ideally would have small bias and small variance this is a difficult trade_off in small sample settings in small sample cases resubstitution generally has small variance but tends to be quite optimistically biased cross_validation has small bias but tends to display high variance bolstered error estimation braga attempts to achieve a compromise to this bias variance dilemma in small sample settings it is based on the idea of modifying bolstering the empirical distribution of the data by placing kernels at each data point and then estimating classifier error by the error on this bolstered empirical distribution in such a way that it reduces bias while at the same time reducing variance bolstered error estimation has shown good performance when compared with popular error estimators in small sample settings in particular for feature_set ranking and when used internally within a feature selection_algorithm and for ranking feature_sets its good performance including the latter applications has been demonstrated in the context a small number of features including feature_selection via sequential forward selection sfs where it is applied to small potential feature_sets in the sfs algorithm a critical aspect of the method is selecting the right amount of bolstering which is given by the variance of the bolstering kernels the original bolstering paper braga proposed a non parametric estimator for the kernel variance which was found empirically to perform well in low_dimensional spaces however estimation was found to degrade in high_dimensions so that a correction_factor can be required in fact it was demonstrated in a preliminary study that a correction_factor can also be beneficial for low_dimensional bolstering this leads us to consider optimal bolstering specifically finding an optimal variance for the bolstering kernels error estimators like resubstitution and cross_validation assuming the number of folds is preset are non parametric they contain no free_parameters this is not the case for bootstrap in general bootstrap has the form of a convex error estimator namely wher resub andand and zero are the resubstitution and zero bootstrap estimators and a the zero bootstrap utilizes the empirical distribution f which puts mass n on each of the n available 
