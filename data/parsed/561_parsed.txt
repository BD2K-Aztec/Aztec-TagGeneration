genome_analysis a support_vector for identification of single_nucleotide from next_generation accurate determination of single nucleotide polymorph isms snps from next_generation data is a significant challenge facing bioinformatics researchers most current methods use mechanistic_models that assume nucleotides aligning to a given reference position are sampled from a binomial_distribution while such methods are sensitive they are often unable to discriminate errors resulting from misaligned reads sequencing_errors or platform artifacts from true variants results to enable more accurate snp_calling we developed an algorithm that uses a trained support_vector svm to determine variants from bam or sam formatted alignments of sequence_reads our svm based implementation determines snps with significantly_greater sensitivity_and than alternative platforms including the unifiedgenotyper included with the genome_analysis samtools and freebayes in addition the quality_scores produced by our implementation more accurately_reflect the likelihood that a variant is real when compared with those produced by the genome_analysis while results depend on the model used the implementation includes tools to easily build new models and refine existing_models with additional_training data availability source_code and executables are available from github com brendanofallon snpsvm contact high_throughput produce large_quantities of relatively low quality data discrimination of true sequence_variants from variants produced alignment base_calling or platform specific errors presents a significant bioinformatic challenge in projects seeking to identify disease_causing even a relatively modest number of false_positive calls may significantly impede analysis as commonly used variant filtering strategies often enrich for false_positive calls for instance discarding variants above a certain frequency in the population preferentially retains false variants as nearly all false_positive calls are likely to be rare traditional variant_calling techniques such as those available in the genome_analysis gatk or the samtools package imagine that bases aligning to a reference position are drawn from a binomial_distribution under the binomial assumption the number of nonreference bases aligning to a position is approximately pfx xjcg c x may be assessed to form an educated guess regarding the state of a query variant the variant quality_score recalibration vqsr procedure is a semisupervised technique that fits multidimensional gaussian_distributions to a collection of suspected true variants variants whose properties differ from those of the true variants are deemed more likely to be false_positives while the vqsr procedure improves the quality of variant_calls it suffers from several limitations for example vqsr requires tens_of of variants to accurately fit the distributions and inclusion of more than a few roughly features may cause the algorithm to fail an alternative type of machine_learning known as the support_vector svm addresses some of the difficulties_encountered in earlier models svms are numerical classification_techniques designed to identify an arbitrarily defined class to which a query data point belongs and have been previously used in bioinformatics applications from cancer subtype classification to splice_site prediction e g in a manner similar to vqsr a vector of features is collected for all possible sites at which a variant may exist the svm is then trained on collections of sites known to contain true and false variants unlike vqsr svm training produces a model that may then be used repeatedly to call variants from query datasets svms can incorporate large_numbers of features and after training an svm does not require a large number of variants for precise calling it may be used to classify a single query variant in this work we demonstrate that an appropriately_trained svm can be used to accurately determine the positions of snps from next_generation data and we present a software implementation designed to make such calculations practical for bioinformaticians our algorithm takes as input a sam or bam formatted alignment of sequencing_reads and emits as output a vcf formatted file containing positions of likely variants the svm is used to predict whether an alignment column contains a sequence variant of any zygosity and additional non svm calculations are performed to determine the most likely zygosity of each variant machine_learning such as svms offer several advantages over traditional snp_calling procedures most importantly machine_learning allow for multiple and diverse measurements to be incorporated into a statistically_robust model of variant_calling allowing for errors produced by miscalled bases erroneously mapped_reads and platform specific artifacts to be detected in a single statistical_procedure by including features such as strand bias read position base_quality measurements and mismatch counts into a single_variant assessment algorithm significantly_greater sensitivity_and may be achieved in addition inclusion of these multiple error sources results in quality_scores that more accurately_reflect the probability that a variant is real when compared with the gatks unifiedgenotyper another advantage of the svm based technique is that the variant_calling model may be continually improved as more training data become available external_information regarding true and false variant_calls from trusted sources for instance sanger_sequencing methods or snp_chips can be used to refine the variant_calling model and improve the accuracy of all future calls for sequencing centers or laboratories that process many samples and routinely use sanger_sequencing to confirm certain variants such data are likely to be widely available in our implementation we have included several features to aid incorporation of newly acquired data into an existing model to facilitate the refinement procedure while we have demonstrated that an svm based technique can yield more accurate results than traditional variant_calling techniques the performance of our algorithm depends critically on the model used as more accurate training_sets are developed and more informative features identified the sensitivity_and may be improved_substantially additionally because models and training data are stored as simple text_files they may be easily distributed among researchers once developed 
