gene_expression updating rna_seq analyses after re annotation the estimation of isoform abundances from rna_seq requires a time intensive step of mapping reads to either an assembled or previously annotated transcriptome followed by an optimization procedure for deconvolution of multi mapping reads these procedures are essential for downstream_analysis such as differential_expression in cases where it is desirable to adjust the underlying annotation for example on the discovery of novel isoforms or errors in existing annotations current pipelines must be rerun from scratch this makes_it to update abundance estimates after re annotation or to explore the effect of changes in the transcriptome on analyses we present a novel efficient algorithm for updating abundance estimates from rna_seq experiments on re annotation that does not require re analysis of the entire dataset our approach is based on a fast partitioning algorithm for identifying transcripts whose abundances may depend on the added or deleted isoforms and on a fast follow_up approach to re estimating abundances for all transcripts we demonstrate the effectiveness of our methods by showing how to synchronize rna_seq abundance estimates with the daily refseq incremental updates thus we provide a practical approach to maintaining relevant databases of rna_seq derived abundance estimates even as annotations are being constantly revised availability_and our methods are implemented in software called rexpress and are freely_available together with source_code at http bio two major bottlenecks in rna_seq analysis are the mapping of reads to transcripts which is a prerequisite for quantification and differential analysis and abundance estimation following mapping the latter step is particularly complex when multimapping reads need to be resolved which is necessary for estimating isoform level abundances or when genes have been duplicated popular programs for multiread assignment such as cufflinks and rsem have large memory and time requirements seeof alternative_approaches such as express which uses a streaming algorithm for assignment are faster with a low memory_footprint but must still re process all the data from scratch when the underlying annotation is adjusted for large_datasets such as the billion reads of a complete run of read_mapping with bowtie followed by abundance estimation with express takes days with cores used for the mapping in cases where an annotation of transcripts in a genome may change after mapping current analysis_pipelines require re mapping of all reads followed by a complete recomputation of abundances this has made it time consuming and impractical to determine the effects of the addition of possibly novel transcripts on results or the impact of removal of transcripts that appear to be incorrect moreover in cases of model_organisms it has resulted in the freezing of analyses with respect to specific annotation sets even though re annotation efforts are resulting in continuous changes to reference transcriptomes the problem we solve in this article is how to update quantification of transcript_abundances in cases where annotations change without remapping all reads to all transcripts and running abundance estimation procedures from scratch this problem is non trivial for two reasons multi mapping frequently reads map to multiple_transcripts and therefore the removal or addition of transcripts may change the posterior_probabilities associated to read mappings in particular the addition of a single transcript may require re quantification of many other related transcripts abundance estimates from rna_seq are relative and not absolute because rna_seq abundance estimates are relative a change in the abundance estimate of a single transcript affects all other transcripts given a change in the underlying transcripts we show that abundance estimates can be updated by a procedure that only involves mapping reads to a small subset of the transcripts and re computing assignment probabilities of multi mapping reads for a similarly small set this is made possible by isolating a small relevant set of transcripts using a partitioning algorithm on a graph constructed from read_alignments when abundance estimation is subsequently performed using a fast online algorithm the updating of estimates is particularly fast when the change to the underlying annotation is small an implication of this result is that it is possible to easily update rna_seq abundance estimates for annotations that are continuously updated as is the case with the nightly reference_sequence refseq updates refseq is a large database of sequences that includes widely used reference transcripts for to whom correspondence should be addressed the author published_by all_rights for permissions please_e journals permissions_oup com overview of the approach reads are initially aligned to a set of known transcript sequences and these alignments are used to probabilistically assign multi mapping reads and to estimate abundances of the transcripts the result is a set of relative_abundances for example in fragments per kilobase per million mapped fpkm units when a new annotation is given differences are identified reads are mapped to any added transcripts and the ambiguity graph where vertices correspond to transcripts and edges correspond to pairs of transcripts to which reads have mapped ambiguously is updated deleted transcripts in red and added transcripts in blue the affected transcripts whose abundance must be re computed are obtained from a partitioning in the graph finally the subset of affected transcripts have their abundances re computed using the relevant reads and abundances for the transcriptome are re computed many organisms refseq is updated nightly to reflect improvements in annotations and although the changes are small we show that they can affect abundance estimates in rna_seq analyses our results demonstrate that it is possible with our algorithm to analyze an rna_seq dataset by building up the annotation one transcript at a time in particular our tool rexpress allows scientists to routinely update abundance estimates for rna_seq analyses to reflect best possible results at any time although rexpress is designed to work with formats produced by the express rna_seq quantification tool the program is general and suitable for use with many mapping and abundance estimation methods despite the difficulties in storing processing and distribution of high_throughput sequence_data repositories such as the gene_expression have led to an explosion in publicly_available genome_wide expression data however numerous technical_challenges that arise in re using data have limited the utility of publicly archived rna_seq our results show that it is possible to efficiently update rnaseq abundance estimates on re annotation thus removing a major_obstacle to re using publicly_available data this should prove to be particularly useful in newly_sequenced organisms whose annotations are not stable and undergo periodic revision and also in human cancer transcriptomics where structural_alterations can be tumor specific we also believe that rexpress will be particularly useful for sequencing centers providing analysis services instead of producing one time output it should now be possible to refresh analyses as annotations improve without expensive hardware or compute time needed as user bases and datasets grow other applications of our work include a randomized approach to optimization of transcriptome_assembly in conjunction with abundance estimation and the development of an rna_seq quantification database for publicly_available datasets that is automatically updated as annotations improve moreover our work on component identification in and partitioning of the ambiguity graph can be used to develop more efficient batch methods for abundance estimation a recurring issue in the commonly used batch em solutions is the necessity of iterating over a large number of reads which has a memory bottleneck as shown in attempts to avoid the bottleneck by treating all genomic_loci as independent blocks and using a heuristic rescue method to partially correct for the approximation a better solution for the memory bottleneck in the batch method is to iterate over approximately independent partitions of the ambiguity graph whose associated reads can be fit into memory because most components are often small only the largest will need to be partitioned as in our method above the blocks can then be processed in parallel only a single machine or distributed over a cluster finally in conjunction with the streaming algorithm for quantification in the present method b provides an online algorithm in both the reads and the targets in any setting where probabilistic assignment of multi mapping reads is a bottleneck in analysis of high_throughput sequencing_data 
