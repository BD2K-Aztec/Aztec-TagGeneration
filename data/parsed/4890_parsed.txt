data_and warpgroup increased precision of metabolomic data_processing by consensus integration bound analysis motivation current informatic techniques for processing raw chromatography mass_spectrometry data break down under several common non ideal_conditions importantly hydrophilic liquid interaction chromatography a key separation technology for metabolomics produces data which are especially challenging to process we identify three critical_points of failure in current infor matic workflows compound specific drift integration region variance and naive missing value im putation we implement the warpgroup algorithm to address these challenges results warpgroup adds peak subregion detection consensus integration bound detection and intelligent missing_value steps to the conventional informatic workflow when compared with the conventional workflow warpgroup made major_improvements to the processed data the coefficient of variation for peaks detected in replicate injections of a complex escherichia_coli extract were halved a reduction of integration regions across samples were much more robust additionally many signals lost by the conventional workflow were rescued by the warpgroup refinement thereby resulting in greater analyte coverage in the processed data availability_and warpgroup is an open_source r package available on github at github com nathaniel mahieu warpgroup the package includes example data and xcms compatibility wrappers for ease of use omics scale separation mass_spectrometry approaches e g lc_ms gc_ms ce ms etc generate large d data_sets consisting of elution time rt mass to charge ratio m z and signal_intensity information analytes are separated by their chemical characteristics prior to being introduced into the mass_spectrometer yielding rt the mass_spectrometer acts as a second dimension of separation and a detector providing information on the accurate_mass m z and amount of each analyte signal_intensity each sample run can generate gigabytes of data representing tens_of of distinct analytes k ll and the processing of raw_data is a significant challenge and the conventional workflow consists of several steps these steps include mass trace detection chromatographic feature_detection inter sample retention time drift correction inter sample grouping of common features correspondence determination and statistical_analysis of feature groups a feature in this context refers to signal which displays a peak shape in both m z and rt domains the result of this data_processing is quantification of all unique analytes detected across multiple sample runs historically most chromatography mass_spectrometry experiments have been performed with reversed_phase this well established separation_technique commonly generates gaussian peak shapes and exhibits highly_reproducible retention_times a simple retention_mechanism based primarily on compound polarity also minimizes compound specific drift one drawback to reversed phase_separation is a lack of retention for the highly polar compounds such as sugars and organic_acids commonly of interest in metabolomic_studies as a result many new separation chemistries have emerged under the umbrella_term hydrophilic_interaction hilic which aim to achieve separation of polar molecules unfortunately analytes measured by hilic separation exhibit a wide_range of non gaussian peak shapes as well as larger compound specific retention time drift current informatic approaches for metabolomics were primarily developed by using reversed_phase c chromatography and even today most new advances are benchmarked solely on reversed_phase datasets thus the performance of these algorithms degrades when applied to hilic datasets detection of features and selection of integration regions is an initial and critical step of the informatic workflow in cases where peak shapes are simple and peaks exhibit large signal_to the detection and integration of peaks is reproducible complex metabolomic datasets however contain a high proportion of poorly resolved and low_abundance peaks additionally the non gaussian peak shapes exhibited by a large portion of hilic features impede the robust selection of integration bounds these factors complicate peak_detection and result in undetected features as well as integration bounds which describe different regions of a peak in each sample and b the second major informatic step is determination of correspondence current feature grouping techniques rely on the reproducible elution of compounds across multiple experimental runs the elution time of m z rt pairs i e features is the key information used to associate the same compound detected in different runs in practice elution times vary from sample to sample due to many factors this necessitates correction of retention time drift prior to grouping most techniques assume that drift is a function of retention time alone and thus generate a global correction curve f rt a rt b this critical assumption is overly simplistic in practice retention time drift is compound dependent supplementary figs s and s additionally residual drift becomes greater when using more vagarious separation strategies such as hilic as larger groups of samples are aligned and as research studies begin to incorporate inter laboratory comparisons given the global correction assumption most alignment_techniques minimize only the average drift between samples considering all analytes equally supplementarypost correction is an optimistic example of retention drift for technical_replicates run over the course of nine hours as such the inherent compound specific drift results in many peaks remaining unaligned after correctionmoreover many compounds move even further out of alignment upon global correction supplementary this poor feature alignment causes major challenges for current peak grouping algorithms the density method employed by xcms e g can only group peaks if their maximum residual drift is less than the distance to the nearest group is an example of this failure further complexity is added by samples in which a feature is undetected or when spurious noise is detected as a feature both common occurrences in current workflows these failings of the current informatic workflow motivated our development of the warpgroup algorithm warpgroup is an algorithm which utilizes dynamic time warping dtw and network graph decomposition herein we achieve five goals i accurate grouping of features between samples even in the case of deviation from the global retention time drift ii splitting of peak subregions into distinct groups iii determination of consensus integration bounds within each group such that each group represents a similar chromatographic region iv detection of the appropriate integration region in samples where no peak was detected and v reporting of several parameters which allow filtering of noise groups the warpgroup algorithm establishes a correspondence between the time domains of each features extracted ion chromatogram eic trace utilizing dtw by default based on this correspondence warpgroup evaluates whether all supplied peak bounds represent a similar chromatographic region using graph community detection subsequently it determines consensus integration regions for each sample and selects the appropriate integration region for samples with no detected peak during the time warping and graph analysis several descriptors of each group are generated and reported for use in filtering unreliable and noise containing groups increased precision of metabolomic_data processingthe exact use cases of warpgroup are dependent on the data and the problem at hand we imagine four distinct goals in the next section and summarize appropriate inputs and expected outputs warpgroup operates optimally after inter sample peak correspondence has been established though it is possible to supply ungrouped data to the warpgroup algorithm there are several drawbacks to this approach first processing time for the dtw algorithm scales with the square of the input length second if a feature is present in one sample but missing from the others this dissimilar topography can result in incorrect alignments finally establishing correspondence is a complex challenge for which many more sophisticated solutions have been suggested these should be used in conjunction with the warpgroup refinements although warpgroup is not intended to determine peak correspondence it does make a less restrictive assumption for peak alignment current_algorithms assume that peak elution order remains monotonic across all masses warpgroup assumes only that peaks of indistinguishable mass retain their elution order this more relaxed assumption allows for rudimentary correspondence to be established in more complex cases such as that shown_inand is a major improvement to the xcms based workflow in summary we have found warpgroup to be an important refinement step for current integration and correspondence methods with warpgroup refinement in place data_processing results remain robust across a wide_range of experimental_conditions major_advantages have been noted in coverage as well as quantitation especially in lowabundance signals further warpgroup output includes additional descriptors which can be used to filter noise and unreliable groups from the final datasets overall we expect the addition of a warpgrouping step to the informatic workflow to improve the quality and reliability of untargeted metabolomic analyses 
