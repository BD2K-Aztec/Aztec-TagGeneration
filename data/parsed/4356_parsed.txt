sequence_analysis specificity control for read_alignments using an artificial reference_genome guided false_discovery motivation accurate estimation comparison and evaluation of read_mapping error_rates is a crucial step in the processing of next_generation data as further analysis steps and interpretation assume the correctness of the mapping results current approaches are either focused on sensitivity estimation and thereby disregard specificity or are based on read simulations although continuously improving read simulations are still prone to introduce a bias into the mapping error quantitation and cannot capture all characteristics of an individual dataset results we introduce arden artificial reference driven estimation of false_positives in next_generation data a novel benchmark method that estimates error_rates of read_mappers based on real experimental reads using an additionally generated artificial reference_genome it allows a dataset specific computation of error_rates and the construction of a receiver_operating thereby it can be used for optimization of parameters for read_mappers selection of read_mappers for a specific problem or for filtering alignments based on quality estimation the use of arden is demonstrated in a general read_mapper comparison a parameter_optimization for one read_mapper and an application example in single_nucleotide discovery with a significant reduction in the number of false_positive identifications availability the arden source_code is freely_available sourceforge net_projects arden throughout the past_years the rapid development of next_generation ngs_technologies has shaped computational_biology the analysis of large_amounts of data from sequencing runs which regularly reaches millions of reads is a key challenge in retrieving biological_information hence a common part of most ngs applications is to perform a read_mapping the search of given read sequences in a much larger reference_sequence various methods have been published to efficiently solve the read_mapping problem popular mappers include bowtie mrsfast bwa and razers for a comprehensive_overview on current read_mappers we refer the reader to however it is difficult to judge whether a mapping result is appropriate for a given dataset and how to efficiently compare read_mappers and how to choose their increasingly_large number of tuning parameters these challenges in read_mapping become particularly apparent in the search for genomic_variations such as single_nucleotide snps by definition the sequence of reads indicating snps differs from the reference_genome hence the difficulty is to distinguish true snps from sequencing_errors or computational mapping errors the distinction between error and variant is not obvious in case a read does not match perfectly to the reference here the parameterization of a read_mapper plays_a using only default_settings may result in imperfect mappings as they might be optimized for certain organisms or sequencing_platforms allowing mismatches may result in a high number of mappings but these may be error_prone and have a low quality in contrast requiring a high similarity might hinder the detection of snps thus a method for evaluation and quality_control is required to find an optimal setting for a read_mapper to the best of our knowledge quality_control of read_mappers is primarily based on sensitivity measurements or relies on read simulation as in e g oliver and as in general no ground_truth is available for ngs experiments however we observed that adequate read simulations are difficult to achieve and prone to introduce a bias it is infeasible to model all influence factors on data_acquisition and the continuously improving sequencing chemistry poses a challenge to keep simulations up to date further the correlation between simulation result and a specific real_dataset is inexplicit as it is challenging to set parameters such as the error_rate of the instrument a priori to avoid this bias we developed arden artificial reference driven estimation of false_positives in ngs_data which takes the opposite approach rather than replacing reads by a simulation with a known ground_truth arden uses real reads and a simulated decoy reference_genome for generating confidence measurements thereby arden is able to estimate and to control the number of incorrect alignments similarly to the widely used decoy strategy in proteomics our decoy approach is used to estimate the number of false_positive read mappings this is motivated by the assumption that the number of hits on the decoy genome provides an estimate of the expected number_of in the original genome the expectancy is that the occurrence of one hit on the decoy genome considered as a random hit has to whom correspondence should be addressed the author published_by all_rights for permissions please email journals permissions_oup com approximately the same probability as an incorrectly mapped read on the original reference_genome this leads to an approximation of a false_discovery as no read simulation is necessary arden is applicable on every dataset and adjusts to the specific sequencing runs thus it can be applied as a concurrent quality_control and allows adjusting specificity settings separately for single experiments and the exclusion of potentially incorrect mappings from subsequent analyses further it provides a novel approach to benchmark read_mappers or different read_mapping settings we demonstrate the applicability of arden in several evaluations first we use arden for a basic read_mapper comparison further we determine the best parameter setting for a specific read_mapper and finally we show a specific application example for snp discovery arden is a method for the identification and control of false_positives in mappings of ngs_data for which we demonstrate a broad range of applications arden allows the comparison of mapping algorithms on any dataset of interest rather than relying on a simulated dataset with potentially differing properties the here presented comparison study also gives insight into characteristic algorithmic properties of different classes of read_mappers for example fewer reads are expected to map distinctively to different positions on reference and artificial reference for hamming based_methods such as mrsfast for these approaches a single_point does not change the start or end position of an alignment that falls into the same region on the reference and the artificial reference moreover hamming based_methods have harder constraints for finding an alignment as they only consider substitutions because of the seed and extend step index based_methods suffer from a higher probability for mapping a read to the same region but on a different shifted position thus two classes of errors may contribute to false_positive alignments shifted alignments and alignments that map to diverse regions in general this leads to a higher_error for mappers such as bowtie or bwa than for hamming_distance based_methods also in general edit_distance mappers align a higher percentage of mapped_reads in comparison with hamming_distance mappers at the cost of an increased probability of false mappings the reason is that edit_distance mapping has relaxed constraints for finding an alignment than hamming_distance mapping as it allows substitutions and indels accordingly razers configured in edit_distance mode and bowtie mapped a highernote the ground_truth contained simulated snps arden decreases the number of fp while retaining all tps the effect of filtering depends on the particular mapper and the respective results of arden for bowtie bwa and razers the percentage of all alignments that have been removed by the filter are and respectively the relative difference between the all and filt category is denoted as note tps were compared with a simulated ground_truth containing simulated snps and to public available snp data a more detailed distinction is available in the supplementary_material for razers and bwa the filtering with arden considerably_reduced the numbers of fps along with a comparably small loss of tps for bowtie the number of fps is decreased along with a gain in tps the relative difference between the all and filt category is denoted as the error measurement allows the dataset specific optimization of mapping parameters and makes read_mappers comparable by an auc metric moreover arden provides the possibility to determine a user specified cut_off to improve the accuracy of alignments for a specific read_mapper based on sensitivity specificity and the corresponding auc more accurate mappings improve the quality of follow_up applications as we demonstrated in an snp discovery experiment where using arden decreased the number_of by up to while maintaining the majority of true_positives 
