real_time multi view deconvolution in light_sheet overall image_content and resolution are improved by acquiring and fusing multiple_views of the sample from different directions state of the art multi view mv deconvolution simultaneously fuses and deconvolves the images in d but processing takes a multiple of the acquisition time and constitutes the bottleneck in the imaging pipeline here we show that mv deconvolution in d can finally be achieved in real_time by processing cross_sectional planes individually on the massively_parallel architecture of a graphics_processing gpu our approximation is valid in the typical case where the rotation axis lies in the imaging_plane availability_and source_code are available on github https github com bene native code under the repository gpu deconvolution java wrappers implementing fiji plugins under spim reconstruction cuda contact mv imaging is particularly useful in light_sheet where consecutive views are acquired in short succession allowing reconstruction of entire developing organisms without artifacts due to the low photo toxicity in light_sheet time lapse experiments are oftentimes run over days and terabytes of data accumulate quickly mv fusion is therefore particularly desirable to be performed in real_time to eliminate redundant information from different views best fusion results however are achieved by combining fusion with d deconvolution although efficient bayesian mv deconvolution based on the richardsonlucy rl algorithm has been shown recently to outperform existing_methods in terms of fusion quality and convergence speed it is still too slow for real_time processing of typical data_volumes the rl deconvolution iterations consist only of convolutions and pixel wise arithmetic operations and could therefore be significantly_accelerated using dedicated hardware such as a graphics_processing gpu the large memory_requirements of mv deconvolution however exceed the limited resources of modern gpus even for moderate data sizes supplementary note s previous attempts therefore required splitting the data into blocks of appropriate size each block then either had to be transferred to and from the gpu in each rl iteration or blocks needed to share a considerable amount of overlap to avoid border artifacts therefore gpu based implementations only achieved a three times performance_gain the primary goal of mv fusion is the improvement of the poor axial resolution in a single d dataset using the superior lateral resolution of an additional overlapping dataset and not necessarily to improve resolution beyond the intrinsic lateral resolution we therefore approximated the full d point_spread psf with a d psf neglecting one lateral component along the rotation axis and processed each plane orthogonal to the rotation axis independently memory_requirements were thereby reduced by the number of lines read out from the camera chip i e typically fold this allowed us to implement the entire mv deconvolution on a gpu taking_advantage of three cuda compute_unified streams we interleaved gpu v c the author published_by the photo efficiency of light_sheet enables long timelapse imaging of living samples to study fundamental_questions in developmental_biology however its huge data rates also open new challenges for data_processing a key problem in light_sheet has been the fusion of data recorded from multiple angles in this article we presented a new method that performs mv deconvolution plane wise which reduces memory_requirements compared with existing_methods and thus permits an entirely gpu based implementation the achieved acceleration makes mv deconvolution for the first time applicable in real_time without the need for data cropping or resampling averaged 
