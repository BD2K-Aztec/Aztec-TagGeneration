an automated workflow for parallel processing of large multiview spim recordings selective plane illumination microscopy spim allows to image developing organisms in d at unprecedented temporal_resolution over long_periods of time the resulting massive_amounts of raw image data requires extensive processing interactively via dedicated graphical_user gui applications the consecutive processing_steps can be easily automated and the individual time points can be processed independently which lends itself to trivial paralleliza tion on a high_performance hpc cluster here we introduce an automated workflow for processing large multiview multichannel multiillumination time lapse spim data on a single workstation or in parallel on a hpc cluster the pipeline relies on snakemake to resolve dependencies among consecutive processing_steps and can be easily adapted to any cluster environment for processing spim data in a fraction of the time required to collect it availability_and the code is distributed free_and under the mit licensethe duration and temporal_resolution of d fluorescent_imaging of living biological specimen is limited by the amount of laser_light exposure the sample can survive selective plane illumination microscopy spim alleviates this by illuminating only the imaged plane thus reducing photo damage dramatically additionally spim achieves fast acquisition_rates due to sensitive wide_field detectors and sample rotation enables complete coverage of large nontransparent specimen taken together spim allows imaging of developing organisms in toto at single_cell resolution with unprecedented temporal_resolution over long_periods of time this powerful technology produces massive terabyte size datasets that need computationally expensive_and processing before analysis existing software solutions implemented in fiji preibisch unpublished https github com fiji spim registration or in zeiss zen black are performing chained processing_steps on a single computer and require user inputs via a gui as the spatial_and of the light_sheet data increase such approaches become inconvenient since processing can take days in controlled experiments spim image_processing is robust enough to be automated and key_steps are independent from time point to time point hpc is inherently designed for such time v c the author published_by we compared the performance of the pipeline on a gb single_channel spim recording of a drosophila embryo consisting of time points and views processed either on a single computer or on a hpc cluster supplementary the processing using average fusion takes almost precisely one day on a single powerful computer in contrast using the full cluster resource the dataset can be processed in h min which represents a fold speedup in processing since the time lapse covers h of drosophila embryonic_development the processing becomes real_time with respect to the acquisition using deconvolution on a cluster with only gpus supplementary still brings a more than fold speed up supplementary a dataset of tb in size with time points would take an estimated week to process on a single computer using this method the processing is reduced to only h with typical cluster workload from other users 
