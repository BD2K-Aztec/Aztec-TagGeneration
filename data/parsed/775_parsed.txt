bioq tracing experimental origins in public genomic_databases using a novel data provenance model motivation public genomic_databases which are often used to guide genetic_studies of human disease are now being applied to genomic medicine through in silico integrative genomics these databases however often lack tools for systematically determining the experimental origins of the data results we introduce a new data provenance model that we have implemented in a public web_application bioq for assessing the reliability of the data by systematically tracing its experimental origins to the original subjects and biologics bioq allows investigators to both visualize data provenance as well as explore individual_elements of experimental process flow using precise tools for detailed data exploration and documentation it includes a number of human genetic_variation databases such as the hapmap and genomes projects the rapid expansion of biotechnology continues to drive the public availability of massive complex genomic_databases these databases are often used in applications of in silico integrative genomics to genetic_studies of human disease as well as genomic medicine it is therefore critical for investigators to have tools for systematically assessing the credibility of the data we have developed a straightforward model for tracing experimental process flow in genomic_databases the goal is to isolate the key entities in the databasethe biologics the experiments and the experimental resultsand to express their relationships in terms of experimental process flow we call this the biologic experiment result bert model and have implemented this model in our bioq web_application http bioq saclab net bioq builds on our dbsnp q application to allow investigators to visualize experimental process flow and retrieve process related data with powerful query tools tables containing data on subjects biologics and key experimental_results are indicated by the labels s b and r respectively the goal is to trace the results back to subjects and biologics some groups and individual tables contain auxiliary reference data for processes and flow groups respectively reference nodes are indicated by dashed lines see the supplementary_materials for addition information on the bert model way with numerous tools for data_retrieval other models such as fuge are more appropriate for capturing the full spectrum of experimental detail the relative simplicity of the bert model will allow applications such as bioq to adapt as the requirements of investigators evolve very few tools allow investigators to trace the experimental source of genomic_data and to assess qc in detail as in bioq without tools such as bioq these undertakings can take days even weeks given the enormity of tests required to thoroughly assess qc the sheer size of the datasets involved and the difficulty in locating provenance data it is therefore likely that in many cases these assessments will not be done and this may lead to the use of faulty data a recent incident at duke university for example involving the use of flawed data in a translational genomic study has led to the creation of a new framework at duke on the quality of translational genomic medicine in which data provenance plays_a http tinyurl com pkfdgd accessed bioq is a direct extension of our previous web_application dbsnp q while dbsnp q provides powerful query and documentation tools for the dbsnp database it does not implement the bert model these methods and tools for systematically tracing experimental process flow are unique to bioq resources such as the ucsc database focus on graphical_representations of genomic_data these resources do not provide tools for systematically tracing experimental process flow and for querying the underlying relational databases in a web_browser as in bioq the bert model and the bioq application are designed to complement these resources by providing tools for systematically determining the origins of and assessing the quality of the data used in other tools such as the ucsc_genome the ability to establish the experimental origins of genomic_data and to systematically assess qc at all stages of the experimental process is a systemic issue relevant to all genomic applications it is therefore useful to have a separate resource dedicated to resolving this issue that can be used in conjunction with other applications as new bioinformatics applications emerge that further bridge the gap between genomics and medicine the availability of tools for systematically determining experimental origins will be crucial for maintaining reasonable levels of credibility the bioq project has taken a number of measures to ensure that updates to external genomic_databases are incorporated punctually and accurately to each database there corresponds a custom command_line driven program written in perl that downloads the data processes it checks for errors performs qc analyses and creates the mysql databases used in bioq barring any major changes to the formats released by these databases these programs allow the bioq update process to be completely automated all code is publicly_available from our subversion server http svn saclab net and our code review resource http fisheye saclab net these programs can be easily modified to accommodate any changes encountered in updates to external genomic_databases and will be used to incorporate these updates as they become available bioq 
