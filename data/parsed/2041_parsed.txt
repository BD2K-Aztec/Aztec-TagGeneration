genetics_and genotype_calling and phasing using next_generation reads and a haplotype scaffold motivation given the current costs of next_generation large studies carry out low_coverage followed by application of methods that leverage linkage_disequilibrium to infer genotypes we propose a novel method that assumes study samples are sequenced at low coverage and genotyped on a genome_wide micro array as in the genomes_project kgp we assume poly morphic sites have been detected from the sequencing_data and that genotype likelihoods are available at these sites we also assume that the microarray genotypes have been phased to construct a haplotype scaffold we then phase each polymorphic site using an mcmc_algorithm that iteratively updates the unobserved alleles based on the genotype likelihoods at that site and local haplotype_information we use a multivariate_normal model to capture both allele_frequency and linkage_disequilibrium information around each site when sequencing_data are available from trios mendelian transmission constraints are easily accommodated into the updates the method is highly parallelizable as it analyses one position at a time results we illustrate the performance of the method compared with other methods using data from phase of the kgp in terms of genotype accuracy phasing accuracy and downstream imputation performance we show that the haplotype panel we infer in african samples which was based on a trio phased scaffold increases downstream imputation_accuracy for rare_variants r increases by for minor_allele and this will translate into a boost in power to detect associations these results highlight the value of incorporating microarray genotypes when calling variants from next generation sequence_data genome_wide gwas are known to be well powered for the detection of common_variants that increase disease risk and have uncovered many replicated associations in recent_years however the effect_sizes of many associated loci are relatively small and together explain only a small proportion of the heritability for many diseases and traits it has been argued that rare_variants with larger effects might harbour the remaining genetic_variability next_generation allows whole_genome of a large sample of individuals so that a more detailed picture of human polymorphism can be obtained projects such as the kgp are working to produce a catalogue of polymorphisms with low minor_allele and rare maf allele_frequencies the current analysis_pipeline starts by detecting sites exhibiting evidence of polymorphism genotypes are then called at the polymorphic_sites and then haplotypes are estimated across all such sites often as a by product of calling the genotypes the sets of haplotypes produced can be used as reference_panels for imputation into gwas and allow investigations of rare_variant associations that go beyond previous imputation analyses from less complete reference_panels such as hapmap given the current costs for sequencing it is still not viable to deeply sequence a large number of individuals so given a fixed amount of resources there is a trade_off between sample_size and coverage the consensus view favours low_coverage of large_numbers of samples for example the kgp will be sequencing individuals at the uk k project will sequence whole genomes at http www uk k org and the genome of the netherlands is sequencing individuals at http www nlgenome com the current_paradigm for detecting genotyping and phasing polymorphic_sites from low coverage sequence_data starts by mapping sequence_reads to a reference_genome mapped_reads that overlap a given site s in a single individual i are then combined together to form genotype likelihoods gls gls are the probabilities of observing the reads given the underlying unknown genotype and can be written as pr is jg is where r is and g is denote the reads at site s and the true underlying genotype respectively methods exist for calculating these gls and involve combining information about the bases observed in reads while allowing for the possibility of sequencing_errors via base and mapping quality_scores so for example if the set of reads only contains the a allele then the gl pr is jg is aa will be larger than the other likelihoods but other genotypes will still have non zero likelihood as sequence to whom correspondence should be addressed coverage increases the likelihoods should become more peaked around the true genotype in low_coverage there may be no reads spanning a site in which case the gls will be identical across all possible genotypes detecting polymorphic_sites involves combining information across individuals at a site to infer whether there are at least two alleles observed across all individuals in the sample once a site is detected the sites genotypes can be called using a missing_data likelihood that is optimised via an em_algorithm but this will only work well when coverage is high and the gls contain very good information about the genotypes of all samples when coverage is low power to call genotypes can be gained by taking_advantage of linkage_disequilibrium ld between sites in close_proximity methods that do this are extensions of phasing and imputation algorithms that pool information across samples and sites to infer multi_site genotypes and their underlying haplotypes e g impute beagle browning andand mach in some studies such as gwas the individuals being sequenced will also have been genotyped on a genome_wide snp chip for example in the kgp individuals are both sequenced and genotyped on the illumina omni m chip some commercial vendors also return gwas array data with sequencing results so this design may become more prominent in the future up to now chip genotypes have primarily been used to validate sequencingbased genotype_calls as the error_rates of snp_chips are generally low o in this article we present a method that uses snp chip genotypes to aid the process of genotype_calling from sequencing_reads the first step of our method involves estimating haplotypes at the chip snps using an accurate phasing method to form a haplotype scaffold we then call genotypes at a polymorphic site using a model of the ld between the site and the surrounding sites in the haplotype scaffold we use an markov_chain mcmc_algorithm that iteratively updates the unobserved alleles at a site using the gls and the local ld we use a multivariate_normal model to capture both allele_frequency and ld_information around each site that results in fast mcmc updates when sequencing_data are available from motherfatherchild trios mendelian transmission constraints are easily accommodated into the updates the method analyses one position at a time and results in a highly parallelizable method that can be applied to a large sample we call our method mvncall our approach is similar to the qcall approach which also analyses one snp at a time using a haplotype scaffold qcall builds approximate coalescent trees at each site and then infers phased genotypes by considering possible mutations on branches of the trees this approach does not scale well as the number of sequences increases and is the reason why this method was not applied to the phase of the kgp mvncall is much faster and has enabled us to analyse the phase dataset in the sections that follow we present in detail the underlying model developed for genotype_calling and phasing we apply our method and other methods to chromosome of the phase of the kgp we carry out an imputation analysis using the haplotype sets inferred by the different methods as reference_panels and we compare imputation_accuracy our proposed model for genotype_calling and phasing assumes a study_design where samples have been both sequenced and genotyped the kgp uses exactly this design and this was a major motivation for developing such an approach in addition many cohorts of samples from gwas have been genotyped using microarray chips and it is likely that these samples might be sequenced in the future providing a combined set of data that also fits in with our approach in fact some commercial vendors also return gwas array data with sequencing results the genotyped data from the microarrays can be fed into a phasing algorithm and the resulting haplotypes serve as a haplotype scaffold in our model so that ld_information between the scaffold sites and non scaffold sites can be utilised to capture this ld_information we use an approximate model that summarises the allele_frequencies and the pairwise correlation between snps using a multivariate_normal there is an increasing body of literature that the use of a normal distribution can capture enough information about correlations in alleles both between snps and between individuals to provide useful levels of inference future extensions might utilise a normal_approximation to efficiently call genotypes from low_coverage data together with a haplotype reference_panel and without a haplotype scaffold our model would also be relatively easy to extend to other types of polymorphism such as indels and multi allelic_variants utilising phase_informative when constructing haplotype panels from sequence_data may also prove to be beneficial when applied to data from phase of the kgp that include individuals from distinct population backgrounds sequenced at and genotyped on the omni m chip we find that our method outperforms beagle in all population groups in terms of genotype accuracy this is an interesting result because mvncall analyses one site at a time rather than all sites jointly as in beagle it may be argued that jointly modelling all sites at once is a more appropriate strategy because this approach utilises ld_information between all the sites being called on the other hand when the calling of genotypes is difficult which can be the case when sequence_coverage is low it may be that the beagles joint approach suffers from convergence problems and the resulting haplotypes include errors due to this problem the methods snptools and thunder also model all sites jointly but perform slightly better than mvncall on the european and asian comparisons it may be that the underlying models they use are much better than the model used in beagle or that the computational strategies that they use do a better job at avoiding convergence problems a major use of the haplotype panels produced by the kgp is imputation of genotypes into gwas it was thus natural that we assess the ability of mvncall to produce haplotype panels in terms of downstream imputation performance a key finding of this work is that the panel of haplotypes that we produce from the kgp african samples results in a clear boost in downstream imputation performance at rare_variants when compared with the haplotype panels produced by snptools thunder or beagle mvncall results in a increase in mean r at rare_variants below frequency when compared with other methods this is a substantial boost in accuracy as studies of rare_variants are in general less powerful the r metric used for our assessments has direct relevance to the power of such studies in admixed samples mvncall produces similar results to snptools and both these methods have better performance than thunder and beagle at rare_variants we do not see the same increase in imputation performance when imputing european samples this may be because a substantial_proportion of african samples in the reference_panel have a haplotype scaffold that has been derived using trio phasing we have shown that the haplotypes our method constructs when using a trio phased scaffold have much lower switch error_rate compared with the haplotypes from a scaffold phased without family information it may be that it is this increase in haplotype accuracy that translates into a downstream effect on imputation performance in contrast only of the european haplotypes in the reference_panel were derived from a trio phased scaffold almost of the mexican samples in the haplotype reference_panel were derived using a trio based scaffold which might lead us to expect that imputation in mexican samples should be better when using mvncall reference haplotypes the ancestry ofhaplotype diversity across the genome and this degrades imputation performance and drives the similarity between methods imputation of rare_variants in mexican samples is noticeably worse supplementary than in the african and european samples and supplementary overall these results highlight the gains that can be made when using microarray genotypes to improve genotype_calls and phasing using low coverage sequence_data future analysis of the genomes_project data would benefit from fully incorporating the illumina omni m genotypes into the genotype_calling and haplotype estimation process 
