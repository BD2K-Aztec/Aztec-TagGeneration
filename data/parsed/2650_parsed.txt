kmerstream streaming algorithms for k_mer abundance estimation motivation several applications in bioinformatics such as genome_assemblers and error corrections methods rely on counting and keeping track of k_mers substrings of length k histograms of k_mer frequencies can give valuable insight into the underlying distribution and indicate the error_rate and genome_size sampled in the sequencing_experiment results we present kmerstream a streaming algorithm for estimating the number of distinct k_mers present in high_throughput sequen_cing data the algorithm runs in time linear in the size of the input and the space requirement are logarithmic in the size of the input we derive a simple model that allows us to estimate the error_rate of the sequencing_experiment as well as the genome_size using only the aggregate statistics reported by kmerstream as an application we show how kmerstream can be used to compute the error_rate of a dna sequencing_experiment we run kmerstream on a set of whole_genome sequenced individuals and compare the error_rate to quality values reported by the sequencing equipment we discover that while the quality values alone are largely reliable as a predictor of error_rate there is considerable variability in the error_rates between sequencing runs even when accounting for reported quality values k_mers are one of the most fundamental objects used when analyzing dna sequencing_data many assembly algorithms start by constructing a de_bruijn a graph containing all k_mers for some fixed k some of the most commonly used algorithms for aligning_reads to a reference_genome start by finding short exact_matches of a fixed_length k commonly referred to as a seed an index of all k_mers is constructed and from this index an initial alignment of a part of the read is found in this work we focus on the problem of estimating the number of distinct k_mers in a set of sequencing_reads this problem is related to k_mer in the sense that if we can solve k_mer we can report the number of distinct k_mers however the methods we develop are an order of magnitude faster and use only a fraction of the memory compared with current k_mer software we develop streaming algorithms to solve this problem a framework first proposed by a similar approach is used by kmergenie which samples kmers to approximate the frequency histogram of k_mer occurrences sequencing_errors cause considerable problems for k_mer based_algorithms for both assembly and read_mapping in assembly these may cause the assembly to become disconnected and increases both the memory_usage and computational time in read_mapping it may lead to increased computational_overhead and the true location of the read not being found the removal or correction of erroneous bases and erroneous fragments is therefore a common preprocessing_step in the analysis of dna_sequences in particular when doing de_novo or read_mapping to a reference assembly several programs use k_mers to explicitly fix or remove sequencing_errors in the dataset and it is recommended to use them prior to assembly a number of software programs have been written for quality_control of dna sequencing_data including fastqc http www bioinformatics babraham ac uk projects fastqc fastqc has a number of functionalities useful for quality_control including giving a distribution of the quality values assigned by the sequencer quality distribution by position n content and gc_content identifying overrepresented k_mers and sequence length_distribution however the k_mers identified tend to be short basepairs by default and although they are useful for identifying contaminants they are not unique enough in the underlying genome to be useful for assessing the sequencing_error independent of what is given by the dna sequencers the problem of k_mer for high_throughput data_sets has been well studied given a set of reads report the coverage of each k_mer i e how many reads contain that k_mer current methods for obtaining aggregate statistics of k_mer data are based on keeping track of all k_mers in a set ofmuch work has been done on reducing memory_requirements based on exact or approximately correct methods of keeping track of a large set of k_mers this work includes using succinct set representations or probabilistic encodings such as bloom filters whereas recent_advances have focused on more speed although the impact on memory_usage is considerable compared to previous_approaches these methods require storing all k_mers explicitly or implicitly in memory thus the amount of resources will grow linearly with the input size many methods also rely on having access to all the reads for multiple passes over the data or require additional disk_space for storing intermediate results thus all of the above methods suffer from the curse of deep_sequencing in which more sequencing can overwhelm the program in terms of memory_usage and the algorithms simply fail to make use of increased amounts of data the amount of data being gathered with modern sequencing methods continues to grow at a faster rate than our ability to analyze and store the data an alternative view to the current state of the art is to consider technologies that sequence dna on the fly in this case the sequencing machine does not store all the results but rather transmits the sequence_reads as they aregenerated technologies that fit this framework have been proposed and are currently in development such as technologies from oxford nanopore but technical_details are limited at this point in time regardless of the exact technologies used this new sequencing paradigm opens up new opportunities for online or streaming analysis of the data where we bypass the storage requirements and simply plug the sequencing directly into the analysis one benefit of the algorithms we have developed is as follows f f is a crude estimate of the number of k_mers that have been sequenced at least twice when this number goes above a certain fraction of the genome_size we can decide to stop sequencing another benefit is that when the error_rate goes above some threshold we can decide to stop the experiment immediately not wasting our time on failed experiments the method presented here can be particularly useful when used for a species that has not been previously_sequenced allowing us to get an estimate the coverage of this genome while sequencing prior to assembly when we condition on the error_rate given by illumina we see considerable variability in the error_rate between individuals hence it is not advisable to use the error_rates in a model without considering differences between individuals our results show that although the base_pair quality values given by the sequencing equipment are largely correct there appears to be a considerable sample dependent difference in the error_rate conditioned on the base_pair quality rate reported by the manufacturer our recommendation based on the results of sequencing individuals is to estimate both the number of k_mers f as well as the coverage and k_mer error_rate for multiple q value thresholds and decide on a case by case basis conflict of interest none declared 
