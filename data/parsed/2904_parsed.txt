metaktsp a meta_analytic top scoring pair method for robust cross study validation of omics prediction analysis downloaded from motivation supervised machine_learning is widely_applied to transcriptomic_data to predict disease diagnosis prognosis or survival robust and interpretable classifiers with high_accuracy are usually favored for their clinical and translational_potential the top scoring pair tsp algorithm is an example that applies a simple rank_based algorithm to identify rank altered gene_pairs for classi fier construction although many classification methods perform well in cross_validation of single expression_profile the performance usually greatly_reduces in cross study validation i e the prediction model is established in the training study and applied to an independent test study for all machine_learning including tsp the failure of cross study validation has largely diminished the potential translational and clinical values of the models the purpose of this article is to develop a meta_analytic top scoring pair metaktsp framework that combines multiple transcrip tomic studies and generates a robust prediction model applicable to independent test studies results we proposed two frameworks by averaging tsp scores or by combining p values from individual studies to select the top gene_pairs for model construction we applied the proposed methods in simulated_data and three large_scale real applications in breast_cancer idiopathic_pulmonary and pan cancer methylation the result showed superior_performance of cross study validation accuracy and biomarker selection for the new meta_analytic framework in conclusion combining multiple omics data_sets in the public_domain increases robustness and accuracy of the classification model that will ultimately improve disease understanding and clinical treatment_decisions to benefit patients high_throughput including microarray and massively_parallel have been widely_applied to discover underlying biological_processes and to predict the multi causes of complex_diseases e g cancer diagnosis prognosis van_de and therapeutic_outcomes the associated data analysis has brought new statistical and bioinformatic challenges and many new methods have been developed in the past_years in particular methods for classification and prediction analysis a k a supervised machine_learning are probably the most relevant tools towards translational and clinical_applications take breast_cancer as an example many expression based biomarker panels have been developed e g mammaprint van t oncotype_dx breast_cancer index bci and pam for classification prediction of survival recurrence drug response and disease subtype reproducibility analysis of these markers and classification_models has been a major_concern and has drawn significant attention to ensure clinical_applicability of these panels many articles have focused on normalization reproducibility of marker detection inter lab or inter platform correlation concordance for direct clinical utilities more attention have shifted towards cross study validation or inter_study prediction i e a prediction model is established in one study and validated independently in a test study such an issue is critical for translating models from transcriptomic studies into a practical clinical tool for example the training cohort may have utilized an old affymetrix u platform a biomarker_panel and a model are constructed and a test study from a different medical_center using an rna_seq platform is available a successful machine_learning model should retain high_prediction in such inter lab and inter platform validation we note that many normalization_methods have been developed to adjust for systematic_biases across studies including distance weighted discrimination cross_platform and knorm correlation but the normalization performance largely depends on whether the observed data_structure fits the model_assumptions in most applications researchers have applied meta_analysis methods and have avoided relying on effectiveness of normalization to compare the metaanalysis methods with mega analysis i e normalize across studies and directly merge data for inference in this article we only perform simple quantile normalization within each study and then standardize each sample to mean zero and unit sd before we adopt mega analysis in addition to the issue of cross study validation its critical to select a robust and accurate machine_learning in the literature many supervised_machine have been proposed and applied to high_throughput experimental_data for example the cma package allows easy implementation of popular classification methods such as linear or quadratic_discriminant lasso elastic_net support_vector svms random_forest pam etc in addition to these popular_methods the top scoring pair tsp method is a straightforward prediction rule utilizing building_blocks of rank altered gene_pairs in case and control comparison see section for more details the method is mostly rank_based without any model parameter it is invariant to monotone data transformation and the feature_selection and the model are more transparent for biological_interpretation although tsp and its variant are robust_methods that do not require normalization in cross study validation we have found that some of the selected tsps from the training study may not reproduce in the test study possibly due to platform differences illustrates the expression levels of a good tsp gene_pair itgax and xbp identified from the first ipf idiopathic_pulmonary training study emblom see data descriptions in supplementary xbp is over expressed than itgax in control samples but under expressed in cases if we use this tsp to validate in the test study konishi we find that xbp is over expressed than itgax in both cases and controls and we obtain sensitivity_and i e youden_index sensitivity_specificity we found similar poor_performance in two other studies tedrow b and pardo showing that the tsp is likely a false_positive in gpr is over expressed than comp in controls and under expressed in cases for all three studies emblom tedrow b and pardo it is a more reliable tsp across three studies and conceptually is less likely a false_positive indeed the cross study validation in konishi shows good performance with youden_index the two real examples inargue the potential of a meta_analytic approach by combining multiple training transcritomic studies to identify reliable tsps so the resulting model has enhanced cross study validation performance in this article we propose three meta_analytic approaches for tsp method metatsp by combining information across multiple training studies using i averaged tsp scores ii combining p values via fishers method iii combining p values via stouffers method to decide the number of tsps used for model construction a classical cross_validation cv method and a variance optimization vo method are applied and compared simulations and three real omics data_sets two gene_expression data on breast_cancer and ipf and two tsp examples from real_data to show advantage of metatsp xaxis and y axis refer to sample indices and gene_expression levels respectively a gene_pair itgax xbp has high tsp score xbp itgax in controls but itgax xbp in cases in the training emblom study but fail to replicate in the testing konishi study as well as the other two tedrow b and pardo studies b gene_pair gpr comp has high tsp scores gpr comp in controls and comp gpr in cases in all three training studies emblom tedrow b and pardo the gene_pair is successfully validated in the testing konishi study one pan cancer methylation data are used to benchmark the crossstudy validation performance 
