genome_analysis a statistical_framework for power calculations in chip_seq motivation chip_seq technology enables investigators to study genome_wide binding of transcription_factors and mapping of epige nomic marks although the availability of basic analysis tools for chip_seq is rapidly increasing there has not been much progress on the related design_issues a challenging question for designing a chip_seq experiment is how deeply should the chip and the control samples be sequenced the answer depends on multiple factors some of which can be set by the experimenter based on pilot prelim inary data the sequencing_depth of a chip_seq experiment is one of the key_factors that determine_whether all the underlying targets e g binding locations or epigenomic profiles can be identified with a targeted power results we developed a statistical_framework named cssp chip_seq statistical_power for power calculations in chip_seq by considering a local poisson_model which is commonly adopted by many peak callers evaluations with simulations and data_driven computational_experiments demonstrate that this framework can reliably estimate the power of a chip_seq experiment at different sequencing_depths based on pilot_data furthermore it provides an analytical_approach for calculating the required depth for a targeted power while controlling the false_discovery at a user specified level hence our results enable researchers to use their own or publicly_available data for determining required sequencing_depths of their chip_seq and potentially make better use of the multiplexing functionality of the sequencers evaluation of power for multiple public chip_seq indicate that currently typical chip_seq studies are powered well for detecting large fold changes of chip enrichment over the control sample but they have considerably less power for detecting smaller fold changes next_generation produce tens of millions of sequence_reads during each instrument run and are used to answer_questions central to human_diseases multiple nih consortia encode modencode genomes roadmap epigenome are pursuing mapping of transcription_factor tf_binding and epigenome in multiple tissues and developmental_stages with chip_seq applications analysis of chip_seq involves comparing sequence_reads from a chip sample to an appropriate control sample e g chromatin input to identify genomic_loci regions that exhibit enrichment in the chip sample compared with the input sample although there are algorithms for analyzing data from chip_seq reviewed in there has been little and mostly empirically driven efforts on the design of these experiments identification of biologically_interesting genomic_regions can be hindered by background_noise detection of these regions can be improved by sequencing more reads the total number of reads from a sequencing_experiment is referred to as the sequencing_depth sequencing_depths so_far have been set empirically because of lack of a formal statistical_framework e g the encode consortium suggested using a minimum sequencing_depth of million m mapped_reads for sequence specific tfs however recently concluded with empirical_studies that the regularly adopted sequencing_depth of m reads in humans may not be high enough explored the impact of sequencing_depths of chip samples using saturation analysis this analysis evaluated the effect of sequencing_depth on the number of peaks discovered by identifying peaks from reads sub sampled at varying proportions from the original chip sample the proportion of sub sample peaks that overlap the peaks from the full set is plotted against the sub sample depth when this curve reaches a horizontal asymptote it indicates that the set of detected enrichment sites has stabilized at the current depth although this computational_approach is useful for evaluating the available sequencing_depth of a chip sample it has three major_drawbacks i it is not suited for addressing how many more reads are needed if saturation has not been reached at the available depth e g in a recent encode publication rna_pol which mainly interacts with dna across genes exhibited a nearly linear gain in the number of peaks through m reads with no indication of how many more reads are needed for saturation ii it only evaluates saturation based on the chip sample and discards the control sample and iii it only allows investigating saturation from the point of either a minimum fold enrichment or false_discovery fdr but not both to whom correspondence should be addressed addressing the question of sequencing_depth requires i defining a statistical criterion that can quantify the information_loss of an experiment because of its apparent sequencing_depth and ii determining the sequencing_depth needed to control the information_loss based on a pilot possibly undersequenced dataset from a statistical point_of chip_seq peak_calling procedures can be cast as multiple testing problems because they aim to assess whether data for each candidate locus is supported by the background_noise distribution or the chip signal therefore the information_loss is naturally connected to the concept of the testing power as a result both of the aforementioned issues can be considered within a power calculation framework where the sequencing_depth plays the role of sample_size power computations require modeling distribution of both the background reads and chip signal in a way that reflects the stochastic_nature of read accumulation at each genomic locus as a function of sequencing_depth although a number of models were proposed for locus specific read_counts none of them explicitly accounted for read accumulation considered models with locally poisson distributed background and did not model chip signal proposed a flexible model taking_into the genome_structure and overdispersion however this model used the input sample as a covariate and did not explicitly parametrize the model in terms of sequencing_depths proposed a hierarchical bayesian t mixture_model to identify local concentration of directional reads but did not consider the relationship between read accumulation and sequencing_depth adopted a signal to noise model parameters of which followed some arbitrary prior_distribution to account for intrinsic read bias although such a prior_distribution if estimated could be utilized to model the background distribution at varying sequencing_depths the work ofexclusively focused on the normalization aspect of chip_seq analysis we developed cssp chip_seq statistical_power framework for statistical_power calculation by considering a local poisson_model for the read generation_process we assume that background reads in the chip and the input samples are generated by local poisson processes with shared gamma prior distributions the corresponding gamma parameters are modeled as functions of the local genome_structure including mappability and gc_content the local poisson parameters for the enrichment signals follow convolution of gamma distributions this model preserves the local structure of themodel while keeping the negative_binomial as the marginal signal distribution as in such a local structure is key for capturing dynamics of the counting process for individual genomic locus as a result of increasing sequencing_depths we introduce a conditional power definition that uses the practically used notion of fold_change of chip signal over the control input sample we show with data_driven computational_experiments that our approach can be used to determine i the apparent conditional power for a given sequencing_depth ii the required sequencing_depth to achieve a target power while controlling the fdr at a specified level simulation_experiments based on a deeply sequenced escherichia_coli dataset indicate that power predictions of our model agree well with the observed empirical power using data from pilot_studies we can reliably estimate power for larger sequencing_depths thus the cssp framework has significant implications for designing chip_seq with the multiplexing functionality finally we study the power of multiple encode datasets with varying sequencing_depths our results illustrate that although the power varies_considerably with the signal_to of the datasets the current sequencing_depths have high power for proteindna_interactions with large_effect and are generally adequate for smaller effect_sizes our calculations are further supported by the data quality_metrics proposed by the encode_project we first evaluated our cssp framework in a simulation_study to assess the consistency of our parameter_estimates power and fdr control supplementary_materials section c then we performed sub sampling experiments based on two deeply sequenced datasets e coli fnr chip_seq dataset of myers et_al and mouse gata chip_seq dataset of wu et_al to demonstrate the consistency and power of our cssp framework we used multiple human ctcf chip_seq from the encode consortium to evaluate the impact of laboratory and laboratory specific batch_effects on power estimation finally we investigated eight encode datasets to assess the power of currently available typical chip_seq studies the sequencing_depths of most if not all initial published experiments have been limited by practical_considerations such as cost or instrument availability with decreasing sequencing_costs considerations are shifting from how many sequences should be obtained for a single experiment to how many experiments one can perform in a single lane therefore power calculations are extremely_important for chip_seq we have developed the cssp framework to enable such power calculations this framework can be applied to compute power at a wide_range of sequencing_depths with varying fold_change and minimum intensity thresholds our extensive computational_experiments demonstrated the consistency in predicting power from pilot_data and its practical_implications to the best of our knowledge this is the first model that enables power analysis for chip_seq through an analytical_approach it is worth noting that although our calculations mostly emphasize the sequencing_depth n y other parameters including e and j which indicate the signal_to of the data as well as the data_quality are also important factors of the power analysis these parameters are fixed when comparing datasets obtained under the same experimental_conditions however for comparing datasets with different experimental_conditions such as tf and cell_line effects of data_quality and strengths of enrichment signals should bear equal emphasis our limited investigation of the laboratory and batch_effects indicated that laboratory effects are larger than batch_effects within a laboratory and that pilot_data from the same laboratory would yield more unbiased power prediction than pilot_data from another laboratory although the analytical calculations in the cssp framework depend on the peak_calling procedure implied by our model theoverlap proportion was calculated as the proportion of spp peaks that are among the cssp peaks the spp peaks were constructed by extending each peak of spp by the estimated half window_size in both of the and directions 
