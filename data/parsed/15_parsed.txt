systems_biology a bayesian_approach to targeted experiment_design motivation systems_biology employs mathematical_modelling to further our understanding of biochemical_pathways since the amount of experimental_data on which the models are parameterized is often limited these models exhibit large uncertainty in both parameters and predictions statistical_methods can be used to select experiments that will reduce such uncertainty in an optimal manner however existing_methods for optimal experiment_design oed rely on assumptions that are inappropriate when data are scarce considering model_complexity results we have developed a novel method to perform oed for models that cope with large parameter_uncertainty we employ a bayesian_approach involving importance sampling of the posterior predictive distribution to predict the efficacy of a new measurement at reducing the uncertainty of a selected prediction we demonstrate the method by applying it to a case where we show that specific combinations of experiments result in more precise predictions availability_and source_code is available at computational_models can be used to predict un measured behaviour or system responses and formalize hypotheses in a testable manner to be able to make predictions parameters are required despite the development of new quantitative experimental_techniques data are often relatively scarce consequently the modeller is faced with a situation where large regions of parameter_space can describe the measured data to an acceptable degree this is not a problem when the predictions required for testing the hypothesis which we shall refer to as predictions of interest are well constrained when this is not the case more data will be required optimal experiment_design oed methods can be used to determine which experiments would be most useful in order to perform statistical_inference classical design_criteria are often based on linearization around a best fit parameter set and to whom correspondence should be addressed pertain to effectively constraining the parameters or predictions however when data are scarce considering the model_complexity or the model is strongly non linear such methods are not appropriate this makes investigating the role of parameter_uncertainty in oed a relevant topic to explore we propose a method for experimental_design that overcomes these issues by adopting a probabilistic_approach which incorporates prediction uncertainty our method enables the modeller to target experimental efforts in order to selectively reduce the uncertainty of predictions of interest using our approach multiple experiments can be designed simultaneously revealing potential benefits that might arise from specific combinations of experiments we focus on biochemical_networks that can be modelled using a system of ordinary_differential these models comprise of equations f x t u t p which contain parameters p constant in time inputs u t and state_variables x t given a set of parameters inputs and initial_conditions x these equations can subsequently be simulated measurements y t are performed on a subset and or a combination of the total number of states in the model measurements are hampered by measurement noise while many techniques used in biology e g western_blotting necessitate the use of scaling and offset parameters q we define as p q x which lists all the required variables to simulate the model in order to perform inference and experiment_design an error_model is required for ease of notation we shall demonstrate our method using a gaussian error_model if we consider m time series of length n n n m hampered by such noise we obtain equation for the probability_density of the output data here y t is the true system with true parameters t where i j indicates the sd of a specific data point and k serves as a normalization constant using bayes theorem we obtain an expression for the posterior probability_distribution over the parameters the posterior probability_distribution is given by normalizing the author s published_by this is an open_access the terms of the creative_commons http creativecommons org_licenses which permits unrestricted non commercial use distribution and reproduction in any medium provided the original_work to illustrate our method we apply it to a model of the jak_stat signalling_pathway the model is based on a number of hypothesized steps see the first reaction describes the activation of the erythropoietin_receptor which subsequently phosphorylates cytoplasmic stat x then phosphorylated_stat x dimerises x and is imported into the nucleus x here dissociation and dephosphorylation occurs which are associated with a time delay similar to the implementation given in the original paper the driving input_function was approximated by a spline interpolant while the delay was approximated using a linear_chain approximation x x in order to infer the posterior_distribution data from the paper by swameye et_al both reported in arbitrary_units which necessitates two scaling parameters the initial cytoplasmic concentration of stat is unknown while all other forms of stat are assumed zero at the start of the simulation given the data not all parameters are identifiable we used uniform priors in logspace for the kinetic_parameters and a gaussian nm nm for the initial condition parameter two was bounded between ranges since this parameter was non identifiable from the data we simulated two chains starting at different initial_values up to one million parameter_sets and assessed convergence by visually inspecting differences between batches of samples the uncertainty in model_parameters propagates as an uncertainty in the predicted responses of the state_variables ppds were simulated for all states as well as the summations of states already measured to simulate the ppds the chain of parameter_sets was thinned to samples using equidistant thinning since the error_model in this case is additive gaussian_noise there is no need to explicitly simulate measurement noise this can be taken into account by multiplying the sd of the measurement by see supplementary_materials for more information an example is shown inrevealing the relation between two predictions at different time points for a complete overview of the ppds for all states see the supplementary_materials the relation between the ppds of different states was explored this relation between two states at the indicated time points is shown in more detail in both scatter_plot and d histogram form in the former shows the actual samples from the ppd for one point in time here each dot represents a simulated value for one parameter set from the mcmc chain as shown in the figure these different states are often non linearly related at specific points in time the associated d histogram corresponds to the same information interpreted as probability density considering state as observable and state as prediction while assuming a measurement_accuracy of for x it can be observed that a significant decrease in variance can be attained during the rise of state measuring state at the peak value however results in a smaller variance_reduction a few things can be observed in order for the measurement to be useful there should be a correlation between the measurement and the prediction of interest additionally the uncertainty in both should be large enough since all predictions of state start with an initial condition of zero this implies that the uncertainty at this point is low therefore an additional measurement at t would not yield appreciable variance_reduction which is also reflected by the fact that the svr starts at a value of zero in order to demonstrate the flexibility of our method it was decided to perform oed for a quantity that depends on the model_predictions in a highly non linear fashion namely the time to peak for the concentration of dimerized stat in the nucleus state the time to peak was computed for the state prediction for each parameter set from the posterior parameter distribution we assumed that all states except state are measurable with an accuracy of as potential measurements we also included the two sums of states as measured in earlier experiments the experiment space was sampled using a monte_carlo approach uniformly sampling the experiment space this sampling is shown inwhere the svr is shown for several combinations of two measurements in this figure each axis corresponds to a potential measurement different model outputs potential measurements are separated using grid lines while the relation between the two states at the indicated time points is shown in both scatter_plot and d histogram form the former shows the actual samples from the ppd for one point in time here the dots represent simulated values belonging to different parameter_sets from the mcmc chain in the histogram the colour indicates the number of samples in a particular region which is proportional to the probability density where the different model outputs are numbered numbers to correspond to the first three states whereas and correspond to the sums of states on which the original ppd was parametrized note that each block on each axis corresponds to an entire time series the block corresponding to experiments involving state is shown enlarged in b variance_reduction is computed using the importance sampling method the interval between each pair of lines corresponds to an entire time series the colour value indicates the svr for that specific experiment recall that the original dataset contained measurements of two sums of model states these two observables correspond to outputs and in which indicates that additional measurements on these would provide very little additional variance_reduction interestingly performing the experimental_design for two measurements revealed that the largest reduction in variance could be obtained by measuring state one at an early_and time point this result underlines the benefit of being able to combine multiple measurements in the oed furthermore the analysis clearly revealed that the timing of this first time point is crucial however if accurate timing is not possible in the experiment one could consider measuring state three and one instead here smaller reductions are attained but the timing accuracy required for a a b comparison of two methods for calculating the variance_reduction variance_reduction of the peak time of dimerized stat x with respect to two new measurements a lvr b difference between the variance_reduction computed by means of lvr and importance sampling shown in reasonable reduction is less stringent additionally we investigated how the bounds of the priors on the non identifiable kinetic rates affected our experimental_design by widening them this revealed that the evrs obtained when measuring state or in combination with state were more robust for more information see the supplementary_materials since both error models in this case are gaussian the same analysis can be performed using the lvr which for t samples is about fold faster the resulting sampling is shown in qualitatively the results agree well with those inrevealing its applicability as an initial sampling step information gained from an initial lvr sweep can subsequently be used to sample only relevant regions of the experiment design_space another example can be found in the supplementary_materials 
