data_and a croc stronger than roc measuring visualizing and optimizing early retrieval motivation the performance of classifiers is often assessed using receiver_operating roc or ac accumulation curve or enrichment curve curves and the corresponding areas under the curves aucs however in many fundamental problems ranging from information_retrieval to drug_discovery only the very top of the ranked_list of predictions is of any interest and rocs and aucs are not very useful new metrics visualizations and optimization tools are needed to address this early retrieval problem results to address the early retrieval problem we develop the general concentrated roc croc framework in this framework any relevant portion of the roc or ac curve is magnified smoothly by an appropriate continuous transformation of the coordinates with a corresponding magnification factor appropriate families of magnification functions confined to the unit square are derived and their properties are analyzed together with the resulting croc curves the area under the croc curve auc croc can be used to assess early retrieval the general framework is demonstrated on a drug_discovery problem and used to discriminate more accurately the early retrieval_performance of five different predictors from this framework we propose a novel metric and visualizationthe croc exp an exponential transform of the roc curveas an alternative to other methods the croc exp provides a principled flexible and effective way for measuring and visualizing early retrieval_performance with excellent statistical_power corresponding methods for optimizing early retrieval are also described in the appendix availability datasets are publicly_available python code and command_line utilities implementing croc curves and metrics are available atone of the most widely used tools to assess the performance of a classification or ranking algorithm in statistics and machine_learning is the receiver_operating roc_curve plotting true to whom correspondence should be addressed versus false_positive together with the corresponding area_under auc metric however in many applications ranging from information_retrieval to drug_discovery the roc_curve and the area under the curve auc metric are not very useful this is because the total number of objects to be classified or ranked such as web_pages or chemical molecules tends to be very large relative to the number of objects toward the top of the list that are practically useful or testable due to for instance financial_constraints specifically consider a typical drug_discovery situation where one is interested in discovering molecules that may be active among a library of molecules by computational virtual_screening methods such as docking or similarity_search depending on the financial conditions and the details of the corresponding experimental_setup experimentalists may be able to test in the laboratory for instance only the top hits on the list in such conditions the majority of the roc_curve is without much relevance and the auc is useless only the early portion of the roc_curve is relevant furthermore the precise ranking of the molecules particularly for the bottom molecules is also of very minor interest similar observations can be made in many other areas ranging from fraud detection to web_page retrieval what one is really interested in across all these cases is the notion of early enrichment recognition retrieval having as many true_positives as possible within the list of top hits to further drive this point consider the following three cases from truchon and bayly corresponding to an algorithm that either ranks half the positive candidates at the top of the list and half at the bottom distributes the positive candidates uniformly throughout the list or ranks all the positive candidates exactly in the middle of the list all three cases yield an auc of although if only the top few hits can be experimentally tested case is clearly better than case which in turn is better than case good early recognition metrics and visualization_tools ought to easily discriminate between these cases and rank them appropriately several metrics have been suggested in the literature to address the early retrieval problem but none seems entirely satisfactory some metrics lack smoothness and require setting arbitrary thresholds including looking at the derivative of the smoothed roc_curve at or near the origin or looking at the roc_curve and its area over the intervalfor some threshold t e g t however as we shall see methods with hard threshold cutoffs tend to be less statistically powerful than methods without threshold cutoffs because they discard meaningful differences in the performance ofpage 
