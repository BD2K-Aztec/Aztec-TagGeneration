structural_bioinformatics redundancy weighting for better inference of protein structural_features motivation structural knowledge extracted from the protein_data pdb underlies numerous potential functions and prediction_methods the pdb however is highly biased many proteins have more than one entry while entire protein_families are represented by a single structure or even not at all the standard solution to this problem is to limit the studies to non redundant subsets of the pdb while alleviating biases this solution hides the many to many relations between sequences and structures that is non redundant datasets conceal the diversity of sequences that share the same fold and the existence of multiple_conformations for the same protein a particularly disturbing aspect of non redundant subsets is that they hardly benefit from the rapid pace of protein structure_determination as most newly solved structures fall within existing families results in this study we explore the concept of redundancy weighted datasets originally suggested by miyazawa and jernigan redundancy weighted datasets include all available structures and associate them or features thereof with weights that are inversely proportional to the number of their homologs here we provide the first systematic_comparison of redundancy weighted datasets with non redundant ones we test three weighting_schemes and show that the distributions of structural_features that they produce are smoother having higher entropy compared with the distributions inferred from non redundant datasets we further show that these smoothed distributions are both more robust and more correct than their non redundant counterparts we suggest that the better distributions inferred using redundancy weighting may improve the accuracy of knowledge_based and increase the power of protein_structure prediction_methods consequently they may enhance model driven molecular_biology mining the riches of experimentally_determined data in the protein_data pdb has been a major source of structural knowledge over the past four decades in a reverse_engineering like fashion it allows the derivation of rules and methods for the prediction of secondary_structure solvent_accessibility and trans membrane regions as well as knowledgebased potentials these methods and potentials have had a considerable impact on our understanding of the protein universe and accelerated progress in biology chemistry and medicine this study aims to enhance these data_mining efforts by attacking their major_obstacle data redundancy the underlying premise behind data_mining of protein_structures is that recurring patterns may result from physical_aspects of protein_folding and stability e g the hydrophobic_effect however the data which are available for mining are not uniform samples of sequence and structure spaces certain folds e g tim barrels and g proteincoupled receptors are far more abundant than others in genomesfor some suggestions of why it is so the pdb content is further skewed by research_interests of the contributing experimentalists and by methodological constraints this bias often referred to as the pdb redundancy may amplify or diminish the signal of recurring patterns for example the stabilizing_effect of the beta alpha_beta supersecondary structure may be overestimated because of the abundance of folds that include it e g tim barrels the common solution to data redundancy is to use a nonredundant subset of the pdb composed of family representatives pioneered this solution using a membered subset of the high_quality entries of the pdb leaving out homologs with sequence_identity of or higher a rather promiscuous threshold by current_standards this approach has been adopted by numerous studies and became the fields norm with publicly_available and standardized tools for data culling yet notwithstanding the evident utility of nonredundant pdb subsets they have inherent_limitations in scalability and descriptive power first and foremost they do not benefit from the rapid_growth of the pdb because almost all new entries are mapped to already known folds more importantly non redundant datasets conceal much of the complexity of protein universe specifically they hide the compatibility of diverse sequences with the same fold and the flexibility of protein_structures our working hypothesis is that this oversimplified perspective manifests itself in artificially bumpy distributions of the measurable features an important alternative was presented more than a decade_ago by who weighted structures in their knowledge_based in those studies they considered all the pdb structures of sufficient quality and length yet assigned non uniform weights to protein_chains so that the weights of chains with many homologs are scaled down thus all the data are considered yet biases are alleviated somewhat surprisingly we are unaware of any recent_studies that use this approach further to the best of our knowledge no study has yet compared its performance with the standard representative subset approach interestingly the redundancy which is removed from structural datasets is valuable when investigating families of homologous_sequences there evolutionary_conserved patterns characterize a family and deviations from these patterns shed light on the uniqueness of specific members the distribution of sequence_similarities across a family is typically uneven that is there may be subsets of sequences that are more closely_related this might bias the analysis toward patterns that appear in such highly_similar subsets in this context however a non redundant subset i e one without recognizable similarities would consist of a single_sequence and be devoid of any information instead scholars have successfully used various weighting_schemes that downscale contributions from large subsets of sequences and references therein most notably for multiple_sequence and sequence_search structural data_mining is a different computational task most importantly it does not focus on a single protein_family but rather must deal with multiple families and account for their varying sizes nonetheless the success of including more and even all available proteins in the context of search and alignment tasks suggests that similar approaches may be valuable in structural data_mining as well our study revisits the redundancy weighting approach and provides the first systematic_assessment of its correctness and robustness to this end we compare interatomic distance distributions a central component in knowledge_based sampled from either non redundant or redundancy weighted datasets for the sake of completeness we also consider distributions that were sampled from an unweighted redundant dataset we estimate the complexity of these distributions by their entropy and observe that the redundancy weighted datasets have higher entropy than their non redundant counterparts we further demonstrate that the higher entropy distributions are more correct and robust our observations suggest that structure_prediction could benefit considerably from training on redundancy weighted datasets rather than on non redundant ones this in turn can improve our understanding of the forces that shape the protein_structure universe distributions of interatomic distances lie at the heart of knowledgebased potentials and as such are among the most studied features in pdb data_mining here we compare data_mining of such distances from three types of datasets redundant non redundant and redundancy weighted the redundant training and test datasets include all proteins that were solved before and after the end of with a weight which is inversely proportional to its redundancy rws considers redundancy at the chain level that is all the features of a given chain have the same weight which is inversely proportional to the number of chains with which it has considerable sequence_similarity and coverage schematically illustrated as thicker lines in contrast rwf considers redundancy at the feature level two features are considered redundant if they are part of an alignment of high identity level and are both complete and continuous for example the query feature instance shown in the illustration is given a weight of as its only counterpart is hit homology subset sizes for the polypeptide structures in the training black and test white sets respectively at a resolution or better the training and test nonredundant datasets are subsets of the redundant ones containing a single representative from each set of homologous structures finally the three pairs training and test of redundancy weighted datasets include the same structures as their redundant counterparts but the contributions of these structures or features thereof are weighted the three redundancy weighting_schemes see section and are i a scheme that assigns a single weight to each polypeptide chainand all the feature instances computed from its structurebased on the number of its homologs rws ii a scheme that computes a per feature weight based only on homologs that cover all the positions in a feature rwf and iii the algebraic sample weighting_scheme of miyazawa and we focus on distributions of cc distances as a proof_of upper panel shows training and test distributions of c distances between three types of amino_acid located positions apart along the sequence tryptophan w and histidine h left tryptophan and tyrosine y center and tryptophan and leucine l right we compute the distributions using the standard non redundant scheme nr or a redundancy weighting_scheme rwf the insets inc depict the similarity of these distributions we assess the performance of a weighting_scheme w by two quantities correctness which measures how similar is ws test distribution to the non redundant distribution over the training_set insets top row and robustness which measures how similar are ws training and test distributions insets diagonal see section for formal definitions figures e and f shows the correctness of cc distance distributions over all pairs of amino_acids when using a nonredundant dataset and a redundancy weighted one predictably correctness for both schemes is lower for amino_acid with a relatively small number i e hundreds of samples top left corner of both heat maps compared with pairs with many more i e tens and hundreds of thousands samples seefor sample counts of each amino_acid pair the spearmans rank correlation between the number of samples and the correctness of nr and rwf is p evidently the distance distributions derived using the redundancy weighted scheme are for the most part more correct than those inferred using the non redundant scheme of distributions one for each amino_acid pair redundancy weighted distributions are more correct moreover the improvement in correctness or the correctness gain is greater for amino_acid with lower number of samples spearmansweighting schemes for all pairs of amino_acids is shown as a heat map entries corresponding to distributions shown in the upper panel are highlighted black boxes correctness gain the difference between the correctness of rwf and nr is positive g blue shades for the vast_majority of amino_acid indicating an improvement obtained using the former scheme the one tailed paired sample wilcoxon_signed p value is shown on the top rank correlation p for which as we indicated above the correctness is poorer a more complete picture is presented in which compares the standard non redundant scheme with the four non standard ones over three performance_criteria correctness entropy and robustness as expected the non redundant c i c i distributions are significantly more correct one tailed paired sample wilcoxon_signed p and associated with greater entropy p than the corresponding redundant distributions this agrees with the common practice of preferring non redundant datasets to redundant ones yet importantly all three redundancy weighting_schemes perform significantly better than the non redundant scheme in terms of correctness and robustness and obtain higher entropy scores for example the median improvement in correctness using rws compared with nr is p finally compares the performance of all weighting_schemes over c distance distributions of residues and amino_acids apart in all these cases and consistent with the results for the c i c i distributions all three redundancy weighting_schemes perform better in terms of their correctness entropy and robustness than the standard non redundant and redundant alternatives among the redundancy weighting_schemes rwf is the most correct in out of amino_acid distances and mj significantly more correct than rws for c atoms and amino_acids apart rwfs entropy values are the greatest for the longer amino_acid ranges and mjs for the shorter ones and consistently mj is the most robust followed by rwf comparing the non redundant and redundant distributions reveals that the latter is always more robust whereas the former is more correct in all but the longest range where redundant is more correct p and obtains greater entropy values in all but the shortest range these results show that the redundancy weighting performs better than the widely used non redundant datasets in all these measures the dominant approach for data_mining of the pdb is to extract the knowledge from a relatively small subset of non homologous structures and consider their homologs all other structures as redundant and thus non informative although this approach circumvents much of the inherent biases in the pdb it also artificially reduces the variability of the structural landscape analternative approach which we term here redundancy weighting considers all available structures but assigns them or features thereof lower weights proportionally to the number of homologs they have in the dataset redundancy weighting originally proposed by miyazawa and jernigan almost two decades_ago has been rarely used since and to the best of our knowledge never been systematically benchmarked against the standard approach here we compare the correctness complexity and robustness of feature distributions which were inferred using non redundant and redundant datasets and three redundancyweighting schemes the algebraic sample weighting of miyazawa and jernigan mj as well as our novel rws and rwf weightings to this end we quantify and compare the correctness complexity and robustness of distance distributions which were derived from training and test datasets according to these schemes our most significant contribution is demonstrating that the three redundancy weighting_schemes outperform the standard non redundant approach in all tested metrics the mj scheme which is the most robust is probably not scalable enough for practical use this scheme requires an eigenvalue decomposition of an all against all similarity matrix as the pdb is quickly approaching the structures milestone such decomposition becomes challenging both in terms of the computational requirements space and time and the numerical stability rwf which is the most correct scheme has a milder limitation it requires recomputing of weights for each structural_feature the rws scheme is less accurate and robust than the other two but does not suffer from these limitations thus it may serve as a simple off_the general weighting_scheme which performs better than non redundant datasets here we focused on a relatively small set only a few thousands of the pdbs most accurately solved structures with resolution better than a focusing on this set had several advantages most importantly the computational_cost of exploring alternative weighting_schemes is tractable and in particular we could easily calculate the eigenvalue decomposition needed for the mj weighting_scheme notice that homology is not too common within this set which includes singletons see thus one could expect that refining the weighting_scheme will not have any impact on the accuracy and robustness when inferring structural_features from the set however it does thus we believe that such weighting_schemes can similarly benefit others even more so when considering larger subsets of the pdb culled using more lax experimental quality thresholds while most residueresidue_contact potentials e g miyazawa and consider un directional residue pairs thus combining pairs of two same residues with different orders to a single unique pair we chose to focus on directional pairs to increase the dynamic range of the explored features notably the trends shown inare preserved when undirectional pairs are considered data not shown sample weighting rws per sequence redundancy weighting rwf per feature redundancy weighting importantly our study shows that the gain in accuracy and robustness is proportional to the rarity of the studied feature figs and current applications of pdb data_mining e g derivation of pairwise potentials and secondary_structure are dominated by highly_prevalent features e g contacts between specific_residues and the three major secondary_structure however in more subtle applications e g multi body potentials and fragment prediction the number of relevant_features grows while their prevalence in the non redundant dataset drops we speculate that shifting to the redundancy weighting paradigm may be essential for the advancement of computational_structural beyond pairwise potentials and prediction of simple features although two of the redundancy weighting_schemes presented here are already useful this study is mostly a proof_of a promising route for improvement is to take advantage of rapid structural search_methods and replace the currently used sequence_alignments by more reliable and sensitive structural_alignments another possible direction is to focus on domains rather than peptide chains which often harbor several repeating domains e g zn fingers and are thus redundant by nature finally the weighting_scheme may apply some evolutionary model to gain better estimate of the interdependencies of homologous_proteins in a wider context redundant datasets are abundant in other domains of knowledge e g genomics natural_language and computer vision while the current work focuses on protein_structure datasets we hope insights obtained in this domain can have impact on data_mining in other unrelated ones 
