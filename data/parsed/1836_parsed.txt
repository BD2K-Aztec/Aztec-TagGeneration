genetics_and fish fast and accurate diploid genotype_imputation via segmental hidden_markov motivation fast and accurate genotype_imputation is necessary for facilitating gene_mapping studies especially with the ever increasing numbers of both common and rare_variants generated by high_throughput sequencing_experiments however most of the existing imputation approaches suffer from either inaccurate results or heavy computational demand results in this article aiming to perform fast and accurate genotype_imputation analysis we propose a novel fast and yet accurate method to impute diploid genotypes specifically we extend a hidden_markov that is widely used to describe haplotype structures but we model hidden_states onto single reference haplotypes rather than onto pairs of haplotypes consequently the computational_complexity is linear to size of reference haplotypes we further develop an algorithm merge and recover mar to speed up the calculation working on compact_representation of segmental reference haplotypes the mar algorithm always calculates an exact form of transition_probabilities regardless of partition of segments both simulation_studies and real_data demonstrated that our proposed method was comparable to most of the existing popular_methods in terms of imputation_accuracy but was much more efficient in terms of computation the mar algorithm can further speed up the calculation by several folds without loss of accuracy the proposed method will be useful in large_scale imputation studies with a large number of reference subjects availability the implemented multi threading software fish is freely_available for academic use at https sites google com site lzhangho mepage fish contact genotype_imputation refers to a process in which missing genotypes at un typed markers in a test sample are statistically inferred by knowledge of genotypes observed at the same markers in a reference_sample the principle underlying genotype_imputation is that modern human_genomes share segments of haplotypes with each other as reflected by linkage_disequilibrium ld patterns imputed genotypes have been widely used to fill sporadic missing genotypes to integrate_multiple studies with different genotyping_platforms into meta_analysis and to finemap causal but un typed disease_loci genotype_imputation has significant potential to greatly enhance our capacity to integrate and extend the scope of current existing datasets at no additional expense consequently it has become a standard toolkit in largescale genetic_association and this has facilitated the discovery of a remarkable number of genetic_loci responsible for a variety of complex_traits and diseases a variety of statistical_methods including mach impute versions and beagle and others have been developed and used widely for genotype_imputation these methods provide_excellent accuracy for imputing common_variants minor_allele maf derived from genomewide_association however as next_generation is getting mature and more widely_applied an increasing number of less common maf and rare_variants maf have been uncovered it has been hypothesized that these less common and rare genetic_variants represent another potential mechanism by which variations in the human_genome influence complex_diseases consequently it has become increasingly important to be able to impute fast and accurately this increasing number of these variants in existing genome_wide in order to facilitate gene_mapping studies and to study a variety of genomic structures the accuracy of genotype_imputation is influenced greatly by the size of reference_panel larger reference samples increase imputation_accuracy when imputing common_variants reference_panels of small to moderate_size e g may be sufficient to attain an acceptable level of imputation_accuracy when imputing less common or rare_variants however the accuracy of imputation will be considerably_lower than that for common_variants with reference_panels of small to moderate_size consequently it is critical to use an expanded reference_panel when imputing less common or rare_variants in order to attain an acceptable level of accuracy fortunately a continuously increasing resource of reference datasets based on next_generation e g genomes_project is becoming publicly_available eventually these well validated datasets will provide a comprehensive set of reference samples that can support accurate genotype_imputation of an extensive range of genetic_variants from common to rare ones one practical limitation of existing imputation_methods is that they can be computationally_intensive when operating with large reference samples for example both mach and impute have quadratic computational_complexity to the number of reference haplotypes used in the hidden_markov hmm a level of complexity which actually prohibits them from making full use of all available reference haplotypes in practice both mach and impute version compensate for this limitation by selecting only a subset of reference haplotypes to use for imputation obviously this approach may cause a potential loss of accuracy under certain conditions and this loss of accuracy may become particularly severe when imputing less common and particularly rare_variants alternatively they both have a haploid model implementation with linear complexity which is achieved by imputing on pre phased haplotypes rather than diplotypes nonetheless phasing diplotypes into haplotypes introduces additional computation demanding as well as phasing uncertainty in the context of a growing number of large sequencing_datasets it is becoming critically_important to develop computationally_efficient imputation_methods that can use large reference datasets in order to retain imputation_accuracy particularly for rare_variants at a reasonably high_level though a variety of alternative solutions have been proposed they fall short regard to either accuracy or extensive computational demand both mach and impute are based on li and stephens haploid hmm their heavy computational demand in imputing diplotypes is attributable to modeling hidden_states on pairs of reference haplotypes rather than on single haplotypes in the present article we propose an alternative and efficient model to impute diplotypes with linear complexity basically we extend the same hmm but we model hidden_states on single haplotypes so that the computational_complexity is linear to the size of reference haplotypes we take into account unphased genotypes through marginalization and decomposition in addition we develop an efficient computing algorithm to further speed up the execution of the proposed method through simulation as well as real_data we show convincingly that the proposed method is much faster than existing_methods and yet is comparable in terms of imputation_accuracy a typical genome_wide imputation analysis for thousands of individuals using the largest reference_panel derived from the genomes_project and routine computing devices can be accomplished within only a few hours with the method we developed in this section we investigated the performance of the proposed method namely fish as well as compared it with several existing popular_methods through simulated_and in this article we have proposed a new method for performing diploid genotype_imputation based on the hmm we have also developed an algorithm mar for efficient execution of the proposed method our method is comparable to most of the existing popular_methods in terms of imputation_accuracy and gdr and is much preferable in terms_of we model hidden_states on single reference haplotypes rather than on pairs of haplotypes consequently the computational_complexity reduces from quadratic to linear to the number of reference haplotypes to achieve the linear complexity we define the equation which assumes the independence ofthe random mating assumption this independence equation holds as long as the total reference haploytypes serve as the entire population from which the test subject is sampled in practice it will hold approximately under large reference sample_size a condition for which our method was proposed the computational improvement is qualitatively_and dramatic we take into account haploid genotype uncertainty at each marker by weighted_sum of both possible configurations our simulation_studies as well as real_data showed no significant loss of accuracy compared to conventional methods modeled on pairs of reference haplotypes in the context of high_throughput sequencing_datasets an urgent priority for genotype_imputation is to improve computational_efficiency several alternative solutions have been proposed one of which is to pre phase genotypes in the test sample into haplotypes then to impute on the inferred haplotypes this reduces the computational_complexity so that it is linear to the number of reference haplotypes however haplotype_phasing itself is a computation demanding process in large_scale settings moreover the success of imputation on phased haplotypes relies largely on the availability and accuracy of statistical_inference of haplotypes and may lose accuracy in certain conditions though recent_developments on haplotype_phasing may ease this limitation compared to the pre phasing approach our proposed method does not require haplotypes to be known it has another potential to impute on data types that could not be pre phased though we did not consider that situation in the current study another recent development includes imputing via matrix operation however this method may cause some potential loss of accuracy though it may lead to increased speed of computation equation provides an approximation of between segmental transition probability calculation when operating on long segments in which recombination_events dominate probability calculations such approximations may provide_reasonable accuracy because individual haplotypes within a block receive the same probabilities regarding recombination when operating on short segments in which initial haplotype probability dominates probability calculations however the loss of accuracy may become severe an ideal requirement would be that the way to split segments will influence only computational_efficiency but not the imputation_accuracy the developed mar algorithm meets this requirement which allows us to optimize the minimal computation without concerns on accuracy the improvement of computation by compact_representation depends on how reference haplotypes could be merged and essentially on maf and ld patterns suppose that the total l markers are partitioned into l s segments and there are on average n s blocks within segments the computational_complexity without compact_representation is c l r for a single individual and that with compact_representation isthat the improvement in computation was highly_correlated with this ratio in summary we have proposed a new statistical_model and method for fast and accurate genotype_imputation our method is suitable for large_scale dataset analyses the implemented software fish is publicly_available for academic use 
