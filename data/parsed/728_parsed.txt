bigbwa approaching the burrows_wheeler aligner to big_data technologies bigbwa is a new tool that uses the big_data technology hadoop to boost the performance of the burrowswheeler aligner bwa important reductions in the execution times were observed when using this tool in addition bigbwa is fault tolerant and it does not require any modification of the original bwa source_code burrowswheeler aligner bwa is a very popular software for mapping sequence_reads to a large reference_genome it consists of three algorithms bwa backtrack bwa_sw and bwa mem the first algorithm is designed for short illumina sequence_reads up to bp whereas the others are focused on longer_reads bwa mem which is the latest is preferred over bwa_sw for bp or longer_reads as it is faster and more accurate in addition bwa mem has shown better performance than other several state of art read_aligners for mapping bp or longer_reads sequence_alignment is a very time consuming process this problem becomes even more noticeable as millions and billions of reads need to be aligned for instance new sequencing_technologies such as illumina hiseqx ten generate up to billion reads per run requiring more than days to be processed by bwa on a single core machine therefore ngs professionals demand scalable solutions to boost the performance of the aligners in order to obtain the results in reasonable time in this article we introduce bigbwa a new tool that takes_advantage of hadoop as big_data technology to increase the performance of bwa the main advantages of our tool are the following first the alignment process is performed in parallel using a tested and scalable technology which reduces the execution times dramatically second bigbwa is fault tolerant exploiting the fault tolerance capabilities of the underlying big_data technology on which it is based and finally no modifications to bwa are required to use bigbwa as a consequence any release of bwa future or legacy will be compatible with bigbwa performance bigbwa was tested using data from the genomes_project for details measurements were performed on a five node aws cluster with cores per node intel_xeon e at ghz cpus running hadoop detailed information about the experimental_setup is provided in the supplementary_material performance results for bigbwa and the other evaluated tools only take into considerationall the datasets were extracted from the genomes_project highlighted the best tool for a particular number of cores for fair comparison with the other tools bigbwa obtains these results using bwa version tool versions pbwa and seal highlighted the best tool for a particular number of cores these results were obtained using bwa version the alignment process time which was calculated as the average of runs per data point after one warm up execution shows a comparison with seal and pbwa for the bwa backtrack algorithm in this case bigbwa clearly outperforms these tools especially when the number of cores used is high in this way speedups of were reached with respect to the sequential case using the original bwa tool as reference it can also be observed that the scalability of seal is worse caused by the overhead introduced by pydoop with respect to the use of jni performance of bwa mem is shown in it was measured using only bwa threaded version and bigbwa because seal and pbwa do not support this algorithm we have also included results for a hybrid version that uses bigbwa in such a way that each mapper processes the inputs using bwa with two threads results show that with a small number of cores bwa behaves slightly better than bigbwa note that bwa is limited to execute on just one cluster node and therefore we cannot provide results using more than cores considering cores bigbwa is always the best solution but due to the memory assigned per map task in our cluster configuration only concurrent tasks can be executed on one node in this way bigbwa always distributes the tasks between two nodes when using cores in addition bigbwa shows good behavior in terms of scalability for all the datasets considered executing up to faster than the sequential case additional performance results are shown in the supplementary_material correctness we verified the correctness of bigbwa by comparing its output_file with the one generated by bwa differences range from to on uniquely_mapped mapping quality greater than zero similarly to the differences shown by the threaded version of bwa with respect to the sequential case 
