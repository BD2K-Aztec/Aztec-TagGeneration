genetics_and joint haplotype_phasing and genotype_calling of multiple_individuals using haplotype informative reads motivation hidden_markov based on li and stephens model that takes_into chromosome sharing of multiple_individuals results in mainstream haplotype_phasing algorithms for genotyping_arrays and next_generation ngs_data however existing_methods based on this model assume that the allele count_data are independently observed at individual sites and do not consider haplo type informative reads i e reads that cover multiple heterozygous sites which carry useful haplotype_information in our previous work we developed a new hidden_markov to incorporate a two site joint emission term that captures the haplotype_information across two adjacent sites although our model improves the accuracy of genotype_calling and haplotype_phasing haplotype_information in reads covering non adjacent sites and or more than two adjacent sites is not used because of the severe computational_burden results we develop a new probabilistic_model for genotype_calling and haplotype_phasing from ngs_data that incorporates haplotype_information of multiple adjacent and or non adjacent sites covered by a read over an arbitrary distance we develop a new hybrid markov_chain algorithm that combines the gibbs_sampling algorithm of hapseq and metropolishastings algorithm and is computationally_feasible we show by simulation and real_data from the genomes_project that our model offers superior_performance for haplotype_phasing and genotype_calling for population ngs_data over existing_methods low_coverage of multiple samples is an efficient strategy to profile genetic_variations in a population because low sequencing_depth makes it affordable to sequence a larger number of samples the high_accuracy of genotype_calling and haplotype_phasing of such a design_strategy is achieved by many innovative developments in the field of bioinformatics and statistical genetics as demonstrated by the genomes_project for common_variants the accuracy of genotype_calling from low_coverage is comparable with that from genotyping_arrays although haplotype_phasing was not the primary goal of the genomes_project the linkage_disequilibrium ld based refinement method thunder used in the project to refine genotype_calls from individual subgroups also phases genotypes into haplotypes thunder and most ld based genotype refinement algorithms is based on the li and stephens model this model takes_into chromosome sharing among multiple_individuals and can be efficiently optimized by hidden_markov hmm based_algorithms this model was traditionally applied to array based genotype data in which at each site it only observed the unphased genotype hmm based_methods can phase the haplotypes of multiple_individuals simultaneously through a population_genetics model that models the chromosome sharing among these individuals with a modification of single site emission probability thunder extended this approach to phase population next_generation ngs genotype data by comparing with the illumina omni m genotyping array data that were phased by additional family samples thunder was reported to make one switch error in about every kilobytes kb however thunder assumes that the allele count_data are independently observed at each site and does not consider haplotype informative reads i e reads that cover multiple heterozygous sites which carry useful haplotype_information in our previous work we developed the hmm_based on the li and stephens model to incorporate a two site joint emission probability that can capture the haplotype_information across two adjacent sites our method which is implemented in the software_package hapseq has achieved a reduction of error_rates compared with thunder for genotype_calling of the sequencing_data from the genomes_project still haplotype_information in sequencing_reads was not fully used in our previous work haplotype_information in reads that cover more than two adjacent sites is not used because of severe computational_burden of higher_order hmms this throws away valuable haplotype_information especially because newer sequencing_technologies can offer longer_reads in addition paired_end can cover non adjacent sites and thus offer haplotype_information over multiple adjacent and or nonadjacent sites paired_end are routinely used in sequencing_projects in aiding read_mapping and assembly it would be important to develop advanced statistical_methods that can fully use the haplotype_information in reads to whom correspondence should be addressed notably a probabilistic haplotype_phasing model hash was proposed byfor a single individual using whole_genome sequencing_reads their approach was termed haplotype_assembly because of its resemblance to the traditional fragment assembly problem traditional fragment assembly generates a single consensus_sequence out of a set of reads from a single individual ignoring the diploid nature of the human_genome bansal et_al s haplotype_assembly was to generate a pair of consensus_sequences out of a set of reads from a diploid individual their model is based on the haplotype likelihood of sequencing readsthe probability of a haplotype pair given the sequencing_reads with the assumption of the uniform prior on the space of haplotypes this probability is proportional to the probability of reads given the haplotype pair a metropolishastings mh algorithm was proposed to sample haplotype pairs in which moves are flipping of substrings of the haplotypes they estimated the switch error_rate of haplotypes inferred for a genome sequenced by x sanger reads was however their method assumes that genotypes are readily known and it requires highsequencing coverage thus it is not applicable to low_coverage in which read_counts are sparse and joint genotype_calling and haplotype_phasing are essential for high_accuracy in addition with the assumption of the uniform prior their method ignores the haplotype_information contained by other individuals and or reference haplotypes another notable work is by their hap seq not our program hapseq method extended the haplotype_assembly approach by incorporating population information their haplotype likelihood was divided_into two independent parts the probability of sequencing of reads given the haplotype pair which is similar to that used in hash and the probability of the haplotype pair given the set of reference haplotypes which can be calculated using the hmm similar to the hmm in thunder hapseq designed a dynamic_programming to find a haplotype pair to maximize the haplotype likelihood their simulation_results showed that the haplotype inferred from such model had lower switch error_rates than those obtained from impute v the method ofcan be used for low_coverage but still assumes that the genotypes at each site are already known essentially they extended the li and stephens model into higher_order markov_models and thus their method incurs a computational_complexity of o v for just running a viterbi pass for phasing one individual where v is the maximum number of sites spanned by reads their approach is impractical if v is large unfortunately paired_end are commonly used in real sequencing_projects as such reads generally span a large number of sites to avoid this potential problem had to split a long_read to the multiple reads that each span only three heterozygote sites obviously this approach is not optimal as it does not fully use the haplotype_information of reads that cover a large number of sites in this work we develop a fully probabilistic_model for joint genotype_calling and haplotype_phasing that incorporates the joint_distribution of two or more sites covered by a read over an arbitrary distance our model integrates elements of the population haplotype likelihood in thunder hapseq and the read haplotype likelihood in hash each capturing complementary haplotype_information because both methods are markov_chain mcmc based we develop a combined mcmc method that embeds a mh procedure into a gibbs_sampling algorithm specifically in each iteration we first use the thunder hapseq hmm to jointly perform genotype_calling and haplotype_phasing and then use the mh algorithm to sample haplotypes of each individual according to the likelihood_based on sequencing_reads and reference haplotypes our method is implemented in the hapseq program and is evaluated together with thunder and hapseq by using simulation and real_data we developed a new approach for haplotype_phasing and genotype_calling from sequencing_data of a set of population samples we designed an mh flipping algorithm that can be embedded into traditional gibbs_sampling algorithms based on the li and stephens hmm_model using simulated_and we showed that our new method can greatly improve the accuracy of haplotype_phasing over current state of the art methods in the genomes_project phase data our hapseq method_produces longer sef haplotype_blocks than thunder although the primary goal of introducing the mhflipping procedure is to improve haplotype_phasing we found that this technique also improves genotype_calling accuracy accurate haplotype_phasing will have broad impacts on genomic and genetic research_areas first reconstructing long haplotype_blocks in reference_panel will improve the accuracy of genotype_imputation second long haplotype_blocks will help haplotype_based genetic_association third accurate haplotype_phasing will produce more insights into population_genetics inferences this work is one of the first to prove the feasibility of incorporating haplotype_information over multiple sites in ultra long_reads and long insert paired_end for phasing sequencing_data with improved accuracy this provides additional methodological support for the ultra low_coverage design in our simulation_studies we only used the read_length of and bp and the fixed insert_size of and bp for the genomes_project chromosome data the insert_size varies and the portion of the proportion of r and r reads also varies across different regions for the chromosome the proportions of reads covering two sites and at least three sites are and for the ceu samples and and for the yri samples respectively for the major_histocompatibility region the proportions of reads covering two sites and at least three sites are higher and for the ceu samples and and for the yri samples respectively the performance read cover and span distributions in the genomes_project datasets of the proposed method for such regions is expected to be further improved therefore more studies are needed to show how the accuracy of haplotype_phasing and genotype_calling is affected by the length of reads the length of inserts and the proportion of r and r reads using our newly_developed it will be future work to conduct extensive simulations including the simulation of reads with varied insert_sizes to investigate the optimal_design strategies in the mh sampling we proposed the new haplotype pair as a single crossover of the current haplotype pair and chose the recombinant point with the probability that is proportional to a weight we defined the weight as the function of the difference of the number of sequencing_reads that are in conflict with the current haplotype pair and the proposed haplotype pair although we also used the uniform weight and found the results from the uniform weight to be just slightly worse than the proposed weight it is not clear whether the proposed weight is optimal we will investigate this with more simulations in the future to investigate whether the single crossover is sufficient for convergence of the mh sampling we ran hapseq c c and c iterations for the mh sampling where c is the number of heterozygote sites of that individual we found the results from c are similar to those obtained from c and c in addition we found the acceptance ratios from c c and c are similar indicating it is sufficient for convergence 
