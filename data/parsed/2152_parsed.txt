sequence_analysis hadoop bam directly manipulating next_generation data in the cloud hadoop bam is a novel library for the scalable manipulation of aligned next_generation data in the hadoop distributed computing framework it acts as an integration layer between analysis applications and bam_files that are processed using hadoop hadoop bam solves the issues related to bam data access by presenting a convenient api for implementing map and reduce functions that can directly operate on bam records it builds on top of the picard sam jdk so tools that rely on the picard api are expected to be easily convertible to support large_scale distributed_processing in this article we demonstrate the use of hadoop bam by building a coverage summarizing tool for the chipster genome_browser our results show that hadoop offers good scalability and one should avoid moving data in and out of hadoop between analysis steps availability available under the open_source mit_license at http sourceforge net_projects hadoop bam next_generation ngs technologies_provide unprecedented_opportunities for life_science research in order to exploit this potential to its full extent new computational_approaches are needed for the efficient processing of large_datasets nearly all ngs applications rely on sequence_alignment as the first analysis step the alignment data is commonly stored in the standardized compact and indexed bam binary alignment map format which is then used for further analysis such as snp_genotyping peak_calling or detecting differential_gene as data sizes increase more rapidly than processing power and diskread speed many of these bioinformatics tasks have been ported to utilize the map reduce distributed_processing framework existing solutions such as gatk seqware query engine o and seal provide useful parts for ngs_data analysis_pipelines however they do not allow efficient parallel access to bam_files to whom correspondence should be addressed map reduce is a distributed computing paradigm that has been designed for processing collections of relatively independent data items and is therefore well suited for sequencing_reads it divides data between processing nodes by splitting the files into chunks which are then processed separately the user has to write map and reduce functions where the map function does the actual processing of a chunk and the reduce function combines partial results the most popular open_source implementation of map reduce is apache hadoop bam_files are conceptually a good fit for map reduce style chunk processing but their low_level structure hinders adoption typically map reduce jobs process data chunks in line based text format where identifying entries is simple as line boundaries are denoted by newline characters detecting entry boundaries and accessing the binary content of compressed bam_files however is nontrivial on the other hand using plain hadoop with text_based sam_files results in several times_greater disk and network loads text formats also complicate the pipeline as data is typically stored in bam_files we developed the hadoop bam java_library to act as an integration layer between analysis applications and bam_files stored in the hadoop distributed file system hdfs to conclude we presented how the combination of a compact data format such as bam and a powerful distributed framework hadoop can be used to efficiently process large ngs_datasets the hadoopbam library provides an easy to use interface for their integration by resolving the incompatibilities these two technologies have we predict that similar integration efforts will become common when cloud_computing is taken into wider use in ngs_data analysis while our use case consisted of coverage calculations it is important to note that hadoop bam can be used for virtually any analysis task based on bam_files ranging from variant detection to peak_calling in order to make hadoop bam more accessible we are currently evaluating simpler and higher_level hadoop based query languages for working with bam_files examples of such include apache pig and hive we have also developed a command_line and are extending it to provide samtools like functionality 
