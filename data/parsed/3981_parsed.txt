sequence_analysis reptile representative tiling for short_read error_correction motivation error_correction is critical to the success of next_generation applications such as resequencing and de_novo genome_sequencing it is especially important for high_throughput where reads are much shorter and more abundant and errors more frequent than in traditional_sanger processing massive numbers of short_reads with existing error_correction methods is both compute and memory intensive yet the results are far from satisfactory when applied to real_datasets results we present a novel approach termed reptile for error_correction in short_read from next_generation reptile works with the spectrum of k_mers from the input reads and corrects errors by simultaneously examining i hamming_distance based correction possibilities for potentially erroneous k_mers and ii neighboring k_mers from the same read for correct contextual_information by not needing to store input_data reptile has the favorable property that it can handle data that does not fit in main_memory in addition to sequence_data reptile can make use of available quality_score information our experiments show that reptile outperforms previous methods in the percentage of errors removed from the data and the accuracy in true base assignment in addition a significant reduction in run time and memory_usage have been achieved compared with previous methods making it more practical for short_read error_correction when sampling larger genomes availability reptile is implemented in c and is available through the link http aluru sun high_throughput is profoundly changing the way genetics data are collected stored and processed the advantages of the new technology have led to revitalization of old techniques and discovery of novel uses with growing applications in resequencing de_novo metagenomics and beyond new technology inevitably comes with challenges for many next generation sequencers the advantage of deeper and cheaper to whom correspondence should be addressed coverage comes at the cost of shorter reads with higher_error compared with the sanger_sequencing they replace genome_assembly the de_novo inference of a genome without the aid of a reference_genome is challenging sanger reads typically bp in length are long enough for overlaps to be reliable indicators of genomic co location which are used in the overlap_layout approach for genome_assembly however this approach does poorly with the much shorter reads of many next_generation e g bp for illumina_genome ii in this context de_bruijn and string_graph based_formulations that reconstruct the genome as a path in a graph perform better due to their more global analysis and ability to naturally accommodate paired_read information as a result they have become de facto models for building short_read genome_assemblers e g allpaths velvet abyss and yaga error_correction has long been recognized as a critical and difficult part of these graph_based assemblers it also has significant impact in other next_generation applications such as resequencing we give a brief review of several well known error_correction methods alignment based error_correction methods such as mised for sanger reads require refined multiple read_alignments and assume unusually isolated bases to be read errors like the sanger motivated assembly algorithms these approaches do not adapt well to short_reads hence proposed the spectral alignment problem sap in a given dataset a kmer is considered solid if its multiplicity exceeds a threshold and insolid otherwise reads containing insolid kmers are corrected using a minimum number of edit operations so that they contain only solid kmers post correction similar approaches have been adapted and used by others to overcome the typically long_run times of sap based_approaches proposed shrec a method based on a generalized suffix_tree constructed from short_read using both forward and reverse complementary_strands shrec compares the multiplicity of a substring represented by a node in the suffix_tree with its expected frequency of occurrence calculated analytically assuming uniform sampling of the genome and uniformly_distributed sequencing_errors the nodes with observed counts that deviate beyond a tolerable threshold from their expected_values are considered erroneous an erroneous node is corrected to a sibling when applicable and all its descendants are transferred to the selected sibling well engineered code is necessary to cope with the largepage we evaluated reptile on several illumina solexa datasets and compared the results with shrec version a recent high_quality short_read error correction_method that is itself shown to give superior results over prior k spectrum approaches we omitted evaluation on simulated_data because simulations with random errors or synthetic genomes do not accurately_reflect actual short_read sequencing_errors and could even be misleading our test datasets are illuminagenerated short_reads of well characterized sanger assembled bacterial_genomes knowledge of the genomes is needed for determining the accuracy of the error_correction methods the six experimental_datasets downloaded from the sequence_read at ncbi are listed in datasets d accession_number srx d srr d srr and d srr are illumina_reads from the e coli str k substr nc genome mbp datasets d srr and d are illumina_reads from the acinetobacter_sp adp nc genome mb the first four datasets are generated by solexa g genome_analyzer where each read has the same length_bp the latter two datasets are generated using the more recent illumina_genome ii with read_lengths of bp in d and bp in d d has high coverage and low_error d has typical coverage and low_error d has high coverage and high_error d is derived from d by randomly selecting short_reads amounting to coverage this is done for evaluating performance on a low coverage high_error dataset both d and d have higher_error in addition of the reads in d contain ambiguous nucleotides denoted by character n since shrec cannot process non acgt characters we eliminated all reads with ambiguous bases even though reptile has no such limitation the number of discarded reads is indicated in column similar to we evaluated error_correction results with the aid of rmap v which maps short_reads to a known genome by minimizing mismatches we allowed up to five mismatches per read in the first four datasets page error_rate is estimated by mapping the reads to the corresponding genome using rmap and finding mismatches based on uniquely_mapped and allowed up to mismatches default value of rmap in d and fifteen mismatches in d since the reads are longer in the latter two datasets reads that could not be mapped to the genome or that map to multiple_locations are discarded the mismatches between uniquely_mapped and the genome are considered read errors quality of the datasets varied as shown in with the percentage of reads that are uniquely mapped ranging from to the large percentage of unmappable reads the higher_error as well as the large percentage of reads with ambiguous bases indicate that d and d have lower_quality than d to d since the goal of error_correction is to identify and correct each erroneous nucleotide we assess the quality of error_correction at the base level a true_positive tp is any erroneous base that is changed to the true base a false_positive fp is any true base changed wrongly a true negative tn is any true base left unchanged and a false_negative fn is any erroneous base left unchanged then sensitivity tp tp fn and specificity tn tn fp note that these definitions are different from those used by which target read level error_detection whether a read is flagged as containing an error or not this is a less stringent measure because any read containing errors was classified as tp provided at least one of its errors was detected and irrespective of whether they were accurately corrected or not we propose two additional measures for assessing the quality of error_correction bullet erroneous base assignment eba let n e denote the number of erroneous bases that are correctly_identified but changed to a wrong base then eba n e tp n e reflects how well we are able to correct an erroneous base to the true base after a sequencing_error has been identified a lower value of eba indicates a more accurate base assignment bullet gain tp fp tp fn this measures the percentage of errors effectively removed from the dataset which is equivalent to the number of errors before correction minus the number of errors after correction divided by the number of errors before correction clearly gain should approach one for the best methods but may be negative for methods that actually introduce more errors than they correct the proposed error_correction algorithm is conservative because it avoids changing bases unless there is a compelling underrepresentation of a tile compared with its d mutant tiles actual errors in read r cannot be corrected if r occurs in a very low coverage region of the genome or there exist multiple candidate d mutant tiles probably because of genome repetition on the other hand a tile may be miscorrected if it contains a minor variant of a highly repetitive element in the genome or it traverses a low coverage region that is similar to other regions with normal coverage our method is not unique in being challenged by non uniform coverage on repetitive genomes error_correction for highly repetitive genomes is essential for successfully assembling larger eukaryotic_genomes but none of the existing_methods successfully addresses this problem including reptile short_read provides a reasonable method to evaluate error_correction methods in well assembled low repetition genomes nevertheless it is not possible to unambiguously determine all errors there are natural polymorphisms among bacterial lines and some presumed polymorphisms may be unrecognized assembly errors furthermore the mapping software chooses among alternative mappings by invoking parsimony but there is some chance that the true number of errors is less than the minimum lastly mapping software cannot map reads that contain more than a constant number of substitutions typically just two with full sensitivity although we considered here and tested as many as with similar results despite these limitations we believe that most errors are correctly_identified and this approach can provide a fair comparison of error_correction methods we and others have found that sequence quality_scores provide_valuable our use of quality_scores probably helped us account for the error_patterns in nextgeneration sequencing_data without explicitly modeling them however it has been observed that high quality_scores may be too optimistic and low quality_scores too pessimistic in estimating sequencing_errors in solexa data since quality_scores may not be precise measures of misread probabilities the current version of reptile uses quality_score information in a very simple manner but can be modified to make more sophisticated use of quality_scores if warranted finally although quality_scores are needed to run reptile it can be run effectively without scores by setting all quality_scores and the threshold q c to the same value there remain several additional challenges in next_generation error_correction one challenge is to distinguish errors from polymorphisms for example single_nucleotide snps reptile could accommodate snp prediction with modification in the tile correction stage algorithm where ambiguities may indicate polymorphisms another challenge is the growing read_length of upcoming high_throughput sequencers currently we define tiles as concatenations of two kmers it might prove useful to extend the tile definition to more than two kmers in order to address error_correction in much longer_reads 
