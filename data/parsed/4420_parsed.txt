data_and statistical interpretation of machine_learning feature importance scores for biomarker_discovery motivation univariate statistical_tests are widely used for biomarker_discovery in bioinformatics these procedures are simple fast and their output is easily_interpretable by biologists but they can only identify variables that provide a significant amount of information in isolation from the other variables as biological_processes are expected to involve complex interactions between variables univariate methods thus potentially miss some informative biomarkers variable relevance scores provided by machine_learning however are potentially able to highlight multivariate interacting effects but unlike the p values returned by univariate tests these relevance scores are usually not statistically interpretable this lack of interpretability hampers the determination of a relevance threshold for extracting a feature subset from the rankings and also prevents the wide adoption of these methods by practicians results we evaluated several existing and novel procedures that extract relevant_features from rankings derived from machine_learning these procedures replace the relevance scores with measures that can be interpreted in a statistical way such as p values false_discovery or family_wise rates for which it is easier to determine a significance_level experiments were performed on several artificial problems as well as on real microarray_datasets although the methods differ in terms of computing times and the tradeoff they achieve in terms of false_positives some of them greatly help in the extraction of truly relevant biomarkers and should thus be of great practical interest for biologists and physicians as a side conclusion our experiments also clearly highlight that using model performance as a criterion for feature_selection is often counter productive availability_and python source codes of all tested methods as well as the matlab scripts used for data simulation can be found in the supplementary_material univariate hypothesis_testing is widely used in the context of biomarker_discovery in bioinformatics where one seeks to identify biological variables e g genes or genetic_polymorphisms that truly provide information about some phenotype of interest e g disease status or treatment response a classic procedure consists in applying a statistical_test to compute a p value for each variable of the considered problem and selecting variables that have a p value lower than a chosen threshold to cope with multiple hypothesis problems p values are typically replaced with an estimation of the false_discovery fdr or the family_wise fwer univariate tests can only identify variables that provide a significant amount of information about the output variable in isolation from the other inputs since biological_processes are expected to involve complex interactions between variables these procedures potentially miss some informative biomarkers nowadays when one seeks multivariate interacting effects between features one can resort to relevance scores provided by machine_learning among these the most popular_methods include importance scores derived from a tree based ensemble_method or feature weights computed for example from a linear support_vector svm however unlike the p values returned by univariate tests these relevance scores are usually not statistically interpretable this lack of interpretability prevents the wide adoption of these methods by practicians biologists or physicians and also makes the identification of the truly relevant_variables among the top_ranked ones i e the determination of a relevance threshold a very difficult_task in practice in this article we evaluate several existing and novel procedures that extract relevant_features from a ranking returned by a multivariate algorithm these procedures replace the original relevance score with a measure that can be interpreted in a statistical way and hence allow the user to determine a significance threshold in a more informed way most of these methods exploit a resampling procedure to estimate the fdr or fwer among the k top_ranked features for increasing values of k just like for standard univariate tests the user can then choose a threshold on this new measure depending on the risk he she is ready to take when deeming that all features above this threshold are relevant experiments on several artificial problems as well as on real microarray_datasets show that some of these measures greatly help in the extraction of truly relevant_features from a ranking derived from a multivariate_approach results on artificial and real microarray_datasets obtained using the described methods are presented in this section in this article we evaluated several procedures that aim to identify a maximal subset of variables that truly provide some information about an output variable these procedures assume that a multivariate ranking_method a was first used to compute a relevance score for each variable of the considered problem and then extract relevant_features from this ranking by replacing the original relevance score with a measure that can be interpreted in a statistical way depending on the procedure this measure is either the generalization error of a predictive_model err a and err trt the fdr nfdr efdr the fwer cer mprobes or a p value mrtest probe although there is still a need to determine a threshold on this new measure the determination of this threshold is clearly easier due to its interpretability this threshold is also not dependent anymore on the problem at hand and on the ranking_method a among the feature_selection that we evaluated err a and err trt are the only ones that do not require to choose a significance_level a priori however on artificial problems they always have the lowest precision among all methods and they wrongly select a non negligible number of variables on the permuted prostate datasets moreover they are subject to the selection_bias problem preventing the selection of an adequate number of variables prediction_performance is thus clearly not an appropriate measure for the identification of relevant_features although they clearly highlight a threshold on the feature ranking several of the remaining methods have also some disadvantages the nfdr method is the simplest one but was shown to overestimate the real fdr in the case of dependent scores the drawback of the probe procedure is that the selected_variables depend on the chosen distribution of the random probe which makes it a parametric method the mr test method estimates the rank distribution of an irrelevant variable from the k variables with the highest observed ranks the determination of k thus introduces some dependency on the problem and ranking_method used although our default choice seems to be robust an inappropriate value of k can lead to a dramatic over or underestimation of the p values the mrtest also includes as a second parameter the number of resampled instances at each iteration among the three remaining methods cer and mprobes are highly_selective methods that avoid the inclusion of any irrelevant feature as much as possible mprobes has a computational advantage 
