halvade scalable sequence_analysis with mapreduce motivation post sequencing dna analysis typically consists of read_mapping followed by variant_calling especially for whole_genome this computational step is very time consuming even when using multithreading on a multi core machine results we present halvade a framework that enables sequencing pipelines to be executed in parallel on a multi node and or multi core compute infrastructure in a highly_efficient manner as an example a dna_sequencing analysis_pipeline for variant_calling has been implemented according to the gatk best practices recommendations supporting both whole_genome and whole_exome using a node computer cluster with cpu cores in total halvade processes the na dataset human bp paired_end coverage in h with very high parallel efficiency even on a single multi core machine halvade attains a significant speedup compared with running the individual tools with multithreading availability_and halvade is written in java and uses the hadoop mapreduce api it supports a wide_range of distributions of hadoop including cloudera and amazon emr itsthe speed of dna_sequencing has increased considerably with the introduction of next_generation for example modern illumina systems can generate several hundreds of gigabases per run with a high_accuracy this in turn gives rise to several hundreds of gigabytes of raw_sequence to be processed post sequencing dna analysis typically consists of two major phases i alignment of reads to a reference_genome and ii variant_calling i e the identification of differences between the reference_genome and the genome from which the reads were sequenced for both tasks numerous tools have been described in literature see e g for an overview especially for whole_genome applying such tools is a computational bottleneck to illustrate this we consider the recently_proposed best practices pipeline for dna_sequencing analysis that consists of the burrow wheeler aligner bwa for the alignment step picard http picard sourceforge net for data preparation and the genome_analysis gatk for variant_calling on a single_node the execution of this pipeline consumes more time than the sequencing step itself a dataset consisting of billion paired_end illumina platinum genomes na bp fold coverage human_genome halvade was benchmarked on a whole_genome human dataset na from illumina platinum genomes the dataset consists of billion bp paired_end fold coverage stored in two gb compressed gzip fastq_files the software was benchmarked on two distinct computer clusters an intel provided bigdata cluster located in swindon uk and a commercial amazon emr cluster 
