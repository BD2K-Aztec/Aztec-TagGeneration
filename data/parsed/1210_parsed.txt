data_and cross_validation under separate sampling strong bias and how to correct it motivation it is commonly assumed in pattern_recognition that cross_validation error estimation is almost unbiased as long as the number of folds is not too small while this is true for random_sampling it is not true with separate sampling where the populations are independently sampled which is a common situation in bioinformatics results we demonstrate via analytical and numerical_methods that classical cross_validation can have strong bias under separate sampling depending on the difference between the sampling ratios and the true population probabilities we propose a new separate sampling cross_validation error estimator and prove that it satisfies an almost unbiased theorem similar to that of random_sampling cross_validation we present two case studies with previously published_data which show that the results can change drastically if the correct form of cross_validation is used availability_and the source_code in c alongthe most important property of a classifier is its error_rate probability of misclassification because the error_rate quantifies the predictive capacity of the classifier if the feature label distribution is known then the true error can be found exactly however in practice the feature label distribution is unknown and the error must be estimated if the sample is small then the estimation must be computed using the same data as that used for training the classifier perhaps the most commonly used training data based classification error estimator is cross_validation it has a long history going back to in its most basic form the k fold_cross error estimate cvk n for a sample of size n it is assumed that k divides n is computed by selecting randomly a partition of the sample into k data folds subsets for each fold applying the classification rule on the data not in the fold computing the error_rate of the designed classifier on the left out fold and then averaging the resulting k error_rates when k n one gets the leave_one estimator l n cross_validations salient good property is that under random_sampling it can be proved see that it is almost unbiased in the sense thatwhere n is the true error probability of misclassification of a classifier designed on a sample of size n hence the bias is not too great as long as n k is small for leave_one e l n e n and the estimator is essentially unbiased the salient point motivating the present article is that depends on the sampling being random and that when sampling is not random there can be severe bias the importance of bias for an arbitrary error estimator n can also be gleaned from its role in the estimator root_mean where bias n e n n and var dev n var n n braga as mentioned previously for classical cross_validation under random_sampling it follows from that if n k is small then bias n in which case rms n var dev n while the variance of cv is known to be large in small sample cases braga it will typically reduce to zero as n however the bias introduced by application of the classical cv estimator under nonrandom sampling will generally not approach zero as n the result is an inconsistent estimator which is imprecise under arbitrarily large_sample under random_sampling an independent and identically distributed i i d sample s is drawn from the mixture of the populations and this means that if a sample of size n is drawn for binary_classification then the numbers of sample points n and n drawn from the populations and respectively are random_variables n binomialn c and n binomialn c where c py is the a priori probability that the label y is zero i e the sample point comes from population this random_sampling assumption is so pervasive that it is usually assumed without mention and in books is often stated at the outset and then forgotten for instance state in typical supervised pattern classification_problems the estimation of the prior probabilities presents no serious difficulties they are referring to the fact that the prior probability c pr y can be consistently estimated by the sampling ratio numbers n n c in probability however suppose the sampling is not random in the sense that the ratios r n n and r n n are chosen before the sampling procedure in this separate sampling case s s s where the sample points in s and s are selected_randomly from and but given n the individual class counts n and n are not determined by the sampling procedure with separate sampling we have no sensible estimate of c recognition of this particular problem of estimating the prior probability when sampling is separate and its effect on linear_discriminant lda goes back to often one says that for separate sampling the ratios r n n and r n n are chosen prior to the sampling procedure but there is in fact no temporal meaning to this for instance one could simply separately randomly sample and with n and n being randomly_selected by a process independent of the sampling procedure and the sampling would still be separate the point is that r cannot be reasonably used as an estimate of c taken from esfahani and dougherty illustrates the effects of separate sampling on the expected true classifier error for two classification rules and multivariate gaussian_distributions of equal and unequal covariance structures and dimensionality d for a given sample_size n sampling ratio r and classification rule the expected true error_rate e n jr is plotted for different class prior probabilities c for lda and a non linear radial_basis support_vector rbf svm for each r and n n is determined as n dnre we observe that the expected error is close to minimal when r c and that it can greatly_increase when r c this kind of poor_performance for separate sampling ratios not close to c is commonplace in this article we investigate the effect of separate sampling on cross_validation error estimation we will see that for a separatesampling ratio r not close to c there can be large bias optimistic or pessimistic a serious consequence of this behavior can be ascertained by looking at whereas the expected true error of the designed classifier grows large when r greatly deviates from c a large optimistic cross_validation bias when r is far from c can obscure the large error and leave one with the illusion of good performanceand this illusion is not mitigated by large samples to overcome the bias problem for classical crossvalidation with separate sampling we introduce a new crossvalidation estimator designed for separate sampling and prove that it satisfies a bias property analogous to 
