genome_analysis e mem efficient computation of maximal_exact for very large_genomes motivation alignment of similar whole genomes is often performed using anchors given by the maximal_exact mems between their sequences in spite of significant amount of research on this problem the computation of mems for large_genomes remains_a the leading current_algorithms employ full text indexes the sparse suffix_array giving the best results still their memory_requirements are high the parallelization is not very efficient and they cannot handle very large_genomes results we present a new algorithm efficient computation of mems e mem that does not use full text indexes our algorithm uses much less space and is highly amenable to parallelization it can compute all mems of minimum_length between the whole human and mouse genomes on a core machine in min and gb of memory the required memory can be as low as mb it can run efficiently gen omes of any size extensive testing and comparison with currently best algorithms is provided availability_and the source_code of e mem is freely_available at maximal_exact mems are exact_matches between two sequences that cannot be extended either way without introducing mismatches mem computation is a fundamental problem in stringology and has important_applications in sequence_alignment closely_related genomes are often aligned by using local similarities as anchors and sufficiently_long mems have been quite successfully used in this respect a theoretically optimal_solution in linear time and space for the mem computation problem is easily_obtained using suffix_trees however suffix_trees require large memory and practical implementations use highly engineered suffix_trees suffix_arrays were introduced by manber and myers as a space efficient alternative to suffix_trees and have replaced them in most applications enhanced_suffix were shown to solve all problems suffix_trees could solve with the same theoretical complexity suffix_arrays still use a significant amount of memory especially with the additional tables required to match the complexity of suffix_trees when whole genomes are aligned the memory required by the computation of all mems may become prohibitively high the large popularity of whole_genome alignment programs most notably that of the mummer software attracted a lot of attention to the mem computation problem with the purpose of enabling the alignment of larger genomes within reasonable amount of memory for example one of the most reliable such programs vmatch uses enhanced_suffix and its memory_usage is very high the idea of sparseness has been already used for suffix_trees k arkk ainen and and it has been successfully employed for suffix_arrays byin their sparsemem program their approach relies on indexing only every kth suffix of the given genome_sequence k is called sparseness factor and is able to find mems faster and using less memory than previous_approaches it can serve as a drop in replacement for the mummer software_package the approach of sparsemem has been enhanced bywith a sparse child array for large sparseness factors and implemented in their essamem software our tests show that essamem is currently the best program for mem computation in large_genomes compressed indexes have been used as well developed backwardmem that uses a backward search method over a compressed suffix_array recently fernandes and freitas employed in slamem a new sampled representation of the longest common prefix lcp array that works with the backward search method of the fm_index in spite of these advances mem computation remains_a for large_genomes the memory_requirements of the current approaches remain_high and very large_genomes cannot be effectively handled we present a new algorithm e mem that targets large genome_sequences e mem does not use full text indexes instead hash tables are efficiently used in combination with several ideas to speed up the search our algorithm uses much less space and is highly amenable to parallelization for example it can compute all mems of to whom correspondence should be addressed the author published_by all_rights for permissions please_e journals permissions_oup com minimum_length between the whole human and mouse genomes on a core machine in min and gb of memory the required memory can be as low as mb it can run efficiently on genomes of any size extensive testing and comparison with currently best algorithms is provided we have used for comparison traditional datasets such as whole human versus mouse genomes and whole human versus chimp genomes but also introduced a new test where two species of wheat triticum_aestivum and triticum durum are used it turns out that only e mem and vmatch could handle these genomes however vmatch requires gb whereas e mem can use less than gb while being also faster our e mem software is implemented in c and openmp is freely_available and can be used as a stand alone program or as a drop in replacement for the mummer software_package we have compared e mem with several programs including the top ones essamem slamem sparsemem and vmatch we have also tested backwardmem and mummer but they could not run any of our large tests the genomes involved in the tests are given in where we give also their length and number of sequences included in each fasta file download information for each genome_sequence as well as for the source_code of the programs tested is given in the supplementary_material note that the wheat genome has gb however the available sequence has only gb we performed three tests the first two are classical problems of large genome alignment human versus mouse human versus chimp we have added two larger genomes of two wheat species common_wheat versus durum_wheat the results are presented in tables respectively in each table we include the time andnote a dash means the program could not run that test that is in serial mode the output was incorrect or empty whereas the parallel mode was not supported of all programs were run details are given in the supplementary_material since we are trying to reduce both time and memory a trade_off is obtained and the results are better seen when time is plotted against memory we show these plots in and for the first two tests we give two plots for clarity one for the serial mode the other for the parallel e mem provides a practical solution for finding mems between arbitrarily large_genomes it uses much less memory than the currently available programs it is freely_available and it can be used as a stand alone program or as a drop in replacement for the mummer software_package mems are good anchors for closely_related genomes otherwise approximate matches are more suitable the approach of e mem can be generalized to work with spaced seeds inorder to search efficiently for approximate matches highly_sensitive multiple spaced seeds of large weight are necessary and they can be designed using the approach of ilie and ilie by the speed program the exact matching procedure of index based_algorithms is not well suited for finding approximate matchings 
