hi corrector a fast scalable and memory_efficient package for normalizing large_scale hi c data genome_wide proximity ligation assays e g hi c and its variant tcc have recently become important tools to study spatial genome_organization removing biases from chromatin contact matrices generated by such techniques is a critical preprocessing_step of subsequent analyses the continuing decline of sequencing_costs has led to an ever improving resolution of the hi c data resulting in very large matrices of chromatin contacts such large size matrices however pose a great challenge on the memory_usage and speed of its normalization therefore there is an urgent need for fast and memory_efficient methods for normalization of hi c data we developed hi corrector an easy to use open_source implementation of the hi c data_normalization algorithm its salient_features are i scalabilitythe software is capable of normalizing hi c data of any size in reasonable times ii memory efficiencythe sequential version can run on any single computer with very limited memory no matter how little iii fast speedthe parallel version can run very fast on multiple computing nodes with limited local memory availability_and the sequential version is implemented in ansi c and can be easily compiled on any system the parallel version is implemented in ansi c with the mpi library a standardized and portable parallel environment designed for solving large_scale scientific problems the package is freely_available atthe recent development of genome_wide proximity ligation assays such as hi c and its variant tcc has significantly_facilitated the study of spatial genome_organization the raw chromatin_interaction data obtained by hi c methods can have both technical and biological biases therefore correcting biases in the hi c data is an important preprocessing_step among several recently_developed the iterative correction abbreviated as ic algorithm has been used most widely by recent_studies due to its conceptual simplicity parameter free algorithm and ability to account for unknown biases although its assumption of the equal visibility across all loci may require further exploration mathematically the ic algorithm is a matrix scaling or balancing method that transforms a symmetric matrix into one that is doubly stochastic meaning that the row and column sums of the matrix are equal to however the hi c chromatin_interaction matrix is of the massive size o n where n is the number of genomicwe compared three algorithms ic ic mes and ic mep on the tcc hi c data of two human cell_types gm and hesc the whole_genome is partitioned into the equal size regions or bins the bin size is the mainall algorithms were terminated after iterations for the purpose of performance comparison since each iteration has almost the same running time memory includes only the memory allocated for computation in each processor not system overhead the elapsed time format is hours minutes seconds fast scalable and memory_efficient normalization for hi c dataindicator of hi c data resolution the results are listed in in the experiment with k bp resolution data the basic ic algorithm requires a minimum memory of gb the algorithm icmes can run with just gb_memory a common memory configuration in office computers and complete the same work in reasonable time within h ic mep can dramatically speed up the computation using more processors about min with processors while using only gb of memory in each processor for the k bp data none of hpc computer nodes with gb_memory limit can load the full matrix about gb for the basic ic algorithm but ic mes and ic mep can use gb_memory to quickly get the results even in half hour using processors details are provided in the supplemental materials with the rapidly increasing resolution of hi c datasets the size of the chromatin contact_map will soon exceed the memory capacity of general computers we developed hi corrector a scalable and memory_efficient package for bias removal in hic data hicorrector can run on any single computer or a computer cluster with limited memory size to complete the task we performed experiments on high_resolution hic data from two human cell_types to show that the package can process very large_data in reasonable time using the single processor and in very short time with multiple processors the experiments further demonstrate the scalability of our package with the observation shown inthat the more processors used the faster it is therefore hi corrector is a timely resource addressing the challenge of normalizing high_resolution hi c data 
