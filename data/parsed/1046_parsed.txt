data_and combining multiple approaches for gene_microarray classification motivation the microarray report measures the expressions of tens_of of genes producing a feature_vector that is high in dimensionality and that contains much irrelevant information this dimensionality degrades classification_performance moreover datasets typically contain few samples for training leading to the curse of dimensionality problem it is essential therefore to find good methods for reducing the size of the feature_set results in this article we propose a method for gene_microarray classification that combines different feature_reduction approaches for improving classification_performance using a support_vector svm as our classifier we examine an svm trained using a set of selected genes an svm trained using the feature_set obtained by neighborhood preserving embedding feature transform a set of svms trained using a set of orthogonal wavelet_coefficients of different wavelet mothers a set of svms trained using texture descriptors extracted from the microarray considering it as an image and an ensemble that combines the best feature_extraction methods listed above the positive results reported offer confirmation that combining different features extraction methods greatly_enhances system performance the experiments were performed using several different datasets and our results expressed as both accuracy and area_under roc_curve show the goodness of the proposed approach with respect to the state of the art availability the mathlab code of the proposed approach is publicly_available at bias dna_microarray has proven to be an important breakthrough in molecular_biology this rapidly maturing technology is providing scientists with a means of monitoring the expression of genes on a genomic_scale one important application area is disease prognostication benefits include the potential for identifying individual genes responsible for disease and for providing scientists with a more accurate means of diagnosis to whom correspondence should be addressed and prognosis largescale profiling of gene_expression can reveal for example normal versus malignant_cells and the genetic and cellular changes in the progression of tumor_metastasis the benefits offered by simultaneously monitoring tens_of of genes however depend on developing tools capable of handling not only the sheer size of this data but also the small number of samples usually available for analysis machine_learning systems are well suited for this problem but they must be designed to handle high levels of noise as only a small minority of genes is typically relevant for any given problem the small_sample compared to the large number of features means that these systems must also contend with the dreaded curse of dimensionality it would be very beneficial therefore if good methods for identifying these small sets of relevant_genes could be developed in the literature gene_selection methods have been organized into three categories filter wrapper and embedded methods filter methods reveal dependencies without using classifiers and are based on statistical_methods of ranking genes e g t statistics class separability and fishers criterion wrapper and embedded methods consider the mutual_information among genes as well as its relevance example classifiers used in wrapper methods include bayesian_classifier k nearest_neighbor and support_vector svms wrapper methods are much slower than filter methods because they search for optimal combinations of features genes but filter methods may not select the most optimal set of features examples of embedded methods include one norm svm logistic_regression sparse logistic_regression and methods based on regularization an interesting embedded method is that developed by they devised a genetic_algorithm with fishers linear_discriminant lda as the fitness_function that performed well across a number of databases using a small number of selected genes most of these filter wrapper and embedded methods are comparable in accuracy several recent_advances include reducing the sample set using classifier ensembles rather than single classifiers and using hybrid or multiple sets of different type ofthe goal of this study was to develop a robust ensemble of svm classifiers based on feature perturbation for microarray classification the reported results of our experiments expressed as both accuracy and auc show that our approach performs very well across several datasets our study examined an svm trained using a set of selected genes by fisher criterion an svm trained using the feature_set obtained by npe a set of svms trained using a set of orthogonal wavelet_coefficients of different wavelet mothers and a set of svms trained using texture descriptors extracted from the microarray considering it as an image the positive results we obtain compare well with those reported in the literature and provide further confirmation that ensembles of classifiers obtain more reliable results in future_studies we plan on testing our approach using more datasets we will also study combining additional methods in ensemble construction e g combining our feature perturbation approaches with a pattern perturbation approach 
