lambda the local aligner for massive biological data motivation next_generation produce unprecedented amounts of data leading to completely new research_fields one of these is metagenomics the study of large size dna samples containing a multitude of diverse organisms a key problem in metagenomics is to functionally and taxonomically classify the sequenced dna to which end the well known blast program is usually used but blast has dramatic resource requirements at meta genomic scales of data imposing a high financial or technical burden on the researcher multiple_attempts have been made to overcome_these and present a viable alternative to blast results in this work we present lambda our own alternative for blast in the context of sequence classification in our tests lambda often outperforms the best tools at reproducing blasts results and is the fastest compared with the current state of the art at comparable levels of sensitivity availability_and lambda was implemented in the seqan open_source c library for sequence_analysis and is publicly_available for download at http www seqan de projects next_generation has opened the door to a multitude of possible research_fields among them metagenomics in metagenomic_projects millions or billions of dna or cdna reads are collected in a single experiment usually it is attempted to either assemble the genomes of the organisms contained in the sample or to determine its taxonomic content i e conduct a sequence classification this means assigning a read to a known usually protein_coding and annotated subject sequence to identify the encoded function the organisms present in the sample or identify the closest relative bazinet and cummings give an overview of the various programs that have been developed to address this problem of the approaches they compare of use blast in their pipeline hence blast can be seen as the de facto standard used for trying to solve this problem also note in their study that blast step completely dominates the runtime for alignment_based for the two programs with the highest precision in their comparison carma and megan the blast step actually made up and of the runtime another metagenomic study states that cpu hours at a supercomputer center were required to conduct the study hence since some time there is an effort to replace the blast suite by algorithms and tools that are much faster while not sacrificing too much accuracy that means the tools aim at finding the same alignment locations as blast and possibly an alignment of similar quality expressed by bit score we performed a comprehensive experimental evaluation of lambda and competing tools on two real_world datasets all these tests were conducted on a debian gnu linux system http www debian org with intel_xeon e v cpus at ghz a total of physical virtual cores and gb of ram all temporary data intermediate data and both input and output_files were read from and written to a tmpfs i e a virtual filesystem in main_memory this prevents disk caching effects from disturbing the benchmark and increases overall performance the latter effect is stronger on io heavy tools but since memory is a small cost factor in bioinformatics_pipelines we recommend this approach for general use as well all programs were run with threads and an e value cutoff of more on scoring below the running_times do not include the creation of a database index however for lambda they include the time needed for indexing the query_sequences memory_usage is measured as the maximum of the sum of the process and its child processes virtual memory resident set size in proc this did not work for pauda which uses difficultto track java processes here we give gb as an upper boundbecause this is the maximum reserved by the java virtual_machine the publication states that memory_usage is up to gb for our test datasets the fast pauda program seems to be an unsuitable choice when recalling blasts results is important one possible explanation for the poor_performance is that bowtie which works at paudas core and is designed for read mappingperforms poor in its local_alignment mode when the expected local_alignment size is much shorter than the original read another factor of why pauda likely misses many hits early on is that its seeds are long finally the bad rate of blast recalls might be explained by pauda apparently not performing a realignment in regular protein space a slightly_lower recall could have been the outcome of hard masking but not to this extent only of blasts best matches are recalled on the second dataset paudas speed is comparatively_high but even if taking the measure of results per time into account which is discussed in paudas publication lambdas fast profile is always a better choice rapsearch is a sensitive program with good results on both datasets it outperforms lambda slightly in sensitivity on dataset i but is in turn outperformed on dataset ii it beats ublast in speed but is times slower than lambda in the respective modes of ublast we had to compare an older version because the newest ublast did not produce correct results we evaluated the free bit version which allowed us to use it only on dataset i it performed well there in terms of sensitivity however it came out as one of the slowest programs the evaluation of the specificity is a challenging_task as there is no ground_truth and hence a definition of specificity is difficult to gain more insight into the composition of the results of different tools and their comparability we included a cluster_analysis conducted with megan in the supplements it confirms the previous_findings i e similar results between rapsearch ublast and lambda 
