genome_analysis assembling the gb white_spruce picea glauca genome from whole_genome shotgun sequencing_data white_spruce picea glauca is a dominant conifer of the boreal forests of north_america and providing genomics resources for this commercially valuable tree will help improve forest management and conservation efforts sequencing and assembling the large and highly repetitive spruce genome though pushes the boundaries of the current_technology here we describe a whole_genome strategy using two illumina sequencing_platforms and an assembly approach using the abyss software we report a giga base_pairs draft_genome in million scaffolds with a scaffold n of bp we demonstrate how recent improvements in the sequen_cing technology especially increasing read_lengths and paired_end from longer fragments have a major impact on the assembly contiguity we also note that scalable bioinformatics_tools are instrumental in providing rapid draft assemblies availability the picea glauca genome_sequencing and assembly data are available through ncbi accession alwz pid prjna http www ncbi nlm nih gov bioproject the assembly of short_reads to develop genomic resources for non model species remains an active area of development the feasibility of the approach and its scalability to large_genomes was demonstrated by the abyss publication using human_genome sequencing_data and was later used to assemble the panda genome with the soapdenovo tool the technology provides high_quality results as demonstrated for bacteria and has been successfully_applied numerous times on more complex genomes estimated at giga base_pairs gb sequencing and assembly of the genome of this gymnosperm species of the pine pinaceae family present_unique on the data generation end those challenges include representation biases in whole_genome shotgun sequencing_data and difficulties in building reduced representation resources to scale down the magnitude of the problem on the bioinformatics end assembling massive sequencing_datasets is extremely demanding on computing cycles memory_usage storage requirements and for parallel programming implementations on communication traffic we addressed the data representation challenges by preparing and sequencing multiple whole_genome shotgun libraries on the hiseq and miseq sequencers from illumina san_diego ca usa compared with localized sequencing protocols such as building and sequencing fosmid libraries or the recent approach of isolating kb dna_strands to generate indexed sequencing fragments in high_throughput moleculo san_diego ca usa a shotgun only sequencing approach rapidly provides sequence_data effectively covering the target_genome at a cost that can be an order of magnitude less the difference in cost is especially substantial when sequencing a large genome in this work we demonstrate that shotgun sequence_assembly at this scale remains viable and produces valuable results to to whom correspondence should be addressed the author published_by this is an open_access the terms of the creative_commons http creativecommons org_licenses which permits non commercial re use distribution and reproduction in any medium provided the original_work for commercial re use please_contact permissions_oup com assemble the spruce genome we used the abyss algorithm which captures a representation of read to read overlaps by a distributed de_bruijn and uses parallel computations to build the target_genome the modular nature of the tool allowed us to execute a large number of tests to tune the message_passing for a successful execution train the assembly parameters for an optimal assembly and quantify the utility of long_reads for large genome_assemblies to the best of our knowledge the abyss algorithm is unique in its ability to enable genome_assemblies of this scale using whole_genome shotgun sequencing_data prior experience indicates that sampling a large genome with multiple libraries and fragment_lengths can mitigate potential sampling_biases and capture a more even representation of the underlying genome one novel feature in our sequencing approach was to complement the high coverage data from the hiseq sequencers with longer_reads from the miseq at low coverage to support the assembly process using an early access bp kit on the hiseq we generated pet reads from two libraries with bp nominal fragment_lengths and libraries with bp nominal fragment_lengths to a total of fold raw coverage using the miseq we generated bp pet reads from four libraries with bp nominal fragment_lengths and bp pet reads from one library with bp nominal fragment length contributing a further fold raw coverage we also generated large fragment_libraries of and kb nominal fragment_lengths to provide linkage information across repeat structures the first two of these libraries were prepared using the mpet protocol of illumina and the third was a pool of seven libraries prepared using a modified paired_end protocol life_sciences roche branford ct all long fragment_libraries were sequenced at bp and the resulting sequences were used only for their linkage information during the scaffold stage of the assembly the first release of the sequencing chemistry on the miseq allowed for read cycles which increased to cycles in a subsequent_release to obtain longer read_lengths we modified the sequencing instrument as detailed in the supplementary_material longer_reads obtained from this platform were instrumental in improving the contiguity of the genome_assembly as described later in the text to build the white_spruce genome we used the abyss de_novo tool which has been rigorously evaluated the process broadly has three stages unitig contig and scaffold building performed on a computer cluster of dual intel_xeon core processors each addressing gb of memory the three stages of the spruce genome_assembly took approximately two four and four days using and cpu cores respectively the first assembly stage constructs a distributed and scalable de_bruijn to represent read to read overlaps for unitig assembly the second stage involves read to unitig alignments and path traversals on the unitig adjacency graph from the previous stage for contig construction resolving short repeats along those paths when possible similarly the third stage involves read to contig alignments and path traversal on the contig adjacency graph for scaffold construction denoting unresolved sequence content with ns the first assembly stage can further be conceptualized in two parts with roughly_equal run times the first part provides preliminary unitigs and a graph representing their adjacency which is defined as k bp overlaps where k is the primary assembly parameter denoting the minimum read to read overlap length that is considered specific enough for assembly the second part eliminates short redundant unitigs when their neighbors on both sides share more than a certain length of sequence default bp and enables further graph simplification we based the preliminary assessment of assembly_quality on the first part of the first stage and optimized our assembly parameters using the pre unitig contiguity statistics the relatively short run time of this part of the assembly process allowed us to execute a large number of tests here we also take this opportunity to demonstrate the utility of longer_reads as they pertain to the optimal k_mer length as a larger k would resolve longer sequence ambiguities it is desirable to choose it as large as possible yet not too large otherwise we lose the sensitivity to detect valid read to read overlaps the choice of this parameter is determined by several factors including read_lengths fold coverage genome complexity genome_size and experimental_noise among these genome complexity and size are determined by the choice of the species to study and the experimental_noise is determined by the sample_collection methods and the choice of the sequencing_platform longer_reads and higher fold coverage would enable one to use a longer k_mer length shows results of our parameter search for an optimum k_mer length using the short hiseq reads only and combined short hiseq and long miseq reads the contiguity statistics nx describing x reconstruction in assembled sequence_lengths nx or longer are typically locally concavedown functions of the k_mer length in a neighborhood where the total sequence reconstruction is close to the genome length controlled for the misassemblies contig or scaffold n lengths are widely used quality_metrics for genome_assemblies we demonstrate that the optimum pre unitig n occurred at k bp when using both short and long_reads and at k bp when using just the short_reads thus we observe that incorporating the modest low coverage long_read data from the miseq allowed us to use a more stringent overlap parameter for the assembly process and resulted in improved assembly statistics optimum k using short and long_read data yielded n bp whereas the optimum k using short_read only yielded n bp the difference between assembly contiguity numbers became more pronounced when the assembly process proceeded to use million and million pre unitigs in these two cases respectively to construct unitigs contigs and scaffolds we also note that the optimum k values in both datasets were longer than the sequencing length of the mpet libraries we propagated the optimum k bp assembly with short and long_reads through the assembly pipeline the full assembly of our data yielded scaffolds over bp bp in length representing of the gb reconstructed gb estimated spruce genome the assembly statistics of the white_spruce genome are presented inin comparison with the whole_genome shotgun sequence assemblies of three barley cultivars the recent barley genome_assemblies represent results from a whole_genome and assembly project using similar data and offer a context for plant genomics as a means to assess the quality of the assembled spruce genome the sequences of several bacs from the same genotype were aligned against the assembly using blast six previously_sequenced targeted bacs containing known terpene synthase and cytochrome_p genes see_supplementary were then compared with mummer dot plots twenty six scaffolds longer than bp aligned with similarity to reconstruct of the sequence of these six bacs note short fragment_libraries prepared by the illumina pet protocol were used for their sequence content long fragment_libraries prepared by the illumina mpet and a modified protocols were used for linkage information during scaffolding as long fragment_libraries do not contribute to the sequence content of the assembly their contribution to genome_coverage is marked as n a not applicable assembly optimization the de_bruijn stage pre unitig of the assembly was used to optimize the overlap parameter k_mer length and the effect of inclusion of longer_reads was assessed the contiguity metrics n solid curves left y axis and n dotted curves right y axis are shown for assemblies that use the short_reads only blue and short and long_reads black the contiguity of the two datasets peaked for different k_mer lengths with dataset of short and long_reads having a maximum n and a maximum n for the same k bp for short_reads only optimization with respect to n resulted in a slightly_lower k_mer length_bp compared with optimization with respect to n bp both of which are lower than the optimum k_mer length for the full dataset longer k_mers were desirable as they help disambiguate longer repeat motifs the choice between a whole_genome approach and sequencing reduced representation libraries was extensively discussed during the human_genome and the former became the dominant technology as the sequencing throughput rapidly increased rendering library techniques to prepare data for the latter approach relatively expensive a decade later researchers studying conifer genomes are trying to answer the same question in our study we demonstrate that modern whole_genome and assembly methods can provide competitive draft genome_assemblies at the multi gb scale for downstream biological studies in a cost_effective way even if it is far from producing chromosome level contiguous sequence we note that a rigorous assessment of the reported assembly is not a trivial undertaking and will need to be performed as the assembly evolves from its draft stage toward a more established reference for example de_novo evaluation_tools such as cgal frcbam and ale would either not scale to the size of the problem or require substantial time and computational_resources still compared with previous targeted gene and genome subsampling studies the assembly introduced in this article already gives the community considerably greater_power to identify and study gymnosperm genes to assist forest management_strategies and to understand the environmental biological_interactions that involve spruce trees at a basic level 
