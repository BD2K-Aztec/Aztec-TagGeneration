test_set bias affects reproducibility of gene_signatures motivation prior to applying genomic predictors to clinical samples the genomic_data must be properly normalized to ensure that the test_set data are comparable to the data upon which the pre dictor was trained the most effective normalization_methods depend on data from multiple patients from a biomedical perspective this implies that predictions for a single patient may change depending on which other patient samples they are normalized with this test_set bias will occur when any cross sample normalization is used before clinical prediction results we demonstrate that results from existing gene_signatures which rely on normalizing test data may be irreproducible when the patient population changes composition or size using a set of curated publicly_available breast_cancer microarray_experiments as an alternative we examine the use of gene_signatures that rely on ranks from the data and show why signatures using rank_based features can avoid test_set bias while maintaining highly_accurate classification even across platforms availability_and the code data and instructions necessary to reproduce our entire analysis is available at https github com one of the most common barriers to the development and translation of genomic_signatures is cross sample variation in technology normalization and laboratories technology batch and sampling artifacts have been responsible for the failure of genomic_signatures irreproducibility of genomic results and retraction of papers reporting genomic_signatures even highly_successful signatures such as mammaprint vant have required platformspecific retraining before they could be translated to clinical use an under appreciated source of bias in genomic_signatures is test_set bias test_set bias occurs when the predictions for any single patient depend on the data for other patients in the test_set for example suppose that the gene_expression data for a single patient is normalized by subtracting the mean expression and dividing by the standard_deviation of the expression across all patients in the test_set then the normalized value for any specific gene for that patient depends on the values for all the patients they are normalized with the result is that a patient may get two different predictions using the same data and the same prediction algorithm depending on the other patients used to normalize the test_set data there are many scenarios under which a patients classification ought to change if new information updates or alters the prediction algorithm or if the raw biological patient data itself changes the case we would like to explore is when the gene_signature and prediction algorithm are locked down and when there is no biological_variation in the patient data we are concerned with how much data transformation due to pre_processing and normalization affects classification it is our assertion that steps taken to transform patient data for the purposes of applying a prediction algorithm should not alter the patients eventual classification some normalization_methods and some batch correction methods have addressed this issue by normalizing each sample against a fixed or frozen set of representative_samples unfortunately these approaches can be applied only to specific platforms where large_numbers of representative_samples have been collected this is especially relevant when custom chips are designed as is the case in many clinical_applications there remain a large range of platforms for measuring gene_expression in use by researchers and single sample normalization_methods are not currently available for many of these platforms additionally methods such as quantile normalization and other forms of data scaling and transformation have become well known in the field and are often applied as standard steps in a data_processing pipeline even if single sample normalization_methods were universally available public measures of gene_expression are frequently preprocessed using a range of methods for cleaning normalization and analysis resulting in a range of expression values for the same gene across different platforms a more tractable solution is to build gene_signatures that do not rely on raw gene_expression values we propose using the ranks of genes instead of their raw expression values under the assumption that any transformation applied to the data is rank preserving as a concrete example we focus on the pam signature for breast_cancer subtyping which is used to assign patients with breast_cancer to one of five molecular_subtypes basal luminal a luminal b her and normal we show that when the number of patients in the test_set changes the predictions for a single patient may change dramatically we also show that variation in patient populations being predicted upon leads to test_set bias interestingly pam can be easily modified into a rank_based signature we show that predictions from rank_based pam are comparable to those from standard pam and that predictions from rank_based pam are invariant to test_set bias test_set bias is a failure of reproducibility of a genomic signature in other words the same patient with the same data and classification algorithm may be assigned to different clinical groups a similar failing resulted in the cancellation of clinical_trials that used an irreproducible genomic signature to make chemotherapy decisions the cancer the implications of a patients classification changing due to test_set bias may be important clinically financially and legally in the example of pam a patients classification could affect a treatment or therapy decision in other cases an estimation of the patients probability of survival may be too optimistic or pessimistic the fundamental issue is that the patients predicted quantity should be fully determined by the patients genomic_information and the bias we will explore here is induced completely due to technical steps 
