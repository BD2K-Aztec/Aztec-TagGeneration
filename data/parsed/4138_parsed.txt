scalable metagenomic taxonomy classification using a reference genome_database motivation deep metagenomic_sequencing of biological_samples has the potential to recover otherwise difficult to detect microorganisms and accurately characterize biological_samples with limited prior_knowledge of sample contents existing metagenomic taxonomic_classification algorithms however do not scale well to analyze large metagenomic_datasets and balancing classification_accuracy with computational_efficiency presents a fundamental challenge results a method is presented to shift computational costs to an off line computation by creating a taxonomy genome index that supports scalable metagenomic classification scalable performance is demonstrated on real and simulated_data to show accurate classification in the presence of novel organisms on samples that include viruses prokaryotes fungi and protists taxonomic_classification of the previously_published giga base tyrolean iceman dataset was found to take h on a single_node core large memory machine and provide new insights on the metagenomic contents of the sample availability software was implemented in c and is freely_available sourceforge net_projects lmatmetagenomics is a powerful_tool for assessing the functional and taxonomic contents in biological_samples early shotgun metagenomics projects used giga bases of genetic data to demonstrate accurate sample surveys with less bias than previous methods the potential to detect even lower abundance organisms and provide more accurate surveys across a broad_spectrum of biological environments is being advanced now by sequencers reported to generate up to mega bases per second calculated by dividing total base output by total number of sequencer hours run for the hiseq rapidrun mode excludes library and sample_preparation time increased sequencing throughput presents a major scaling challenge to existing shotgun metagenomic classification algorithms the ability for an algorithm to scale can be measured by the difference between sample classification run time and sequencer run time and assumes sufficient computing_resources for each sequencer run scaling is being addressed through the use of larger compute clusters which can be managed by a third_party service cloud_computing as sequencer use grows however algorithms that run on a single_node and scale with sequencer output could be paired with individual sequencers and eliminate the need for high bandwidth network connections which are not always available in this article we attempt to meet the scaling goal running fast and accurate taxonomic sample classification on a single compute node to match analysis throughput with sequencer output two major design choices were made which present possible limitations i a larger than typically used single address space memory resource is exploited terabytes and ii larger search seeds are used than default sensitive blast settings for matching reads to a reference_database relaxing conventional memory constraints allows a reference genome_database to be annotated with taxonomic information and indexed to support fast metagenomic taxonomy classification of every sequencer read for all microbial_taxa including virus prokaryotes fungi and protists decreasing memory costs make this approach accessible to many practitioners because the cost of a single large memory compute node remains a fraction of the initial sequencer cost and need not require specialized system administration expertise large search seed sizes can potentially limit the ability to detect novel organisms but nonetheless is proving to be more effective as the number of microbes with representative reference_genomes grows for environments like the human_microbiome our goal is to efficiently assign taxonomic labels to the reads down to the species level for reads with reference representation and maintain accuracy in the presence of novel organisms by avoiding overly specific e g species and strain taxonomic_assignments this alleviates the computational bottleneck by limiting the number of unlabeled reads subjected to additional computational interrogation the results show comparable or better accuracy than existing_methods and even with novel genomes in a sample accurate and scalable classification is obtained in the vast_majority of cases the methods are made available as an open_source software_package livermore metagenomics analysis toolkit lmat to whom correspondence should be addressed the author s published_by this is an open_access the terms of the creative commons attribution license http creativecommons org licenses by which_permits distribution and reproduction in any medium provided the original_work existing bioinformatic approaches address scalability in three ways query size reduction reference_database size reduction and faster database_search query size reduction is achieved with metagenomic assembly and clustering which merges overlapping and redundant reads into longer contiguous genomic_segments metagenomic assembly improves the strength of the taxonomic signal contained in individual short_reads but careful parameter_settings are required to avoid mis assembly and assembly costs could remain_high reference_database size reduction is achieved through the use of genetic_markers storing only the more informative sequences marker based_approaches offer efficient summarization of metagenomic contents but only cover a portion of the query set leaving novel and other informative reads buried within the larger pool of unclassified reads which could require additional examination a less lossy approach reduces sequence redundancy by storing only the genetic_differences among reference_genomes this approach was shown to speed up blast and blat genome database_searches faster database search_methods apply larger search seeds and examples_include blat bwa and other read_mapping tools but analyzing the search results remains a challenge with some approaches selecting the lowest_common lca of multiple matches and others using variants of a best match selection procedure to improve rank specificity of the reported taxonomic label moreover parameter_settings of the search tools can dramatically alter the outcome of the reported label and must be considered carefully our approach uses faster search using larger seeds k_mers with a non redundant search of taxonomic identifiers associated with the k_mers found in the reference genome_database our kmer taxonomy database supports efficient retrieval of detailed taxonomic information and allows for an exhaustive comparison between competing taxonomic_assignments using a novel rankflexible classification procedure our new classification algorithm invokes variants of lca and best match selection depending on the context of the search results the approach differs from compositional binning methods as it uses larger values for k and unlike alignment search each k_mer is mapped to the individual source genomes minus the genome position the method compensates for the lack of positional_information by resolving the multiple k_mer taxonomy associations recovered during search to assign each read the most rank specific taxonomy identifier possible lmat leverages large single address space memory to efficiently and accurately assign taxonomic labels to individual_reads in large metagenomic_datasets even in the presence of novel organisms although the classification_method is highly automated attention to three parameters should be highlighted minimum read label score minimum difference between the best selected read label score and the competing alternatives and maximum number of taxonomic labels retrieved per k_mer although the first two parameter_settings were preset early in the development stage application to the tyrolean iceman dataset required revisiting these parameters the data featured especially short_reads as short as nt degraded dna likely leading to lower quality_scores and higher_error and substantial human contamination with respect to analyzing the microbial contents as a result the default read label threshold needed to be lowered from to to avoid ignoring a larger fraction of the reads interestingly nt length reads classified as human were assigned a read label score of but could still be classified as human when no competing alternatives were found however if the sample came from a truly unknown source the nt reads with read label scores near would require additional validation the minimum difference threshold also needed to be increased when a large percentage of reads were initially classified as toxoplasma_gondii on further examination the matches identified human contamination in the genomes from lmats reference_database ideally these reads would be classified as superkingdom eukaryota on the first pass identified as both human and t gondii the random model however led to a slightly_lower score for the human label compared with equivalent t gondii label thus while default parameter_settings should be acceptable for many analysis cases there may be conditionswhere awareness of these parameter_settings is needed the final user_defined parameter setting limits the number of candidate taxonomy identifier considered and was set to early on to ensure efficient run times with the understanding that accuracy costs are incurred for genetic fragments associated with a complex taxonomic hierarchy lmats fast run times allow the software to be run initially with default_settings and quickly rerun on targeted subsets of reads as needed the reported lmat tests focus on identifying known organisms in complex samples which the results show still presents a major_challenge the use of relatively short_reads bases indicate that even known sequences can be difficult to taxonomically classify when they represent short genetic_elements conserved among multiple taxa lmat analysis on human clinical samples exhibits a high read label rate allowing the much smaller pool of unlabeled reads to be interrogated for more distant evolutionary_relationships with other tools for some environmental_samples more of the microbial contents are expected to be highly_divergent from the reference_database and populated with greater amounts of non microbial eukaryotic dna in these cases lower rates of read labeling are obtained the supplementary_material shows the high_scoring read label rates score for four different environmental_samples range from to but relaxing the default minimum read label score threshold increases the read label rate to in all cases we find that the species identified by reads with low scores are frequently the same as those identified by high_confidence high_scoring reads one can pull out additional lower scoring reads for taxa that are likely present as indicated by the higher scoring reads thus diminishing the fraction of unclassified reads the flexibility of adjusting the score threshold without rerunning the whole analysis enables lmat to rapidly screen large environmental datasets and obtain a large fraction of labeled reads although the full library should be fast enough to run on large metagenomes marker libraries still have a speed advantage recently_published marker library approaches like metaphlan rely on bacterial marker_genes which cannot be applied directly to other microbial contents other marker libraries like sequedex rely on an individual marker sequence to contain the taxonomic signal in a single contiguous genetic element by contrast our method resolves the taxonomic signal across the entire read with a scoring procedure individual k_mers may contain part of the signal with the intersection of taxonomic labels from multiple k_mers yielding a stronger signal and thus accuracy should improve with sequencer read_length the reference_database size is a function of genetic and taxonomic diversity allowing near neighbors to be added with only a limited increase in the database size as the number of neighbor strains increase strain level discrimination run time costs grow although our method reports strain level discrimination accuracy was measured at the species level because minimum genome_coverage affects accuracy and the available synthetic test_sets focus on species discrimination future work will include designing better strain discrimination tests and expand the database to include functional_annotation 
