predicting regulatory variants with composite statistic motivation prediction and prioritization of human non coding regulatory variants is critical for understanding the regulatory_mechanisms of disease_pathogenesis and promoting personalized_medicine existing_tools utilize functional_genomics data and evolutionary_information to evaluate the pathogenicity or regulatory_functions of non coding variants however different algorithms lead to inconsistent and even conflicting predictions combining multiple methods may increase accuracy in regulatory variant prediction results here we compiled an integrative resource for predictions from eight different tools on functional_annotation of non coding variants we further developed a composite strategy to integrate_multiple predictions and computed the composite likelihood of a given variant being regulatory variant benchmarked by multiple independent causal_variants datasets we demonstrated that our composite model significantly_improves the prediction_performance availability_and we implemented our model and scoring procedure as a tool named prvcs which is freely_available to academic and non profit usage at http jjwanglab org prvcs interpreting functions of non coding regulatory variants is an important topic in current genetics study because the majority of the variants discovered by genome_wide gwass and large_scale cancer whole_genome studies are located in the non coding regulatory_regions thus evaluating and prioritizing the functional impact of regulatory variants especially for their roles in disease pathogenicity and applications in personalized_medicine are major challenges in current human_genetics with the accumulation of functional_genomics data computational_methods have been developed to predict and prioritize noncoding regulatory variants strategies such as supervised_learning trained on different gold_standard datasets as gwava funseq funseq gwas d surfr dann and fathmm mkl can achieve satisfactory performances based on different levels of functional_annotations and causality assumptions however current methods either performed_poorly or acted inconsistently compared with in vivo saturation mutagenesis of enhancer region to systematically assess the performance and consistency of current methods comprehensive evaluations are needed using different genome_wide benchmark_datasets in addition computing and querying prediction results from separate algorithm database web_server is a time consuming process resources which can integrate pre_calculated prediction scores for prevalent algorithms will benefit the functional_annotation of regulatory variants furthermore it has been demonstrated that combining multiple algorithms significantly_outperforms each single_measurement in prioritizing disease_causing non_synonymous variants and positively_selected loci which implies potential effectiveness in non coding regulatory variants prioritization in this study we first compiled genome_wide prediction scores from eight tools that prevalently used in predicting non coding regulatory variants we observed significant inconsistence among these investigated predictions to borrow the potential complementarities and strengths of different tools we used a composite strategy to integrate_multiple predictions and compute the composite likelihood of a given variant being causal in gene_regulation we demonstrated that our method significantly_improved the performance of regulatory variants prediction and prioritization in several independent benchmark_datasets in summary we have addressed several essential problems in the field of regulatory genetic_variants prioritization we provide an integrative and lightweight resource to facilitate the efficient query of prediction scores for current prevalent algorithms the refined training and benchmark data of regulatory variants could be used to evaluate subsequent methods in the future the inconsistent prioritization among existing_tools impedes the identification of true regulatory variants compared with the field of disease causal nonsynonymous variant prediction ensemble methods are urgently_needed to predict and prioritize non coding regulatory variants our composite strategy takes_advantage of the complementary attributes of individual tools to achieve a better performance identifying the high_quality and confident causal regulatory variants training_dataset including functional and pathogenic and corresponding control is challenging because the mechanisms of gene_regulation are complicated regulatory variants could affect many different gene_regulation processes such as transcription_factor binding nucleosome_positioning epigenomic modification and noncoding_rna tethering the limited number ofpredicting regulatory variants with composite statisticexperimentally validated regulatory variants impedes the comprehensive and sufficient capture of these regulatory_events for example there are only a few hundred known causal non coding variants in clinvar and oreganno databases and these variants are highly region biased lots of clinvar pathogenic_variants are colocated many oreganno variants are located in the tss region although current massively_parallel reporter_assay has been applied to investigate the allele effect on gene_expression studies were only carried_out on limited chromosome_regions and inevitability lost chromatin context on the other hand current high_density genotyping_arrays and sophisticated fine_mapping strategies enable us to identify the most likelycasual variants from large_scale gwas and qtl studies the most widely used hgmd database has integrated many diseaseassociated variants although we still face difficulty to identify false_positive hits from ld proxy of gwas fine mapped snps to construct larger and less regionbiased training_dataset incorporating the most reliable gwas qtl fine_mapping results would be a temporary practicable solution in the non coding regulatory variant prediction field besides selecting appropriate control dataset could improve the training model comparing with the random regional sampling our control selection_strategy can avoid the bias of specific region selection such as promoter and remove all causal ld blocks that may contain bias of gwas ascertainment however there is still no guarantee that those variants are not functional also some of our control snps could locate in the intron region and regulate pre mrna_processing and splicing furthermore snps in the exonic region which were omitted by our selection can also regulate the gene_expression the correlations among the investigated existing_methods are from weak to moderate which might be attributed to the different perspectives and logics of existing algorithms cadd and dann applied fixed or nearly fixed human derived alleles and simulated de_novo mutations to train the model which focus on classifying the deleterious variants from neutral selected variants however our refined training_dataset summarized causal_variants from a regulatory angle by merging the functional regulatory deleterious and pathogenic non coding variants therefore compared with tools trained on hgmd gwava fathmm mkl and surfr or under regulatory assumption gwas d funseq and funseq cadd and dann didnt perform well in most of the evaluations on regulatory qtls but obtained good performance on clinvar dataset this may suggest that our composite method is very suitable to prioritize functional regulatory variants instead of identifying pathogenic non coding variants using dann and cadd in addition certain annotation_features were frequently incorporated into many algorithms resulting in the similar scoring_scheme of specific variants clearly cadd and dann utilized same feature_set and are hence moderately correlated also encode genomic epigenomic annotations as well as base wise evolutionary_information like gerp and phastcons were substantially adopted in funseq funseq gwas d surfr and fathmm mkl interestingly cadd and fathmm mkl used different training_datasets but correlated well with each other probably due to large number of shared annotation_features the better performance of our subset combination model than the full model may reflect these redundant or even conflicted relationships among existing_tools nevertheless large and independent gold_standard is needed to test the correlation of different tools and stability of reduced combination model furthermore for some machine_learning programs like cadd dann gwava and fathmm mkl they used training_dataset partially overlap with our refined training_dataset so the performance might be inflated in cross_validation therefore completely_independent and highquality causal non coding regulatory variants are needed 
