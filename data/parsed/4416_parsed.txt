genome_analysis statistical confidence measures for genome maps application to the validation of genome_assemblies motivation genome maps are imperative to address the genetic_basis of the biology of an organism while a growing number of genomes are being sequenced providing the ultimate genome mapsthis being done at an even faster pace now using new generation sequencersthe process of constructing intermediate maps to build and validate a genome_assembly remains an important component for producing complete_genome however current mapping_approach lack statistical confidence measures necessary to identify precisely relevant inconsistencies between a genome map and an assembly results we propose new methods to derive statistical_measures of confidence on genome maps using a comparative model for radiation hybrid data we describe algorithms allowing to i sample from a distribution of maps and ii exploit this distribution to construct robust maps we provide an example of application of these methods on a dog dataset that demonstrates the interest of our approach availability methods are implemented in two freely_available softwares carthagenegenome maps are imperative to address the genetic_basis of an organism biology while a growing number of genomes are being completely_sequenced providing the ultimate genome maps the process of constructing intermediate mapsgenetic maps rh maps to name only a fewremains certainly an important task indeed the current whole_genome shotgun approach for genome_sequencing produce a large number of contigs and scaffolds of limited length the n scaffold size of the recent panda genome_assembly for example reaches mb compared with the mb of the smallest human_chromosome providing a limited picture of the genome_architecture for this species dense chromosomal maps remain invaluable for organizing the scaffolds along the chromosomes and to whom correspondence should be addressed can be of great help for checking the order of markers within assemblies radiation hybrid rh maps for example have played_an in facilitating the process of whole_genome and assembly they provide an independent source of information for the validation of genome_assemblies because the comparison of maps produced by independent protocols genetic rh sequence_based gives clues about map accuracies one of the most sensitive aspect of comparing maps howeverfor example the comparison of a map to a genome assemblylies in the interpretation of inconsistencies indeed as a result of the limited nature of experimental_data used in the mapping construction process the resulting maps are not exempt of errors perhaps more importantly because of the difference in marker informativeness and also in the density of markers along a map the experimental_data support for the local order of markers at different locations of the map may vary_considerably the usual output of a mapping experiment consists however in a single map representing the optimal_solution of the optimization_problem associated with the mapping experiment e g minimum obligate breaks or maximum_likelihood order in genetic or rh mapping while lod_scores between pairs of markers in genetic or rh maps measure the degree of linkage between adjacent markers genome maps lack statistical confidence measure to reflect middle to long_range accuracy in contrast for example to the long_standing practice of support values in phylogenetic_analysis i e the bootstrap values or the bayesian posterior_probabilities for the internal nodes of phylogenetic_trees the aforementioned difficulties are particularly relevant when addressing the quality of genome_assembly indeed having in hand a single map resulting from a mapping_process and a single genome_assembly there is no straightforward rules that enable to select assembly regions inconsistent with the map that deserve further investigations here we propose to address this difficulty by constructing statistical confidence measures for maps that reflect locally the confidence or support we have for a particular map order this enables to rank the inconsistencies with respect to these measures and help in the validation of whole genome_assemblies previous work has been done on the modeling of map uncertainty using bayesian_models for rh data and genetic data they were however limited to a small number of markers in this article we propose a new model that i exploit the availability of prior information on marker ordering on a closely_related or on a draft assembly and ii aims at analyzing large_datasets such as provided by high_throughput genotyping_platforms snp_chips radiation_hybrid is a powerful_tool to facilitate the localization of genes of interest on animal_genomes integrating comparative_genomics into rh mapping allows to further improve the mapping_process by exploiting the important colinearity conserved synteny between genomes of closely_related in this work we present methods that exploit this model to help in the process of producing robust whole genome_assemblies we exploit a comparative model which has the key property that only when the rh data is informative enough with respect to a different ordering than that of the reference order will an alternative order be accepted as a consequence our approach allows to pinpoint regions where the assembly order disagree with an rh map order that is strongly supported by the rh data as was previously explained by we found that the main impact of the presence of genotyping_errors was to increase the uncertainty in the marker ordering this can be explained by the resulting inflation of markers distances corresponding to higher estimates of breakage probability the main consequence is that robust maps tend to have a smaller number of markers however the quality of the robust maps which we measured by the lis criterion is only marginally impacted this shows how estimating the map uncertainty allows to take into account and to some extent overcome the problems created by genotyping_errors to further reduce the uncertainty in the maps when errors are present we propose to combine an error_model with the map distribution we observed however that for high_error in our simulations using imputations was not enough to produce good quality robust maps indeed it tended to produce robust maps with a higher number of markers but low lis i e a biased inference our explanation for these results is that the initial map distribution which we use for imputation is too far from the true distribution to provide accurate imputation of the genotypes and consequently good robust maps in particular we observed that some of the markers tend to have a very large number of imputations most of them being erroneous see supplementary this is in great contrast with imputation on datasets with a error_rate and explains the differences in performance in these two cases more generally our results stress the fact that the estimation of the map distribution is greatly impacted by markers with a large number of errors for real_data care as to be taken for including only markers for which genotyping is a priori of good quality the criteria to identify good quality marker will depend on the genotyping method used for snp_chips our experience is that genotyping controls markers and non irradiated genome and using conservative thresholds for genotype_calling from the raw_data are quite important considering that today the density of markers provided by snp_chips is larger than the one that the resolution of rh panels allows to separate working with a subset of high_quality markers is not problematic this being said it is reassuring to note that even large error_rates can be estimated confidently with the error_model supplementary this has the practical consequence of providing a mean to quantify the level of confidence that can be placed in the data to produce good rh maps the robust maps presented here correspond to a subset of markers with an order common to all the maps in the distribution we can note that a search for the longest common subsequence of all the maps would lead to the same subset of markers the notion of robust maps however can easily be extended using the inclusion tree as a guideline to a subset of markers with preserved order in a controlled proportion of the distribution e g this last notion is very close to the notion of framework maps well known in the context of rh mapping the metamap representation of the distribution of maps could therefore eventually_lead new approaches for the construction of framework maps a classical problem when using mcmc is to make sure that the chain has converged and provides samples from the target distribution our main argument to show that the mcmc chains have converged in our simulation is the good calibration of the posterior distributions of the probability of adjacency we obtained this result while performing a relatively modest number of iterations but in the same time using proposal distributions that tend to propose moves with high_probability of acceptance see details in appendix provided in supplementary_material on the dog data we checked that our results were consistent across several mcmc runs indicating that we have performed a sufficient number of iterations in previous bayesian approaches to rh mapping the authors were dealing with much smaller datasets and incorporated the estimation of breakage probabilities and retention fraction into the model with large_datasets this becomes computationally impractical and so we relied on simple points estimates for these quantities although trying to incorporate an update of these parameters without increasing too much of the computation time could be interesting our results show that good robust maps can be obtained with our more simple approach an important aspect of our model is the incorporation of a reference order as a prior for the sampling of maps via the mcmc_algorithm we found that this was particularly true when running the algorithm on the rh data without a reference order which corresponds to specifying a uniform prior on all possible orders the number of maps visited becomes huge after very few iterations using comparative information allows to reduce the space of orders visited to those that are compatible with the mechanisms of chromosome evolution known to preserve large conserved segments between genomes of related species in our example of application in the dog we used the human_genome as a reference this was possible in large part because the markers used were gene coding_sequences page 
