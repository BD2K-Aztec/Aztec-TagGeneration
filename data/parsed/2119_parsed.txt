graphical pan genome_analysis with compressed suffix_trees and the_burrows motivation low_cost genome_sequencing gives unprecedented complete information about the genetic_structure of populations and a population graph captures the variations between many individuals of a population recently marcus et_al proposed to use a compressed_de for representing an entire population of genomes they devised an on log g time algorithm called splitmem that constructs this graph directly i e without using the uncompressed de_bruijn graph_based on a suffix_tree where n is the total length of the genomes and g is the length of the longest genome since the applicability of their algorithm is limited to rather small_datasets there is a strong need for space efficient construction algorithms results we present two algorithms that outperform splitmem in theory and in practice the first implements a novel linear time suffix_tree algorithm by means of a compressed suffix_tree the second algorithm uses the burrowswheeler_transform to build the compressed_de in on log r time where r is the size of the alphabet to demonstrate the scalability of the algorithms we applied it to seven human_genomes availability_and we implemented our new algorithms in c using the library sdsl of software and test data are available at http www uni ulm de in theo research seqana html both algorithms use a variant of the semi external algorithm described into construct the cst and the bwt respectively the experiments were conducted on a bit ubuntu lts kernel system equipped with two ten core intel_xeon processors e v with ghz and gb of ram but no parallelism was used all programs were compiled with g version using the provided makefile with the cst based and the bwt based algorithm respectively we built compressed de_bruijn for the e coli genomes containing million base_pairs listed in the supplementary_material of using the k_mer lengths and lists the results of our experiments the run times include the construction of the index but similar to splitmem it is unnecessary to rebuild the index for a fixed dataset and varying values of k the peak memory_usage reported inincludes the size of the index and the size of the compressed_de because of its large memory_requirements splitmem was not able to build a compressed_de for all strains of e coli on our machine equipped with gb of ram that is why we included a comparison based on the first e coli genomes containing million base_pairs of the dataset the experimental_results show that both of our algorithms use significantly less space two orders_of than splitmem the cst based algorithm is five times_faster than splitmem while the bwt based algorithm is more than an order of magnitude faster it is worth mentioning that our two algorithms compute isomorphicbut not necessarily identicalcompressed de_bruijn because the node identifiers may differ to show the scalability of our new algorithms we applied them to five different assemblies of the human_reference ucsc_genome assembly ids hg hg hg hg and hg as well as the maternal and paternal haplotype of individual na utah female of the genomes_project see the compressed de_bruijn of their first chromosomes xchr containing million base_pairs and the complete seven genomes xhg containing million base_pairs were built for the k_mer lengths and the experimental_results inshow that the bwt based algorithm clearly outperforms the cst based algorithm it took slightly over h s to construct the index of the seven human_genomes and less than h s to build the graph with the our cst based algorithm mimics splitmem in this respect whereas the bwt based algorithm treats the different occurrences of as if they were different characters assuming that is the second smallest character this can be achieved as follows as explained in the supplementary_material all right maximal k_mers can be determined without the entire lcp array if the algorithm inis used if there are m occurrences of in total and this algorithm starts with m singleton intervals i i i m instead of the interval m then the different occurrences of are treated as if they were different characters we have presented two space efficient methods to build the compressed_de from scratch an experimental comparison with splitmem showed that our algorithms are more than an order of magnitude faster than splitmem while using significantly less space two orders_of to demonstrate their scalability we successfully_applied them to seven complete human_genomes consequently it is now possible to use the compressed_de for much larger pan genomes than before consisting e g of hundreds or even thousands of different strains of bacteria although the bwt based algorithm is the clear winner of the comparison cstbased algorithms are still important this is because sts play_a in sequence_analysis and most bioinformatics curricula comprise courses that cover this important data_structure it is therefore conceivable that a bioinformatician might be able to come up with a suffix_tree algorithm that solves his her problem at hand but not with an algorithm that is based on the bwt and or related data_structures if the space requirement of the st is the bottleneck in the application one can use a cst instead csts with full functionality are e g implemented in the succinct data_structure library sdsl of on the downside extra features such as suffix skips are not implemented in those libraries so that a direct implementation of a suffix_tree algorithm by means of a cst might not be possible future work includes parallel implementations of the algorithms moreover it should be worthwhile to investigate the time space tradeoff if one uses data_structures that are optimized for highly repetitive texts see navarro and ord n ez and the references therein most important however is to address the problem of compressing the compressed_de itself our experiments show that for smaller k the size of the graph can be larger than the size of the index e g the graph for the seven human_genomes and k takes bytes per base_pair whereas the bwt index requires only bytes per base_pair very recently two bloom_filter methods were presented that can be used for this purpose solomon and kingsford introduced the sequence bloom tree to support sequence_based querying of large_scale collections of thousands of short_read sequencing_experiments and applied it to the problem of finding conditions under which query transcripts are expressed the second approach byis closer to the splitmem approach their data structurethe bloom_filter trie bft allows to efficiently store and traverse the uncompressed de_bruijn in the section conclusion of their article write future work concerns the possibility to compress non branching paths this is exactly what splitmem and our new algorithms do so maybe the combination of both approaches will yield the ideal pan_genome representation the first row in a block specifies the experiment the second row shows the graph size in bytes per base_pair rows contain the numbers of edges nodes uniquenodes and repeatnodes respectively rows show the average out degree of the nodes as well as the average string length of the nodes uniquenodes and repeatnodes the remaining rows if applicable contain the percentage of the nodes that are shared by x sequences 
