hydra gene_prioritization via hybrid distance score rank_aggregation gene_prioritization refers to a family of computational_techniques for inferring disease genes through a set of training genes and carefully_chosen similarity criteria test genes are scored based on their average similarity to the training_set and the rankings of genes under various similarity criteria are aggregated via statistical_methods the contributions of our work are threefold i first based on the realization that there is no unique way to define an optimal aggregate for rank ings we investigate the predictive quality of a number of new aggregation methods and known fusion_techniques from machine_learning and social choice theory within this context we quantify the influence of the number of training genes and similarity criteria on the diagnostic quality of the aggregate and perform in depth cross validation_studies ii second we propose a new approach to genomic_data aggregation termed hydra hybrid distance score rank_aggregation which combines the advantages of score based and combinatorial aggregation techniques we also propose incorporating a new top versus bottom tvb weighting feature into the hybrid schemes the tvb feature ensures that aggregates are more reliable at the top of the list rather than at the bottom since only top candidates are tested_experimentally iii third we propose an iterative procedure for gene_discovery that operates via successful augmentation of the set of training genes by genes discovered in previous rounds checked for consistency motivation fundamental results from social choice theory political and computer sciences and statistics have shown that there exists no consistent fair and unique way to aggregate rankings instead one has to decide on an aggregation approach using predefined set of desirable properties for the aggregate the aggregation methods fall into two categories score and distance based_approaches each of which has its own drawbacks and advantages this work is motivated by the observation that merging these two techniques in a computationally_efficient manner and by incorporating additional constraints one can ensure that the predictive quality of the resulting aggregation algorithm is very high results we tested hydra on a number of gene_sets including autism breast_cancer colorectal_cancer endometriosis ischaemic_stroke leukemia lymphoma and osteoarthritis furthermore we performed iterative gene_discovery for glioblastoma meningioma and breast_cancer using a sequentially augmented list of training genes related to the turcot syndrome li fraumeni condition and other diseases the methods outperform state of the art software_tools such as toppgene and endeavour despite this finding we recommend as best practice to take the union of top_ranked items produced by different methods for the final aggregated list availability_and the hydra software may be downloaded from http web engr illinois edu mkim hydra zipidentification of genes that predispose an individual to a disease is a problem of great interest in medical_sciences and systems_biology the most accurate and powerful_methods used for identification are experimental in nature involving normal and disease samples experiments are time consuming and costly complicated by the fact that typically multiple genes have to be jointly mutated to trigger the onset of a disease given the large number of human genes testing even relatively small_subsets of pairs of candidate_genes is prohibitively_expensive to mitigate this issue a set of predictive analytical and computational_methods have been proposed under the collective name gene_prioritization techniques gene_prioritization refers to the complex procedure of ranking genes according to their likelihoods of being linked to a certain disease the likelihood_function is computed based on multiple sources of evidence such as sequence_similarity linkage_analysis gene_annotation functionality and expression activity gene_product attributesall determined with respect to a set of training genes a wide_range of tools has been developed for identifying genes involved in a disease as surveyed existing software includes techniques based on network information such as guildify and genemania data_mining and machine_learning based_approaches as described in pocus suspects and and methods using statistical_analysis including endeavour toppgene and networkprioritizer here we focus on statistical_approaches coupled with new combinatorial algorithms for gene_prioritization and emphasize one aspect of the prioritization procedure rank_aggregation the problem of aggregating rankings of distinct objects or entities provided by a number of experts voters or search_engines has a rich history one of the key_findings is that various voting paradoxes arise when more than three candidates are to be ranked it is frequently possible not to have a candidate that wins all pairwise competitions the condorcet paradox and it is theoretically impossible to guarantee the existence of an aggregate solution that meets certain predefined set of criteria such as those imposed by arrows impossibility theorem these issues carry over to aggregation methods used for gene_discovery and as a result the rank ordered lists of genes heavily depend on the particular aggregation method used two families of methods have found wide_applications in rank_aggregation combinatorial methods including score and distancebased approaches and statistical_methods in the bioinformatics literature the aggregation methods of choice are statistical in nature relying on pre specified hypotheses to evaluate the distribution of the gene rankings one of the earliest prioritization softwares endeavour uses the q statistics for multiple significance testing and measures the minimum false_discovery at which a test may be called significant in particular rankings based on different similarity criteria are combined via order_statistics approaches for this purpose one uses the rank ratio normalized ranking of a gene g for m different criteria r g r m g and recursively computes the q value defined aspost processed q values are used to create the resulting ranking of genes the drawbacks of the method are that it is based on a null_hypothesis that is difficult to verify in practice and that it is computationally_expensive as it involves evaluating an m fold integral to enable efficient scaling of the method endeavour resorts to approximating the q integral the influence of the approximation errors on the final ranking is hard to assess as small changes in scores may result in significant changes of the aggregate orderings likewise toppgene uses a well known statistical_approach called the fisher v method it first determines the p values of similarity_score indexed by j denoted by p j for j m the p values are computed through multiple preprocessing stages involving estimation of the information contents i e weights of annotation terms setting up a similarity criteria based on sugeno fuzzy measures i e non additive measures and performing meta testing the use of fuzzy measures ensures that all similarities are non negative then under the hypothesis of independent_tests toppgene uses fishers inverse v result stating that x m j logpj v m here v m stands for the chisquare distribution with m degrees_of the result is asymptotic in nature and based on possibly impractical independence assumptions a number of methods and additive scoring_methods in particular have the drawback that they tacitly or implicitly rely on the assumption that i only the total_score matters and the balance between the number of criteria that highly ranked the gene and those that ranked it very low is irrelevant for example outlier rankings may reduce the overall ranking of a gene to the point that it is not considered a disease gene candidate while the outlier itself may be a problematic criterion to illustrate this observation consider a gene that was ranked st nd st th by four criteria at the same time consider another gene that was ranked th by all four criteria it may be unclear which of these two genes is more likely to be involved in the disease given that additive score methods would rank the two genes equally as one has nevertheless it appears reasonable to assume that the first candidate is a more reliable choice for a disease gene as it had a very high_ranking for three out of four criteria and ii no distinction is made about the accuracy of ranking genes in any part of the list i e the aggregate ranking has to be uniformly accurate at the top middle and bottom of the list clearly neither of the two aforementioned assumptions is justified in the gene_prioritization process there are many instances where genes similar only under a few criteria such as sequence_similarity or linkage distance are involved in the same disease pathway furthermore as the goal of prioritization is to produce a list of genes to be experimentally tested only the highest ranked candidate_genes are important and should have higher accuracy than other genes in the list in addition most known aggregation methods are highly_sensitive to outliers and ranking errors we propose a new approach to gene_prioritization by introducing a number of novel aggregation paradigms which we collectively gene_prioritization via hydrarefer to as hydra hybrid distance score rank_aggregation the gist of hydra is to combine combinatorial approaches that have universal axiomatic underpinnings with statistical_evidence pertaining to the accuracy of individual rankings our preferred distance measure for combinatorial aggregation is the kendall distance which counts the number of pairwise disagreement between two rankings and was axiomatically postulated by kemeny the kendall distance is closely_related to the kendall rank correlation_coefficient as such it has many properties useful for gene_prioritization such as monotonicity reinforcement and pareto efficiency the kendall distance can be generalized to take into account positional relevance of items as was done in our companion article there it was shown that by assigning weights to pairs of positions in rankings it is possible to i eliminate negative outliers from the aggregation_process ii include quantitative data into the aggregate and iii ensure higher accuracy at the top of the ranking than at the bottom the contributions of this work are threefold first we introduce new weighted distance measures where we compute the weights based on statistical_evidence of a function of the difference between p values of adjacently ranked items aggregation weights based on statistical_evidence improve the accuracy of the combinatorial aggregation procedure and make them more robust to estimation errors second we describe how to scale the weights obtained based on statistical_evidence by a decreasing sequence of tvb top versus bottom multipliers that ensure even higher accuracy at the top of the aggregated list as aggregation under the kendall metric is np_hard non deterministic polynomial time hard and the same is true of the weighted kendall metric we propose a approximation_method that is stable under small_perturbations aggregation is accomplished via weighted bipartite matching such as the hungarian algorithm and derivatives thereof third we test hydra within two operational scenarios cross_validation and disease_gene in the former case we assess the performance of different hybrid methods with respect to the choice of the weighting function and different number of test and training genes in the latter case we adapt aggregation methods to gene_discovery via a new iterative re ranking procedure we performed extensive cross validation_studies for eight diseases using both endeavour and toppgene generated p values our results indicate that the similarity criteria that exhibits the strongest influence on the performance of the toppgene and the endeavour method is the pubmed and literature criteria which award genes according to their citations in the disease related publications in order to explore this issue further we performed additional cross validation_studies for both toppgene and endeavour datasets to examine how exclusion of the literature criteria changes the performance of the two methods as well as our hybrid schemes our results reveal that hydra aggregation methods outperform endeavour and toppgene procedures for a majority of quality_criteria but they also highlight that each method offers unique advantages in prioritization for some specific diseases for gene_discovery we again used endeavour and toppgene p values and investigated three diseasesglioblastoma meningioma and breast cancerincluding all criteria available we recommend as best practice a nested aggregation method i e aggregating the aggregates of endeavour hydra and toppgene coupled with iterative training_set augmentation we start by discussing the results in the first observation is that the lov sz bregman method performs worse than any other aggregation method this finding may be attributed to the fact that the p values have a large span and small values may be masked by larger ones scaling all p values may be a means to improve the performance of this technique but how exactly to accomplish this task remains a question in almost all cases except for leukemia and lymphoma the average rankings produced by toppgene and the weighted kendall distance appear to be almost identical but average values may be misleading as individual rankings of genes may vary substantially between the methods as can be seen from the supplementary_material it is due to this reason that we recommend merging lists 
