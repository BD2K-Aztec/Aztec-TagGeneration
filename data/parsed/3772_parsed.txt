data_and prroc computing and visualizing precision_recall and receiver_operating in r precision_recall pr and receiver_operating roc_curves are valuable measures of classifier performance here we present the r package prroc which allows for computing and visualizing both pr and roc_curves in contrast to available r packages prroc allows for computing pr and roc_curves and areas under these curves for soft labeled data using a continuous interpolation between the points of pr curves in addition prroc provides a generic plot function for generating publication quality graphics of pr and roc_curves the assessment of classifier performance is a recurring task in machine_learning and data_mining and in particular in bioinformatics applications it assists researchers in identifying the most promising approach for the classification_problem at hand for binary_classification tasks the receiver_operating roc_curve and the area under this curve auc roc are widely_accepted as a general measure of classifier performance in many bioinformatics applications however positive examples are substantially less abundant than negative_examples resulting in a highly imbalanced class ratio for instance the number of target_genes of a microrna is substantially smaller than the number of non target_genes in such cases the precision_recall pr curve and auc auc pr is better suited for comparing the performance of individual classifiers than the roc_curve and auc roc often the decision for the true class_labels of a given data point is arguable and for instance based on an arbitrary threshold for some continuous measurement or based on multiple possibly contradictory expert labelings however the choice of this threshold decisively influences classifier training and assessment one solution to this problem is the transition from hard labeling to softlabeling where each data point is assigned to both classes with a certain probability that reflects confidence in the labeling although soft labeling has been used extensively for classifier training in the past it has been neglected for classifier assessment computing empirical auc pr and auc roc values from a limited set of test data_points requires interpolation between discrete supporting points corresponding to a series of classification threshold affecting the classification result auc roc can be computed by linear_interpolation between the supporting points of the curve for hard labeled and soft labeled data in contrast davis andshow that for auc pr an interpolation along the true_positives is more accurate than linear_interpolation for hardwe present prroc an r package for computing pr and roc_curves as well as their aucs for soft labeled and hard labeled data which may be beneficial for typical bioinformatics applications additionally prroc provides a function for plotting pr and roc_curves within r the prroc package provides r documentation files and a vignette conflict of interest none declared plots of roc left and pr right curves generated by prroc for the roc_curve we consider hard labeled data and show the plotting variant with a color scale that indicates classification thresholds yielding the points on the curve for the pr curve we consider soft labeled data and show a comparative plot for two classifiers as solid and dashed lines we also include the maximal and minimal possible curves and the curve of a random classifier for the given soft labels 
