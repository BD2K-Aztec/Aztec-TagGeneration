data_and exploration and retrieval of whole metagenome sequencing samples motivation over the recent_years the field of whole metagenome shotgun_sequencing has witnessed significant growth owing to the high_throughput that allow sequencing genomic samples cheaper faster and with better coverage than before this technical advancement has initiated the trend of sequen_cing multiple samples in different conditions or environments to explore the similarities and dissimilarities of the microbial_communities examples_include the human_microbiome and various studies of the human intestinal_tract with the availability of ever larger databases of such measurements finding samples similar to a given query sample is becoming a central operation results in this article we develop a content based exploration and retrieval method for whole metagenome sequencing samples we apply a distributed string mining framework to efficiently extract all informative sequence k_mers from a pool of metagenomic_samples and use them to measure the dissimilarity between two samples we evaluate the performance of the proposed approach on two human_gut metagenome datasets as well as human_microbiome metagenomic_samples we observe significant_enrichment for diseased gut samples in results of queries with another diseased sample and high_accuracy in discriminating between different body sites even though the method is unsupervised availability_and a software implementation of the dsm framework is available at https github com hiitmetagenomics metagenomics is the study of microbial_communities in their natural_habitat using genomics techniques it is undergoing a boom owing to the proliferation of highthroughput sequencing_technologies many studies focus at targeted_sequencing of specific marker_genes such as the s rrna gene in bacteria but recently there has been a growing interest in whole metagenome sequencing e g human_microbiome although targeted studies provide data for phylogenetic profiling at a lower cost whole metagenomes provide much more information for example about the collective metabolism and the population_genetics of the community recent_studies have also found associations between features of whole human_gut metagenomes and type_ii new data are accumulating rapidly with a popular web_based mg rast server listing almost public whole metagenomes analyzing whole metagenome shotgun wms sequencing_data is very challenging the original_sample typically contains genetic_material from hundreds to thousands of bacterial_species of different abundances most of which have not been fully_sequenced previously after sequencing we obtain a huge collection of short_sequence whose species of origin is unknown although significant progress has been made analysis relying on either the limited previously annotated genomes or assembling the reads into novel more complete_genomes remains difficult and inefficient and potentially susceptible to annotation biases in this article we introduce an efficient purely data_driven feature_extraction and selection method as well as similarity_measures for wms sequencing_datasets and apply them in retrieval of similar datasets such content based retrieval is an extremely powerful_tool for exploration of the data and generating hypotheses of disease associations as previously demonstrated with gene_expression data retrieval from existing databases makes it possible to automatically explore a much greater variety of hypotheses than relying solely on the more common specifically_designed focused studies content based similarity_measures and retrieval of similar metagenomic_datasets have been suggested previously based on quantifying abundances over a relatively small number of predetermined features requiring existing annotation up to some thousands of known taxa genes or metabolic_pathways have been used we introduce similarity_measures that are based solely on raw sequencing_reads and hence unbiased and insensitive to the quality of the existing annotation a similar measure has been previously_suggested by but only for pairwise_comparisons using a method that is computationally too expensive to scale to even modestly large to whom correspondence should be addressed the author published_by this is an open_access the terms of the creative commons attribution license http creativecommons org licenses by which_permits distribution and reproduction in any medium provided the original_work datasets furthermore instead of considering all sequences of particular length also known as k_mers as has been done earlier for other tasks and by we employ an efficient distributed string mining dsm algorithm to find informative subsequences that can be of any length to deal with the large number of features some feature_selection is necessary previous_approaches for detecting relevant_features in metagenomic_data have been based on direct comparison of two classes of samples again most of these methods work on up to some thousands of features with the notable_exception of one study where quantification and association testing was done for million predefined genes without feature_selection one can use short k_mers or limit to a set of k_mers that are likely to be informative such as k_mers associated with well characterised protein_families although there are no previous examples of unsupervised feature_selection for metagenomics it is a common practice in information_retrieval with text documents a particularly relevant method assesses the entropy of the distribution of documents in which a specific term occurs we evaluate the performance of the proposed unsupervised unconstrained retrieval method on synthetic data as well as metagenomic_samples from human_body sites to evaluate the performance of the retrieval engine we use external_validation based on a ground_truth similarity between two samples to simplify this process we consider a binary similarity which is crude but easily_accessible the human_gut samples in come from studies_exploring the change in bacterial species_composition between healthy_persons and either inflammatory_bowel ibd or type_ii we utilize disease_state to construct a binary ground_truth thus we study if given the metagenomic sample of a person with a disease the retrieval finds metagenomic_samples related by having the same disease in the body site data human_microbiome we use the body sites as ground_truth to investigate whether it is possible to identify the bacterial_communities at different body sites in an unsupervised setting without the need of reference_genomes it should be noted that especially for the gut data two samples may be related in other ways too the external_validation with one simple ground_truth nonetheless provides an objective platform for comparing different methods given that the method is unsupervised and hence completely oblivious of the disease labels if such retrieval is successful it is a promising starting_point for developing methods for leveraging data from earlier patients in early detection of disease and personalized_medicine of a retrieval task iii compute a distance_metric using the filtered k_mer frequencies and iv execute these steps fast without explicitly storing the frequency values summarizes the method we evaluated the retrieval_performance on three human metagenomics datasets metahit metagenomic_samples from healthy people and patients with ibd syndrome each sample has on average ae million_reads our goal was to retrieve ibd positive patients t d phase_ii metagenomic_samples from healthy people and patients_with each sample has on average ae million_reads our goal was to retrieve patients with diabetes we chose to explore the phase_ii data instead of the phase i data as the former has higher_coverage about more reads than the latter of samples that passed the qc assessment http www hmpdacc org hmasm we discarded samples that had of the number of reads of the largest sample to recapitulate for metahit and t d p our goal is to observe if given a positive sample e g from a patient with a particular disease one can retrieve relevant samples i e with similar disease whereas for hmp our goal is to observe if given a sample from a particular body site one can retrieve relevant samples i e samples from the same body site for all data we applied a quality threshold of and ignored any base_pairs with quality less than the threshold gives an overview of the computational resources_required for each dataset additionally number of k_mers used by different methods for each dataset are available in the supplementary retrieval of samples with similar annotation we applied the proposed approach and a number of alternatives for retrieval of similar samples from the same dataset and evaluated by how many of the retrieved samples had the same annotation class label disease_state or body site a comparison of the obtained map values averaged over queries by all positive samples is shown in the results show the performance achieved by the optimized metric the alternatives we considered were i retrieval_performance based on the proposed distances between frequencies of mers appearing in known protein_families figfams with added pseudocounts but without entropy filtering ii retrieval based on bray curtis dissimilarity between relative species abundancesin the wake of collecting multiple samples from similar environments information_retrieval for metagenomic_samples is expected to become a handy tool in metagenomics research in this article we have addressed the problem of retrieving relevant metagenomic_samples given a query sample from the same collection the novelty of the proposed approach is that it is unsupervised and does not rely on the availability of reference_databases we for proposed approach all individual ks as well as figfam based distance_metric the metrics are optimized averaged over equally_spaced threshold_values between and each error bar line shows the map value along with the standard_error the grey horizontal line shows retrieval by chance map computed over zero dissimilarity metric an arrow if present over a method implies whether the performance of the corresponding method top average metric bottom optimized metric is better or worse than when entropy filtering is employed the stars denote significance_level we observe that filtering has a positive impact on the retrieval_performance comparison of best performances for different k_mer lengths the figures show the performance over queries by all positive samples as a violin plot all methods use the optimized metric chosen over equally_spaced threshold_values between and the box denotes the map value the horizontal lines show retrieval by chance avep computed over zero dissimilarity metric straight_line is the mean and dotted lines are and quantiles respectively when number of relevant samples differ for different queries an arrow if present over a method implies whether the corresponding method performs significantly better or worse than all the stars denote significance_level we observe that the considering all k_mers usually perform equally well with respect to considering a single k 
