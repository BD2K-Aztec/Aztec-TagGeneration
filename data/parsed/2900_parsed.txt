metafast fast reference free graph_based comparison of shotgun metagenomic_data motivation high_throughput metagenomic_sequencing has revolutionized our view on the structure and metabolic potential of microbial_communities however analysis of metagenomic composition is often complicated by the high_complexity of the community and the lack of related reference genomic_sequences as a start point for comparative metagenomic_analysis the researchers require efficient means for assessing pairwise similarity of the metagenomes beta diversity a number of approaches were used to address this task however most of them have inherent disadvantages that limit their scope of applicability for instance the reference based_methods poorly perform on metagenomes from previously unstudied niches while composition based_methods appear to be too abstract for straightforward interpretation and do not allow to identify the differentially_abundant features results we developed metafast an approach that allows to represent a shotgun metagenome from an arbitrary environment as a modified de_bruijn consisting of simplified components for multiple metagenomes the resulting representation is used to obtain a pairwise similarity matrix the dimensional structure of the metagenomic components preserved in our algorithm reflects the inherent subspecies level diversity of microbiota the method is computationally_efficient and especially promising for an analysis of metagenomes from novel environmental niches availability_and source_code are freely_available for download at https github com ctlab metafast the code is written in java and is platform independent tested on linux and windows x recently computational life_scientists have witnessed an astounding increase in the volume of available shotgun metagenomic_datasets the challenge of reducing dimensionality of the data analysis is of primary demand for statistical_analysis of metagenomes this includes taxonomic and functional profiling assessing richness and similarity technological_advances and cost reduction of high_throughput allow to examine microbiota from previously unexplored ecological_niches the degree of detail has increased in an unprecedented way the average coverage depth has increased by several orders_of since the first metagenomic_studies vast genomic_data obtained in studies of microbial isolates served as a cornerstone for developing reference based_approaches subsequently there was a boom of such methods based on more elaborate techniques than direct alignment of each read with a reference_genome e g kraken clark focus metaphlan however a real challenge for reference based_methods is represented by the communities from novel unexplored niches that contain a large fraction of uncultured bacteria accordingly there is a lack of representative genomes for many clades of microbes and viruses that could serve as a reference this problem is of significant weight even for the environments that have been thoroughly studied for decades e g human_gut where unknown genomes form a lions share of the total dna_reads one of the approaches for measuring metagenomic similarity that was developed in order to cope with the rapidly_accumulating volume of data is based on an adaptive subsampling another one is an alignment_free approach that appears to be attractive to metagenomic researchers due to the sparseness of available reference_genome sets among such methods there are abstract composition based_methods k_mer spectrum_analysis neural_networks markov_models that are computationally_efficient and can be run in parallel sections however there are certain limitations of these methods the differentially_abundant features between two or more groups of metagenomes turn out to be concealed within the method or provide little information an alternative idea for assessing similarity is a de_novo of the metagenomes similar to the process applied to individual_genomes followed by an analysis of the yielded contigs classification differential abundance analysis based on coverage depth here each individual feature is meaningful however the assembly is complicated due to a wide_range of typical abundance of bacterial_species and significant intra species genomic variability special algorithms intended for metagenomic assembly have been developed that address_these particularly combined assembly of metagenomic_reads was proposed for estimating pairwise similarity crass however complete assembly from reads to contigs is computationally and memory intense especially due to the rapid increase of publicly_available metagenomic_data we have developed the metafast algorithm for compact_representation of metagenomes using an adaptive segmentation of metagenomic de_bruijn essentially based on a simplified metagenomic de_novo our method lies between the k_mer spectrum_analysis and assembly and combines the best of these two alignment_free approaches the speed of the former with the precision of the latter its independence of the reference allows to perform efficiently for both extensively_studied and novel microbiota types the performance of metafast was compared with several taxonomic profilers kraken clark focus metaphlan as well as with a cross assembly based algorithm crass on simulated_data and real metagenomes of gut_microbiota new_york subway and viruses of lake_water comparative_analysis showed that metafast is highly_efficient and the results of its work are in agreement with the existing_methods microbial samples originating in the same type of environment e g gut of the same host_species or from the different time points of the same environment typically contain a significant amount of common bacterial speciesand their genes the abundance of such shared genomic_sequences can be analyzed via various algorithms including those based on the elements of combined assembly of metagenomes particularly metafast when many prevalent components are common for two samples it reflects their similarity while the low number and lack of such components reflect the fact that the communities are quite dissimilar in order to perform a comprehensive evaluation of usability of the metafast algorithm we examined the following essential characteristics in dedicated computational_experiments i accuracy ii speed iii memory_consumption iv dependence on the reference_set regarding accuracy on simple data our method should produce the results that are in agreement with the results obtained on thesame data using a traditional approach i e based on the mapping to the reference_set therefore as a basic check of metafast validity it was compared with a reference based method on the metagenomes with an a priori known composition accordingly we used simulated gut metagenomesto assess accuracy we also tested metafast on previously unexamined novel microbiota data by including ny subway metagenomes and performing the comparison of our method with the published relevant algorithmsto compare the dependence on the reference_set as well as the processing time and memory_consumption to demonstrate the usability of our method in large_scale metagenomic_studies we analyzed a large group of real gut metagenomes and assessed speed accuracy and memory_consumption the stability of metafast derived dissimilarity values in regard to the size of the group was shown using subsamples of this dataset finally to deepen the evaluation of the dependence on the reference we tested metafast and other algorithms on a dataset with an even higher fraction of components with unavailable reference_sequences for which a reference based_approach is expected to faila metagenome of a viral fraction of lake_water microbiota thus evaluating dramatic rates of accumulation of publicly_available metagenomic_data can be illustrated by a times increase in the number of spearman_correlation between the pairwise dissimilarity matrices obtained using metafast and other algorithms the correlation values were obtained using mantel test p the label metafast sp denotes a modified_version of metafast analysis when the step of pseudo assembly is replaced with the assembly using spades metafast nb when it was replaced with the assembly using newbler datasets in some of the largest online metagenomic resources during the last two years the sequencing_depth also grows rapidly reaching more than a hundred of terabasepairs per sample such explosion of metagenomic big_data makes comparative metagenomic_studies an even more challenging area demanding new efficient algorithms and visualization approaches issues of speed accuracy and memory_efficiency become the key_factors for novel approaches in metagenomic data_processing especially when the methods are intended to be applied to the broad_spectrum of environmental datasets available bearing in mind the special nature of metagenomic_datasets we developed a hybrid algorithm that combines the principles of de_novo pseudo assembly with the k_mer spectrum_analysis allowing to perform computationally and memory_efficient accurate analysis for a large number of metagenomes in a reference independent way the domain of shotgun metagenomic_sequences currently contains two large niches the first one encompasses projects that target moderate coverage for a large number of monotypic samples e g human_gut consortia the second category includes the projects mostly oriented towards de_novo of novel genomic_sequences basing on high_coverage of a small number of samplestypically coming from various unique environments e g most metagenomic_datasets can be placed in between of these two extremesby containing a fraction of data from unknown organisms and a fraction of genetic_material already contained in the public reference_databases a researcher chooses the approach basing on the understanding of the proportions between those two fractions in the current dataset interestingly even in a seemingly well understood metagenomes the combination of the accumulated data even from multiple projects allows for the discovery of novel species the two described groups of datasets imply the choice of considerably different types of algorithms alignment against a reference base is a fast and easily parallelized algorithm while assembly algorithms are hardware demanding typical reference based_approaches imply the selection of a similarity criterion to create a non redundant cataloguenormally selecting a sequence of a gene or a genome from a group having a high percent identity over a high percent of length this step creates further biases in mapping the more the difference between the analyzed sequence and the reference the fewer reads are mapped the assembly based_approaches for metagenomic_datasets are using the same paradigm producing long reference_sequences for estimating the relative_abundance of the sequences in a metagenome the mapping is used againthis time against the sequences assembled from metagenomes that are considered to be more appropriate for mapping although one uses several metagenomic_samples to increase the coverage the intrinsic presence of mutations in bacterial_genomes leads to selection of only the one variant of a path in the graph out of all available variants therefore the variants are underrepresented in the final obtained sequencethe genomic_diversity is thus flattened the presented algorithm metafast is an intermediate solution allowing to work with the speed of mapping and at the same time to gain benefits of de_novo assemblyparticularly yielding novel genetic_sequences moreover one of the ideas implemented in the feature representation allows to avoid the mapping bias and to use unflattened references technically metafast has several differences from the traditional metagenomic assembly approaches firstly metafast does not perform a complete de_novo e g used in the global human_microbiome catalog construction but rather an incomplete version of assembly pseudo assembly this greatly_improves the performance of the algorithm in terms of speed to assess whether the precision is affected negatively we replaced the pseudo assembly step with a conventional assemblerthe results were highly_similar second while qin et_al performed the pairwise_alignment of the combined pool of sequences and select a single representative per each cluster basing on high percent identity and alignment_length we do not drop the other similar variants but rather connect all of them into a single subgraph this allows to capture the genomic details of each metagenome individually and then combine the individual results together for the comparison task thirdly we do not perform the final flattening step instead preserving the branching nature of the graph components metafast features thus information about the variation of the same species between different samples is not lost and can be used for further analysis of gene variations this also allows to avoid the mapping biases as the calculation of feature representation in each separate metagenome is performed via k_mer for a branched metafast feature finally in the spirit of metagenome based research metafast allows to identify the features differentiating the groups and concentrate the researchers attention on them advantages of our approach in terms of speed accuracy memory_efficiency and independence of reference base were demonstrated using both simulated and real metagenomes the performance was compared with a variety of tools widely used in metagenomics simulations showed high correlation with the results of read_mapping confirming basic accuracy of metafast however it should be kept in mind that the provided simulated_datasets are a primitive model of real_data particularly genomic polymorphisms and gene content variations are ignored in these simulations a high degree of correlation was shown in experiments with real_data where the results of metafast were compared with two versions of mappingto a reference_genome and gene catalog high correlation with the results obtained via mapping to a genome catalog reflects the correct functioning of the algorithm it means that the most part of genetic_information is mappable to genomes and is also assembled to yield the features noteworthy the comparison of metafast with the combined assembly demonstrated memory_efficiency of metafast while in conventional assembly the memory_usage increases approximately linearly with the number of the samples in metafast it tends to achieve saturation at a certain number of samples e g around for gut metagenomes see supplementary and does not increase further this fact is likely associated with the effect of componentcutter module see methods that limits the size of the total graph as soon as the number of metagenomes is sufficiently_high to encompass the major diversity of community_structures an addition of new metagenomes does not increase the size of the graph thus does not demand extra memory overall our approach provides a more economic memory_usage accompanied with significant speed improvement at the expense of only slight_decrease in accuracy applicability of the approach for a wide_range of problems was demonstrated for metafast it has shown good correlation with the adopted methods in human_gut datasets and comparative accuracy in case of novel microbiota types and reference based_approaches interestingly the only tool comparable to metafast in the terms of applicability to a set of metagenomes without welldescribed reference_set is the crass algorithm designed specifically to assemble species from multiple metagenomes the results of the comparative viral profiling showed that metafast is an adequate tool for dissimilarity analysis of novel microbiota metagenomes due to the independence of the reference base that might also contain poorly_annotated sequences unclassified at various levels of taxonomy our results showed that on viral datasets it outreaches crass in the terms of both speed and memory_consumption allowing to work with hundreds of metagenomes while obviously even in well studied datasets there is a chance to find novel genes we suggest metafast is a very useful tool for exploratory_data the features and their quantification across metagenomes can be obtained rapidly and the technical implementation allows to work with a high number of metagenomes in a robust manner the settings help to orient the algorithm towards obtaining the features of desired lengthcomparable to the typical microbial gene lengthmaking it convenient for primary analysis 
