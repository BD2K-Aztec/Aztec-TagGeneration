genetics_and fast and accurate site_frequency estimation from low coverage sequence_data motivation the distribution of allele_frequencies across polymorphic_sites also known as the site_frequency sfs is of primary interest in population_genetics it is a complete summary of sequence_variation at unlinked sites and more generally its shape reflects underlying population_genetic processes one practical challenge is that inferring the sfs from low_coverage data in a straightforward manner by using genotype_calls can lead to significant bias to reduce bias previous_studies have used a statistical_method that directly estimates the sfs from sequenc ing data by first computing site allele_frequency saf likelihood for each site i e the likelihood a site has each possible allele_frequency conditional on observed sequence_reads using a dynamic_programming dp algorithm although this method_produces an accurate sfs computing the saf likelihood is quadratic in the number of samples sequenced results to overcome this computational challenge we propose an algorithm score limited dp algorithm which is linear in the number of genomes to compute the saf likelihood this algorithm works because in a lower triangular matrix that arises in the dp algorithm all non negligible values of the saf likelihood are concentrated on a few cells around the best guess allele counts we show that our score limited dp algorithm has comparable accuracy but is faster than the original dp algorithm this speed improvement makes sfs estimation practical when using low coverage ngs_data from a large number of individuals availability_and the program will be available via a link from the novembre lab website_http jnpopgen org a site_frequency sfs describes the distribution of allele_frequencies across sites in the genome of a particular species the sfs is of primary interest in population_genetics as it is a complete summary of sequence_variation at unlinked sites and its shape reflects underlying population_genetic processes such as growth bottlenecks and selection moreover a number of population_genetic inferences can proceed directly from the sfs for example demographic_history e g evidence for population expansions bottlenecks or migrations can be directly inferred from the sfs using for example dadi or the sfs can also be compressed down to univariate summary_statistics that form the basis of popular neutrality tests that underlie many empirical genome_wide selection scans e g hence inferring the precise sfs from genetic data is crucial in many population_genetic with the recent rapid progress in sequencing_techniques obtaining large_scale genomic_data from thousands to tens_of of individuals is practical e g and this increased sample_size enables us to conduct more accurate population_genetic inference however current massively_parallel short_read sequence technologies also pose many inherent challengesfor example reads have high_error read_mapping is sometimes uncertain and coverage is variable and in many cases low or completely_absent these challenges make accurate individual_level genotype_calls difficult and make some downstream_analysis based on the inferred genotypes problematic in a previous study we showed that the sfs computed from genotype_calls a call based estimation_approach is biased at low to medium coverage whereas the sfs directly inferred from aligned short_read sequencing_data a direct estimation_approach is unbiased even at low coverage the direct estimation_approach infers the maximum_likelihood estimate mle of the sfs by an em_algorithm or a broydenfletchergoldfarbshanno bfgs algorithm assuming independence across all individuals and sites both of these algorithms are implemented in the angsd software_package both of these algorithms require computation of the site allele_frequency saf likelihood for all sites these vectors contain the likelihood that an allele for each possible allele_frequency at a site regardless whether monomorphic or polymorphic conditional on observed sequence_reads based on the precomputed saf likelihoods the mle of the sfs is obtained by optimization using either the em or the bfgs algorithm the bottleneck in obtaining the mle of the sfs is computing the saf likelihoods rather than optimization in fact the maximization of the likelihood either by the em or the bfgs algorithm takes only a small fraction of time compared with the computation of the saf likelihood this is because computation of the saf likelihood at each site requires a summation over all possible genotype combinations for n individuals and naive computation of this sum has a runtime complexity of o n to overcome this computational_burden li proposed a dynamic_programming dp algorithm to effectively compute the saf likelihood for each site in on andimplemented this algorithm in the angsd software however this algorithm is still not practical to use if there are large_numbers of individuals because it is quadratic in the number of genomes seefor runtime moreover this algorithm is numerically unstable for a large sample to solve this problem of computational inefficiency and numerical instability we compute the saf likelihood in a more efficient way that still retains the accuracy of the original dp algorithm our new method uses a combination of rescaling and sensible approximation to compute the saf likelihood a large_sample enables us to infer more precise summary_statistics and parameters in many population_genetic however at the same time we confront computational challenges with large samples and in many cases we have to deal with these challenges to make the method practical with large_sample we showed that although the direct estimation_approach for computing the sfs can provide the unbiased sfs even at low coverage it does not scale up to large_sample because the computation time for running this method is quadratic in a number of diploid individuals to overcome this problem we developed a new algorithm called the scorelimited dp algorithm and showed that the computation time for running this algorithm is linear in the number of genomes this algorithm exploits the observation that for most sites the saf likelihoods non negligible values are all concentrated on a few elements around the element corresponding to the best guess allele count therefore we approximate this vector by curtailing computation to only a few components of the dp update vectors more importantly be polymorphic we only considered polymorphic_sites for the sfs inferred from the bam_files and rescaled it so that all elements sum to b relative deviation of a fraction of sites with the derived allele count of we computed the relative deviation of the sfs inferred from the bam_files compared with the sfs computed from the vcf file in each derived allele_frequency bin i n c tajimas d comparison this algorithm can adaptively choose the bandwidth d during updating the saf likelihood for each site we showed that the bandwidth change is robust to sequencing_coverage and the variation of the saf likelihood we also showed that the em combined this new algorithm has comparable accuracy but is fold faster than the original dp combined with the em_algorithm when analysing the data from individuals our new algorithms improvement in speed makes it possible to directly estimate the sfs from very large samples of low coverage short_read sequencing_data our score limited dp algorithm could be applied to other dp algorithm whose runtime is quadratic in a sample_size for example proposed an empirical_bayes approach to estimate a posterior_probability of a minor_allele maf they used a dp algorithm to effectively compute summation over all possible genotype configurations for n diploid individuals and therefore this algorithm has a runtime complexity of on similar to the dp algorithm introduced here furthermore similar to the distribution of the saf likelihood the distribution of the posterior_probabilities of the maf is unimodal and most of the probabilities are close to therefore we can apply our score limited dp algorithm for this dp algorithm to reduce runtime complexitiy to be o dn rather than original on where d is the maximum bandwidth our score limited dp algorithm can also be directly applied to speed up estimation of the d sfs derived the em_algorithm to get the mle of the d sfs as an extension to the d sfs estimation and this requires precomputation of the saf likelihoods for all sites for each population independently this implies that we can make this method faster with the score limited dp algorithm compared with the original dp algorithm the computation time for running the original algorithm is on n whereas the runtime of the score limited dp algorithm becomes od n d n where n n represent a sample_size for each population and d d are the maximum bandwidth one might argue that uncertainty associated with genotype_calls can be overcome by simply increasing sequencing_coverage and there is therefore little need for algorithms that handle low coverage data however cost constraints require difficult choices between increasing sample_size and increasing_coverage there are certain cases where one prefers a large sample of low_coverage data over a smaller sample_size with high coverage for example in genome_wide one can obtain more power by sequencing a large number of individuals at low coverage as another example identification of rare_variants always requires large_sample and moderately rare loci will be detectable even with low coverage data finally even though sequencing cost keeps dropping cost constraints will not disappear because users will continue to work with limited budgets and push these limits with applications involving very large_numbers of individuals thus we expect low_coverage will remain an attractive approach for many investigators and that methods like ours will retain their appeal for the foreseeable_future 
