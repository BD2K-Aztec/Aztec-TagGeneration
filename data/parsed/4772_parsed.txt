ultrafast snp analysis using the_burrows of short_read motivation sequence_variation analysis is conventionally performed on mapping results that are highly redundant and occasionally contain undesirable heuristic biases a straightforward approach to single_nucleotide snp analysis using the burrowswheeler_transform bwt of short_read is proposed results the bwt makes it possible to simultaneously process collections of read fragments of the same sequences accordingly snps were found from the bwt much faster than from the mapping results it took only a few minutes to find snps from the bwt with a supplementary data fragment depth of coverage fdc using a desktop workstation in the case of human exome or transcrip tome sequencing_data and min using a dual cpu server in the case of human_genome sequenc ing data the snps found with the proposed method almost agreed with those found by a time consuming state of the art tool except for the cases in which the use of fragments of reads led to sensitivity loss or sequencing_depth was not sufficient these exceptions were predictable in advance on the basis of minimum_length for uniqueness mlu and fdc defined on the reference_genome moreover bwt and fdc were computed in less time than it took to get the mapping results provided that the data were large enough availability_and a proof_of binary code for a linux platform is available on request to the correspondingsince the advent of so_called next generation dna sequencers ngss which rapidly and cost effectively generate billions of short_reads large_scale analysis of sequence_data of a few hundred giga base_pairs gbp requiring a large computational_resources is not uncommon anymore the first step to extract biologically meaningful_information from sequence_data often involves analysis of the variation mutation of that data in comparison with a reference_genome sequence_data billions of short_reads are first mapped onto the reference_genome and unambiguous and recurrent mismatches between the short_reads and the reference_genome are identified as candidate_mutations this line of approach is hereafter referred to as the mapping based_approach although it is the most appreciated and most commonly used approach it has the following basic weak points i the computation of mapping is highly redundant because of large sequencing_depth typically ranging from to ii some mutations can be lost by mapping tools because such tools use certain heuristics of their own to resolve mapping ambiguities iii it is not easy to switch from one reference_genome to another after the computation of mapping has been completed to address these weak points an alternative_solution the dictionary based_approach is proposed the short_read are converted into a dictionary of reads so that numbers of occurrences of any sequence in the short_read are immediately obtained then mutations can be inferred on the basis of these numbers by means of querying genomic subsequences with and without the mutations the dictionary can be implemented efficiently by means of the burrowswheeler_transform bwt a k a fm_index because it is simple and particularly suitable for dna_sequences although the proposed approach appears to be too navenave it has the following potential advantages i redundancy due to deep sequencing_coverage is efficiently managed by the dictionary of reads ii the dictionary of reads does not suffer information_loss or heuristic bias because it is essentially constructed by means of sorting the data in alphabetical order iii it is easy to switch from one reference_genome to another one after the dictionary of reads is constructed however the following issues of the proposed approach remain to be addressed the construction of bwt for large data more than gbp is very time consuming even with the fastest known algorithm bcrext a large number of occurrences in the short_read of a genomic subsequence with a candidate mutation do not necessarily imply the existence of the mutation because some of them might be derived from different genomic_regions with similar subsequences to get useful information from the dictionary of reads it is necessary to prepare effective queries that are likely to contain candidate_mutations namely it is necessary to locate genomic positions with a significant chance of finding mutations to address_these the following algorithm and concepts are introduced in this study bwt wt a modified and parallelized bcrext algorithm for computing the bwt of reads the minimum_length for uniqueness mlu a simple criteria for evaluating the uniqueness of the subsequence the fragment depth of coverage fdc an estimate of sequencing_depth of coverage on the basis of exact matching of read fragments at single_base 
