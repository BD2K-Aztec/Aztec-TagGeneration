rapid genotype refinement for whole_genome sequencing_data using multi variate normal_distributions motivation whole_genome low_coverage has been combined with linkage_disequilibrium ld based genotype refinement to accurately and cost effectively infer genotypes in large cohorts of individuals most genotype refinement methods are based on hidden_markov which are accurate but computationally_expensive we introduce an algorithm that models ld using a simple multivari ate gaussian_distribution the key feature of our algorithm is its speed results our method is hundreds of times_faster than other methods on the same data_set and its scaling behaviour is linear in the number of samples we demonstrate the performance of the method on both low and high coverage samples availability_and the source_code is available at https the genomes_project gp has pioneered the approach of combining low coverage whole_genome lcwgs with linkage_disequilibrium ld based genotype refinement to successfully build large panels of accurately genotyped individuals this has provided a cost_effective alternative to sequencing many individuals at high coverage however genotype refinement has a large computational_burden for example quote around compute years to perform haplotype estimation on lcwgs individuals using the gp haplotype estimation pipeline this figure measures the cost of haplotype_phasing which our method does not address as well as genotype refinement given increasing sample_sizes decreasing sequencing_costs and the typically super linear scaling of refinement algorithms we are fast approaching a point where computation will account for a substantial_proportion of the cost of such analyses low coverage genotyping typically proceeds by calculating genotype likelihoods gls at a fixed set of variants snps and small_indels from read_alignments the variant list being created at an earlier variant discovery step these gls reflect the likelihood of the read data conditional on each of the three possible genotypes assuming a bi_allelic site these uncertain gls are then refined into genotypes by exploiting ld the correlation between physically close variants across individuals this final step is often referred to as genotype refinement and involves one or more phasing and imputation algorithms the most accurate phasing and imputation techniques typically employ hidden_markov hmms which are computationally_demanding examples_include beagle thunder and shapeit the final genotypes of gp were created using a combination of shapeit and beagle starting haplotypes were generated with the faster beagle method and then were further refined using the slower and more accurate shapeit a closely_related problem is the imputation of variants into study samples assayed on dna_microarrays from reference_panels of sequenced individuals several very fast methods have recently_emerged for this scenario these rely on theavailability of phased haplotypes for both study and reference data and it is not clear such algorithms will generalize to the lcwgs use case an alternative to hmm_based imputation is simply to predict genotypes as linear_combinations of other genotypes at physically close flanking markers modelling the correlation between variants as a multivariate_normal mvn distribution this idea was first introduced by wen and stephens where it was used in the more traditional setting of imputing genotypes into dna_microarray samples from a reference_panel menelaou andintroduced a related approach mvncall that performs imputation on lcwgs data for which the individual has also been assayed on a dna_microarray exploiting the backbone of confident microarray genotypes to improve genotypes at non microarray sites we introduce a new technique based on mvn representations of ld that extends these ideas to the lcwgs only imputation scenario the method exploits various efficient linear algebra operations making it hundreds of times_faster than the fastest hmm method this speed comes with a decrease in accuracy compared with hmms but is still substantially more accurate than genotype_calls made using no ld_information in the methods section we outline the model and its implementation in our results section we contrast the speed and accuracy of our technique with beagle on samples from gp phase lcwgs and samples taken from the uk k project uk k finally we demonstrate the applicability of ld based genotype refinement in the high coverage wgs setting something that has not been investigated to date the method is implemented in a software_package called marvin multivariate_normal imputation and is freely_available under the gplv_license the algorithm presented in this article is at least two orders_of than beagle on the uk k cohort although this speed does come with a decrease in accuracy particularly for rare_variants our method still makes nearly fold fewer errors than a genotyping routine that does not take ld into account the rapidly_growing size of reference_panels may soon preclude the use of super linear complexity techniques such as beagle since computation will become too expensive for example the haplotype reference consortium has collected lcwgs samples to create a reference_panel for imputation extrapolating from it seems unlikely it would be tractable to run beagle on a cohort of this size one possible use of marvin would be to quickly generate an initial estimate of genotypes which could then be supplied as starting values to a more sophisticated routine reducing the number of iterations the latter needs to perform marvin might also be an ideal routine for intermediate coverage projects the reduced accuracy of marvin compared to beagle at lower frequency variation is likely due to the limitations of modelling the population using one vector of allele_frequencies and one covariance_matrix this simplistic model may not capture more subtle population_substructure notably marvin performs better on the more homogeneous uk k cohort than on the gp cohort which has far more population_structure although also has a smaller sample_size one possible way to improve this situation would be to add more flexibility to the marvin model by using an mvn mixture distribution but we leave this for future work we have also demonstrated the efficacy of genotype refinement in the high coverage scenario the first such investigation to our knowledge a modest gain in recall for snps was achieved at a cost of a negligible decrease in precision we also attempted refining indels with this approach gains in recall were indeed observed but were accompanied by unacceptable increases in the false_discovery fdr this may be due to a higher fdr in the gp indels and could perhaps be solved via aggressive filtering although the improvements seen on high coverage data are modest we nevertheless believe it noteworthy that results achieved from high coverage data can be improved at all by this method moreover the efficiency of our method means it adds little additional overhead to processing pipelines for wgs_data whereas genotype refinement using existing hmm based_methods would be a considerable computational undertaking 
