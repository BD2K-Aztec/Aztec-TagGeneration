gene_expression parasam a parallelized version of the significance analysis of microarrays algorithm motivation significance analysis of microarrays sam is a widely used permutation based_approach to identifying_differentially in microarray_datasets while sam is freely_available as an excel plug in and as an r package analyses are often limited for large_datasets due to very high memory_requirements summary we have developed a parallelized version of the sam algorithm called parasam to overcome the memory limitations this high performance multithreaded application provides the scientific_community with an easy and manageable client server windows application with graphical_user and does not require programming experience to run the parallel nature of the application comes from the use of web_services to perform the permutations our results indicate that parasam is not only faster than the serial version but also can analyze extremely large_datasets that cannot be performed using existing implementations shrinkage based_approaches to testing for differential_expression in microarray_experiments have proven to best identify the genes of scientific interest the computational demand of analyzing these data continues to increase due to the reduced_cost of microarrays and increases in the number of replicates being measured the computational_burden is especially evident with shrinkage based tests where permutations are often used to assess_statistical and the false_discovery fdr the significance analysis of microarrays sam algorithm is a popular method for differential_expression using a shrinkage based test and permutations for the fdr the popularity of sam is enhanced by its free availability as an excel plug in or r package sam is a computationally to whom correspondence should be addressed demanding algorithm and analysis of larger datasets is challenging due to the high memory_requirements creating a parallel version of sam could address problems often encountered with larger experiments with a parallel algorithm the computational workload is divided among multiple cpus and the main_memory of all participating computers is utilized to avoid caching operations to the disk which will significantly decrease algorithm execution time the most time and memory intensive portion of the sam algorithm is permuting the columns to determine the null_distribution for large_datasets users of the serial version of sam will decrease the number of permutations used in analyses to allow the algorithm to complete without error this results in a poorly_characterized null_distribution to overcome_this we developed a high performance parallelized version of the sam algorithm called parasam this version divides the permutations across multiple compute nodes allowing parasam to perform a large number of permutations e g a larger number of people by writing the software to run in the windows operating system this parallel implementation of the sam algorithm does not require expensive hardware and the number of compute nodes can be as small as one in fact any number of inexpensive desktop computers connected by a network can be used the permutation partitioning scheme is not restricted and is entirely dependent on the number of compute nodes participating in the algorithm in parasam we have utilized the memory efficiently using c and have achieved almost a fold speed up even on a single machine 
