genome_analysis exact algorithms for haplotype_assembly from whole_genome sequence_data motivation haplotypes play_a in genetic_analysis and have many applications such as gene disease diagnoses association studies ancestry_inference and so forth the development of dna_sequencing makes it possible to obtain haplotypes from a set of aligned_reads originated from both copies of a chromosome of a single individual this approach is often known as haplotype_assembly exact algorithms that can give optimal solutions to the haplotype_assembly are highly demanded unfortunately previous_algorithms for this problem either fail to output optimal solutions or take too long time even executed on a pc cluster results we develop an approach to finding optimal solutions for the haplotype_assembly under the minimum error_correction mec model most of the previous_approaches assume that the columns in the input matrix correspond to putative heterozygous sites this all heterozygous assumption is correct for most columns but it may be incorrect for a small number of columns in this article we consider the mec model with or without the all heterozygous assumption in our approach we first use new methods to decompose the input read matrix into small independent blocks and then model the problem for each block as an integer_linear problem which is then solved by an integer_linear solver we have tested our program on a single pc a linux x desktop pc with i x cpu using the filtered huref and the na data_sets after applying some variant_calling methods with the all hetero zygous assumption our approach can optimally solve the whole huref data_set within a total time of h h for the most difficult block of the th chromosome and only h for the other blocks to our knowledge this is the first time that mec optimal solutions are completely obtained for the filtered huref dataset moreover in the general_case without the all heterozygous assumption for the huref dataset our approach can optimally solve all the chromosomes except the most difficult block in chromosome within a total time of days for both of the huref and na datasets the optimal costs in the general_case are sometimes much smaller than those in the all heterozygous case this implies that some columns in the input matrix after applying certain variant_calling methods still correspond to false heterozygous sites availability our program the optimal solutions found for the huref dataset available at http rnc r dendai ac jp hapassembly html contact a haplotype is the sequence of snps in each of the two copies of a given chromosome in a diploid organism haplotypes are crucial for genetic_analysis and have many applications such as gene disease diagnoses association studies ancestry_inference drug_design and so forth traditional approaches to obtaining haplotypes are based on genotype data from a set of individuals the genotype data tell the status of both alleles at a position without distinguishing which one is on a specific copy of the chromosome this approach is generally known as haplotype_phasing one can use various algorithms to infer the haplotypes a drawback of this approach lies in its weakness in identifying rare and novel snps besides it is hard to verify whether the inferred haplotype is completely correct with the development_of an alternative way to obtain the haplotypes for an individual is to combine sequence_fragments which is known as haplotype_assembly given a set of aligned_reads sequenced from the two copies of a given chromosome of a single individual the goal of haplotype_assembly is to correctly determine two haplotypes each of which corresponding to one of the two copies of the chromosome the haplotype_assembly was first introduced by basically when reads contain errors the reads cannot be partitioned perfectly into two disjoint sets each of which consists of non conflicting reads to deal with errors when looking for the best reconstruction of haplotypes one has to fix an objective_function for evaluating candidate haplotypes for this purpose various functions such as minimum fragment removal minimum snp removal longest haplotype reconstruction minimum error_correction mec minimum implicit snp removal and minimum implicit fragment removal have been subsequently proposed recently proposed the minimum weighted edge removal function whereasproposed the maximum fragments cut function of special interest among the proposed functions is to whom correspondence should be addressed mec which aims at minimizing the total number of conflicts errors between the reads and the constructed haplotypes h h the problem of minimizing mec is np_hard for this problem presented an exact algorithm based on the branch andbound method and a genetic_algorithm a weighted version of this problem is considered by in the remainder of this article we only consider the problem of minimizing mec presented the first diploid genome_sequence of an individual human j craig venter using sanger sequencing_technology they also designed a greedy heuristic_method that concatenates the reads with minimum conflicts their method is fast but not accurate when errors appear in reads developed a software_package named hapcut and their algorithm tries to minimize the mec score of the reconstructed haplotypes by iteratively computing maxcuts in graphs derived from the sequenced fragments designed a markov_chain algorithm named hash both hash and hapcut work well in practice but there is no guarantee of finding optimal haplotypes recently proposed a dynamic_programming for the problem that runs in time o k mn where k is the length of the longest read m is the number of reads and n is the total number of snps in the haplotypes their experiments show that their algorithm works well when k on the other hand when k is large they model the problem as a maxsat problem which is then solved by a maxsat solver to compare their maxsat approach with the previous methods they use the filtered huref dataset fromover chromosomes via experiments they show that their program can construct better haplotypes than the previous programs by it is worth pointing out that to solve the problem for the chromosomes their program takes a total time of h on a pc cluster moreover their program does not solve the problem exactly because it excludes certain reads reads in total from consideration furthermore their program fails to find optimal haplotypes for a total of eight blocks of the chromosomes in this article we develop a new approach to optimally solving the problem in our approach we first use new methods to decompose the input read matrix into small independent blocks and then model the problem for each block as an integer_linear ilp problem which is then solved by an ilp solver such as cplex ibm ilog cplex optimizer and glpk gnu linear_programming kit we have tested our program on a single pc namely a linux x desktop pc with i x cpu using the filtered huref dataset our experimental_results show that our program can optimally solve all the chromosomes within a total time of h h for the most difficult block of the th chromosome and only h for the other blocks to our knowledge this is the first time that optimal haplotypes under the mec model are completely obtained for the filtered huref dataset moreover to find almost optimal haplotypes within much shorter time for the difficult blocks we propose several powerful heuristic methods have generalized the problem by removing the all heterozygous assumption to handle the existence of a small number of homozygous sizes in the solution the generalized problem is much harder because it allows many more candidate haplotypes nevertheless we develop a program that can optimally solve the generalized problem for all the chromosomes of the filtered huref dataset except the most difficult block of the th chromosome within a total time of days as far as we know this is the first strike on computing optimal solutions for the huref dataset without the all heterozygous assumption moreover to find almost optimal haplotypes within much shorter time for the difficult blocks we propose several powerful heuristic methods via experiments with the simulated dataset of geraci we show that an optimal_solution for the general_case of the problem achieves a better reconstruction rate than an optimal_solution for the all heterozygous case of the problem multiple optimal solutions may exist for both the all heterozygous and the general cases if there is no error in the reads the optimal_solution is unique if the error_rate in reads is low the chance that the optimal_solution is unique is high however if the error_rate is high many optimal solutions may exist in general enumerating all optimal solutions are much harder and takes much longer time than computing a single optimal_solution from the experiments on simulated_datasets we can see that the single optimal_solution found by our exact algorithm can achieve better reconstruction rate than the previously known heuristics in most cases still it remains_an to handle multiple optimal solutions evaluating our exact program using the simulated dataset of geraci for those combinations c e with f g c f g and e where column prev rr shows the best average reconstruction rate reported by geraci and columns org score score time and rr show the average mec score of the correct solution the average mec score of the solution found by our exact program the average time in minutes taken by our exact program and the average reconstruction rate of our program over the instances in the dataset for a particular combination c respectively evaluating our heuristics for the general_case using the simulated dataset of geraci for those combinations c e with f g c f g and e where the columns mean the same as in 
