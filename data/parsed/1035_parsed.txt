sequence_analysis codoc efficient access analysis and compression of depth of coverage signals current data_formats for the representation of depth of coverage data doc a central resource for interpreting filtering or detecting novel features in high_throughput sequencing_datasets were primarily designed for visualization purposes this limits their applicability in stand alone analyses of these data mainly owing to inaccurate representation or mediocre data compression codoc is a novel data format and comprehensive application_programming for efficient representation access and analysis of doc data codoc compresses these data better than the best current comparable method by exploiting specific data characteristics while at the same time enabling more exact signal recovery for lossy_compression and very fast query answering times availability_and java source_code are freely_available use at http purl org bgraph codoc depth of coverage doc data are one dimensional discrete genomic signals describing the number of reads from a highthroughput_sequencing hts experiment covering each position in a reference_genome doc is determined by traversing shortread alignments column wise and counting the number of mapped_reads overlapping with each individual position i e its coverage doc is a primary source of information for the detection of structural_variants where it is assumed that a gain loss of genetic_material results in increased decreased coverage the same fundamental assumption is exploited in rna_sequencing where estimated expression rates are calculated from normalized coverage signals doc also plays_a in e g identifying novel transcripts characterizing the alternative_splicing landscape of a sample or comparing multiple snp_calling datasets where it is required to determine what genomic_regions are sufficiently covered in all considered datasets to be comparable among each other current data formatsbroads tiled data file_format tdf and ucscs bigwig format were optimized for efficient display of doc in genomic browsers but not for their stand alone analysis coverages can be read from these external lists at decompression time this further reduces the number of required codewords while at the same time preserving near exact doc values at close to variant positions blocked encoding and compression codewords are converted to byte representations using different encoders chromosome identifiers are stored by standard rle position offsets by differential golomb rice encoding and coverage values are stored unencoded eventually all encoded bytes are additionally compressed by a general_purpose compression algorithm gzip or bzip the data are then split into blocks bits that contain a configurable maximum of codewords by default which enables efficient random_access at decompression time decompression signal reconstruction is done by linear_interpolation at neighboring key_positions decompression starts by constructing an in memory interval tree of bits and their byte offsets when a particular genomic_position is queried codoc consults this index and loads the bit containing the queried position from disk finds the key_positions and their coverage values by binary search and reports the interpolated result codoc caches accessed bits using a leastrecently used strategy to exploit spatial locality of queries to close genomic positions 
