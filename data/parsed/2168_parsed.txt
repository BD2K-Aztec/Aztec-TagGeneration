data_and harmonization of gene protein annotations towards a gold_standard medline motivation the recognition of named_entities ner is an elementary task in biomedical_text a number of ner solutions have been proposed in recent_years taking_advantage of available annotated corpora terminological resources and machine_learning currently the best performing solutions combine the outputs from selected annotation solutions measured against a single corpus however little effort has been spent on a systematic analysis of methods harmonizing the annotation results and measuring against a combination of gold_standard corpora gscs results we present totum a machine_learning solution that harmonizes gene protein annotations provided by heterogeneous ner solutions it has been optimized and measured against a combination of manually_curated gscs the performed experiments show that our approach improves the f measure of state of the art solutions by up to achieving in exact alignment and achieving in nested alignment we demonstrate that our solution delivers reliable annotation results across the gscs and it is an important contribution towards a homogeneous annotation of medline_abstracts availability_and totum is implemented_in and its resources are available atin the last decades we have witnessed an explosion of publicly_available data a consequence of the deep integration of computerized solutions in society this rapid_growth was also observed in biomedicine with an overwhelming amount of data resulting from high_throughput methods accompanied by a corresponding increase of textual information for instance medline contains over million references to journal papers covering various biomedical fields e g medicine and dentistry medline and other biomedical resources are manually_curated by expert annotators in order to correctly identify biological_entities e g genes and proteins and the relations between them e g proteinprotein_interactions from texts however manual to whom correspondence should be addressed annotation of large_amounts of data has become a very demanding and expensive task this situation naturally led to the development of computerized systems to perform these steps automatically the goal of information_extraction ie is to extract structured and unambiguous information from unstructured data e g natural_language texts named_entity ner is a crucial initial task of biomedical ie which intends to extract chunks of text that refer to specific entities of interest it is one of the most important tasks as the identified entities will be used as input to the following steps in the ie pipeline however gene and protein_names have several characteristics that make difficult their identification in texts bullet many entity names are descriptive e g normal thymic_epithelial bullet two or more entity names sharing one head noun e g and kda proteins refers to kda_protein and kda_protein bullet one entity name with several spelling forms e g nacetylcysteine n_acetyl and nacetylcysteine bullet ambiguous abbreviations are frequently used e g tcf may refer to t cell factor or to tissue culture_fluid various systems were developed using different approaches and techniques which can be categorized as being based on rules dictionaries or machine_learning however the most recent results clearly indicate that better performance can be achieved by using an ensemble of ner systems as an example the top five systems of the biocreative ii gene mention challenge used ensembles of ner solutions in these systems each approach identifies entity mentions with different characteristics and based on different knowledge moreover most of the ner solutions are trained and or tested in only one corpus which is usually focused in a specific biomedical_domain and provides specific gene protein_names and contexts as a consequence when the system is applied to a corpus from a different domain the global performance drops significantly although this occurs with machine_learning it also affects dictionary based_solutions depending on the specificity of the used lexical resource this is not only a consequence of the different domains but also a result of the different annotation guidelines and their interpretation by human annotators for instance in this article we presented totum a new cross corpus solution to harmonize heterogeneous gene protein_names from several ner or normalization systems this approach uses crfs to take advantage of the variability existent in several corpora from different domains 
