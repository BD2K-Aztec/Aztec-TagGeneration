genome_analysis toward a statistically explicit understanding of de_novo sequence_assembly motivation draft de_novo genome_assemblies are now available for many organisms these assemblies are point_estimates of the true genome_sequences each is a specific hypothesis drawn from among many alternative_hypotheses of the sequence of a genome assembly uncertainty the inability to distinguish between multiple alternative assembly hypotheses can be due to real variation between copies of the genome in the sample errors and ambiguities in the sequenced data and assumptions and heuristics of the assemblers most assemblers select a single assembly according to ad_hoc criteria and do not yet report and quantify the uncertainty of their outputs those assemblers that do report uncertainty take different approaches to describing multiple assembly hypotheses and the support for each results here we review and examine the problem of representing and measuring uncertainty in assemblies a promising recent development is the implementation of assemblers that are built according to explicit statistical_models some new assembly methods for example estimate and maximize assembly likelihood these advances combined with technical_advances in the representation of alternative assembly hypotheses will lead to a more complete and biologically_relevant understanding of assembly uncertainty this will in turn facilitate the interpretation of downstream_analyses and tests of specific biological_hypotheses the low_cost and increasing availability of next_generation data have driven a growing interest in methods and software_tools for de_novo of short_read recent surveys of assembly tools practical guides competitions like the assemblathon and benchmarking tools like gage highlight the diverse ecosystem of available assemblers new data_structures algorithms and software_tools for assembly continue to be published every month many investigators have claimed that it is now possible to assemble high_quality genomes from next_generation data when using appropriate protocols and assembly methods yet others have expressed concern over the integrity of publicly_available draft_genomes assembled from such data some have described errors and shortcomings in specific draft assemblies whereas others have questioned the quality of publicly_available draft assemblies in general and advocated better quality_standards for the community in particular the assemblathon competition found large_scale inconsistencies among current assembly methods suggesting they are not robust to changes in parameters and input_data and that there is a need for unambiguous measures of assembly uncertainty a genome_assembly is a hypothesis consisting of a collection of contigs contiguous sequences and scaffolds groups of contigs with gaps of known length between them that typically cover or more of the genome but are often fragmented and unordered current de_novo assemblers use various heuristics and algorithms to select an assembly that optimizes some criteria such as path_length or graph complexity however these optimization criteria are typically ad_hoc this is largely because of the computational difficulty of performing assembly on short_reads and a primary goal for existing assembly methods has been computational tractability and efficiency as a result assemblers choose a single point_estimate as their final output with sparse information about the quality certainty or validity of the chosen assembly or of alternative assembly hypotheses many of which may have almost as much support in most cases it is difficult if not impossible to answer even basic questions like how well is this contig supported by the read sequences or are there alternative assemblies that have similar support from the data downstream_analysis tools use assemblies to make their own point_estimates of other aspects of biology such as multiple_sequence differential gene_expression or phylogenetic_trees in the end there is no accounting for how the uncertainty is compounded at each stage existing_tools cannot be integrated into pipelines that propagate uncertainty through a large multistep analysis for example integrating assembly uncertainty with tree uncertainty when constructing phylogenies the ability to propagate uncertainty about point_estimates or preferably to propagate entire sets of multiple alternative_hypotheses will become increasingly important as analyses grow in complexity to whom correspondence should be addressed thanks to the progress on computational_efficiency of genome_assembly it is now possible to tackle the difficult goal of placing de_novo sequence_assembly within an explicit statistical_framework in such a framework single assembly hypotheses selected according to ad_hoc optimality criteria are replaced by sets of hypotheses accompanied by statistics that summarize confidence in each the pieces are now falling in place for assembly to move away from point_estimates that are selected according to ad_hoc criteria toward a statistically explicit framework that provides not only biologically_relevant measures of certainty but also sets of alternative_hypotheses this will greatly_facilitate the evaluation of assemblies their application to specific biological_questions improvements in assembly algorithms and integration with downstream_analyses that can then take assembly uncertainty into account bioinformatics workflow frameworks such as the web_based framework galaxy and the lightweight command_line framework biolite already provide biologists with functionality for establishing provenance and reproducibility for computational_analyses these workflow frameworks are the logical foundation for implementing pipelines that propagate uncertainty through complex multistage analyses 
