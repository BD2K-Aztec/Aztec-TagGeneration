data_and small sample precision of roc related estimates motivation the receiver_operator roc_curves are commonly used in biomedical_applications to judge the performance of a discriminant across varying decision thresholds the estimated roc_curve depends on the true_positive tpr and false_positive fpr with the key metric being the area under the curve auc with small samples these rates need to be estimated from the training data so a natural question arises how well do the estimates of the auc tpr and fpr compare with the true metrics results through a simulation_study using data models and analysis of real microarray_data we show that i for small samples the root_mean differences of the estimated and true metrics are considerable ii even for large samples there is only weak correlation between the true and estimated metrics and iii generally there is weak regression of the true metric on the estimated metric for classification rules we consider linear_discriminant linear support_vector svm and radial_basis svm for error estimation we consider resubstitution three kinds of cross_validation and bootstrap using resampling we show the unreliability of some published roc results availability companion web_site at http compbio tgen org paper supp roc roc html contact high_throughput such as those based on microarrays or next_generation make it possible to generate data on large_numbers of genes transcripts or proteins simultaneously in biological_samples typical variables assessed include mutations dna_copy dna_methylation mrna_expression microrna expression protein expression and post_translational a central_goal of current biomedical_research is to use those molecular_profiles to identify_biomarkers or multi gene biosignatures for personalization of medicinethat is to use them for the full range of medical_management choicesin disease risk_assessment sub classification of disease early_diagnosis prognosis choice of optimal_therapy evaluation of response to therapy and or identification of relapse to whom correspondence should be addressed the profile data are used to develop univariate or multivariate predictors of biologically or medically interesting outcomes often the aim is to develop a binary classifier for example diseased versus normal disease subtype versus disease subtype response versus non response to a drug or year survival versus death a large literature has developed on such classifiers but the recurring question is how accurate are their predictions and classifications this question is supposed to be answered by the error_rate however recent monte_carlo have shown large uncertainty in the error estimates in the presence of high_dimensional feature spaces and small samples a ubiquitous situation with high_throughput resampling error estimation methods for example cross_validation cv suffer from high deviation variance that is the variance of the difference between the true and estimated errors is large braga for an early criticism of moreover there tends to be a lack of correlation and regression between the true and estimated errors to the extent that the regression_line of the true error on the estimated error is nearly horizontal these monte_carlo studies have been supported by analytical studies in the case of the discrete histogram rule braga and linear_discriminant lda for assessment of binary classifiers in addition to the error_rate a favorite analytical tool is the receiver_operator roc representation for instance with regard to gene_expression in cancer seeon the companion web_site compbio tgen org paper supp roc roc html an roc_curve is formulated by plotting the sensitivity_and of the classifier against each other as a function of some threshold criterion for example based on a biomarker or biosignature the resulting roc_curve presents graphically the trade_off between false_positives fp and false_negatives fn in the classification process the area_under provides a scalar parameter that reflects the overall quality of the classifier a natural question is whether parameters associated with roc_curves such as the area under the curve auc would suffer the same degree of uncertainty as discovered in the previous_analyses of classifier error accordingly we have established the computational machinery to address_this for both simulated_and and have performed a variety of analyses based on different predictive algorithms and methods of validation we have analyzed the effect of sample_size and the effect of an unbalance in the number of cases per class that type of imbalance is common in biological_datasets 
