gene_expression classification of mislabelled microarrays using robust sparse logistic_regression motivation previous_studies reported that labelling errors are not uncommon in microarray_datasets in such cases the training_set may become misleading and the ability of classifiers to make reliable inferences from the data is compromised yet few methods are currently available in the bioinformatics literature to deal with this problem the few existing_methods focus on data cleansing alone without reference to classification and their performance crucially depends on some tuning parameters results in this article we develop a new method to detect mislabelled arrays simultaneously with learning a sparse logistic_regression classifier our method may be seen as a label noise robust extension of the well known and successful bayesian logistic_regression classifier to account for possible mislabelling we formulate a label flipping process as part of the classifier the regularization_parameter is automatically set using bayesian regularization which not only saves the computation time that cross_validation would take but also eliminates any unwanted effects of label noise when setting the regularization_parameter extensive experiments with both synthetic data and real microarray_datasets demonstrate that our approach is able to counter the bad effects of labelling errors in terms of predictive_performance it is effective at identifying marker_genes and simultaneously it detects mislabelled arrays to high_accuracy availability the code is available fromhigh throughput microarray_technologies make it possible to measure the expression levels of thousands of genes our ability to use these data to reliably_predict the presence of a certain disease and to better understand the biological_mechanisms the development of disease is of fundamental_importance from the perspective of treatment and prevention statistical machine_learning have already shown a lot of promise towards these goals and methods that can deal with high_dimensional and low sample_size settings have been the subject of considerable research_efforts over the last decade however the classical machinery of learning a classifier relies on a set of labelled examples and the quality of a classifier depends crucially on the accurate labelling of these data unfortunately the task of labelling is complex and not without ambiguities as a result there is no guarantee that the class_labels are all correct in fact there is an increasing realization that labelling errors are not uncommon in microarray datasee the presence of class label noise in training_sets has been reported to deteriorate the performance of the existing classifiers in a broad range of classification_problems although the problem posed by the presence of class label noise is acknowledged often it is naively ignored in practice part of the reason may be that symmetric label noise can be relatively harmlesshowever asymmetric noise inevitably deteriorates the performance as it changes the decision boundary between the true classes various approaches have been devised in the machine_learning literature to address the issue of learning from samples with label noise the seemingly straightforward approach is by means of data preprocessing where any suspect samples are removed or relabelled however these approaches hold the risk of removing useful data too which is unsuitable in microarray classification as the number of training examples is limited in sharp_contrast with the multitude of methods for microarray classification there are few attempts to address the problem of label noise in the bioinformatics literature pointed_out the difference between mislabelled arrays and outliers and proposed two methods to detect mislabellings based on data perturbation developed this work further and obtained improved precision and recall in both synthetic and real_data settings both of these works are based on data perturbation and their main focus is to detect suspects that are potentially mislabelled these methods can help repairing the labels so we can imagine a two stage procedure of creating a repaired training_set first and feed this to existing classifiers in a second stage however one must be aware that any errors made in separate stages of analysis will necessarily accumulate in this article we address the above problems by developing an integrated approach where the ambiguity of the given label assignments is modelled explicitly during the training of a to whom correspondence should be addressed classifier this allows us to build on classifiers that have been successful for microarray classification by developing an extension to account for possible label noise specifically here we will harness the sparse bayesian logistic_regression blogreg model proposed bywith a robustness against label noise from our model formulation we then derive a new algorithm that alternates between training the classifier and estimating the label noise probabilities straightforward calculations further provide the posterior_probability of mislabelling for each of the training points this enables us to detect the suspect samples for possible follow_up study in addition our experimental_validation results using both synthetic and real microarray_datasets demonstrate that the proposed method improves on traditional algorithms and achieves a reduced classification error_rate a variant of our approach appears in bootkrajang and kabankaban 
