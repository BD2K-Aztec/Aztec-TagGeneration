recovering key biological constituents through sparse_representation of gene_expression motivation large_scale rna expression measurements are generating enormous quantities of data during the last two decades many methods were developed for extracting insights regarding the interrelationships between genes from such data the mathematical and computational perspectives that underlie these methods are usually algebraic or probabilistic results here we introduce an unexplored geometric view point where expression levels of genes in multiple experiments are interpreted as vectors in a high dimensional_space specifically we find for the expression_profile of each particular gene its approximation as a linear combination of profiles of a few other genes this method is inspired by recent_developments in the realm of compressed_sensing in the machine_learning domain to demonstrate the power of our approach in extracting valuable information from the expression data we independently applied it to large_scale experiments carried_out on the yeast and malaria_parasite whole transcriptomes the parameters extracted from the sparse reconstruction of the expression_profiles when fed to a supervised_learning platform were used to successfully predict the relationships between genes throughout the gene_ontology hierarchy and proteinprotein_interaction map extensive assessment of the biological results shows high_accuracy in both recovering known predictions and in yielding accurate_predictions missing from the current databases we suggest that the geometrical approach presented here is suitable for a broad range of high_dimensional experimental_data high_throughput have come to play_a in biological and biomedical_research in the last decade advances in large_scale technologies on a genome_wide scale produce enormous amounts of data yet a major_goal of functional_genomics is the quest for a comprehensive description of the functions and interactions of all genes and proteins in a genome to whom correspondence should be addressed data such as large_scale gene_expression are usually represented by a matrix where n genes are examined in d experimental_conditions here we view such data as a set of n points vectors in d dimensional_space each of which represents the profile of a given gene over d different experimental_conditions many known methods that have yielded meaningful biological_insights in fact seek geometric or algebraic features of these vectors for example analyzing the angles between vectors amounts to a correlation based analysis similarly the direction in space along which these points are most spread out correspond to singular_value svd and its principal_component implementation these are powerful_tools in providing biological inference in general methods and disciplines developed toward extracting information from expression data include pairwise properties e g correlation variance entropy based distance clustering bayesian_networks information_theory ordinary_differential and other sophisticated distance measures in this study we applied a different approach to gene_expression the geometric principle that underlies it is very natural and different from existing_methods though it is close in spirit and inspired by recent_advances in compressive_sensing and sparse signal recovery a simple probabilistic consideration implies the following geometric claim given a set of n randomly_chosen points in the d dimensional_space it is very unlikely that a linear subspace y exists where more than dim y points of the chosen points reside very close to y see section in this study we present a natural yet unexplored approach for the seemingly exhausted problem of gene_expression analysis adopting a sparse signals reconstruction mindset we recover a support set of genes for each gene in a genome geometrically we uncovered linear subspaces that are overpopulated with expression_profiles in the multidimensional space of the experiments set we could verify the robustness and significance of the sparse reconstructions using measures intrinsic to the method and data formally we are interested in subsets s of our n point_set that nearly resides on a subspace of dimension strictly smaller than s having found such sets several immediate questions suggest themselves i are these findings robust ii if they are robust can we directly interpret their biological meaning iii can such representation uncover meaningful structures iv does the method generalize in this article we answer_these by considering gene_expression alone and testing datasets coming from the transcriptomes of the budding_yeast and the_malaria a conceptually new method that we call sparcle sparse recovery of linear_combinations of expression is introduced it is inspired by the plausible assumption that expression data when considered over a broad range of experimental_conditions encodes profound layers of systematic yet hidden behaviors we further confirmed the stability and robustness of sparcle results for entire transcriptomes under perturbations to the data extracting features from the geometric parameters of sparcles results and training adaboost a machine_learning platform to exhaustively reveal pairwise associations between gene function represented by gene_ontology go annotations and by the proteinprotein_interaction ppi map confirmed the principal information_encoded by the geometric based representation the generality of the method is confirmed by applying it to both the knowledge rich yeast model and the poorly_annotated malaria_parasite proteome to demonstrate the utility of sparcle on gene_expression data we analyzed two very large experimental_datasets from the yeast s cerevisiae and from the malaria_parasite p falciparum composed of and experiments and covering and genes respectively while the sparcle methodology is not restricted by the type or source of data we used mrna_expression measurements from which constitute a microarray compendium of chemostat_cultures of s cerevisiae that cover unique growth conditions including nutrient limiting substrates growth_rate aeration ph and temperature this dataset was divided randomly into two equal sized sets of d experiments covering n yeast genes our matrix has full row rank d and linear algebra implies that the smallest support of a solution to p will never exceed d indeed the coefficient vectors obtained were considerably sparser with an average support size of thus our goal of achieving a short compact linear representation is achieved to ensure robustness half of the experiments were not used for such representation and were reserved for the purpose of cross_validation and evaluation random partitions of the data into two parts were performed five times with essentially_identical results see section following this new geometrical representation of the data and confirming its stability to perturbations we turned to extracting valuable biological_information for the entire proteomes the first functional test was based on searching enrichment in go annotations for of the genes significant_enrichment of functional_annotation could be found among their set of supporting genes retrieved by sparcle an example is the gene mep for which many of the support members share annotations supplementary the statistical enrichments of go annotations for a sample of gene supports are shown supplementary furthermore mep is interconnected with several of the support gene_products as reflected by the connected graph of the ppi_network however for most genes an immediate biological_interpretation could not be retrieved from the support set typically the objective gene and its support gene_products are isolated in a ppi_network graph examples are shown in as sparcle results proved meaningful and robust by the cross_validation test supplementary we expect the method to capture hidden information to this end we used sparcle results as input for a machine_learning procedure specifically we trained the adaboost framework to classify whether each pair of genes has a reported ppi or not using information that is only extracted from the input_data itself i e the expression matrix and the sparcle analysis see section together the results of sparcle with the page a set of genes and their assigned coefficient for each pair of genes a feature_vector was constructed from the properties of their representing sets the feature_vector also included another high_dimensional analysis i e distances of each profile from the convex_hull of the others other features were obtained directly from the input_data see section features in the illustration i co occurrence in supports ii gene is coefficient in gene js support iii gene js coefficient in gene is support iv pearsons_correlation of the expression_profiles b prediction of ppi as represented by the string database by supervised_learning from sparcle results sparcle ab accuracy is traded off with coverage by applying certainty thresholds on the classifier output other methods for predicting genes interrelationships are as follows pearsons_correlation of the expression_profiles correlations and a transitive correlations method spath see section c prediction of associations for the go slim annotations covering cc ontology for detailed_analyses of accuracy coverage tradeoff see supplementary go slim and ppi input expression data were condensed into feature_vectors for each pair of genes we tested whether functional information that is encoded in the yeast ppi map can be successfully recovered using a confidence threshold for the classification accurate performance can be traded off in exchange for providing lower coverage of the data the results of the supervised_learning were exceptionally good for coverage of the high_confidence predictions an accuracy of was reached even for coverage the accuracy reaches recall that the yeast unfiltered ppi map still exhibits a high false_positive fp rate the combined protocol of the unsupervised sparcle method and supervised_learning platform based on sparcle feature_vector was then tested for the task of recovering the go associations between genes with the three functional branches covering mf cc and bp specifically gene_pairs were classified as sharing or not sharing similar go annotations for comparison we compare the prediction results to other correlation based_methods and c while the go hierarchical database covers different descriptive resolutions supplementary our protocol exhibited accurate_predictions at all resolution levels supplementary figs s s for example with coverage at high go resolution the accuracy reached and for cc bp and mf respectively sparcle ab c and supplementary figs s s for coverage we still achieved_accuracy for all ontology branches at low_resolution sparcle ab c and for the more specific terms of the high_resolution of go annotations sparcle ab supplementary figs s s an additional perspective on the sparcle ab method is retrieved from the tradeoff of sensitivity_and as presented by the receiver_operating in all tests for ppi go low and high levels and go slim when sparcle ab and correlation ab are compared a higher sensitivity is measured for the same specificity data not shown next we tested whether our inference_method happens to do well on the yeast as a model system indeed the yeast_genome is extremely rich in annotations and currently of its genes are associated with some informative go annotation similarly the quality and density of the yeast interactome exceed those of any other model system we thus repeated the entire protocol for a set of experiments measuring p falciparum genes expression levels from cells exposed to anti malaria drugs note that only of the malaria genes are reviewed by swissprot of the proteins are annotated as putative and only of the genes are associated with some go annotations often at a low_resolution supplementary the sparcle based protocol again demonstrated high predictive_power f supplementary finally we systematically tested the novel knowledge gained from the above described protocols figs and supplementary figs s s to this end we randomly_sampled pairs of yeast genes which were annotated as unrelated and yet which we predicted to be related fp and for comparison pairs of genes which were annotated as unrelated and predicted to be unrelated tns we manually examined each such pair of genes for functional_connections remarkably we verified our predictions for interrelations in of all fp samples yet could only detect relations in about a third of the tn set supplementary while this manual_inspection cannot be considered to stand on solid statistical ground it provides support for the relevance of sparcle based properties when they are fed into a machine_learning platform to empower functional inference the value of the information retrieved by the sparcle approach was demonstrated by using its results as a basis for machine_learning classification of gene_associations a systematic and comprehensive evaluation ranging from ppi_networks and going through all resolution levels of the go annotation database covering the immensely explored yeast transcriptome and the poorly_annotated malaria_parasite genome revealed the large potential of using such a poorly_studied geometric approach to extract principal insights from gene_expression data many approaches aim to develop a systematic way to unravel hidden structure in data most studies that looked for biologicalcoherence in gene_expression data applied clustering at different levels of sophistication revealing the existence of some hidden structure in the data in the current research comparisons to clustering_results were not carried_out as our goal here is quite different the high performance of sparcle based adaboost learning should be considered as evidence for the principal information that is embedded in the geometric properties of the data therefore a critical comparison was performed to evaluate the information that is embedded in correlation a form of geometric representation see below we show that the correlation performed very poorly on the malaria data and somewhat better on the yeast data in addition by combining the adaboost learning protocol with the correlation correlation ab we isolated the contribution of the adaboost learning itself sparcle ab outperformed these other approaches for the entire range of accuracy and coverage and supplementary figs s s several aspects of our approach differ from common practices and should be elaborated most of the activity in the machinelearning area can be viewed as a modern day approach to the classical questions of statistics the data at hand is considered as being sampled from some distribution and the question is to get as accurate as possible a description of that distribution our approach is different when data items are or can be naturally viewed as points in space it is possible to utilize any unexpected geometric properties that this set of points corresponding to data items has in fact many successful existing_methods in machine_learning can be viewed from this perspective thus if s is a generic set of n points in d dimensional_space and if n is subexponential in d then we do not expect to see any pairs of points even nearly in the same direction from the origin if the set of points that is your dataset violates this statement you can conclude that it has a geometrically nontrivial structure this structural property is very likely a reflection of an interesting albeit not necessarily interpretable property in the domain from which the dataset came this is our interpretation of correlation_analysis one of the most reliable workhorses of bioinformatics likewise a generic point_set in euclidean_space is not expected to be stretched in any special directions in space therefore if your dataset viewed geometrically is stretched in certain directions it tells you something that can often be used to discover interesting phenomena this is our interpretation of svd analysis correlations and stretch are only two of the numerous properties that one may consider in a point_set in euclidean_space our work considers another very basic property that we know not to exist in generic sets nearly linearly dependent sets of points of cardinality that is substantially smaller than the dimension of the host space when such an unexpected property of the dataset is discovered two questions suggest themselves i is this phenomenon only coincidental and ii how can this geometric property of the data help us learn something about the system which it represents in this study we confirm the robustness of this page 
