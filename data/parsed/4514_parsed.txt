systems_biology systematic parameter_estimation in data rich environments for cell_signalling dynamics motivation computational_models of biological signalling_networks based_on odes have generated many insights into cellular_dynamics but the model_building process typically requires estimating rate parameters based on experimentally_observed concentrations new proteomic methods can measure concentrations for all molecular_species in a pathway this creates a new opportunity to decompose the optimization of rate parameters results in contrast with conventional parameter_estimation methods that minimize the disagreement between simulated and observed concentrations the spedre method fits spline curves through observed concentration points estimates derivatives and then matches the derivatives to the production and consumption of each species this reformulation of the problem permits an extreme decomposition of the high_dimensional optimization into a product of low_dimensional factors each factor enforcing the equality of one ode at one time slice coarsely discretized solutions to the factors can be computed systematically then the discrete solutions are combined using loopy belief_propagation and refined using local optimization spedre has unique asymptotic behaviour with runtime polynomial in the number of molecules and timepoints but exponential in the degree of the biochemical_network spedre performance is comparatively evaluated on a novel model of akt_activation dynamics including redox mediated inactivation of pten phosphatase_and availability_and web_service software and supplementary_information are available at www ltklab org spedredynamic behaviours of biochemical_networks can be captured by ordinary_differential ode_models that compute the change of molecular concentrations with respect to time for most biochemical_pathways with known topology most reaction rate_constants i e the coefficients of the differential_equations are not available from direct experiments rate parameters are typically estimated by regression in other words by fitting the global behaviour of the simulated model to the experimentally_observed concentrations this is a difficult high_dimensional non linear problem and search_strategies often experience poor convergence and local_optima the rate parameter_estimation problem can naturally be formulated as minimizing a sum of squared errors sse where each error is a difference between simulated concentration and observed concentration and the summation is over time points and or experimental_treatments optimizing this type of sse objective_function can be attacked using a variety of traditional global and local search_methods lm levenbergmarquardt local sd steepest descent local sres stochastic ranking evolution strategy global pso particle_swarm global and ga genetic_algorithm global local and global search_methods both have drawbacks and global local hybrid searches have also become popular traditional search_methods generate a full vector of rate parameters simulate the model with this full set of parameters and then accept reject or adjust the parameters based on how well the simulation agrees with experimental_measurements for networks with few unknown_parameters these simulate and match methods have been successful at finding good values or multiple good candidates the search_space for parameter vectors is exponential and the inevitable trend with any type of exponential_growth is that there will eventually be a large enough number of unknown_parameters such that reasonable sampling will not explore very many of the basins of convergence and the results will deteriorate indeed many high impact models of biological_pathways continue to be built without automating the parameter_estimation process to whom correspondence should be addressed the author published_by this is an open_access the terms of the creative commons attribution license http creativecommons org licenses by which_permits distribution and reproduction in any medium provided the original_work in contrast to standard simulate and match methods of parameter_estimation spline based collocation methods have recently been developed that use experimental_observations of a protein over time to interpolate the time derivative of the concentration rather than computing the derivatives based on simulating the odes traditional_methods minimize the violation of experimental_observations subject to obeying the ode trajectories while the spline based collocation methods can be seen as optimizing a dual like objective_function because they minimize the violation of the ode trajectories subject to obeying the experimental_observations note that the spline based collocation methods require an extensive input dataset with observations for many or all of the proteins in the past few large_networks had such comprehensive measurements available but recent trends in proteomic technology suggest that data rich cases may be increasingly common in the future several spline based collocation methods have been published_recently for the context of biological_networks a spline based collocation scheme for parameter fitting problems using a modified data smoothing method and a generalization of profiled estimation was proposed by a similar method for problems with high noise and short time course was introduced by zhan and yeung used non linear_programming nlp to optimize the dual objective several decoupling strategies also use some forms of slope approximation from time series data to avoid doing multiple simulations estimating ode parameters has been studied in the mathematical literature for decades and an important class of data rich methods called multiple shooting b has recently been applied to biological_networks to the best of our knowledge no data rich parameter_estimation methods have implementations publicly_available for practical problems with biological_networks the asymptotic runtime of data rich methods has also been neglected many data rich methods have been published with claims of good accuracy but to the best of our knowledge efficiency and runtime have not yet been compared with state of the art simulate and match parameter_estimation methods scalability with network size is a major remaining challenge in the parameter_estimation field regardless of the objective_function or optimization approach a common strategy for large systems is to decompose the problem however the objective_functions of parameter_estimation are not generally decomposable some decomposition approaches exploit specific_situations such as having derivatives available at all timepoints or having small sub networks connected by species with observed concentrations the dual like objective_functions of spline based collocation methods are not readily decomposable but they do exhibit the important property of sparse interdependence locality between the variables this locality can be a basis for conditional decomposition belief_propagation see review and textbook is an inference_method for probabilistic graphical networks with sparse interdependence or locality it can compute the maximum a posteriori map values for variable parameters in a factor graph given joint probability_distributions that describe the dependencies between adjacent variables for acyclic graphs belief_propagation guarantees exact optima and for general graphs a variant called loopy belief_propagation lbp has had empirical success at approximating the map our method of systematic parameter_estimation in data rich environments spedre optimizes the dual objective approximately via lbp the innovation is conditional decomposition of the problem into local terms with pre_computed look up tables for the discretized solutions to the local terms of the dual objective_function spedre provides dramatic_improvement in empirical efficiency and in effect brings the spline based collocation dual objective methods to the same level of efficiency as the state of the art primal objective methods asymptotic runtime is polynomial with respect to the number of species parameters and timepoints in the biological_networks while it is exponential only in the degree of the network finally we compare the scalability and robustness of spedre against state of the art standalone and hybrid parameter_estimation methods using both a spectrum of artificial cases and also a novel model of akt_activation based on our previous experimental_studies of akt aberrant hyper activation of the akt_pathway has been detected in up to of all human_tumours and the akt_pathway is an attractive target for anti_cancer discovery our model of akt includes oxidative inactivation of the lipid phosphatase_and on chromosome pten as well as the phosphatidylinositol_kinases pi k activation as competing regulators of akt in serum stimulated fibroblasts a more detailed understanding of pten dynamics is important because many cancers activate akt through disruptions of pten before testing the overall performance of the method on full problems we first performed simplistic tests with partial problems to isolate specific variables of interest such as species and timepoints we monitored performance as a function of network size and timepoint spacing to probe two sources of potential error in the spedre base method spline accuracy and the pof objective_function the simplistic tests used ring_shaped networks with nominal parameters randomly_chosen to be at exact mid points of the parameter discretization bins simulated_data were generated with random initial_concentrations using the nominal rate parameters for each run of spedre base we monitored the objective normalized logpof logpof n t n s normalized with respect to the number of factors in the product of equation the objective declined when the number of timepoints increased indicating as expected that spedre gives better estimates of the parameters when timepoints are densely sampled next we compared the normalized log pof value between the results of spedre base and the nominal correct rate_constants using time steps i e timepoints for each test shows that the pof scores of the exact nominal parameters were higher than the pof scores of the parameters found by spedre base for all networks of significant size because spedre base found parameters with better scores than the correct parameters we infer that the pof objective is an imperfect score of parameter accuracy the key innovations of spedre are the use of a probabilistic_graphical to decompose the dual objective_function and pre computation of discrete solutions to each sub problem the method has a well defined asymptotic runtime and good scalability in exchange for approximate heuristic optimization the spedre approach aims for asymptotic scalability at the expense of accuracy this philosophy appears in i the use of splines to approximate the species derivative ii the use of binning to discretize the parameter_space and iii the use of lbp for probabilistic_inference each of these elements can introduce error we believed the dangers of compounded errors would make the spedre method less robust to noisy_data than simulation based_methods the expected sensitivity of spedre to input noise has not yet been confirmed in the tests shown and in other tests such as supplementary rather we found that all methods_gave unacceptably poor answers with noisythe accuracy and speed of spedre were compared against several methods of parameter_estimation in low degree data rich test cases spedre performance was competitive in all tests and spedre was the best performing method for the akt network test we conclude that spedre performs well when tested in the specific niche of problems for which it was designed naturally the spedre performance would degrade perhaps exponentially outside of its intended niche spedre exhibits an abrupt trade_off between problem type and performance but performance trade_offs are not new to parameter_estimation research major pathway simulation software_packages already maintain collections of multiple parameter_estimation methods rather than expecting a single best method to cover all problems a current hurdle for broader applicability of spedre is the inability to handle high degree nodes many small networks are low degree but large_networks often have at least one hub in order for new spline based collocation methods to be truly superior to conventional primal objective parameter_estimation methods they would have to handle high degree networks and extensive gaps in experimental_observations robustly future innovations may be able to develop a new composition of parameter_estimation methods so that low degree sub problems can be solved by spedre and high degree hubs can be treated separately a side effect of our work is to provide performance_comparisons for several hybrid and standalone parameter_estimation methods our tests reproduced the earlier observation that hybrid methods generally perform better than standalone global methods one surprising phenomenon we observed was that performing a global search prior to a local_search sometimes caused the total runtime to be faster than using the local_search alone future work may be able to exploit this non additive runtime effect perhaps through deeper integration of global and local search_methods rather than applying independent methods sequentially a distinguishing_feature of spedre is that it requires large_amounts of concentration measurement data which would have been prohibitive a decade_ago traditional experimental methods required an investment of labour and resources that was roughly linear in the number of proteins studied new proteomic methods can measure additional proteins at virtually no additional_cost and proteomic_datasets are starting to provide data rich environments with measurements of all proteins in a system silac technology has recently been used for time series measurements of proteins in nih t derived cells and again for time series of proteins in the cytosol and proteins in the nucleus in glucocorticoid exposed myogenic cells most proteomic_studies have not been performed with time series repeats for studying dynamics but large_scale dynamic data will become increasingly available with the explosive_growth in the number of proteomic experiments new studies of large_networks will give rise to huge parameter_estimation problems with rich datasets but with too many unknown_parameters for conventional methods to solve we believe that proteomic technology both enables and requires novel approaches to parameter_estimation such as spedre as models grow in size owing to technological_advances decomposition based_methods will probably dominate nondecomposition based search_methods which suffer from the curse of dimensionality the trade_offs exhibited by our method may be increasingly desirable for future trends in parameter_estimation 
