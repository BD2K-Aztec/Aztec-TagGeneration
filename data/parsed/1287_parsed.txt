sequence_analysis decombinator a tool for fast efficient gene assignment in t cell receptor sequences using a finite_state machine high_throughput provides an opportunity to analyse the repertoire of antigen specific_receptors with an unprecedented breadth and depth however the quantity of raw_data produced by this technology requires efficient ways to categorize and store the output for subsequent analysis to this end we have defined a simple five item identifier that uniquely and unambiguously defines each tcr sequence we then describe a novel application of finite_state automaton to map illumina short_read for individual tcrs to their respective identifier an extension of the standard algorithm is also described which allows for the presence of single base_pair mismatches arising from sequencing_error the software_package named decombinator is tested first on a set of artificial in silico sequences and then on a set of published human tcr b sequences decombinator assigned sequences at a rate more than two orders_of than that achieved by classical pairwise alignment_algorithms and with a high degree of accuracy even after introducing up to error_rates in the in silico sequences analysis of the published sequence_dataset highlighted the strong v and j usage bias observed in the human peripheral_blood repertoire which seems to be unconnected to antigen_exposure the analysis also highlighted the enormous size of the available repertoire and the challenge of obtaining a comprehensive description for it the decombinator package will be a valuable_tool for further in depth analysis of the t cell repertoire availability_and the decombinator package is implemented in python v and is freely_available at https github com uclinfectionimmunity decombinator along with full documentation and examples of typical usage contactthe power of vertebrate adaptive_immunity lies in its ability to synthesize and deploy an enormously diverse repertoire of antigen specific_receptors by a unique process of imprecise recombination of dna_segments within the lymphocyte germline estimates for the number of possible b and t cell receptors that can be generated by this mechanism are in excess of because of this diversity global analysis of immune repertoires and responses has lagged behind the structural understanding of receptor antigen interactions advances in high_throughput hts now offer the possibility of probing cataloguing and analysing immune_responses with unprecedented breadth and depth so_far this approach has been applied to only a handful of examples however with the rapid increase in highquality read_length that can be achieved and the fall in cost the number of such datasets generated in the coming_years is likely to increase rapidly the ability to extract the maximum possible useful information from such datasets whether to answer basic scientific questions or for more translational applications in diagnosis and disease stratification will depend on simple and efficient bioinformatic pipelines with which to process and analyse the raw_data an individual t cell receptor we focus here on t cell receptor analysis although a similar approach is equally applicable to b cells is made up of a heterodimeric b chain of t cells or chain each chain is made up of a variable and constant_region which is encoded by separate open_reading and spliced together after transcription the dna sequence_encoding the variable region is itself made up of two variable v and joining j for or three v diversity d and j for b minigenes the chain locus contains v and j gene_segments not including a number of pseudogenes the b locus contains v d and j gene_segments during t cell development in the thymus one v d and j minigene are recombined to give a contiguous open_reading additional diversity is achieved by random deletion of germline nucleotides and addition of non template nucleotides at the vj junction and chains or vd and dj junctions b and chains to unambiguously define an individual tcr chain therefore it is necessary to specify the v d j gene which is being used and both deletions and additions occurring at each relevant junction in this study we focus on the tcr b chain as hts_data are publicly_available as the two d region sequences are short and rather similar it is difficult to unambiguously assign d gene_usage of a specific b sequence we therefore define each tcr b sequence in terms of a unique five part identifier the first two parts identify the v and j to whom correspondence should be addressed regions used the third part gives the number of deletions of the v region the fourth part gives the number of deletions of the j region the final part is the sequence found between v and j which includes added nucleotides at the vd and dj junctions as well as any remaining nucleotides from the d region itself to generate identifiers from a large number potentially million from a single experiment using illumina_hiseq technology of short_read rapidly and efficiently we implement the algorithm described by aho and corasick existing algorithms to analyse tcr and ig sequences include imgt highv quest that can only analyse up to sequences per batch soda which uses dynamic_programming to analyse ig sequences typically taking up to s sequence to perform such analysis and expectation_maximization to determine the most likely distributions over recombination variables e g v and j gene_usage and v and j deletions other alternatives include classic pairwise_alignment implemented in r which can deal with larger batches of sequences than imgt highv quest but it still lacks the efficiency to deal with the prodigious increase in sequence volume now obtainable from hts the ahocorasick algorithm was originally developed for exact pattern set matching within a text string and it has been widely used it constructs a finite_state machine that resembles a trie with additional links between the various internal nodes the trie for any specific set of query texts need only be built once in advance thus the preprocessing time is o n where n is the sum of the lengths of all keywords to search for the algorithm then works in o n m x where x is the number of keywords found in the query text and m is the length of the text being queried we first implement this algorithm using a set of unique identifying short tag sequences from each known tcr b v and j sequences as the set of query texts the algorithm is then tested both on artificial sets of sequences created in silico and on real sets of tcr sequences the standard form of the ahocorasick algorithm requires exact_matches between query and target to accommodate realistic estimates of sequencing_error using current hts technology we develop an extension of the basic algorithm in comparison with pairwise_alignment the ahocorasick modified algorithm increased speed of execution by over two orders_of while still unambiguously assigning identifiers to of sequences tested pseudocode outlining our modification to the classic ahocorasick algorithm whereby a search is first adopted using the full_length v keywords and the modification is used if no full_length v keyword is found the classic ahocorasick approach outputs all keywords found along with their position within the sequence an identical approach is adopted in searching for j keywords sequence of symbols a keyword as a desired string to be found and a target as a string in which one searches for a keyword the framework of aho and corasick allows one to search within a text string t of length m for the occurrence of all keywords within a pattern set p of length j where p p p p j if n p j i p i j j then the algorithm works in o n m x time where x is the number of keywords in p that were found in t this can be compared with complexity of order o tm for smith_waterman pairwise_alignment for each keyword of length t a pattern matching machine comprises a set of states which are traversed by making a series of comparisons with characters of the target string at each step the new state reached depends on the next character seen in the target string the pattern matching machines output is derived from goto failure and output functions the goto function is based on a keyword trie such that all keywords are contained within the trie and listed from the root of the trie and it maps a given state and an observed input character to a new state the failure function maps one state to another and it is used when a given state and an observed input character are not defined for a particular state the failure function for each state is given by the longest suffix y already matched such that y is the prefix of another keyword finally the output function is defined for those states that once reached give one of the keywords in p thus the beauty of this approach is that it makes only one pass through the target string to find all keywords present within it the algorithm was implemented using acora implemented as a c extension embedded in python using cython and biopython this combines the speed of c with the user_friendly interface of python this provides a fast efficient tool capable of large_scale hts analyses combined with a user_friendly high_level programming_language appealing to those with limited programming experience the keyword trie i e the set of patterns to be identified represents the set of v or j functional prototypic alleles of which there are vb jb db v and j in the human_genome we consider only the b chain of the tcr for the purpose of testing our software on real sequences as it is the only one for which hts sequence_data have been published although our software is tested on both tcr and tcrb in silico sequences in line with many other studies we found that the two alternative db genes are often too short or bp and too similar to reliably assign in most sequences after germline deletions have occurred therefore these are considered to be part of the additional non template nucleotides at the vj junction rather than searching for a whole v or j gene each v or j region was represented by a short sequence bp which we call a tag which unambiguously identifies one and only one gene_segment the tags corresponding to each v or j segment were found by a simple exhaustive_search where each v or j region was split into a set containing all possible substrings and then searched for in all other v or j regions we have presented a novel application of an fsa developed by aho and corasick to the problem of gene assignment and characterization of t cell receptor sequences by comparison with previous methods such as spectratyping and amplicot hts provides an unprecedented opportunity to analyse the tcr repertoire in depth however the quantity of raw_data produced by this technology requires efficient ways to categorize and store the output for subsequent analysis to this end we have defined a simple five item identifier that uniquely and unambiguously defines each tcr sequence fields one to four each contain a two digit integer which defines the v and j gene_segment and the number of n_terminal v and c terminal j deletions respectively the fifth field is a categorical variable consisting of the string of contiguous nucleotides a t c or g from v to j the length of the fifth field varies between zero and bp a t c and g the identifier is therefore an economical way of storing all the required information about each sequence and it is readily incorporated into a potentially large tcr database structure that can be searched and processed efficiently using established database management_tools it provides a simple framework to mitigate for sequencing_errors while simultaneously allowing interrogation of such fundamental frequency distribution of v left and j right gene_usage in distinct sequences obtained from three individuals non uniform usage is clearly apparent for both sets of gene_segments whereas the overall pattern of usage seems to be largely conserved across multiple_individuals the distributions of usage are based on sequences obtained from three individuals from two separate blood_draws using only distinct sequences to avoid biases associated with the analysis of clonally_expanded populations of cellsthe implementation was tested on the same set of in silico and b sequences with and sequencing_error without modification of the classic aho corasick method an extra of sequences is lost see also this modification does not significantly affect the algorithms efficiency features as v and j region use and the distribution of germline deletions moreover in using decombinator to process raw sequence_reads the resultant file of identifiers produced makes further downstream_analyses far easier to conduct for the uninitiated taking away the challenging step of dealing with unprocessed data and translating it to a form which is accessible to even the most inexperienced programmer having defined the five part identifier the main aim of this study was therefore to develop an efficient way of mapping raw hts sequence_data to the identifier decombinator is an fsa based on a modified keyword trie incorporating goto failure and output functions that allow fast pattern matching by using information from characters that have already been matched this approach is therefore completely different from previous_studies using hts to determine tcr repertoire diversity which have relied on common methods such as pairwise_alignment and blast like alignment_tool blat these methods or variants thereof have been successful in the context of large_scale genome_sequencing studies where the objective is to assign a series of overlap of shared sequences between male male_and from sequences obtained from the study described in in each venn_diagram the blood_sample from day is shown on the left and the sample from day on the right the numbers in each venn_diagram represent lr the number of distinct sequences found in the respective sample taken on day the number of distinct sequences common to both samples and the number of distinct sequences found in the respective sample taken on day two separate samples even from the same individual leading diagonal show only partial overlap but display a greater proportion of shared sequences than samples taken from two different individuals distribution of the number of nucleotides found between v and j sequences were obtained from male from two separate blood_draws using only distinct sequences to avoid biases associated with clonally_expanded populations the region between v and j includes any remnants of the d region that remains after germline deletions the distribution is quasi normal centred on a mean insert length of or bp distribution of germline v deletions non uniform_distribution of v deletions is apparent in broad agreement with previously published_data the distribution is based on sequences obtained from male from two separate blood_draws using only distinct sequences to avoid biases associated with the analysis of clonally_expanded populations of cells distribution of germline j deletions as with germline v deletions a non uniform_distribution of j deletions is apparent in broad agreement with previously published_data the distribution is based on sequences obtained from male from two separate blood_draws using only distinct sequences to avoid biases associated with the analysis of clonally_expanded populations of cells short_reads to a large and diverse target the wholegenome for example in contrast the problem which is tackled here is distinguishing between a limited but highly overlapping series of queries in the most efficient manner possible fsa matching is likely to perform well under these conditions as it focuses on short regions of exact_matches and it can simultaneously search for several similar tags even tools that have been developed with tcr and ig sequences in mind still struggle to deal with the vast number of sequences obtained from hts in practice decombinator demonstrated remarkable efficiency improving on equivalent pairwise matching algorithms by several orders_of while retaining a high degree of accuracy although it is possible that fine_tuning the parameters of pairwise algorithms specifically in the context of tcr data could improve their efficiency somewhat it seems unlikely that they would achieve anything like comparable speed on the current datasets however a weakness of the original ahocorasick fsa was that it required an exact match between query and target and indeed many attempts have been made to extend the strategy to accommodate error or uncertainty in the query the major causes of mismatch are sequencing_errors whose frequency is well known in theory polymerase_chain error can also introduce mismatches although in practice the rate of polymerase_chain error using high_fidelity polymerases is much lower than sequencing_error and can be largely ignored to accommodate a realistic degree of sequencing_error without compromising too much on efficiency we developed a straightforward modification of the fsa which identified sequences even if the location of the tags contained a single error the algorithm delivered a significant increase in the proportion of sequences that could be assigned even at error_rates of which lies at the upper_bound of that observed_experimentally further modifications that could accommodate two or even more mismatches are unlikely to generate major benefits as the chances of having two sequence errors within a typical bp tag are low however we are exploring whether slower methods including pairwise_alignment or hidden_markov might be useful in characterizing the small proportion of sequences which cannot be assigned by decombinator the major objective of this study was to produce a tool that can efficiently assign large number of t cell short_read with high_accuracy the strengths and limitations of the tool we have developed are discussed earlier in the text however it is also worth commenting on some features of the output generated from the published set of sequences we analyse in the article one striking feature is the non uniform nature of the distribution of the different indices of the identifier even after restricting the analysis to distinct tcrs i e counting each different identifier only once so as to remove the potential effects of clonal_expansion both v and j usage is strikingly non uniform v for example is found at a much higher frequency whereas v or v are rarely present this pattern is at least in part conserved across three unrelated_individuals making it extremely unlikely that it reflects any exposure to specific antigen the pattern observed is similar to that described in several previous_studies suggesting that it is not an effect of bias introduced either by experimental or computational methodology a recent hts study of mouse v and j usage found similar bias which was attributed to constraints imposed by physical features of the chromosome_structure non uniform distributions of the number of deletions and insertions has also been observed previously and it presumably reflects molecular_features of the recombinase machinery overall learning the underlying distributions of each facet of the overall recombination_process from this type of sequence_data will be an important objective for future work and it will allow us to build more realistic computational_models for repertoire generation an initial step in this direction in which the experimentally_observed v and j distributions were incorporated into the in silico generation algorithm is described in the article the second feature that emerges immediately from analysis of the sequence_data is the enormous diversity of tcrs which exist which is reflected in the small overlaps observed between samples the limited overlap between repeat samples from the same individual presents an obvious potential drawback as each sample only captures a small proportion of the sequences present in that individual only sequences that occur at relatively high_frequency are therefore likely to be sampled consistently by this approach however as the sequences at higher frequency are in fact likely to be those associated with specific immune_responses this may not prove to be a major_limitation in studies focusing on events associated with antigen_specific challenges the overlap between samples of different individuals is even smaller reflecting not only differences in repertoire generation e g the effects of major_histocompatibility polymorphism and different histories of antigen_exposure but also the larger possible pool of all possible tcr sequences given the enormous_number of possible sequences it is in fact rather surprising that there are any sequences in common at all between any two randomly_chosen individuals the sequences found are often present at rather low_frequency suggesting that they may not reflect responses to antigen instead such common sequences may correspond to public sequences described previously like preferential v and j region usage these sequences found at unexpectedly high_frequencies within the population may reflect some specific feature of the mechanisms for generation of diversity further work to investigate the characteristics of these common sequences is in progress comparing two separate samples from the same individual yields jaccard_index values of o whereas samples from two different individuals yields jaccard_index values of o indicating far greater overlap of sequences observed from samples from the same individual see in conclusion we describe a five part identifier that uniquely classifies all tcr sequences and a computational_tool that maps hts reads to this identifier efficiently and accurately the computational_tool is based on the classic approach of aho and corasick to pattern matching but it crucially includes a novel modification to correct for sequencing_error these tools and the increasing application of hts technology to lymphocyte antigen_receptor analysis will lead to a better understanding of the rules that regulate the tcr repertoire the decombinator package is implemented in python v and is freely_available at https github com uclinfectionimmunity decombinator along with full documentation and examples of typical usage 
