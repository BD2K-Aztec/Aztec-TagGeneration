estimating optimal_window for analysis of low coverage next generation sequence_data motivation current high_throughput has greatly transformed genome sequence_analysis in the context of very low_coverage performing binning or windowing on mapped short_sequences reads is critical to extract genomic_information of interest for further evaluation such as copy_number analysis if the window_size is too small many windows will exhibit zero counts and almost no pattern can be observed in contrast if the window_size is too wide the patterns or genomic_features will be smoothed out our objective is to identify an optimal_window in between the two extremes results we assume the reads density to be a step function given this model we propose a data based estimation of optimal_window based on akaikes information criterion aic and cross_validation cv log_likelihood by plotting the aic and cv log_likelihood curve as a function of window_size we are able to estimate the optimal_window that minimizes aic or maximizes cv log_likelihood the proposed methods are of general_purpose and we illustrate their application using low coverage next generation sequence_datasets from real tumour_samples and simulated_datasets availability_and an r package to estimate optimal_window is available at http www maths leeds ac uk arief r win the recent advent_of or ngs next_generation has revolutionized the quantity and quality of data produced the ability to sequence a large number of dna or cdna_fragments at reasonable cost is proving to be flexible and powerful one of the applications is to use ngs to assess copy_number cna in tumour_cells although information about copy_number is often obtained by analysing high coverage data we have previously shown that it can also be reliably obtained by more affordable lowcoverage data from small amounts of fragmented dna obtained from formalin_fixed samples we expect low coverage data will still be a valuable choice because regardless of falling sequencing_costs data storage analysis time and infrastructure costs associated with large_datasets will not decrease as quickly wider use of ngs means it will be used more and more in diagnostic settings where low costs and rapid analysis time are critical finally the recently launched sequencing_machines illumina_miseq life technologies pgm have allowed costs to be within reach of individual laboratory budgets although this means that they produce fewer reads for these reasons ngs low coverage data could become common and partially replace hybridization based_technologies such as acgh and snp_arrays owing to the sparse nature of the data however it is important to extract the maximum information in particular the size of the genomic window used for binning reads is a critical tuning parameter if it is too wide the analysis will miss some genomic_regions that exhibit important features and if it is too narrow the noise_level will be dominant and many windows will contain zero reads we expect that in high coverage cases the choice of window_size is less crucial because by the time reads windows are so small they are of the same order of magnitude as the reads themselves and information about chromosomal junctions can be precisely obtained by reads spanning across chromosomal_regions that are disjointed in the reference_genome the number of reads per window should in theory follow a poisson_distribution it was however evident from the early experiments that there is overdispersion this is due to a number of reasons including gc_content bias mappability underlying changes in copy_number both somatic and germ_line and possibly other biological and technical_factors still to be described in this study our focus is on estimating an optimal_window for analysis of ngs_data to best track the depth of coverage signal in a very low coverage setting motivated by our study of cna the principle that we use to answer this problem is by considering that the binning or windowing is basically the to whom correspondence should be addressed same process as a histogram construction in the construction we calculate either the count of the data falling in each window or equivalently the density in each window by assuming a statistical_model for the underlying density in each window we are able to quantify the statistical distance of the model to the truth across different window sizes from here we can identify the optimal_window as the one that minimizes the distance once the optimal_window is estimated further analysis e g gc correction comparison with matched normal cna analysis can be performed based on the optimal_window before we propose our method we consider in the next section some studies that have discussed the notion of an optimal_window in the context of next generation sequence_data for the ls data the results on estimation of optimal_window are presented in based on the aic and cv loglikelihood the minimum aic is achieved at the window_size kb equivalent to an average of reads per window in both tumour and normal samples similarly the maximum cv log_likelihood is located at the window_size kb in both tumour and normal samples because the horizontal axis of the figures is in a log scale the range of window sizes around the optimal one that can be considered near optimal is actually wider than it seems to be for example although the window_size kb is optimal window sizes between and kb can be considered near optimal in supplementarywhere the horizontal axis is in a linear scale this can be regarded as an advantage as we will revisit in the discussion section the estimation of optimal_window for analysis of low coverage next generation sequence_data can be considered to be a histogram construction where the breaks for histogram are the window limits as such each experiment will result in one particular optimal_window depending on the underlying features and biases both technical and biological previous_approaches to this problem are problematic some methods tend to underestimate the optimal_window in ngs_data because of a poor approximation to the underlying reads density in the genome for example the method proposed byresulted in an estimated optimal_window of kb reads per window to kb reads per window in our datasets for detecting a copy_number ratio of to respectively with p value of supplementary_material although cnv seq is only meaningful for window_size reads per window the latter requirement is to prevent the random variability to dominate the analysis some other approaches which mainly rely on a subjective consideration also tend to overestimate the optimal_window this is because having a wide window_size gives a smooth pattern of genomic_features that can easily be interpreted however this mainly subjective approach ignores the potential discoveries of genomic_features that are present in short regions as we discussed previously in this study we proposed to use aic and cv log_likelihood given in the model in section because the methods do not depend on an approximation of the reads density have a simple interpretation and are relatively easy to implement results from our analysis with the ls and ls data suggest that some window sizes around the optimal one can be considered as near optimal and with a linear scale horizontal axis in the supplementary_material this is an advantage when we want to analyse ngs_data across different samples or patients as each sample may exhibit a different optimal_window there may be a window_size that is in the overlapping regions of near optimal window sizes across the different samples our tool will help the experimenter to make an informed decision when estimating an optimal_window to analyse the data our previous_experience suggested that we lose little information when we use slightly suboptimal window_size compared with the optimal one in the analysis across different samples one important message that we can take here is that the calculation of aic and cv log_likelihood usually fails or becomes uninterpretable when the window_size we evaluate has reads per window on average although the optimal_window differs from one dataset to the next or from one experiment to the next we found in our ls and ls datasets that the optimal_window is reads per window we also found in our study that window_size of reads per window can be considered near optimal in the ls data this corresponds to a the aic left and cv log_likelihood right as a function of window_size or number of reads per window from the low coverage samples the horizontal axis is in log scale sensitivity analysis of the simulated_data at different window sizes in detecting gains or losses when the cna are segmented using cbs and smooth segmentation the solid grey diagonal line is the identity line range of kb window_size and in the ls data kb window_size our proposed methods assume a simple model for the underlying density of reads therefore our estimation of the optimal_window depends on all technical and biological_factors that contribute to the observed signal the window_size needs to be optimized so that it is capable of tracking all the concurring factors that contribute to the final signal as an example to be able to correct for gc_content the signal needs to follow the gc_content bias and a window_size unnecessarily too large or too small might prevent the best normalization however we have observed that reads_mapped with low_confidence sometimes cluster in particular regions of the genome and introduce extreme peaks in the signal that might negatively_affect the optimal size of the window as they dominate the calculation of aic and cv log_likelihood for this reason we suggest that an estimation of optimal_window is made on the data with good mapping quality our simulation_study supplementary_material indicates that the proposed methods are able to estimate an optimal_window that minimizes the distance between the observed reads density in the low coverage data and the true underlying density this holds in many typical cases where for example structural_rearrangements are reasonable in a rare case where we have extreme structural chromosome_rearrangements our proposed methods can still estimate a near optimal_window which is close to the optimal one in this regard the proposed methods can still be useful to identify a good estimate of window_size that can be used in the analysis last but not the least our proposed methods can also be used in a higher_coverage context as well or possibly in transcriptome or chip_seq or whenever data need to be binned in windows of predefined size in the context of the analysis of very low coverage next generation sequence_data the estimation of optimal_window is critical if the window is too narrow or too wide we will potentially miss genomic_features of interest to estimate the optimal_window we first assume the reads density to be a step function given this the optimal_window is estimated as the one that minimizes aic or maximizes cv log_likelihood across different window sizes that we evaluate our analysis on ls and ls data indicates that the optimal_window is approximately equivalent to reads per window our simulation_study confirms that the optimal_window we estimated produces the closest distance between the reads density in the low coverage data and the true underlying density 
