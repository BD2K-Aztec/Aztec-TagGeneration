sequence_analysis seed efficient clustering of next generation sequences motivation similarity clustering of next generation sequences ngs is an important computational_problem to study the population_sizes of dna rna_molecules and to reduce the redundancies in ngs_data currently most sequence clustering_algorithms are limited by their speed and scalability and thus cannot handle data with tens of millions of reads results here we introduce seedan efficient algorithm for clustering very large ngs sets it joins sequences into clusters that can differ by up to three mismatches and three overhanging residues from their virtual center it is based on a modified spaced seed method called block spaced seeds its clustering component operates on the hash tables by first identifying virtual center sequences and then finding all their neighboring sequences that meet the similarity parameters seed can cluster million short_read in h with a linear time and memory_performance when using seed as a preprocessing tool on genome transcriptome_assembly data it was able to reduce the time and memory_requirements of the velvet oasis assembler for the datasets used in this study by and respectively in addition the assemblies contained longer contigs than non preprocessed data as indicated by larger n values compared with other clustering tools seed showed the best performance in generating clusters of ngs_data similar to true cluster results with a to fold better time performance while most of seeds utilities fall into the preprocessing area of ngs_data our tests also demonstrate its efficiency as stand alone tool for discovering clusters of small rna_sequences in ngs_data from unsequenced organisms in recent_years the data_volumes generated by next_generation ngs_technologies have been growing at a pace that has now begun to greatly challenge the data_processing and storage capacities of modern compute systems only years_ago ngs_technologies like illuminas reversible terminator to whom correspondence should be addressed method or abis ligation approach created billion bases of dna sequence_information per instrument run which has now increased to over billion bases per run with even shorter turnaround times this corresponds approximately to a fold increase of sequence_data output per year as a result of this rapid_improvement of the technology many exciting sequencebased research applications have evolved recently these include genome resequencing of entire organism populations personalized_medicine rna_seq chip_seq and many others genomes processing and storing the large_amounts of data produced by these technologies is a major_challenge for modern genome research thus it is important to develop methods that can improve the efficiency of the analysis workflows for ngs_data to mention just a few these include algorithms for processing the data more time and space efficiently as well as data reduction approaches that aim to retain only the scientifically relevant and non redundant information from ngs projects rather than everything for example in genome resequencing projects one can greatly reduce the dataset sizes by storing only genetic_variations while removing the bulk of the sequence_information that only confirms what is already known similarly in quantitative ngs experiments for profiling pools of mrnas small_rnas or proteindna_interactions one can convert the data to much less storage intensive tag counts at an early_stage of the analysis workflow solutions that prevent or greatly minimize information_loss are always preferred however with the current growth_rates of ngs_data many of them may soon become impractical especially when the data sizes become the main time and financial bottleneck for conducting scientific experiments in the ngs field this study introduces a new algorithm capable of clustering ngs sets in size ranges of several hundred million entries using a modified spaced seed method this method hereafter referred to as seed efficiently joins sequences into clusters with user definable similarity parameters ranging from to mismatches and overhanging ends with up to nt in length these mismatch features are important to make the method less sensitive to base call errors imprecise molecular cleavage events or inaccurate adaptor trimming the main utilities of seed are the identification enumeration and removal of redundant sequences in ngs_data in its current_implementation seed is designed to function as a short_read clustering tool with controllable mismatch parameters but not as an error corrector like freclu there are several practical_applications of this clustering approach first the method can be used to reduce the complexity in ngs_data by collapsing redundant reads to a singlepage 
