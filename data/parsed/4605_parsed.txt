genome_analysis the human_genome contracts again the number of human_genomes that have been sequenced completely for different individuals has increased rapidly in recent_years storing and transferring complete_genomes between computers for the purpose of applying various applications and analysis tools will soon become a major_hurdle hindering the analysis phase therefore there is a growing need to compress these data efficiently here we describe a technique to compress human_genomes based on entropy coding using a reference_genome and known single_nucleotide snps furthermore we explore several intrinsic_features of genomes and information in other genomic_databases to further improve the compression attained using these methods we compress james watsons genome to megabytes mb improving on recent work by similar compression is obtained for most genomes available from the genomes_project our biologically_inspired techniques promise even greater gains for genomes of lower organisms and for human_genomes as more genomic_data become available with the constant advances in sequencing_technologies genome_sequencing has become faster and more affordable although the main effort thus far has been to sequence the genomes of different organisms the focus is gradually shifting toward sequencing different instances of the same genome i e different individuals to study the variations underlying phenotypic_differences between individuals and to identify the variations that are associated with diseases and disorders consequently the number of complete human_genomes that have been sequenced is increasing rapidly as the amount of and demand for genomic_data grow the cost of storage and transmission of these data is fast becoming a bottleneck for research and future medical_applications thus there is a growing need for compression algorithms suited to genomic_data genome_compression has been the subject of multiple studies in the past several years see_supplementary for an overview of these related studies the most successful methods are those that use reference_genomes and code just the differences between the input genome and a reference_genome which for humans account for of the genomes length the best single reference compression was reported in who compressed james watsons genome to mb by utilizing dbsnp to represent more efficiently known snps in the difference map in this work we report further improvements to this scheme which result in a significant reduction of in the size of the compressed genome for only mb our work is motivated by two observations first entropy coding techniques can be nearly optimal in exploiting known patterns in a dataset but have not been fully optimized on human_genome data second in finding patterns to exploit a wealth of biological_insight remains untapped our improved scheme is the result of incorporating multiple sources of information on the presence of haplotypes tag_snps coding_and and other biologically_motivated modifications we applied our compression tool to each of the human_genomes available from the genomes_project genomes as of october the results are presented in showing the uncompressed file sizes converted to the same uncompressed format as watsons genome and the compression_ratios labeled by population these results confirm that the success of the algorithm in compressing genomes is not unique to watsons genome however we notice a significant variation by population in both the uncompressed file size and the compression_ratio achieved by our approach further analysis is required to understand the functional significance of the underlying differences it should be noted that the genomes_project provides allele specific information on variations while the publicly_available difference map for watsons genome combines the variations into a single list without specifying which allele s they occur at therefore we modified our algorithm to account for diploids by introducing a vector indicating homo heterozygosity and which allele in case of heterozygosity this is done by using two bits per variation which can take the value homozygosity both alleles have the variation or coding the allele indicator vector takes kb per genome using a huffman code for a markov_chain fit to the indicator vector described in greater detail in the supplementary_material another difference between the genomes and watsons genome is that the genomes_project lists indels in addition to snps deletions and insertions the number of indels per genome is small on average there are only indels out of m variations per genome in the genomes data and we represent each as a pair of an insertion and a deletion 
