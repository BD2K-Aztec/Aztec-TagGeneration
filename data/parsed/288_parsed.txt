sequence_analysis analyzing genome_coverage profiles with applications to quality_control in metagenomics motivation genome_coverage the number of sequencing reads_mapped to a position in a genome is an insightful indicator of irregularities within sequencing_experiments while the average genome_coverage is frequently used within algorithms in computational gen omics the complete information available in coverage profiles i e histograms over all coverages is currently not exploited to its full extent thus biases such as fragmented or erroneous reference gen omes often remain unaccounted for making this information accessible can improve the quality of sequencing_experiments and quantitative_analyses results we introduce a framework for fitting mixtures of probability_distributions to genome_coverage profiles besides commonly used distributions we introduce distributions tailored to account for common artifacts the mixture_models are iteratively fitted based on the expectation_maximization we introduce use cases with focus on metagenomics and develop new analysis strategies to assess the validity of a reference_genome with respect to meta gen_omic read data the framework is evaluated on simulated_data as well as applied to a large_scale metagenomic study for which we compute the validity of microbial_genomes the results indicate that the choice and quality of reference_genomes is vital for metagenomic analyses and that validation of coverage profiles is crucial to avoid incorrect conclusions availability the code is freely_available and can be downloaded from http sourceforge net_projects fitgcp genome_coverage the number of sequencing reads_mapped to a specific position within a reference_genome contains valuable information about reference_genome and the mapping_process and is easily_accessible therefore it is frequently consulted in bioinformatics analyses to improve decisions in algorithms or to provide meaningful_information to the user for instance experimental_design methods guide the experimentalist to achieve a specific average sequencing_depth i e genome_coverage after sequencing the obtained reads can be mapped to a reference_genome quality_control tools analyze the mapping data and report measures such as coverage_information mapping quality or error_rate to the user for example qualimap visualizes the coverage profile and the coverage over the whole_genome together with the gc_content which allows detecting biases in the sequencing_process if no reference_genome is available the reads can be assembled to complete_genomes or at least longer contiguous sequences contigs the latter is nowadays possible for metagenomic_data i e datasets containing reads of many different species with different abundances the assembler metavelvet uses the coverage_information in the de_bruijn to connect contigs of similar coverage as they are more likely to belong to the same organism in addition to these examples local coverage_information is also used for detecting copy_number in genomes e g despite these versatile applications of genome_coverage a vast amount of information commonly remains unused most current methods either use the average coverage over a certain sequence or describe the coverage profile using single probability_distributions such as the negative_binomial or gamma_distribution yet to the best of our knowledge more complex models such as mixtures of distributions are not used to fit genome_coverage profiles gcps here we suggest that more complex models can improve current methods and can open doors for new analysis strategies we see one application of complex coverage distribution models in metagenomics where reference based_methods have become increasingly popular with the advent_of sequencing_technologies however there are two major problems with reference_genomes first the process of assembling and finishing reference_genomes is time consuming and cumbersome and many reference_genomes remain unfinished in the draft stage with varying qualities depending on the used sequencing_technologies draft_genomes are typically a set of assembled_contigs where many contigs may be erroneous or if assembled from metagenomic_data belong to different organisms the second problem is of biological nature evolution in the microbial world proceeds at high pace due to short replication times and new subtypes or even species emerge perpetually this causes different microbial_species to have high genomic similarities therefore the coverage is generally far from homogenous when mapping metagenomic_reads to a reference_genome describing it with a single uni modal to whom correspondence should be addressed distribution would not be appropriate here more complex models can have the power to disentangle and quantify different contributors to the genome_coverage in this article we present a framework for fitting complex_mixtures of probability_distributions to gcps we demonstrate in simulated experiments that the proposed_framework can produce reliable and robust results and present a real_data experiment where we use our framework to reanalyze the data presented in a large_scale metagenomic study we introduced gcps as a means to extract quantitative information from mapping data by fitting mixtures of probabilitydistributions to the gcp we obtain valuable information about the reference_genomes and the mapping_process such as the fraction of the genome that could not be covered by reads or if there is more than one organism contributing to the coverage this makes the proposed_framework a powerful_tool for the analysis of mapping data without restriction to the application the introduced gdv score is a simple yet powerful measure for how well a reference_genome fits to the mapped_reads especially in metagenomics reference_genomes are typically not required to fit perfectly to the data nevertheless the degree of divergence should not become too large as one example we observed a gdv score of in the experiment in section where we mapped e coli reads to a s flexneri genome this illustrates a relatively high biological divergence between data and reference despite a high gdv score we assessed gdv scores in a real metagenomic experiment conducted by qin et_al and observed surprisingly low scores for genomes that were originally considered to be present in the dataset only of reference_genomes achieved scores this is an imposing example for high discrepancy between metagenomic_data and reference_genomes which we presume to be a common challenge of metagenomic experiments one of the major reasons might be the quality of the reference_genomes as microbes from metagenomic experiments are typically not cultivable their genomes must be assembled from environmental_samples which is significantly more complicated and error_prone than assembly from pure samples in the experiment at hand of reference_genomes consisted of up to separate contigs only six genomes were one contiguous sequence the framework proposed and applied in this work makes these flaws quantifiable the first experiment showed that the iterative algorithm is able to fit complex_mixtures of highly_specialized probability_distributions to gcps the impact of the tail distributions became apparent as they significantly_reduced the fit error the second experiment showed that quantities calculated on fitted gcps are robust toward influences of the average genome_coverage there we observed stable estimates of the gdv score over a wide_range of coverages starting at average coverages below although our method is robust toward the average coverage it can be sensitive to the mapping parameters more restrictive mapper settings typically yield a lower gdv score and a higher influence of the tail distributions this has to be considered when comparing gdv scores over different experiments the iterative algorithm encounters limitations in extreme cases for example when the average coverage is very low but locally extremely_high this can be the case when a genome is not present in the data but shares a gene with other highly abundant genomes then the algorithm may fail to fit the low coverage distribution as intended by the user but tries to fit the extremely_high noise contributions in other cases the standard start parameters are inappropriate such that the algorithm ends up in a local probability maximum instead of fitting the distribution as intended these problems demonstrate that visual_inspection of the fit is necessary and this is supported by the framework common strategies used for the em_algorithm are also possible such as the initialization with different or manually determined starting parameters 
