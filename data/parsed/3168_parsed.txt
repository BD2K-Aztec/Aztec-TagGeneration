multiscale dna partitioning statistical_evidence for segments motivation dna segmentation i e the partitioning of dna in com positionally homogeneous segments is a basic task in bioinformatics different algorithms have been proposed for various partitioning criteria such as guanine cytosine gc_content local_ancestry in population_genetics or copy_number a critical component of any such method is the choice of an appropriate number of segments some methods use model selection_criteria and do not provide a suitable error control other methods that are based on simulating a statistic under a null_model provide suitable error control only if the correct null_model is chosen results here we focus on partitioning with respect to gc_content and propose a new approach that provides statistical error control as in statistical_hypothesis it guarantees with a user specified probability that the number of identified segments does not exceed the number of actually present segments the method is based on a statistical multiscale criterion rendering this as a segmen tation method that searches segments of any length on all scales simultaneously it is also accurate in localizing segments under benchmark scenarios our approach leads to a segmentation that is more accurate than the approaches discussed in the comparative review of elhaik et_al in our real_data examples we find segments that often correspond well to features taken from standard university of california at santa_cruz ucsc genome_annotation tracks availability_and our method is implemented in function smucer of the r package stepr available atit has been observed a long time ago that dna_sequences are not composed homogeneously and that bases fluctuate in their frequency these inhomogeneities often have an evolutionary or a functional_interpretation and can be relevant for the subsequent analysis of sequence_data because it correlates with many features of interest the gc_content i e the relative frequency of the bases g and c is one of the most commonly_studied sequence properties large_scale regions typically kb of approximately homogeneous gc_content have been called isochores in view of the somewhat vague notion of approximate homogeneity and conceptual criticism in studies such asor there is less interest in isochores nowadays however there is no doubt about variation in gc_content along genomes and search is done instead for domains of any length exhibiting distinct local gc_content see for instance elhaik et_al b several factors can influence the gc_content of a region at larger scales it correlates with the density of genes with gene_rich regions typically exhibiting an elevated gc_content compared with regions of low gene density at smaller scales there is fluctuation in the gc_content for instance because of repetitive_elements and gpc islands the gc_content is also known to vary between exons and introns especially for long introns their lower gc_content seems to play a role in splice_site recognition there is also a correlation between the gc_content and the local recombination_rate for a further discussion of features correlated to the gc_content see in gene_expression studies regions of homogeneous gc_content are of interest because the gc_content of a region affects the number of reads_mapped to this region for dna and rna_seq experiments with the illumina_genome platform this has been for instance investigated in benjamini and speed and segmentation_algorithms aim to partition a given dna_sequence into stretches that are homogeneous in their composition but differ from neighboring segments the classical_approach of using moving windows is simple and available for instance as an option with the ucsc and ensembl genome_browsers however it has some disadvantages for instance the choice of the window_size is difficult because it defines implicitly a fixed scale at which segments primarily will be detected further the involved smoothing blurs abrupt changes without additional statistical criteria the method also does not tell us whether differences between neighboring windows are statistically_significant therefore several more sophisticated approaches have been proposed these methods include hidden_markov and walking markov_models there are also change_point methods available see for instance a bayesian_approach to whom correspondence should be addressed that relies on the gibbs_sampler has been proposed by an older approach based on information criteria can be found in furthermore recently_developed based on entropy criteria have been shown to perform particularly well see elhaik et_al a and elhaik et_al b a review of segmentation_methods can be found in the article by braun and muler and for a more recent comparative_evaluation of the more popular approaches see in this paper we focus on binary segmentation where the four letter alphabet of a dna_sequence is converted into a two letter code for gc_content we set the response to be for g or c at a position and for a t we use y i to denote the response at position i and summarize the responses for a sequence of length n by y y y y n we model the responses y i to be independent and bernoulli bin i distributed and also assume that there is a partition k n into an unknown number k of segments on which the i are piecewise_constant i e i p j for i i j here i j j j denotes the jth segment with response_probability p j for j k a segmentation_algorithm provides estimates k for the number of segments for the internal segment boundaries and for the response probabilities p j on the estimated segmentsin the following we will identify a segmentation with p i where p p p k and i i i k our proposed algorithm provides a parsimonious estimate k for k k will not exceed the actual number of segments k except for a small user specified error probability as a default value we suggest the error probability also chosen in our simulations and data analyses relaxing this significance_level to a larger value say will typically lead to more identified segments but at the cost of statistical accuracy we evaluated our segmentation approach both on simulated_data and on data taken from the human_genome and the longknown phage in our simulations we used the benchmark scenarios proposed in because an extensive comparison of popular dna segmentation_algorithms under these benchmark scenarios is already available in elhaik et_al a we provide a comparison of our approach with the method that performed best in namely the one based on the jensenshannon divergence this recursive approach_called d js splits one of the current segments in each step this is done by adding a new break_point such that the improvement in jensenshannon divergence is maximized the algorithm stops when the improvement does not reach a threshold value obtained via simulations here we used the matlab_implementation djsegmentation m of the algorithm which is publicly_available as part of isoplotter http code google com p isoplotter there is taken as a threshold a value obtained from simulating long mb homogeneous sequences although this value seems to work well for the considered benchmark scenarios and might also be useful to prevent false_positive when searching for long homogeneous sequences it might be less suitable for balancing false_positives under other scenarios therefore a modified_version called isoplotter of d js has been proposed briefly after that uses critical_values dependent both on the segment length and the standard_deviation of the gc_content therefore we also report on the performance of isoplotter again under the default parameter_settings and provide detailed results in the supplementary_material to facilitate the comparison and to accelerate the computations for longer_sequences we binned the data and applied our algorithm to the resulting binomial frequencies we choose the bin size equal to which is the default value with the d js and isoplotter software and has also been used in 
