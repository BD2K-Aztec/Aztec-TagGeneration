screenbeam a novel meta_analysis algorithm for functional_genomics screens via bayesian_hierarchical modeling motivation functional_genomics fg screens using rnai or crispr technology have become a standard tool for systematic genome_wide loss of function studies for therapeutic_target discovery as in many large_scale assays however off target effects variable reagents potency and experimental_noise must be accounted for appropriately control for false_positives indeed rigorous statistical_analysis of high_throughput fg screening data remains_challenging particularly when in tegrative analyses are used to combine multiple sh sgrnas targeting the same gene in the library method we use large rnai and crispr repositories that are publicly_available to evaluate a novel meta_analysis approach for fg screens via bayesian_hierarchical modeling screening bayesian evaluation and analysis method screenbeam results results from our analysis show that the proposed_strategy which seamlessly combines all available data robustly outperforms classical algorithms developed for microarray_data as well as recent_approaches designed for next_generation remarkably the screenbeam algorithm works well even when the quality of fg screens is relatively low which accounts for about of the public datasets availability_and r package and source_code are available at https github com recent_technological have significantly_improved our ability to perform systematic and informative functional_genomics fg studies in mammalian_cells specifically during the past_decade rna_interference rnai has become a standard_technique for studying phenotype specific gene function via suppression of gene specific mrna_expression or translation more recently the crispr_cas system has emerged as an even more effective tool to implement complete gene knock_out as a result loss of function genome_scale screens have become popular especially in pooled shrna library format these have been widely used not only to identify essential genes in a specific context but also genes that are differentially essential in different contexts or synthetic_lethal genes results from these screens may ultimately inform discovery of novel therapeutic_targets in tissue_specific subtypespecific or mutation specific_contexts not only in cancer but in many other diseases and physiologic contexts fg screen design has also been extended to identify tumor_suppressors that increase cell_growth upon repression or genes that modulate drug_sensitivity complementing direct knock_out methodologies the crispr_cas gene_editing technology has also been scaled up for high_throughput fg screens to study the effect of specific mutations on cellular_phenotypes however progress in large_scale fg screens has been hampered by a nontrivial modelling of false_positives for example many candidate therapeutic_targets identified from shrna screens have failed validation in independent assays among the possible reasons for lack of robustness one must consider rnai off target effects variable potency and knock_down out efficiency of rnai and crispr reagents biological and technical noise in highthroughput screens cell_line specific efficiency of viral pool infection and toxicity from additional viral_vector expression cassettes e g fluorescence reporter proteins this suggests that sophisticated statistical_methods may be required to model the complexity of these experiments thus reducing false positive_and rates and leading to improved more robust interpretation of fg screen results a key computational challenge in genome_scale fg screens is to score gene level activity from individual reagents whole_genome fg libraries normally include multiple optimally designed shrnas hairpins or crispr sgrnas targeting the same gene to increase the likelihood of an effective gene knock_down out for instance on average or hairpins per gene were used with gipz and trc shrna libraries respectively similarly and sgrnas per gene were used in the zhang or sabatini lander crispr libraries respectively it is thus critical that such diverse evidence from multiple sh sgrnas targeting a gene is integrated when assessing its contribution to a specific endpoint phenotype in addition both microarray and next_generation ngs_technologies have been used to quantitatively assess sh sgrnas representation or abundance in pooled fg screens each one introducing bias and measurement noise traditional_methods to summarize gene level activity usually rely on single_probe level analysis specifically shrna are first individually scored and then the scores of representative e g highscoring shrnas or of all shrnas targeting a specific gene are combined several algorithms have been proposed to select or combine shrna level evidence including choosing the second best or most depleted shrna riger sb averaging the two shrnas that produced the largest scores riger ws performing enrichment_analysis of all shrnas targeting one gene against all shrnas in the library riger ks comparing rank distributions of effective size of all shrnas per gene rsa and more recent modelbased mageck and hitselect an intrinsic limitation with all of these approaches is that they rely on the accurate assessment of an individual sh sgrna activity which is difficult to achieve in large_scale screens that typically have a relatively small number of replicate samples moreover off target effects variable silencing efficiency differences among sh sgrnas targeting the same gene and experimental technical noise make heuristic selection of representative sh sgrnas problematic causing_significant false_discovery to overcome_these we propose a novel screenbeam screening bayesian evaluation and analysis method algorithm via bayesian_hierarchical modeling to directly_assess gene level activity from all relevant measurements due to its robustness hierarchical modeling also known as multilevel_modeling has been increasingly valuable in largescaled omics studies in this context screenbeam algorithm analyses all sh sgrnas targeting the same gene as a set instead of one at the time and then fits a linear mixture_model that directly models the potential activity variability of different hairpins as a random effect this multi probe analysis strategy improves parameter_estimation by increasing sample_size and reduces prediction_error and false_positive by integrating information from multiple shrnas use of bayesian_inference with markov_chain mcmc techniques in this analysis further improves accuracy and robustness of scoring metrics systematic benchmark assays using large_scale publicly_available shrna rnai and sgrna crispr screens designed to profile gene_essentiality by microarray or ngs suggest that the screenbeam method robustly outperforms existing single_probe analysis algorithms the screenbeam algorithm improvements are especially significant with assays with lower data_quality which accounts for about of the fg screens considered in this manuscript meta_analysis of shrna screening data increase gene level inference robustness remains difficult we proposed a novel multi probe analysis strategy screenbeam screening bayesian evaluation andscreenbeamanalysis method implemented via a bayesian_hierarchical modeling to address this problem the evaluation results demonstrated that the screenbeam method outperformed traditional single_probe analysis approaches riger and rsa and recent model based_methods mageck and hitselect this was especially relevant when the screen data was in relatively low quality which account for about cases hierarchical modelling also known as partial pooling can be viewed as a compromise between two extremes one extreme complete pooling assumes the equal knock_down effect across all shrna classes targeting the same gene the other extreme no pooling ignores the similarity of the replicates within one shrna group and treat each hairpin replicate separately the assumptions of these two extreme methods are too strong for shrna screening design to be considered for integration of multiple shrna evidences because different shrnas targeting the same gene in the library might have significantly different silencing efficiencies hierarchical modeling comprises two extremes by allowing between group variance and considering within group effects thus making an appropriate solution to this question the problem of multiple_comparisons can also disappear in bayesian hierarchical_models partial pooling in hierarchical_models shifts estimates toward each other whereas classical procedures for multiple comparison correction typically adjust p values corresponding to intervals of fixed width thus screenbeam fitting results in reliable and conservative estimates for main effects or gene level effects in this context for single_probe analysis strategy a few other possible algorithms might be considered to integrate shrna level scores for the same gene for example fishers method to combine signed p values or stouffers method to combine z statistics however these integrating p values or z scores methods easily over estimate the significance of gene level activity and generate a long list of significant candidates also they ignore the magnitude of knock_down effects for each hairpin by only considering the statistical_significance of how the effect is away from zero and require strong assumptions thereby these methods might not be comparable to this screenbeam algorithm or could be even worse than the other single_probe analysis methods additionally other enrichment_analysis algorithms such as gsa have been used in this context and might perform better than ks based gsea method however these algorithms still bear the drawbacks of single_probe analysis strategy making them less powerful than screenbeam the valuable point from enrichment type methods that might improve screenbeam is to borrow information from all shrnas or genes in the library because current screenbeam algorithm only considers shrnas corresponding to one gene looking at entire list of candidates might produce more robust statistics for cut_off based hits selection but probably would not change the rank of a gene as a potential candidate ngs has dominated as a cost_effective technology for quantitatively measuring the abundance of short_length dna or rna in a short time and this multiplexing parallel technology has been used in genome_wide fg shrna and crispr sgrna screens compared to microarray based_approaches ngs offers several potential advantages in terms of coverage of targeting genes flexibility of input library scalability and dynamic range which will possibly replace microarray for fg screens in the near future however the data_quality of ngs based genome_wide fg screens still has a big room to improve as only of over achilles screens are in good category compared to of microarray_based data supplementary the two existing best algorithms mageck and hitselect were specifically_designed for ngs based count_data however screenbeam can handle both microarray_based intensity data and ngs based count_data using conserved housekeeping_genes or rnai screen identified essential genes as the gold_standard of essential genes identified by loss of function screens we demonstrated that the screenbeam algorithm improves the sensitivity by up to of that by classical approaches without loss of precision overall screenbeam demonstrated the most robust and consistent performance identifying true hits in all scenarios even from small_sized noisy high_throughput which accounts for about of the public datasets high_quality data in high_throughput loss of function screens is rarely achieved in microarraybased and in ngs based data due to a variety of error and variability sources for high_quality screens method selection is less relevant as all of the tested methods had small difference performance yet for the lower_quality sh sgrnas within a high_quality dataset screenbeam would still produce significant improvements as a result there would be potential advantages even in this kind of datasets in summary we developed a novel hierarchical modelling algorithm within bayesian_framework for meta_analysis of large_scale fg screens this novel multi probe approach performs more robustly than previously_established analysis methods especially with noisy high_throughput data 
