gene_expression estimating classification probabilities in high_dimensional diagnostic studies motivation classification algorithms for high_dimensional biological data like gene_expression or metabolomic fingerprints are typically evaluated by the number of misclassifications across a test_dataset however to judge the classification of a single case in the context of clinical_diagnosis we need to assess the uncertainties associated with that individual case rather than the average_accuracy across many cases reliability of individual classifications can be expressed in terms of class probabilities while classification algorithms are a well developed area of research the estimation of class probabilities is considerably less progressed in biology with only a few classification algorithms that provide estimated class probabilities results we compared several probability estimators in the context of classification of metabolomics profiles evaluation criteria included sparseness biases calibration of the estimator the variance of the estimator and its performance in identifying highly_reliable classifications we observed that several of them display artifacts that compromise their use in practice classification probabilities based on a combination of local cross_validation error_rates and monotone regression prove superior in metabolomic_profiling availability the source_code written in r is freely_available atdiagnosis prognosis and prediction of treatment response based on transcriptomic proteomic or metabolomic_profiles is a well developed field a plethora of classification algorithms have been proposed and critically compared it very much depends on the classification_problem at hand whether an almost error_free classifier can be developed or whether classification errors are unavoidable regardless of what algorithm is chosen in the latter case it is natural that a clinician asks for the reliability of an individual diagnosis before moving on to treatment_decisions classification algorithms are typically evaluated by the frequency of misclassifications in cross_validation or on an independent test_set these performances are averages over many predicted cases they say little about the reliability of an individuals diagnosis the case to whom correspondence should be addressed might be easier or more difficult_to than the average in the test_set for each case every class is assigned a value p j which is an estimated probability that the case belongs to that class given the profiling data in microarray_based classification the performance of classification algorithms has been analyzed and compared in great detail however little attention has been given to the usefulness of probability estimates and this is even more true for metabolomic analyses in fact only relatively few classification algorithms estimate class probabilities and in the majority of clinical papers on the performance of classifiers case specific probabilities are not shown a class probability estimator is most useful if it flags incorrect classifications as low_confidence classifications in other words if a classifier produces confident class probabilities close to one these should be correct classifications in this article we compare class probability estimators in the context of high_dimensional based diagnosis we briefly_review a selection of class probability estimators including those that are most frequently used in the context of gene_expression analysis like naive_bayes estimators or binary regression in addition we discuss alternative_approaches from different fields of application like text categorization and digit recognition and adapt them to metabolomics analysis we complement the pool of methods by a novel approach based on smooth local error_rates the approaches are compared on a recently_published metabolomics dataset of patients with various types of kidney_disease we found that artifacts can compromise the utility of some frequently used methods a widely observed problem is the dependence of classification probabilities on the number of features used in a diagnostic signature the more features are used by a classifier the more confident the classification probabilities even in cases where the classification is incorrect moreover class probabilities need to be estimated from test data or cross_validated classification scores since training scores display a better but unrealistic separation of classes this overfitting phenomenon can greatly affect class probabilities in our comparative metabolomics study class probabilities derived from local error_rates proved to be the method of choice we compared the class probability estimators in the context of a recently_published metabolomic_profiling study on kidney_diseases the dataset comprised urine_samples measured using d nuclear_magnetic nmr_spectroscopy samples were obtained from patients with autosomal polycystic_kidney the challenge is to separate them from samples taken from healthy volunteersfrom patients months after renal_transplantation more details on the composition of cases in the study can be found in nmr d spectra were split into equally sized buckets and globally normalized to the signal of the ch group of creatinine to ensure sample to sample comparability furthermore compatibility across metabolites was ensured by applying the glog transformation for full details of sample_preparation and data preprocessing see we learned a shrunken centroid classifier aiming at the separation of adpkd patients and healthy_controls across all patients we observe a classification_performance of correct classification in cross_validation resolves this classification_performance further the ticks on the x axis show the cross_validated classification scores s x j from adpkd patients top and healthy_donors bottom in line with the global performance of only one can observe that there is no perfect separation of the two groups scores between and can be observed in both classes the separating hyperplane lies in the middle of these points it assigns of them to the adpkd class and to the healthy_donor class confined to this range of scores the classifier has a performance of correct classifications these diagnoses should be flagged unreliable however scores are only found among adpkd patients and hence reliably indicate that a patient_suffers from adpkd identifying this group of patients boils down to estimating adpkd probabilities for all patients the y axis exemplarily shows such estimates_obtained using a local error frequency approach all patients with a score receive probabilities close to one indicating their reliable classification as adpkd positives patients with scores between and obtain probabilities between and flagging them as problematic classifications we next compare the six cpf estimators naive_bayes nb compound bayes cb binary regression breg and the local error frequency methods lef bin lef smooth lef adapt with respect to several criteria including modification of classification_performance sparseness bias calibration and the performance in identifying reliable classifications 
