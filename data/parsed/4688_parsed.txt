bioinformatics review sequence_analysis for mapping high_throughput a ubiquitous and fundamental step in high_throughput analysis is the alignment mapping of the generated_reads to a reference_sequence to accomplish this task numerous software_tools have been proposed determining the mappers that are most suitable for a specific application is not trivial results this survey focuses on classifying mappers through a wide number of characteristics the goal is to allow practitioners to compare the mappers more easily and find those that are most suitable for their specific problem availability a regularly updated compendium of mappers can be found atin the past_decade high_throughput hts has changed the way life_sciences research is done the decreasing costs have made hts technology more mainstream and it is now exploited in a growing number of biological_applications the so_called seq experiments dna_seq chip_seq rna_seq bs_seq and numerous other applications such as investigating the spatial_organization of the genome inside the cell_nucleus we refer tofor an overview of sequencing_technologies and related applications a common_feature of all hts technologies and applications is the generation of relatively short_reads fragments of dna_sequences which have to be aligned mapped to a reference_sequence the primary challenge is to efficiently find the true location of each read from a potentially large quantity of reference data while distinguishing between technical sequencing_errors and true genetic_variation within the sample presently more than mappers are available seefor a list of mappers andfor a timeline most of them proposed after concurrent with developments in sequencing_technologies mappers have had to adapt to i handle growing quantities of data generated by hts ii exploit technological_developments and iii tackle protocol developments for instance paired_end library protocols motivated the development of mappers that exploit read pairing information furthermore the appearance of novel protocols may result in specific_biases one consequence of the increasing number of mappers is that making a suitable choice for a specific application is not easy resources such as the seqanswers forum wiki pages have collated information about different mappers such as the operating system supported and different technologies that the mappers have been designed to handle however information about other equally_important features characteristics of the mappers is difficult to find being still scattered through publications source_code when available manuals and other documentation this survey aims to help overcome these challenges by allowing practitioners to compare mappers more easily and thus find those that are most suitable for their specific problem it does not evaluate mappers in terms of their accuracy but instead it presents an overview of their characteristics it complements previous_studies that focused mainly on a reduced subset of mappers and or empirically compared the performance of a small number of mappers the development of numerous mappers for hts_data is motivated not only by novel developments of hts technology but also by the growing number of biological_applications the variety of applications has led to the appearance of specific types ofone commonly asked question is what is the best mapper for a given application although the best mapper criterion involves application specific requirements such as how well it work in conjunction with downstream_analysis tools e g variant callers it often also includes speed and in particular accuracy despite some recent evaluation studies determining the most accurate and fastest mappers for a particular application is still difficult the primary challenge in assessing mappers is the lack of gold_standard datasets for different applications and sequencing_technologies these datasets would not only include the reads but also their true locations and could be based on true data or data generated in silico using novel or existing simulators such as art beers or fluxsimulator the research_community has started to address_these in the context of different projects such as the rgasp http www gencodegenes org rgasp and the alignathon http compbio soe ucsc edu alignathon projects which aim respectively to assess the status of computational_methods to map human rna_seq and dna_seq data to whole genomes however no results are publicly_available at this time more generally a common approach for comparing mappers has been to count the number of reads aligned however increasing the number of reads is not useful if the probability of the reads being correctly mapped decreases i e if the increase in mapped_reads is done at the expense of increasing the proportion of incorrectly mapped_reads one way to address this problem would be to compute the likelihood of a read being correctly mapped e g as available in rmap or zoom and allow the users to choose only the alignments above some threshold users may want to consider several mappers in their hts analysis and to incorporate them in pipelines such as in arrayexpresshts this raises the issue of mapper interoperability to achieve interoperability input and output_formats need to be standardized currently the majority of the mappers accept input_files in fastq or cfastq format and generate sam bam_files as output hence the level of interoperability is high however there is still room to improve because fastq_files include quality values encoded in different formats and bam_files can also come in different flavours their standardization should be encouraged moreover in the future mappers may also include the option to output_files in the cram format which may prove useful for efficiently compressing dna_sequences the input_parameters of the mappers are far from being normalized which makes it more difficult for a practitioner to switch between mappers hence it would be useful if there was an effort to standardize the most commonly used parameters e g for defining seed lengths input output_files and formats finally the great flexibility and configurability of most mappers comes with a price a considerable number of parameters that have to be set determining the best parameter_values to achieve some pre defined level of mapping specificity sensitivity is far from being trivial mappers with the ability to automatically tune their parameters to achieve some user_defined specificity sensitivity may be a solution to this problem 
