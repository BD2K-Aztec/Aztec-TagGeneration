genome_analysis eceo an efficient cloud epistasis computing model in genome_wide motivation recent_studies suggested that a combination of multiple single_nucleotide snps could have more significant associations with a specific phenotype however to discover epistasis the epistatic_interactions of snps in a large number of snps is a computationally challenging_task we are therefore motivated to develop efficient and effective solutions for identifying epistatic_interactions of snps results in this article we propose an efficient cloud_based epistasis computing eceo model for large_scale epistatic interaction in genome_wide gwas given a large number of combinations of snps our eceo model is able to distribute them to balance the load across the processing nodes moreover our eceo model can efficiently process each combination of snps to determine the significance of its association with the phenotype we have implemented and evaluated our eceo model on our own cluster of more than nodes the experiment results demonstrate that the eceo model is computationally_efficient flexible scalable and practical in addition we have also deployed our eceo model on the amazon elastic compute cloud our study further confirms its efficiency and ease of use in a public cloud availability the source_code of eceo is available atit is becoming increasingly important and challenging in genomewide association study gwas to identify single_nucleotide snps associated with phenotypes such as human_diseases e g breast_cancer diabetes and heart_attacks traditionally researchers focused on the association of individual snps with the phenotypes such methods can only find weak associations as they ignore the genomic and environmental_context of each snp however snps may interact known as epistatic interaction and jointly influence to whom correspondence should be addressed the phenotypes as such there has been a shift away from the one snp at a time approach toward a more holistic and significant approach that detects the association between a combination of multiple_snps with the phenotypes in the meantime the number of discovered snps is becoming larger and larger for example the dataset from the hapmap project contains million snps and the genome_project provides million snps from a computational perspective it is very time consuming to determine the interactions of snps given n snps the number of k locus is n c k n k nk this renders existing statistical_modeling techniques which work well for a small number of snps impractical likewise techniques that enumerate all possible interactions are not scalable for a large number of snps to reduce the computation overhead heuristics have also been developed these schemes add a filtering step to select a fixed number of candidate epistatic_interactions and fit them to a statistical_model however these approaches risk missing potentially significant epistatic_interactions that may have been filtered out therefore a scalable and efficient approach becomes attractive for such a computationally_intensive task in a large_scale gwas a promising solution to the computation challenge is to exploit parallel processing there are a variety of high_performance solutions for example in a tool is provided for processing single locus and two locus snps analyses using a supercomputer however it is not easy for researchers to rewrite their own programs on specialized hardware as another example in two locus snps analysis is performed using the graphics_processing gpu however this requires the users to understand the gpu architecture well to fully_exploit the computation power of the gpu instead we aim to develop a cloud_based solution which has a number of benefits first the mapreduce framework available in most cloud services offers high scalability ease of programming and fault tolerance secondly most software can be easily deployed on the cloud and made accessible to all thirdly there are already lowcost commercially_available cloud platforms e g amazon elastic compute cloud fourthly the pay as you use model of such commercial platforms also makes them attractiveapache hadoop is an open_source equivalent implementation of the mapreduce framework running on hadoop distributed file system hdfs we conduct a series of experiments on our local cluster with over nodes and a public cloud environment amazon elastic compute cloud amazon ec for our local cluster each node consists of a ax ghz cpu running centos with gb_memory and x g sata disks for amazon ec we use extra large instances each with ec compute units virtual cores with ec compute units each gb of memory and gb of local instance storage running on a bit platform moreover since our tasks at hand are computationally_intensive we set the number of reducers per node to be equal to the number of cores at the node which is in our local cluster and in ec instances this guarantees that each reducer can get one core therefore there are a total of n and n reducers which can be run simultaneously on a n node local cluster and ec clusters respectively effect of number of reducers for hadoop application a user can specify the number of reducers to be used in one job because we have preconfigured the total number of reducers to be n for a n node cluster this may require_multiple phases to complete a job for example if n then by specifying reducers in one job we can complete it in one phase with reducers it will then take three phases to complete the job our first experiment is to investigate the optimal number of reducers that should be set for one job based on a given cluster_size this experiment is conducted with a snps dataset on a local node cluster note that all the datasets we used include samples presents the running time for the greedy model as shown there is a certain optimal number of reducers that should be used when the number of reducers is too small the computation resources are not fully utilized on the other hand when the number of reducers is too large the processing may require_multiple phases that increases the communication page overhead we note that the greedy model is optimal when the number of reducers corresponds to the actual configured value i e presents the running time for the square chopping model here the snps are evenly split into and partitions corresponding to and reducers needed from the results we observe that when the reducer number is close to a multiple of n where n is the total number of reducers configured in the cluster its performance is good otherwise n rn reducers in the last phase where r is the reducer number set in the job will be wasted looking at the results for the greedy and the square chopping models we observe that the square chopping model is generally inferior to the greedy model this is because of wasted reducers in the last phase as discussed above its performance however is closer to the greedy model as the partition number increases because the task in each reducer is smaller and hence the wasted reducers in the last phase will not affect the total performance so much based on these results for the subsequent_experiments we only use the greedy model scalability first we study the scalability of the eceo model as the system resources increase shows the completion time to analyze snps as the cluster sizes increases from to nodes the reducer numbers in each job are set as and respectively from the result we can see that completion time reduces with increasing number of nodes in fact we observe a almost linear speedup in performance when we double the resources the execution time reduces by half now let us consider the scalability of eceo as the number of snps increases shows the processing time for exhaustively computing all the significant interactions for two locus with and snps on a local node cluster and output the results whose p values are smaller than we made two interesting observations first the result shows that our eceo offers a feasible and practical solution to perform pairwise epistasis for a large number of snps according to it would require years to do the pairwise epistasis testing of snps using the serial program on a ghz single processor without parallel processing our eceo model can accomplish this task in not more than h using only a node cluster second we note that the processing time is essentially proportional to the number of interacting snp_pairs to be evaluated this article aims at providing an efficient epistasis computing model for large_scale epistatic interaction in gwas which can be run on a computing cluster local or cloud_based we have proposed an efficient and feasible_solution called eceo based on the mapreduce framework as such eceo inherits the nice properties of mapreduce which is high scalability and good fault tolerance moreover it can leverage cloud_computing with almost unlimited elastic computing_resources we have demonstrated the practical advantage of using eceo model to exhaustively search two locus and three locus epistatic_interactions our eceo model can also retrieve top k most significant interactions we have conducted extensive experimental study on a local cluster of over nodes and instances on amazon ec the results showed that our eceo model is computationally_efficient flexible scalable and practical as future work we plan to implement more test_statistics we also plan to explore the possibility of integrating eceo as a filtering step to other methods e g those based on statistical model_fitting finally we plan to develop pruning strategies based on domain_knowledge and integrate these into our scheme for example by knowing that certain snps do not interact their computations can be avoided totally 
