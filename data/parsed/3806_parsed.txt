data_and pygcluster a novel hierarchical_clustering approach pygcluster is a clustering_algorithm focusing on noise injection for subsequent cluster validation the reproducibility of a large amount of clusters obtained with agglomerative hierarchical_clustering is assessed furthermore a multitude of different distance linkage combinations are evaluated finally highly_reproducible clusters are meta clustered into communities graphical illustration of the results as node and expression maps is implemented availability_and pygcluster requires python it is freely_available pygcluster github io and published under mit_license dependencies are numpy scipy and optionally fastcluster and rpy omics_technologies yield large_data which are commonly subjected to cluster_analysis to organize them into comprehensible i e coregulated groups which might be functionally_related a critical step in cluster_analysis is cluster validation the most stringent form of validation being the assessment of exact reproducibility of a cluster in the light of the uncertainty of the data this issue is addressed by pygcluster an algorithm working in two steps first it creates many agglomerative hierarchical clusterings ahcs of the input_data by injecting noise based on the uncertainty of the data and clusters them using different distance linkage combinations dlcs second pygcluster creates a meta clustering i e clustering of the resulting highly_reproducible clusters into communities to gain a most complete representation of common patterns in the data communities are defined as sets of clusters with a specific pairwise overlap the first key concept is based on the importance of the uncertainty in the data_set which can be assessed by biological and or technical repetitions classical bootstrapping offers a way to include the repetitions to estimate the uncertainties of the data_points for example one could cluster each repetition separately and clusters consistently formed would be highly_reliable however a more refined approach would be to use the repetitions to derive the shape of the value distributions these shapes and their describing functions can be used to define the noise injecting function in pygcluster that allows a new data_set to be generated during each iteration the second key concept is the evaluation of different dlcs although all clustering_algorithms require a method to calculate the distance i e a similarity_metric between objects the linkage method is specific for ahc in a classical ahc approach one has to define a specific distance_metric e g correlation aiming at relative distances and linkage method albeit other distance metrics e g euclidean aiming at absolute distances and linkage methods may also yield interesting clusters using a variety of different dlcs results in a broader result spectrum and in a reduction of user bias in data evaluation these key_concepts coupled with high numbers of iterations and meta clustering of highly_reproducible clusters into communities make pygcluster a novel hierarchical_clustering approach approach with a specifically developed distance_metric and complete linkage complete linkage was chosen because it insures that all clusters or meta clusters have overlapping objects the distance between two objects i and j is defined as follows disti j root j j if i orj root root j j if ij max i j j j j j minimal required overlap max i j j j i j 
