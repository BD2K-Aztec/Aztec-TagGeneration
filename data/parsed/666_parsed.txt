sequence_analysis bayesian_analysis of gene_essentiality based on sequencing of transposon_insertion libraries motivation next_generation affords an efficient analysis of transposon_insertion libraries which can be used to identify essential genes in bacteria to analyse this high_resolution data we present a formal bayesian_framework for estimating the posterior_probability of essentiality for each gene using the extreme value distribution to characterize the statistical_significance of the longest region lacking insertions within a gene we describe a sampling procedure based on the metropolishastings algorithm to calculate posterior_probabilities of essentiality while simultaneously integrating over unknown internal parameters results using a sequence_dataset from a transposon library for mycobacterium_tuberculosis we show that this bayesian_approach predicts essential genes that correspond well with genes shown to be essential in previous_studies furthermore we show that by using the extreme value distribution to characterize genomic_regions lacking transposon insertions this method is capable of identifying essential domains within genes this approach can be used for analysing trans poson libraries in other organisms and augmenting essentiality predictions with statistical confidence_scores transposon_mutagenesis is a frequently used laboratory method for determining essential genes in bacterial_organisms essential genes are those genes necessary for growth under a wide_variety of environmental_conditions knowledge of essential genes is important for the discovery of new antibacterial drugs because these genes are potential targets for inhibitors one way of determining essential genes is to identify regions of the genome in which insertional mutations produce non viable cells to do this a high_density library of transposon mutants is constructed the synthetic transposons used in these studies are small_fragments of dna typically kb which can be inserted into different locations in the chromosome through the action of a distally encoded transposase enzyme for example derivatives of the himar transposon are widely used and have been characterized to insert at arbitrary ta dinucleotides without any other obvious sequence_specificity bias the total number of ta sites within a gene often varies sites depending on gene length and gc_content when a transposon inserts at one of these ta sites within a gene it presumably disrupts the function of the gene in a large library of transposon_insertion mutants genes harbouring insertions are presumed to be non essential genes lacking insertions may be essential as they cannot tolerate disruption however this depends on the size of gene and degree of saturation of the library typically of open_reading orfs in a bacterial_genome are found to be essential including genes involved in core metabolism cell_wall protein_translation and dna_replication all of which are known targets of existing_drugs differential analysis of essential genes in bacteria passaged through a host could be used to identify genes specifically required for infection in the original implementation the location of transposon insertions in individual mutants was read out via microarray_hybridization a primer_extension step using a primer complimentary to one end of the transposon was used to amplify the adjacent genomic_region and the relative_abundance of these nucleic_acid probes was quantified via hybridization to oligonucleotide representing each gene both the resolution and the quantitative_accuracy of this method were limited more recently use of hybridization to analyse transposon libraries has been replaced by deep_sequencing using next generation sequencers which yield millions of short_reads typically bp mapping of reads amplified from transposon boundaries can give precise coordinates of insertions within the genome the high_resolution data afforded by deep_sequencing present some unique challenges for analysis of gene_essentiality it has previously been observed that even essential genes can tolerate transposon insertions in the extreme n and c termini of the to whom correspondence should be addressed the author published_by all_rights for permissions please_e journals permissions_oup com orf previous_analyses have often used an ad_hoc criterion such as exclusion of insertions in the first last of the coding_region for similar reasons insertions are sometimes tolerated in linker regions between domains or one domain but not another of an essential protein for example transposon insertions in the n terminus of mmpl caused attenuation of infection in mouse lungs whereas insertions in the c terminus did not thus it is inaccurate to assume that only genes completely lacking transposon insertions are essential in previous work we described a novel statistical_method for analysing transposon_insertion data to characterize the essentiality of genes within an organism the method was based on identifying the longest consecutive stretch of ta sites lacking insertions in a gene and estimating the likelihood of such an open region occurring by chance through the extremevalue gumbel distribution this model was based on an analogy to runs of tails in a sequence of coin tosses where each ta site is viewed as an independent bernoulli trial given the background insertion frequency in non essential genes this analysis was shown to correlate well with previous characterizations of genes essential for in vitro growth of mycobacterium_tuberculosis the primary advantage of this method is that essentiality is based on statistically_significant stretches of ta sites lacking insertions regardless of the presence of insertions at other regions within the gene this is in contrast to other models such as a multinomial model where the order of insertions is not taken into consideration and it may miss regions characteristic of essential domains one limitation of our previous method is that it depends on an a priori estimate of the insertion frequency in non essential genes although this can be approximated over all ta sites in the whole_genome or tuned iteratively by separating out essential genes a more rigorous_statistical treatment is desirable one possible way to approximate the parameters of this model and find estimates of essentiality is to use the expectation_maximization em_algorithm although the em_algorithm converges relatively quickly it depends on maximizing the likelihood of the given distribution this is not feasible for the product of gumbel distributions as no closed form expression for the derivative exists in this article we present a formal bayesian_analysis of transposon_insertion data that simultaneously estimates the likelihood of essentiality for each gene and the non insertion frequency for each class given in the data we develop a formula for the joint and conditional densities based on the likelihood for each gene we describe how to use a metropolishastings mh sampling procedure to estimate the parameters from the data by sampling from the joint probability densities this method_produces a formal estimate of essentiality for each gene from the posterior_probability given the observed insertion data marginalizing over the unknown insertion frequencies in essential and non essential genes we applied our method to deep sequencing_data from transposon_insertion libraries of the h rv strain of m tuberculosis the full details of the construction of this library are presented in briefly the libraries were prepared by transforming h rv using the mycomart phage leading to independent insertion events colony_forming were inoculated into ml of minimal media and glycerol and grown at c the libraries were sequenced with an illumina gaii sequencer and a read_length of bp million_reads per library the h rv genome has bp and it contains orfs this equates to an average of ta sites per orf spaced bp apart on average reads from two independent libraries were obtained which were then summed together to achieve a higher sampling density of the ta sites of the total ta sites in the genome had reads mapping to them showing evidence of a transposon_insertion at those locations of these insertion_sites of them occurred within orfs we assume that sites with a small number of reads i e one could represent spurious reads possibly because of sequencing_errors therefore those sites were treated as lacking any insertions however supplementaryshows the read_counts fit an overdispersed poisson_distribution suggesting most are legitimate insertions sites with just one insertion are discarded anyway to be safe requiring insertions to be confirmed by at least two reads this might lower the effective density of the dataset however this does not affect the method of the orfs in h rv do not contain any ta sites an additional set of genes were deemed too short because of the fact that they do not contain enough ta sites i e n i or the span of nucleotides was too short i e s i bp therefore a total of genes are reported as no data because our analysis is not appropriate for these genes the sampling procedure was run for iterations providing estimates of essentiality for all viable genes as well as estimates of the parameter to ensure that the algorithm mixed well and the samples obtained were uncorrelated the first samples were treated as a burn in period and discarded only keeping every th sample after there supplementary section s contains an analysis of the convergence of the mh procedure used the value for non insertion frequency in non essential genes was estimated to be ae sd performance on a lower_density dataset also h rv grown on glycerol is described in supplementary section s this lower_density library contains fewer transposon insertions in coding_regions and it has longer runs of non insertions among the genes rather than predicting more essential genes our analysis is more conservative in its predictions as it is less confident of the essentiality of the genes given the sparsity of the insertions 
