lightassembler fast and memory_efficient assembly algorithm for high_throughput sequencing_reads motivation the deluge of current sequenced data has exceeded moores law more than doubling every years since the next_generation ngs_technologies were invented accordingly we will able to generate more and more data with high_speed at fixed cost but lack the computational_resources to store process and analyze it with error_prone high_throughput ngs_reads and genomic repeats the assembly_graph contains massive amount of redundant nodes and branching edges most assembly pipelines require this large graph to reside in memory to start their workflows which is intractable for mammalian_genomes resource efficient genome_assemblers combine both the power of advanced computing techniques and innovative data_structures to encode the assembly_graph efficiently in a computer memory results lightassembler is a lightweight assembly algorithm designed to be executed on a desktop machine it uses a pair of cache oblivious bloom filters one holding a uniform sample of g spaced sequenced k_mers and the other holding k_mers classified as likely correct using a simple statistical_test lightassembler contains a light implementation of the graph traversal and simplification modules that achieves comparable assembly accuracy and contiguity to other competing tools our method reduces the memory_usage by compared to the resource efficient assemblers using benchmark_datasets from gage and assemblathon projects while lightassembler can be considered as a gap based sequence assembler different gap sizes result in an almost constant assembly size and genome_coverage the advent_of ngs_technologies has revolutionized the genomic_research but has not been able to provide a complete picture of a sequenced organism since the relative positions of the billions of fragmented pieces are unknown without a genome_assembly which is a highly ambiguous overlapping puzzle de_novo sequence_assembly is an initial step towards downstream data analysis such as understanding evolutionary diversity across different species evidenced by the multitude of data_collection projects including genome k with the increasing efforts to sequence and assemble the genomes of more organisms the assembly problem becomes more complicated and computationally_intensive especially with short inaccurate sequenced_reads and genomic repeats next generation assembly algorithms play around two basic frameworks for efficiently completing their task namely de_bruijn and string graphs in a de_bruijn nodes are the set of distinct k_mers substrings of length k extracted from reads and the edges are the k overlap among them the string_graph is a simplified_version of a classical overlap_graph where nodes are the sequenced_reads and the non transitive edges encode their suffix to prefix overlaps many efforts have been made to fit the assembly_graph into computer memory by the creation of resource efficient genome_assemblers the term resource efficiency touches on both memory space and speed one compressed representation for a string_graph is introduced in sga using fm_index and burrowswheeler transformation of the sequenced_reads recently an incremental hashing technique combined with a probabilistic data_structure bloom_filter revisited the string graph_representation ben the early condensed representation of de_bruijn is a sparse bit vector later implemented in a gossamer sequence assembler this representation is changed in minia by introducing the exact representation of de_bruijn using the combination of a bloom_filter and a hash_table that holds an approximate set of false positive_nodes the hash_table is replaced in subsequent versions of minia by a set of cascading bloom filters for further space optimization the burrowswheeler transformation plays another role in the succinct representation of de_bruijn by combining fm_index with frequency based minimizers to reduce its complexity sparseassembler stores a subsample of k_mers in a hash_table with their overlap links recorded to maintain de_bruijn graph_representation abyss distributes the assembly_graph nodes among different machines to reduce the representation complexity in a computer memory resource efficient sequence assemblers vary in their assembly results in terms of both accuracy and contiguity measures each tool has a set of advantages_and according to the compromises made to achieve efficiency also different evaluation studies generally_reported that the assembly algorithms differ in their outputs according to their working scenarios such as the quality of sequenced data and the complexity of the corresponding genome there is a common conclusion that there is no one tool is best for all scenarios and that there is still room for improvement in current assembly pipelines in this paper we revisit de_bruijn graph_representation and introduce an optimized cache oblivious bloom_filter to the sequence_assembly our method is inspired by lighters idea to correct the sequenced errors using a pair of bloom filters and a simple statistical_test lighter stores a random_sample of k_mers in a bloom_filter and uses them with a simple statistical_test as seeds to classify the read positions as trusted or untrusted while lighters goal is to use the trust classified k_mers to correct erroneous ones our ultimate_goal is assembling these k_mers without error_correction since they are already classified as trusted nodes k_mers made by k consecutive trust classified positions in the sequenced_reads are considered to be trusted lightassembler obtains a uniform sample of k_mers by skipping g bases between the k_mers where g is the gap length and stores them in a bloom_filter the erroneous bases in a read will produce rare k_mers and are unlikely to survive in the sample compared to the abundant k_mers generated by the correct bases the trustiness of a read position will be determined by comparing the number of k_mers that cover the position and appear in the sample to a statistically computed threshold lightassembler uses the k_mers made by k consecutive trust classified reads positions as the set of assembly_graph traversal nodes while several assemblers rely on error_correction modules to identify and correct the erroneous k_mers before starting the assembly process the majority of error_correction algorithms count the k_mers to determine their confidence and exclude ones with a multiplicity less than a specified threshold which might result in missing a subset of true k_mers with low_abundance other assemblers such as velvet rely on intensive graph simplification modules to resolve the erroneous structures introduced by erroneous bases such as tips and bubbles complex_assembly pipelines combine both approaches and perform postprocessing graph filtering using mate_pairs during scaffolding stage lightassembler uses only two passes over the sequenced_reads to identify the approximate set of trusted nodes without error_correction or intensive graph simplification modules also one of the efficient representations of de_bruijn graph_based on a bloom_filter is implemented in minia and uses k_mer module to identify the set of trusted k_mers minias counting algorithm follows a divide_and paradigm and utilizes the disk_space as secondary memory storage our method is able to identify the set of trusted k_mers without utilizing either a counting module or disk_space overhead we will present our comparable results to the current state of the art sequence assemblers as well as resource efficient ones using the simulated and benchmarked datasets we evaluated the performance of lighassembler against minia v sparseassembler and abyss v using simulated_datasets from the escherichia_coli reference genomewith different attributes listed in supplementary we also compared our results with the same assemblers including velvet v using real benchmark_datasets from gage and assemblathon evaluation studies the characteristics of benchmark_datasets are presented in supplementary lightassembler like the other chosen assembly tools is a lightassembler graph traversal module the first step in the graph traversal module is computing the set of branching k_mers k_mers have multiple extensions a the successors for each trusted k_mer are computed by appending a nucleotide nt a c g t f g for example the successors of a k_mer cata where k are ataa atac atag atat f g b bloom_filter b is queried for each successor to check its presence in the sequenced_reads if the number of existing successors for each trusted k_mer is larger than one the trusted k_mer is considered as a branching node otherwise it is a simple node c each assembled contig starts from a branching node in the assembly_graph where each node is extended one nucleotide at a time and bloom_filter b is continuously queried for checking the presence of extended k_mers the assembly_graph is simplified by removing the dead_end paths and resolving the simple bubbles de_bruijn graph_based assembler lightassembler minia and sparseassembler are also considered as resource efficient contigbased assembly tools they do not utilize the paired_end information_encoded in the sequenced libraries to perform scaffolding while abyss and velvet have their own scaffolding modules in order to make a fair comparison we evaluated all methods based on their resulted contigs without using paired_end information such as the insert_size then we performed scaffold analysis based on our resulted contigs compared to those from other methods using sspace v as one of stand alone scaffolding tools one of the major assembly steps is evaluating assembly results to assess their accuracy and contiguity when a reference_genome is available the assembly results are evaluated by mapping the assembled_contigs or scaffolds back to the reference with the possibility of setting a minimum_length threshold for the mapping contigs scaffolds the assembly evaluation_tools have different reported metrics and even different approaches when a reference_genome is absent gage assemblathon and quast are the most popular tools the metrics used to evaluate the assembly results from the competing tools are described in supplementary according to their definition in gage and assemblathon studies while quast has gage option to run the assembly evaluation using gage standards we found that for the same minimum contigs threshold length quast ng equals to gage n before performing the contigs correction step breaking contigs at every misjoin and at every indel longer than bases quast has a slightly_higher n contig length compared to those from gage and assemblathon the default minimum threshold for contigs analysis in quast is bp which can be adjusted by the end_user gage has a fixed threshold contig length equals to bp while it is not specified in the assemblathons paper their threshold based analysis the scaffold based contiguity analysis is used in assemblathon to report the contigs statistics by breaking the scaffolds into their corresponding contigs which increases the n contig length compared to the length reported by the contigs based analysis from other evaluation_tools also ng reported by the assemblaton script equals to the n length reported by gage before doing the contigs correction step we will use gage script to evaluate the assembly results from all competing programs all conducted computer experiments and the exact command lines used for each tool are described in detail in supplementary 
