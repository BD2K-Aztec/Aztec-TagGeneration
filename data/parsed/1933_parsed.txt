genome_analysis gatb genome_assembly analysis tool box motivation efficient and fast next_generation ngs algorithms are essential to analyze the terabytes of data generated by the ngs machines a serious bottleneck can be the design of such algorithms as they require sophisticated data_structures and advanced hardware implementation results we propose an open_source library dedicated to genome_assembly and analysis to fasten the process of developing_efficient software the library is based on a recent optimized de_bruijn implementation allowing complex genomes to be processed on desk top computers using fast algorithms with low memory footprints the analysis of next_generation ngs_data remains a time and space consuming task many efforts have been made to provide efficient data_structures for indexing the terabytes of data generated by the fast sequencing_machines suffix_array burrowswheeler_transform bloom_filter etc genome_assemblers such as velvet abyss soapdenovo spades or mappers such as bwa or variant detection such as crac for instance make an intensive use of these data_structures to keep their memory_footprint as low as possible at the same time parallelism has been largely investigated to reduce execution time many strategies such as gpu_implementation cloud deployment algorithm vectorization multithreading etc have demonstrated high potentiality on ngs processing the overall efficiency of ngs software depends on a smart combination of data representation and use of the available processing units developing such software is thus a real challenge as it requires a large spectrum of competence from high_level data_structure and algorithm concepts to tiny details of implementation the gatb library aims to ease the design of ngs algorithms it offers a panel of high_level optimized building_blocks to speedup the development of ngs tools related to genome_assembly and or genome_analysis the underlying data_structure is a memory_efficient de_bruijn and the general parallelism model is multithreading the gatb library targets standard computing_resources such as current multicore processor laptop computer small server with a few gigabytes of memory hence from the high_level c functions available in the gatb library ngs programing designers can rapidly elaborate their own software based on state of the art algorithms and data_structures of the domain based on the same idea other bioinformatics libraries exist from which domain specific tools can be elaborated the ngs library is specifically tailored for developing applications that work with genomic_regions and features such as epigenomics marks gene features and data that are associated with bed type files the seqan library is a general_purpose library targeting standard sequence processing advanced data_structures such as de_bruijn are not included in seqan khmer is a library and toolkit for doing k_mer based ngs dataset analysis as with gatb most of khmer relies on an underlying probabilistic data_structure bloom_filter the khmer library can be used in various k_mer processing such as abundance filtering error trimming graph size filtering or partitioning to demonstrate the efficiency of the gatb library a few software implemented from gatb are briefly presented the idea is to give a quick overview of the application spectrum of the gatb library and some performance numbers minia is a short_read de_bruijn assembler capable of assembling large and complex genomes into contigs on a desktop computer the assembler produces contigs of similar length and accuracy to other de_bruijn assemblers e g velvet as an example a boa constrictor constrictor gb dataset illumina bp reads coverage from assemblathon can be processed in h and gb of memory on a standard computer ghz core processor using a single core yielding a contig n of kb prior to scaffolding and gap_filling bloocoo is a k_mer spectrum based read error corrector designed to correct large_datasets with low memory footprints it uses the disk streaming k_mer algorithm contained in the gatb library and inserts solid k_mers in a bloom_filter the correction procedure is similar to the musket multistage approach bloocoo yields similar results while requiring far less memory for example it can correct whole human_genome re sequencing_reads at coverage with gb of memory see supplementary_file for extra_information on bloocoo discosnp aims to discover single_nucleotide from non assembled reads and without a reference_genome from one or several datasets a global de_bruijn is constructed then scanned to locate specific snp graph patterns a coverage analysis on these particular locations can finally be performed to validate and assign scores to detected biological elements applied on a mouse dataset gb bp illumina_reads discosnp takes h and requires gb ram in the same spirit the takeabreak software discovers inversion variants from non assembled reads it directly finds particular patterns in the de_bruijn and provides execution performances similar to discosnp 
