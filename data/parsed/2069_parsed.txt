globalmit learning globally optimal dynamic_bayesian with the mutual_information test criterion motivation dynamic_bayesian dbn are widely_applied in modeling various biological_networks including the gene_regulatory grn due to the np_hard nature of learning static bayesian network_structure most methods for learning dbn also employ either local_search such as hill climbing or a meta stochastic global optimization framework such as genetic_algorithm or simulated_annealing results this article_presents globalmit a toolbox for learning the globally optimal dbn structure from gene_expression data we propose using a recently_introduced information_theoretic based_scoring metric named mutual_information test mit with mit the task of learning the globally optimal dbn is efficiently achieved in polynomial time availability the toolbox implemented in matlab and c is available atbayesian network bn has found applications in modeling various biological_networks including the gene_regulatory grn the two important_limitations when applying static bn to these domain problems are i bn does not have a mechanism for exploiting the temporal aspect of time series data such as time series microarray_data and ii bn does not allow the modeling of cyclic phenomena such as feedback_loops which are prevalent in biological_systems these drawbacks have motivated the development of the so_called dynamic_bayesian dbn its simplest model the first order markov stationary dbn assumes that both the structure of the network and the parameters characterizing it remain_unchanged over time the value of a variable at time t is assumed to depend only on the value of its parents at time t dbn not only accounts for the temporal aspect of time series data i e an inter time slice edge must always be directed forward in time but it also allows the modeling of feedback_loops since its inception dbn has received particular interest from the bioinformatics community kim to whom correspondence should be addressed 
