correcting for cancer genome_size and tumour_cell content enables better estimation of copy_number from next generation sequence_data motivation comparison of read_depths from next_generation between cancer and normal cells makes the estimation of copy_number cna possible even at very low coverage however estimating cna from patients tumour_samples poses considerable challenges due to infiltration with normal cells and aneuploid cancer_genomes here we provide a method that corrects contamination with normal cells and adjusts for genomes of different sizes so that the actual copy_number of each region can be estimated results the procedure consists of several steps first we identify the multi_modality of the distribution of smoothed ratios then we use the estimates of the mean modes to identify underlying ploidy and the contamination level and finally we perform the correction the results indicate that the method works properly to estimate genomic_regions with gains_and in a range of simulated_data as well as in two datasets from lung_cancer patients it also proves a powerful_tool when analysing publicly_available data from two cell_lines hcc and colo availability an r package called cnanorm is available atcancer cells often exhibit severe karyotypic alterations whole chromosome gain or loss and structural_rearrangements such as amplifications deletions and translocations result in widespread aneuploidy the ability to detect copy_number cnas of cancer_cells is a crucial step to access the severity of chromosomal_rearrangements and to find chromosomal_regions where breakpoints are located furthermore comparison of cnas across tumours from different patients makes it possible to find regions commonly duplicated or lost to highlight the locations of cancer_related several methodologies are available to detect cnas comparative_genomic cgh array_cgh acgh to whom correspondence should be addressed single_nucleotide snp_array and more recently a new generation of sequencing_machines enabled massively_parallel roche illumina gaii hiseq miseq abi solid ion_torrent pgm making it possible to sequence full genomes at affordable cost we previously showed how it is possible to multiplex several samples in one illumina gaii lane making copy_number analysis by sequencing affordable and competitive with acgh or snp_arrays between one and eight million aligning_reads compared to approximately half a billion reads for full coverage are enough to provide genome_wide cna at kb resolution as we expect sequencing_technologies to become more widespread affordable and accurate copy_number analysis by low_coverage will become even more convenient and informative furthermore sequencing is possible even with low amounts of dna extracted from formalin_fixed specimens finally one advantage of sequencing compared with array technology is that the signal scales linearly to the input dna and does not show saturation nor background_noise typical of hybridization techniques one of the first steps to take when analysing these data is normalization the total intensity of signal from array technology or the total number of reads from sequencing does not reflect the total dna_content of the cells of interest but it is largely determined by various technical_aspects tuned to achieve the maximum intensity range array technology or highest number of reads sequencing the normalization is a crucial non trivial and often underestimated step which can have enormous repercussions on downstream_analysis and conclusions in this article we present a computational_tool called cnanorm to correct normalize and scale the data from low_coverage experiments we have investigated a method to estimate cna from patient tumour_samples using next_generation we showed how the method performs with a range of simulated_data on low coverage data from patients samples and on higher_coverage data from cell_lines compared with several segmentation tools available to analyse high_throughput sequencing_data cnanorm focuses on correcting the data for contamination different read_depth and different genomic size we acknowledge that the problem could lead to several equally valid solutions but provide an easy way for the user to correct the estimation from cnanorm when independent clues such as tumour content or strong and independent evidence about ploidy of certain regions are available we believe that the normalization step is often underestimated or due to its intrinsic difficulty and plurality of solution left to a simplistic approach that assumes that the overall size of a cancer genome is comparable with that of a normal cell with the data from the two cell_lines hcc and colo we have shown how information on tumour content ploidy of some chromosomes and overall ploidy could guide the experimenter to perform a more meaningful normalization at the same time cnanorm could provide further insight on the cancer material analysed when no external_information is available e g in the case of patientstumours ls and ls cnanorm performs the most conservative normalization in this regard if regions of homozygous_deletions could be identified and confirmed they would be a valuable guide during the normalization process despite being a powerful_tool cnanorm is not a silver bullet for cna analysis in particular we would like to point out how polyclonal tumours could produce misleading_results if several tumour clones each with its gains and loss constitute the tumour sample it will not be possible to detect the underlying ploidy and the mixture_model approach would over fit distributions within a single ploidy range cnanorm is meant to be robust and clonal variability in a few chromosomal_regions would not be problematic however in these cases cnanorm would tend to underestimate tumour content this is in our opinion what happens with cell_lines hcc and colo although the cell_line should be tumour cnanorm estimates only and respectively we think this is due to some variability within cells this variability can be observed for instance in hcc where the copy_number of the long_arm or chromosome are unlike most of the rest of the genome not close to any integer copy_number since we are aware of possible polyclonal variability we chose an approach and a segmentation tool dnacopy that does not force every region of the genome to fit into an integer copy_number clues about polyclonal variation are per se potentially informative next_generation data from clinical samples obtained directly from patients presents a serious challenge analysis of cnas in tumour_samples is not straightforward this is because the observed raw copy_number ratios do not necessarily take the expected_values due to random error different sequencing_coverage and contamination with normal cells we deal with the random error using smoothing methods the other challenges are dealt with by acknowledging the multi_modality in the distribution of the segmented copy_number ratios this allows us to model the locations of the distribution of ratios corresponding to the different copy_numbers and make the necessary correction the simulation_study shows that the method works properly to estimate genomic_regions with gains_and and that it works well in a range of real_datasets from patients samples and cell_lines 
