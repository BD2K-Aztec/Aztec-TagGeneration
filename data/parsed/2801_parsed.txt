masc mappability sensitive cross_correlation for estimating mean fragment length of single_end short_read sequencing_data reliable estimation of the mean fragment length for next generation short_read sequencing_data is an important step in next_generation analysis_pipelines most notably because of its impact on the accuracy of the enriched regions identified by peak_calling algorithms although many peak_calling algorithms include a fragment length estimation subroutine the problem has not been adequately solved as demonstrated by the variability of the estimates returned by different algorithms results in this article we investigate the use of strand cross_correlation to estimate mean fragment length of single_end data and show that traditional estimation approaches have mixed reliability we observe that the mappability of different parts of the genome can introduce an artificial bias into cross_correlation computations resulting in incorrect fragment length estimates we propose a new approach called mappability sensitive cross_correlation masc which removes this bias and allows for accurate and reliable fragment length estimation we analyze the computational_complexity of this approach and evaluate its performance on a test suite of ngs_datasets demonstrating its superiority to traditional cross_correlation availability an open_source perl implementation of our approach is available atnext generation sequencing ngs_technologies have revolutionized molecular_biology with their unprecedented capacity for genome_wide measurement of proteindna_interactions chromatin_state changes and transcription_levels although ngs_technologies differ in their details most of the common platforms work by sequencing large_numbers of shortdna fragments these fragments may originate for example from simple extraction of dna from a sample of cells selective extraction based on a chromatin_immunoprecipitation pulldown or reverse transcription of rna into dna when dealing with dna from an organism that lacks a canonical genome_assembly the sequences can be assembled to create a de_novo estimate of the genome or transcriptome when the organism does have a canonical genome the dna_fragment sequences are typically mapped back to the canonical genome so that their distribution and especially sites of enrichment may be studied ngs_technologies usually do not sequence each dna_fragment in its entirety indeed depending on the size of the fragments this is typically impossible and is not the intended use of the technology the best practical alternative offered by typical current_technologies is sequencing the fragments starting from both ends however most experiments do not take advantage of this option for cost reasons and instead choose to sequence only one end of each fragment thus despite having a canonical genome_assembly to which one end of each fragment can be mapped most ngs experiments lack information on the other unsequenced end of each fragment a fundamental step in many ngs analysis_pipelines is to estimate mean fragment length so that we can have at least some idea of the genomic_locations of the unsequenced ends first this helps in the visualization of the ngs dataset in a genome_browser each read can be extended to the average fragment length and shown as an interval in the browser giving a more accurate impression of the regions of the genome represented by the dna_sample secondly fragment length estimation is important for peak_calling algorithmsmethods for automatically detecting the genomic_regions that are enriched in the sample of dna_fragments in most such algorithms either the reads are extended to an average fragment length e g or the positive_and strand reads are shifted towards each other by half the estimated fragment length e g indeed many peak_calling algorithms include a fragment length estimation subroutine however many of these have not been rigorously validated and different algorithms often produce different fragment length estimates partly as a result the enriched regions identified by different peak_calling algorithms can have poor overlap also see supplementary section s yet other peak_calling algorithms require the fragment length as input e g for all of these reasons reliable fragment length estimation is an important problem that has not yet been adequately solved mean fragment length can be estimated in the wetlab and this is often a part of dna sample_preparation protocols fragment to whom correspondence should be addressed the author published_by this is an open_access the terms of the creative commons attribution license http creativecommons org licenses by which_permits distribution and reproduction in any medium provided the original_work length is commonly controlled by the aggressiveness of dna_fragmentation e g duration of dna sonication and or by gel_based size_selection however such procedures vary by laboratory and even by experimenter and they often go unreported for public ngs_datasets moreover such procedures are typically not highly quantitative and only result in rough estimated ranges for fragment length e g bp which are not satisfactory in this article we investigate the use of cross_correlation of positive_and strand reads for estimating mean fragment length by applying this method to a small number of available paired_end datasets for which mean fragment length can be computed exactly we show that cross_correlation usually produces an accurate fragment length estimate occasionally however estimates are clearly wrong returning a value near the read_length rather than the fragment length our key insight is that the mappability of different parts of the genome can introduce an artificial bias into the cross correlation_function which sometimes results in incorrect fragment length estimates based on this insight we propose a new approach called mappability sensitive cross_correlation masc which removes this bias allowing for much more accurate fragment length estimation we analyze the computational_complexity of this algorithm and evaluate its performance on a test suite of ngs_datasets demonstrating its superiority to traditional cross_correlation we have demonstrated that mappability can introduce a strong bias into genome_wide cross_correlation computations of positive_and strand read densities when those computations are carried_out to estimate fragment length and when the bias is strong enough a dramatically wrong fragment length estimate can result when used for peak_calling such incorrect estimates can have adverse_effects on the set of peaks returned crucially we have shown that the mappability induced bias can be corrected for using our masc algorithm tests using a variety of public ngs_datasets demonstrated the effectiveness of masc we also showed that smoothing the correlation signal helps in obtaining an unambiguous summit location we do recommend checking the plots of the smoothed and the unsmoothed signals provided by our software to ensure a reasonable agreement between the summit locations the computational_complexity of masc is comparable with the traditional cross_correlation computation the only serious caveat to the masc computation is that it requires a mappability map to have been established for the target_genome and for the read_length under consideration such maps are not always available and are non trivial to compute however when such mappability information is available we see no reason not to use the masc computation instead of the traditional biased crosscorrelation computation the first five rows correspond to data from the encode_project sissrs kharchenko correlation and coverage output estimates by chromosome hence these columns have means ae standard_errors the pervasiveness of the mappability problem in correlation_analysis is unclear in some datasets we obtained from geo we found the problem whereas other datasets did not show the problem generally we expect datasets with shorter reads to be more susceptible because a greater fraction of the genome is unmappable with shorter reads however mappability also varies_significantly by organism the problem seems to be present both in older datasets and new datasets we are presently planning a comprehensive_examination of the large number of encode chip_seq to get a better assessment of the issue although we have emphasized positive_versus strand cross_correlation and the fragment length estimation problem our approach to eliminating mappability bias is relevant to other correlative type analysis of short_read for instance if one were to compute autocorrelation_functions as a measure of the spatial_structure of the genomic signal being assessed a similar mappability correction could be performed the concept could also be relevant to correlating different datasetsfor instance relating a transcription_factor binding signal to a histone_modification signal this would especially be true if the different datasets used different read_lengths and thus were differentially susceptible to mappability problems finally based on the cross correlation_function we have begun exploring the possibility of estimating not just the mean fragment length but the variance as well or even more generally the entire fragmentlength distribution 
