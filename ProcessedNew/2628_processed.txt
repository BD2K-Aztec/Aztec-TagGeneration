sequence analysis kaboom! a new suffix array based algorithm for clustering expression data motivation: second-generation sequencing technology has reinvigorated research using expression data, and clustering such data remains a significant challenge, with much larger datasets and with different error profiles. algorithms that rely on all-versus-all comparison of sequences are not practical for large datasets. results: we introduce a new filter for string similarity which has the potential to eliminate the need for all-versus-all comparison in clustering of expression data and other similar tasks. our filter is based on multiple long exact matches between the two strings, with the additional constraint that these matches must be sufficiently far apart. we give details of its efficient implementation using modified suffix arrays. we demonstrate its efficiency by presenting our new expression clustering tool, wcd-express, which uses this heuristic. we compare it to other current tools and show that it is very competitive both with respect to quality and run time. availability: source code and binaries available under gpl atthe clustering of expressed sequence tags (ests) and other gene expression data continues to be a major challenge in bioinformatics. the emergence of new sequencing technologies such as pyrosequencing, collectively referred to as second-generation sequencing , has recently reinvigorated studies using expression data. second-generation sequencing provides the opportunity to study the transcriptomes of organisms for which good quality genomes are not known. however, new computational challenges have emerged, with much larger datasets, shorter sequence length and new error profiles . in expression clustering, we start with a large set of cdna sequences, typically 10 5 or more, which have been derived from transcriptomic data in a laboratory process (commonly, these sequences are referred to as ests). the goal is to find a partitional clustering such that sequences derived from the same gene are to whom correspondence should be addressed. members of the same cluster. expression clustering can broadly be divided into two classes: (i) clustering for which a reference genome is known (supervised clustering) and (ii) clustering for which a reference genome is not known (also called ab initio or de novo clustering). in this article, we focus on the latter class. typically, single linkage clustering is used for expression data: if two sequences are similar, their clusters are merged. within this approach, different similarity measures can be used. traditionally, edit distance/alignment has been used to define similarity between sequences. however, alignment-free measures are increasingly being adopted, such as q-gram distance or d 2 . these define similarity between sequences with respect to the multiplicity of substrings (subwords) of a fixed, usually small, length. because of effects such as alternative splicing, in expression clustering typically a local similarity of a predefined length is sought. for two sequences of length m to be regarded as similar, it suffices to find a pair of similar windows. using subword-based measures, it is possible to compute the maximum similarity between all pairs of windows of a fixed length in time o(m 2 ) [similarly, computation of an optimal local alignment score takes o(m 2 ) time]. est clustering algorithms that use subword-based distance measures rather than alignment methods have proved successful . however, with the new and much larger datasets, computation time is still an issue: given n est sequences, with average length m, computing all pairwise similarities requires (n 2 m 2 ) time. for real datasets this is prohibitive, at least without massive parallelism. much work has gone into breaking these complexity limits. filtering heuristics have been very successful. they test two strings in linear time to see whether they are likely to be similar, before a more expensive comparison is done. in practice, these heuristics have sped up clustering by orders of magnitude. however, the algorithms still remain quadratic in the number of sequences. in this article, we introduce the kaboom filter, which greatly reduces the number of candidate pairs without compromising on clustering quality. this heuristic passes a pair of sequences if they share a given number of common words (substrings) of a given length, occurring at least a given distance apart. we also give details of its efficient implementation, which uses a modified suffix array. contribution: our contribution is 2-fold:(1) we introduce a new heuristic filter for sequence similarity.page: 3349 33483355this section compares wcd-express to the previous version of wcd, and to two other systems, tgicl and peace , evaluating the impact of the kaboom heuristic and the overall performance of wcd-express. all experiments were done on an intel e5335 (2 ghz; dual quadcore processor with 4 mb of l2 cache per processor and 16 gb of ram; single thread; scientific linux 5.4, gcc 4.1.2, o-2 for wcd-express and wcd). we used the asymmetric implementation of wcd-express, which initial experimentation showed was slightly faster (but which is controlled by a compiler-switch).experimental results on different sets of est datasets. seqs is the number of sequences in thousands; size is the number of megabases. e is the average square of the frequency of the distinct words; is the ratio of the number of distinct words to the total number of words. wcd-express is the time our new algorithm takes including pre-processing; wcd is the time our previous version of wcd takes. all times in seconds are rounded to the nearest second. for both versions of wcd, the same parameters were used. the sensitivity of wcd-express with respect to wcd is over 0.999 in all cases.  
