real-time multi-view deconvolution in light-sheet microscopy, overall image content and resolution are improved by acquiring and fusing multiple views of the sample from different directions. state-of-the-art multi-view (mv) deconvolution simultaneously fuses and deconvolves the images in 3d, but processing takes a multiple of the acquisition time and constitutes the bottleneck in the imaging pipeline. here, we show that mv deconvolution in 3d can finally be achieved in real-time by processing cross-sectional planes individually on the massively parallel architecture of a graphics processing unit (gpu). our approximation is valid in the typical case where the rotation axis lies in the imaging plane. availability and implementation: source code and binaries are available on github (https://github. com/bene51/), native code under the repository gpu_deconvolution, java wrappers implementing fiji plugins under spim_reconstruction_cuda. contact:mv imaging is particularly useful in light-sheet microscopy where consecutive views are acquired in short succession, allowing reconstruction of entire developing organisms without artifacts . due to the low photo-toxicity in light sheet microscopy, time-lapse experiments are oftentimes run over days and terabytes of data accumulate quickly. mv fusion is therefore particularly desirable to be performed in real-time to eliminate redundant information from different views. best fusion results, however, are achieved by combining fusion with 3d deconvolution . although efficient bayesian mv deconvolution based on the richardsonlucy (rl) algorithm has been shown recently to outperform existing methods in terms of fusion quality and convergence speed, it is still too slow for real-time processing of typical data volumes . the rl deconvolution iterations consist only of convolutions and pixel-wise arithmetic operations and could therefore be significantly accelerated using dedicated hardware such as a graphics processing unit (gpu). the large memory requirements of mv deconvolution, however, exceed the limited resources of modern gpus even for moderate data sizes (supplementary note s1). previous attempts therefore required splitting the data into blocks of appropriate size. each block then either had to be transferred to and from the gpu in each rl iteration , or blocks needed to share a considerable amount of overlap to avoid border artifacts . therefore, gpu-based implementations only achieved a three-times performance gain .the primary goal of mv fusion is the improvement of the poor axial resolution in a single 3d dataset using the superior lateral resolution of an additional, overlapping dataset, and not necessarily to improve resolution beyond the intrinsic lateral resolution. we therefore approximated the full 3d point spread function (psf) with a 2d psf, neglecting one lateral component (along the rotation axis), and processed each plane orthogonal to the rotation axis independently . memory requirements were thereby reduced by the number of lines read out from the camera chip, i.e. typically 1001000 fold . this allowed us to implement the entire mv deconvolution on a gpu. taking advantage of three cuda (compute unified device architecture) streams, we interleaved gpu v c the author 2015. published by oxford university press.the photo-efficiency of light-sheet microscopy enables long timelapse imaging of living samples to study fundamental questions in developmental biology. however, its huge data rates also open new challenges for data processing. a key problem in light-sheet microscopy has been the fusion of data recorded from multiple angles. in this article, we presented a new method that performs mv deconvolution plane-wise, which reduces memory requirements compared with existing methods and thus permits an entirely gpu-based implementation. the achieved acceleration makes mv deconvolution for the first time applicable in real-time without the need for data cropping or resampling.averaged  
