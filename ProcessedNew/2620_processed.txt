joint stage recognition and anatomical annotation of drosophila gene expression patterns motivation: staining the mrna of a gene via in situ hybridization (ish) during the development of a drosophila melanogaster embryo delivers the detailed spatio-temporal patterns of the gene expression. many related biological problems such as the detection of co-expressed genes, co-regulated genes and transcription factor binding motifs rely heavily on the analysis of these image patterns. to provide the text-based pattern searching for facilitating related biological studies, the images in the berkeley drosophila genome project (bdgp) study are annotated with developmental stage term and anatomical ontology terms manually by domain experts. due to the rapid increase in the number of such images and the inevitable bias annotations by human curators, it is necessary to develop an automatic method to recognize the developmental stage and annotate anatomical terms. results: in this article, we propose a novel computational model for jointly stage classification and anatomical terms annotation of drosophila gene expression patterns. we propose a novel tri-relational graph (tg) model that comprises the data graph, anatomical term graph, developmental stage term graph, and connect them by two additional graphs induced from stage or annotation label assignments. upon the tg model, we introduce a preferential random walk (prw) method to jointly recognize developmental stage and annotate anatomical terms by utilizing the interrelations between two tasks. the experimental results on two refined bdgp datasets demonstrate that our joint learning method can achieve superior prediction results on both tasks than the state-of-the-art methods.the mrna in situ hybridization (ish) provides an effective way to visualize gene expression patterns. the ish technique can precisely document the localization of gene expression at the cellular level via visualizing the probe by colorimetric or fluorescent microscopy to allow the production of high quality images recording the spatial location and intensity of the gene expression . such spatial and temporal characterizations of expressions paved the way for inferring regulatory networks based on spatio-temporal dynamics. the raw data produced from such experiments includes digital images of the drosophila embryo (examples are visualized in) showing a particular gene expression pattern revealed by a gene-specific probe (to whom correspondence should be addressed). the fruit fly drosophila melanogaster is one of the most used model organisms in developmental biology. traditionally, such ish images are analyzed directly by the inspection of microscope images and available from well-known databases, such as the berkeley drosophila genome project (bdgp) gene expression pattern database and fly-fish (l). to facilitate spatio-temporal drosophila gene expression pattern studies, researchers needed to solve two challenging tasks first: drosophila gene expression pattern stage recognition (temporal descriptions) and anatomical annotation (spatial descriptions). as shown in, drosophila embryogenesis has been subdivided into 17 embryonic stages. these stages are defined by prominent features that are distinguishable in living drosophila embryos . to recognize the stages of the drosophila, embryos provide their time course patterns. on the other hand, the drosophila gene expression patterns are often recorded by controlled vocabularies from the biologists perspective . such anatomical ontology terms describe the spatial biological patterns and often cross stages. what is more, because the ish images are attached to each other collectively becoming bags of images, the corresponding stage label as well as anatomical controlled terms are the descriptions of the whole group of images instead of each individual image inside the bag. a drosophila embryo ish image bag belongs to only one stage, but has multiple related anatomical terms. previously, those two tasks are tackled by domain experts. however, due to the rapid increase in the number of such images and the inevitable bias annotation by human curators, it is necessary to develop an automatic method to classify the developmental stage and annotate anatomical structure using controlled vocabulary. recently, a lot of research works have been proposed to solve the above two problems. they considered the stage recognition as a single-label multi-class classification problem while the anatomical annotation was treated as a multi-label multi-class classification problem. first developed an embryo enclosing algorithm to find the embryo outline and extract the binary expression patterns via adaptive thresholding. and developed new ways to represent ish images based on gaussian mixture models, principal component analysis and wavelet functions. besides that, they utilized min-redundancy max-relevance to do the feature selection and automatically classify gene expression pattern developmental stages. recently, constructed a system (called spex 2 ) and concluded that the local regression (lr) method taking advantage of the controlled termterm interactions can get the best enhanced anatomical controlled term annotation results. the lr method was proposed by ji et al. and developed based on their previous worksin this article, we proposed a novel tg model to learn the task interrelations between stage recognition and anatomical terms annotation of drosophila gene expression patterns. the standard bag-of-word features and three major views (lateral, dorsal and ventral) were used to describe the 3d drosophila images. a new prw method was introduced to simultaneously propagate the stage labels and anatomical controlled terms via tg model. both stage classification and anatomical controlled term annotation tasks are jointly completed. we evaluated the proposed method using one refined bdgp dataset. the experimental results demonstrated in the real application, when the number of training data is scarce, our joint learning method can achieve superior prediction results on both tasks than the state-of-the-art methods. what is more, we can discovery more accurate asymmetric termterm correlation, which can potentially improve the results of both tasks even more.) in order to see the asymmetric entries more clearly, we plotafter prw, the entries marked as brighter square have higher conditional probability (positive correlation) than its counterpart which is marked as darker color. this asymmetric reflects more accurate termterm correlation than the original symmetric assumption  
