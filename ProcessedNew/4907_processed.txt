weighted poolingâ€”practical and cost-effective techniques for pooled high-throughput sequencing motivation: despite the rapid decline in sequencing costs, sequencing large cohorts of individuals is still prohibitively expensive. recently, several sophisticated pooling designs were suggested that can identify carriers of rare alleles in large cohorts with a significantly smaller number of pools, thus dramatically reducing the cost of such large-scale sequencing projects. these approaches use combinatorial pooling designs where each individual is either present or absent from a pool. one can then infer the number of carriers in a pool, and by combining information across pools, reconstruct the identity of the carriers. results: we show that one can gain further efficiency and cost reduction by using weighted designs, in which different individuals donate different amounts of dna to the pools. intuitively, in this situation, the number of mutant reads in a pool does not only indicate the number of carriers, but also their identity. we describe and study a powerful example of such weighted designs, using non-overlapping pools. we demonstrate that this approach is not only easier to implement and analyze but is also competitive in terms of accuracy with combinatorial designs when identifying rare variants, and is superior when sequencing common variants. we then discuss how weighting can be incorporated into existing combinatorial designs to increase their accuracy and demonstrate the resulting improvement using simulations. finally, we argue that weighted designs have enough power to facilitate detection of common alleles, so they can be used as a cornerstone of whole-exome sequencing projects.the need for low-cost large-scale rare mutation screens is on the rise, with the current shift of genome-wide association studies towards rare variants . another major application of rare variants genotyping is in prenatal screens for rare genetic disorders; for example, the israeli ministry of health sponsors carrier screening tests for a list of 36 severe and frequent genetic diseases (with prevalence higher than 1 in 1000 live births) in 35 different localities/communities . the israeli ministry of health also provides free-of-charge screening for taysachs, a recessive neurodegenerative disorder which is fatal by the age of 23, to couples of jewish descent , as well as screens for thalassemia (an inherited autosomal recessive blood disease) to all the arab and druze populations to whom correspondence should be addressed. and jews of mediterranean or asiatic descent . recent studies have described how sophisticated pooling designs for high-throughput sequencing (hts) technologies can be used to dramatically reduce the number of pools required for carrier identification, and, therefore, can reduce the costs of such large scale carrier screens drastically . the cost reduction is accomplished because most of the cost of such projects is typically in the capture stage, which has to be performed only once per pool. reducing the capture cost, even at the price of increasing the amount of sequencing, can lead to very significant decrease in overall cost (see typical calculations in section 6.2 below). using a smaller number of pools reduces the overall ability to reconstruct the genomes, but the theory of sparse signal recovery, also known as compressed-sensing , guarantees that with high probability the carriers of rare mutations can be identified. in the traditional pooled testing setup, the result of testing each pool is a true/false value . this is the framework adopted bywho use the number of wild-type and mutant allele reads in each pool to infer whether a pool contains carriers or not. however, the information obtained by sequencing a pool of mixed dna is not limited to a true/false indication as to the presence of a carrier in the pool. the number of mutant and wild-type allele reads can be used to infer the number of carriers within each pool, where a high number of mutant reads is an indication of a high proportion of mutant allele carriers in the pool. this difference between the typical pooled testing scenario and the technology scenario was the basis of several recent works which suggested more complicated designs that take the specific scenario into account and design more efficient pooling and decoding strategies for identification of rare allele carriers.take a random design approach to identify extremely rare carriers whiletake a more structured approach and use a design based on the chinese reminder theorem (crtd) to identify rare allele carriers. these designs allow for the identification of multiple carriers. another design which has been used in similar contexts is the shifted transversal design (std) . one common feature of these designs is that they are all combinatorial: each individual is either present in a pool or absent from it. using this combinatorial approach, one can, at best, hope to infer the number of carriers in a pool but not their identity. this information is accumulated across the overlapping pools and the identity of the carriers is then decoded in a manner reminiscent of the way one solves a sudoku puzzle.consider the following interesting riddle: you are given a set of n coins, one of which is counterfeit and, therefore, has a lighter weight. what is the minimal number of weighing required to identify the counterfeit coins using a spring scale? such spring scale riddles were studied extensivelyfor an overview] and for simple versions of this riddle the solution generally requires o(d log(n)) weighings, where n is the number of coins, and d is the (known) number of counterfeit coins . next, consider a well known but less studied variation of this riddle: instead of n coins, we now have n coin piles, one of which contains counterfeit coins. in this case, the counterfeit pile can be found with a single weighing by taking i coins from the i-th pile and weighing all the selected coins together. even if the number of counterfeit piles is unknown, they can all be identified with a single weighing. this requires taking a i coins from the i-th pile such that the sequence a i n i=1 is a subset-sum-distinct sequence. a straightforward solution is to take 2 i1 coins from the i-th pile, but denser subset-sum distinct solutions exist such as the conwayguy sequence . these riddles demonstrate the power of weighted designs. the former riddle is solved using combinatorial designs, where each coin is either included of excluded from each weighting. the latter riddle allows us to take a different number of coins from each pile to and construct a much better strategy. the fact that we use a different number of coins from each pile allows us eventually to identify any number of counterfeit coin piles with a single weighing. the pooled sequencing scheme resembles the coin piles problem in the fact that we can pool different amounts of dna from each individual similarly to the way we take a different number of coins from each pile. however, there are two important differences. first, with pooled sequencing our measurements are noisythe proportion of mutant reads does not correspond directly to the proportion of mutant reads in the pool. second, the number of carriers in a group follows a binomial distribution, with the parameter p being the minor allele frequency (maf) which is either known or unknown, depending on the exact scenario. however, in the following sections we demonstrate how taking the weighted approach can dramatically increase the power of pooling designs, just as it did for the riddles described above.we start by analyzing nwds. as discussed earlier, we use a conservative error rate of = 1 and an average coverage of 1000 (i.e. r = 1000). while this coverage is high for whole genome sequencing projects, it is very reasonable when targeting a small number of genes or several known mutation loci as is the case in prenatal screening. we start by limiting the discussion to carrier screens, that is, the probability of observing a mutant homozygous individual is 0. as discussed earlier, this is the case when screening for lethal recessive mutants but also when sequencing mitochondrial dna, sex chromosomes in males, or monoploid organisms. we relax this assumption in section 6.1. we computed the optimal nwds and their corresponding values of p suc for d 2,3,4,5,6 using = 4 to simulate the case of taysachs carrier screening in the jewish ashkenazi population . the performance of these designs as a function of the actual carrier prevalence in the populationis given in. our simulations show that for low compression levels (d = 2,3) there is hardly any loss of p suc even for more common mutations. the baseline for comparison is defined as the p suc obtained by assigning the wild-type genotype to all the individuals, that is, 1. we then used numerical optimization to find the optimal nwd for various prevalence values.compares the performance of the optimal nwd for each value of , the optimal nwd for = 4 and the fair nwd for = 4 as described in section 4.2. while the optimal nwd does outperform the other designs when = 4, as expected, the differences between its performance and the performance of the taysachs optimal design are small. the fair design does not perform as well, but this is expected, given that it was not optimized with respect to p suc. as means of comparison to the combinatorial designs, we chose to focus on crtd and std and a cohort size of n = 1000 individuals. for the crtd, we used windows of 31,32,33,35,37, yielding a compression rate of 6, while for the std we used p = 37 and five windows, yielding a compression rate of 5.4.the performance of these designs was estimated by running 100 simulations for each prevalence value and calculating the empirical p suc. the decoding was done by belief-propagation using 20 iterations with a high damping factor ( = 0.95) to alleviate oscillation issues, and by using x map instead of x since finding the latter is intractable for such cohort sizes. the performance of these designs is compared to taysachs nwds with d = 5,6 in. the combinatorial designs, which rely on the principles of compressed sensing, display a near perfect reconstruction rate when the prevalence of carriers is small and therefore the signal is indeed sparse. however, as the prevalence increases, the performance of the combinatorial designs quickly deteriorates, and for prevalence higher than 3 the signal is too dense to reconstruct, and the performance of the designs is roughly equivalent to simply assigning the wild-type allele to the entire group. the nwds do not display this characteristic phase-transition but rather show a slow decline in performance, with much better performance than combinatorial designs once for prevalences above 2.53. to study the performance of hybrid designs, we focused on hybrid designs with only two different weights, which allows us to quantify their performance as a function of one parameterthe ratio of the weights w 1 /w 2. we used a grid of 20 values of w 1 /w 2 and estimated the performance of the hybrid designs for a prevalence of 3 using 100 simulations each time. the optimal weight ratio in both designs was w 1 /w 2 = 0.2, and using w 1 /w 2 = 1, that is, resorting to the combinatorial designs, displayed very poor performance, as can be seen in. we then studied the performance of hybrid crtd and std using the optimal 0.2 ratio, as well as 0.3 and 0.5, and compared their performance to the corresponding combinatorial designs. to do so, we ran 100 simulations for each of the ratios, for each of the designs,and for prevalence ranging from 0.1 to 4 using step size of 0.1. the results for crtd and std are displayed inand 6, respectively, and show a clear improvement in performance when weighting is used. for example, one can look at the minimal prevalence of carriers in the population such that p suc 0.999. the combinatorial std crosses this threshold for prevalence of 1.5, while for the hybrid designs with weight ratios 0.2, 0.3 and 0.5, this happens for prevalence of 1.9, 2.3 and 1.5, respectively. similarly, one can look at the minimal prevalence such that the design underperforms the baseline, which happens for prevalence of 2.4 for the combinatorial std and for prevalence of 3.4, 3.2 and 2.8 for the hybrid stds with weight ratios 0.2,0.3 and 0.5, respectively. results are qualitatively similar for crtd. encouraged by the significant improvement in the performance of the combinatorial designs due to the introduction of two weights, we studied the impact of adding a third weight. we used a grid-searchone, two and three weights, as well as a robust version of the three weights design with larger minimal weight. to find the optimal weight ratios for std with three weights for a population with 3 carriers, which was approximately w 1 /w 2 = 0.35 and w 1 /w 3 = 0.05, and estimated the performance of this design in the same manner as before. the results show that the additional weight improves the performance of the design even further. it might seem counterintuitive at first that assigning such small weights to some of the individuals improves the overall performance of hybrid designs. the key to understanding this is that the decoding process crosses information between overlapping pools. individuals with small weights in certain pools will have high weights in other pools, and in these pools there would be less uncertainty regarding the identity of the carrier. while each pool provides less information regarding the individuals with low weights, it provides much more information regarding the individuals with high weights, narrowing down the list of possible carriers by a factor of the number of weights. for example, with one carrier in a pool of 30, combinatorial designs would only allow us to infer that one individual out of the 30 in the pool is a carrier, while a hybrid design with three weights would narrow the list down to 10 possible carriers if the carrier is not assigned a small weight. so pools where an individual has a small weight provide less information regarding this individual while pools where the individual has a larger weight provide more information, and due to the design of overlapping pools this information can be used for better decoding. the fact that this tradeoff is beneficial might seem less surprising when one thinks about the convexity property of the mutual information. mutual information is a concept from information theory that captures the reduction in uncertainty regarding the true value of one random variable x when we observe the value of a different variable y , and is denoted i (x ;y ) . in our i202  
