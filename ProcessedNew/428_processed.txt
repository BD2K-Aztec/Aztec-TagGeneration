genetics and population analysis a powerful and efficient set test for genetic markers that handles confounders motivation: approaches for testing sets of variants, such as a set of rare or common variants within a gene or pathway, for association with complex traits are important. in particular, set tests allow for aggre-gation of weak signal within a set, can capture interplay among variants and reduce the burden of multiple hypothesis testing. until now, these approaches did not address confounding by family relatedness and population structure, a problem that is becoming more important as larger datasets are used to increase power. results: we introduce a new approach for set tests that handles confounders. our model is based on the linear mixed model and uses two random effectsone to capture the set association signal and one to capture confounders. we also introduce a computational speedup for two random-effects models that makes this approach feasible even for extremely large cohorts. using this model with both the likelihood ratio test and score test, we find that the former yields more power while controlling type i error. application of our approach to richly structured genetic analysis workshop 14 data demonstrates that our method successfully corrects for population structure and family relatedness, whereas application of our method to a 15 000 individual crohns disease casecontrol cohort demonstrates that it additionally recovers genes not recoverable by univariate analysis. availability: a python-based library implementing our approach is available attraditional genome-wide association studies (gwas) test one single nucleotide polymorphism (snp) at a time for association with disease, overlooking interplay between snps within a gene or pathway, missing weak signal that aggregates in sets of related snps and incurring a severe penalty for multiple testing. more recently, sets of snps have been tested jointly in a gene-set enrichment style approach and also in seeking association between rare variants within a gene and disease . as next-generation sequencing rapidly becomes the norm, these set-based tests, complementary to single snp tests, will become increasingly important. however, existing methods for testing sets of snps do not handle confounding such as arises when related individuals or those of diverse ethnic backgrounds are included in the study. such confounders, when not accounted for, result in loss of power and spurious associations . yet, it is precisely these richly structured cohorts that yield the most power for discovery of the genetic underpinnings of complex traits. moreover, such structure typically presents itself as data cohorts become larger and larger to enable the discovery of weak signals. in this article, we introduce a new, powerful and computationally efficient likelihood ratio-based set test that accounts for rich confounding structure. we demonstrate control of type i error as well as improved power over the more traditionally used score test. finally, we demonstrate application of our approach to two real gwas datasets. both datasets showed evidence of spurious association owing to confounders in an uncorrected analysis, whereas application of our set test corrected for confounders and uncovered signal not recovered by univariate analysis. finally, our test is extremely computationally efficient owing to development of a new linear mixed model (lmm) algorithm also presented herein, which makes possible, for example, set analysis of the 15 000 individual wellcome trust case control consortium (wtccc) data. several approaches have been used to jointly test sets of snps: post hoc, gene-set enrichment in which univariate p-values are aggregated , operator-based aggregation such as collapsing of snp values (;), multivariate regression, typically penalized and variance component (also called kernel) models such as a lmms . our approach is based on the lmm, which can equivalently be viewed as a multivariate regression. in particular, use of a lmm with a specific form of genetic similarity matrix is equivalent to regressing those snps used to estimate genetic similarity on the phenotype . if one uses only snps to be tested in the similarity matrix as in), then one is effectively performing a multivariate regression test. however, by also using snps that tag confounders in a separate similarity matrix, our model can additionally correct for confounders, as has been done in a to whom correspondence should be addressed. y the authors wish it to be known that, in their opinion, the first two authors should be regarded as joint first authors. the author 2013. published by oxford university press. this is an open access article distributed under the terms of the creative commons attribution license (http://creativecommons.org/licenses/by/3.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited. single-snp test gwas setting . finally, our approach allows one to condition on other causal snps, by way of the similarity matrix, for increased power, again, as has been done in single-snp test setting . the use of lmms to correct for confounders in gwas is now widely accepted because this approach has been shown capable of correcting for several forms of genetic relatedness such as population structure and family relatedness . independently, the use of lmms to jointly test rare variants has become prevalent . in our new approach, we marry the aforementioned uses of lmms to perform set tests in the presence of confounders within a single, robust and well-defined statistical model. because of the aforementioned equivalence, our approach can also be viewed as a form of linear regression with two distinct sets of covariates. the first set of covariates consists of snps that correct for confounders (and other causal snps), i.e. those that predict race and relatedness, for example. inclusion of these snp covariates makes the data for individuals independently and identically distributed (i.e. knowing the value of these snps induces a common distribution from which the individuals are drawn). the second set of covariates consists of snps for a given set of interest, such as those snps belonging to a gene. we call our approach fast-lmm-set. computing the likelihood for our modelan lmm with two random effectsis, naively, extremely expensive, as it scales cubically with the number of individuals (e.g.). for example, on the 15 000 individual wtccc dataset we analyse, currently available algorithms would need to compute and store in memory genetic similarity matrices of dimension 15 000 15 000 and repeatedly perform cubic operations on them to test just a single set of snpsa practically infeasible approach. however, extending our previous work that made lmms with a single random effect linear in the number of individuals to the two-variance component model needed here, we bypass this computational bottleneck, yielding a new two-random-effects algorithm, which is linear in the number of individuals. this advance enables us to analyse datasets, which could not otherwise be practically analysed, such as the 15 000 individual wtccc cohort (the wellcome trust case). as a case in point, using the navenave cubic approach to test the gene set il23r (containing 14 snps) took 13 h as compared with 1 min for our new approach (all on a single processor), demonstrating a speedup factor of 780 (and significantly less memory usage because the genetic similarity matrix need never be computed with our approach).we have developed a novel efficient approach for testing sets of genetic markers in the presence of confounding structure such as arises from ethnic diversity and family relatedness within a cohort. application of this algorithm demonstrated that our method corrects for confounders and uncovers signal not recoverable by univariate analysis. although we did not analyse rare variant data, we have shown elsewhere that the underlying lmm methodology works well to  
