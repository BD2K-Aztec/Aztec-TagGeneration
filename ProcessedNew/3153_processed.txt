data and text mining multinomial modeling and an evaluation of common data-mining algorithms for identifying signals of disproportionate reporting in pharmacovigilance databases motivation: a principal objective of pharmacovigilance is to detect adverse drug reactions that are unknown or novel in terms of their clinical severity or frequency. one method is through inspection of spontaneous reporting system databases, which consist of millions of reports of patients experiencing adverse effects while taking one or more drugs. for such large databases, there is an increasing need for quantitative and automated screening tools to assist drug safety professionals in identifying drugevent combinations (decs) worthy of further investigation. existing algorithms can effectively identify problematic decs when the frequencies are high. however these algorithms perform differently for low-frequency decs. results: in this work, we provide a method based on the multinomial distribution that identifies signals of disproportionate reporting, especially for low-frequency combinations. in addition, we comprehensively compare the performance of commonly used algorithms with the new approach. simulation results demonstrate the advantages of the proposed method, and analysis of the adverse event reporting system data shows that the proposed method can help detect interesting signals. furthermore, we suggest that these methods be used to identify decs that occur significantly less frequently than expected, thus identifying potential alternative indications for these drugs. we provide an empirical example that demonstrates the importance of exploring underexpected decs. availability: code to implement the proposed method is available in r on request from the corresponding authors.over the past 50 years, pharmacovigilance has evolved from a small limited-scale data collection and evaluation process involving scientific rationale and debate to a large world-wide systematic data collection process, which now additionally includes extensive statistical analysis . as data collection and statistical evaluation of adverse events have become more systematic, the ultimate goal has remained the same: to identify, as soon as possible, drugadverse event combinations (decs) that pose a significant risk to the population . although there has been a manyfold improvement in collecting spontaneous reports, the penultimate goal is extremely difficult to achieve. for one, spontaneous reporting systems (srss) are far from perfect and contain both error and bias. known sources of error include incorrect association between drugs and events, over-reporting (multiple reports for the same incident) and under-reporting (events that are never reported) . in addition, srs databases are subject to reporting bias [over-reporting of decs on publicity of a suspected association (. furthermore, srs databases lack exposure information, thus implying that the event reporting rates derived from databases can only be considered as relative. yet, despite the noise and bias present in srs databases, it is still possible to use this data to identify many unusually large reporting frequencies, which are also known as signals of disproportionate reporting (sdrs) . however, it is extremely important to realize that these sdrs, at best, indicate associations that are potentially causal and that should be scientifically evaluated. moreover, an sdr represents a numerical output devoid of clinical context and is not equivalent to a signal of suspected causality . in addition, srs data are more akin to a census, rather than an unbiased sample from an underlying true population of adverse event reports. therefore estimates and corresponding confidence intervals of sdrs stemming from any data-mining algorithm (dma) should really be viewed as pseudo-estimates and pseudo-intervals. many statistical approaches, also known as dmas, have been applied and developed to find sdrs, especially in the less-thandesirable conditions that srs databases present. dmas fall into two categories: traditional (or frequentist) methods and bayesian methods . each of these approaches provides distinct advantages and inherent disadvantages . the primary advantages of frequentist approaches are that they are simple to compute, are easy to interpret and have higher sensitivity than current bayesian methods when comparing common implementations. however, the underlying model assumptions fail for low-count drugadverse to whom correspondence should be addressed. the author 2012. published by oxford university press. all rights reserved. for permissions, please e-mail: journals.permissions@oup.com event combinations, which represent a majority of decs in srs databases. under these conditions, frequentist signal detection methods can become unstable (i.e. the increased detection of signals is accompanied by an increased detection of noise) and unreliable. bayesian methods, in contrast, attempt to stabilize the resulting ratio metrics for low-count decs via shrinkage. however, these approaches have been shown to be less sensitive for detecting sdrs for low-count combinations, thus implying that they can overshrink . bayesian approaches are also less intuitive and more computationally intensive than frequentist approaches. regardless of approach, no one method has been shown to be superior to others at identifying unusual decs , and the lack of both uniformly accepted gold standards of causality and a calculus of costs and utilities associated with correct and incorrect classifications in pharmacovigilance complicates head-to-head comparisons. this should not be surprising, given the inherent messiness of the data. furthermore, it has been shown that frequentist and bayesian approaches produce similar results for higher-count decs . finally, neither frequentist nor bayesian approaches optimally handle low-count decs, which is where pharmacovigilance desires to first identify signal. in this work, we introduce a method based on a multinomial model for estimating the degree of interaction between a drug and an adverse event. the resulting score is standardized using a nonparametric approach, which avoids the asymptotic pitfalls that frequentist parametric methods must assume in low-count cases. furthermore, we compare the multinomial approach and common dmas on the metrics of shrinkage and scoring of decs. these comprehensive results can enable the practitioner to better assess the relevance of decs. last, we show that these methods can be used to identify decs that occur significantly less frequently than expected. although traditional pharmacovigilance ignores this direction of the test, we advocate that this direction should not be ignored because these results may suggest potential alternative indications of medicines. specifically, large negative scores could imply that a drug may be beneficial for a specific event. this possibility is accommodated by a recently proposed definition of signal . our work is organized as follows: in section 2, we review several dmas and explain the caveats of each. in addition, we propose an empirical approach based on a multinomial model and illustrate how this approach avoids the pitfalls of frequentist approaches. in section 3, we compare each method with the proposed method on a subset of the adverse event reporting system (aers) data. then in section 3.2, we show how these signal detection methods can be used to identify potential alternative indications for individual drugs or classes of drugs. finally, we summarize and discuss these results in section 4.  
