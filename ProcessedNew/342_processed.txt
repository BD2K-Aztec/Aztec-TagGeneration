genetics and population analysis a new way to protect privacy in large-scale genome-wide association studies motivation: increased availability of various genotyping techniques has initiated a race for finding genetic markers that can be used in diagnostics and personalized medicine. although many genetic risk factors are known, key causes of common diseases with complex heritage patterns are still unknown. identification of such complex traits requires a targeted study over a large collection of data. ideally, such studies bring together data from many biobanks. however, data aggregation on such a large scale raises many privacy issues. results: we show how to conduct such studies without violating privacy of individual donors and without leaking the data to third parties. the presented solution has provable security guarantees.genome-wide association studies (gwas) are one of the driving reasons behind the formation of nationwide and privately funded gene banks. many chronic diseases and various cancer types are known to have genetic disposition factors . although many underlying genetic signatures have been successfully identified for mendelian disorders , not many genetic risk factors for complex diseases have been discovered and confirmed. gwas have identified some risk factors for type ii diabetes and for a few other common diseases . gwas have been modestly successful in pharmacogenetics and cancer research . the size and structure of a study cohort are the main limiting factors in such studies, as the individual impact of genomic differences is usually small. larger sample sizes increase the sensitivity of statistical tests and make it possible to apply a wide range of data-mining methods . ideally, studies should use nationwide and continent-wide patient cohorts. formation of such cohorts is becoming feasible as genotyping costs are rapidly decreasing . in addition to nationwide biobanks, e.g. the uk biobank, several personal genomics companies, such as 23andme and navigenics, already possess large and diverse patient cohorts. biobanks are also forming large collaboration networks, such as p3g and hugenet, to combine their patient cohorts and improve study quality. privacy of individual gene donors is one of the biggest concerns in such projects. in many countries, genotype data are classified as sensitive data that can be handled by complying with specific restrictions, e.g. hipaa in the usa and the data protection directive in the european union. these restrictions are justified, as a leak of genetic information can cause genome-based discrimination when more health-related patterns have been discovered. standard anonymization methods are not applicable to genotype data, as the data themselves are an ultimate identity code. only 3080 out of 30 million single-nucleotide polymorphisms (snps) are needed to uniquely identify a person . moreover, the size of online genotype databases for genealogy studies, such as sgmf and yhrd, has made re-identification of anonymized genotype data a real threat . re-identification attacks based on combining inferred phenotypes with public data become practical, as the list of known associations between genotype and phenotypic traits evolves. finally,showed that even aggregated pools of genomic data can leak private information. although follow-up studies softened initial claims, the threat remains. these findings created a debate whether one can promise privacy of genotype data in consent forms at all (p3g). in the following, we show how to set up an infrastructure where the genotype data can be stored and processed so that none of the peers involved in the process can reconstruct the data, and thus the risk of accidental leaks and malicious data abuse is greatly reduced. the data analysis algorithms are executed in an oblivious manner so that only the desired outcome is revealed to the user and nothing else. differently from well-known data perturbation and masking techniques , security guarantees are cryptographic. these guarantees depend on the computational complexity of well-established mathematical problems and not on the background knowledge of potential attackers. as such, the presented methodology is applicable to protecting biobanks and other medical databases. to whom correspondence should be addressed. the author 2013. published by oxford university press. all rights reserved. this is an open access article distributed under the terms of the creative commons attribution license (http://creativecommons.org/licenses/by/3.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.to demonstrate the feasibility of our approach, we used the sharemind multi-party computation platform to implement core algorithms for gwas. our choice was mainly motivated by the efficiency and ease of use of the sharemind platform. alternative platforms) and fairplaymp (should give similar results. we used 270 genotypes from the hapmap project measured with the affymetrix mapping 500k array as the main data source. in each experiment, we divided the data randomly into case and control groups and performed genome-wide search for highly differentiated snps. for that we used cryptographically secure counterparts of standard statistical tests used in gwas: two 2 tests for independence , cochran armitage test for trend and tdt . as our algorithms return exactly the same outputs as original algorithms, we report only performance results for various sub-tasks. to show the variability of running times, we report the mean and standard deviation of four independent runs. each of the donors has 262 264 measured snps. first, we ran the algorithm on the data of 270 donors, and then we went on to test the data of 540, 810 and 1080 donors. we performed the experiments on three servers running sharemind. each server was an off-the-shelf server-grade machine with 48 gb ram of which less was used, twelve 2.93 ghz intel xeon (westmere) cores of which two were used and a 1 gb/s local area network (lan) connection. at the moment, the network connection is the bottleneck in terms of algorithm running time; however, sharemind has been successfully used in real applications . the time spent on data acquisition and secure storage does not depend on the statistical test used later on. it depends only on the number of snps and the number of gene donors. the average time it takes to encode and share the snps for the described case can be seen in. note that secret sharing and uploading data are done only once for each dataset; hence, this is a singletime cost. the time needed to form casecontrol groups depends on the application scenario. when the analyst has direct access to phenotype data and can form case and control groups by herself/himself, then there is no computational overhead. in more involved cases, the case and control groups must be constructed based on secret shared phenotype attributes. in this case, the overhead depends on the complexity of inclusion criteria for case and control groups. filtering results presented inshow that formation of such groups can be done in seconds for typical inclusion criteria that consist of simple comparison operations mixed with logical conjunctives. the time needed to perform the statistical test depends on the test, but in all cases it can be broken down into counting allele frequencies and evaluating test statistic. as tables 4 and 5 clearly show, the main performance bottleneck is frequency counting, which scales linearly w.r.t. the total number of snp measurements. as our encoding is optimized for 2 test, a better encoding will enhance the performance of the cochranarmitage tests but not beyond 2 results. the total duration of the analysis is the sum of the frequency analysis and evaluation, as the other parts have a negligible duration. the presented results clearly show that cryptographically secure evaluation of statistical tests on genome-wide scale is practically feasible. the expected running time is hours instead of a few minutes when computed non-securely. however, the latter is not a significant slowdown compared with the time needed to acquire the data if the secure analysis method is not used.although the results prove the practical feasibility of cryptographically secure gwas, the solution is also notably more resource demanding than the alternatives. we have to analyze further whether potential benefits outweigh costs. we consider three potential application scenarios and contrast our approach with the alternatives.  
