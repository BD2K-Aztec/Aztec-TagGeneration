genome analysis ale: a generic assembly likelihood evaluation framework for assessing the accuracy of genome and metagenome assemblies motivation: researchers need general purpose methods for objectively evaluating the accuracy of single and metagenome assemblies and for automatically detecting any errors they may contain. current methods do not fully meet this need because they require a reference, only consider one of the many aspects of assembly quality or lack statistical justification, and none are designed to evaluate metagen-ome assemblies. results: in this article, we present an assembly likelihood evaluation (ale) framework that overcomes these limitations, systematically evaluating the accuracy of an assembly in a reference-independent manner using rigorous statistical methods. this framework is comprehensive , and integrates read quality, mate pair orientation and insert length (for paired-end reads), sequencing coverage, read alignment and k-mer frequency. ale pinpoints synthetic errors in both single and metagenomic assemblies, including single-base errors, inser-tions/deletions, genome rearrangements and chimeric assemblies presented in metagenomes. at the genome level with real-world data, ale identifies three large misassemblies from the spirochaeta smaragdinae finished genome, which were all independently validated by pacific biosciences sequencing. at the single-base level with illumina data, ale recovers 215 of 222 (97) single nucleotide variants in a training set from a gc-rich rhodobacter sphaeroides genome. using real pacific biosciences data, ale identifies 12 of 12 synthetic errors in a lambda phage genome, surpassing even pacific biosciences own variant caller, evicons. in summary, the ale framework provides a comprehensive, reference-independent and statistically rigorous measure of single genome and metagenome assembly accuracy, which can be used to identify misassemblies or to optimize the assembly process. availability: ale is released as open source software under the uoi/recent advances in next-generation, high-throughput sequencing technologies have dramatically reduced the cost of sequencing . with the development of genome assemblers able to use large volumes of sequence data, reference genomes are now rapidly produced using the whole genome shotgun strategy, from small, simple microbial genomes to large, complex plant or mammalian genomes . meanwhile, genomes are also being generated directly from complex communities using culture-independent approaches, including singe-cell genome sequencing and metagenome sequencing . the ability to assemble a metagenome is particularly important because resolving the genomes of individual species, or at least the most abundant, from a complex community is crucial to exploring inter-species interactions and understanding the communitys structure, dynamics and function. assembly of individual genomes from ngs datasets poses significant informatics challenges, including short read length, noisy data and large data volume . owing to these challenges, errors widely exist in single genome assemblies derived from ngs datasets, with different specific errors commonly associated with particular datasets, genomes and tools . beyond the challenges faced in assembling single genomes, metagenome assembly poses unique additional challenges. first, although the sequence depth of a single genome should be approximately uniform, the sequence depth of genomes in a metagenome varies greatly. second, the difficulty of resolving repetitive regions within a single genome is exacerbated in metagenome assembly because conserved genomic regions and lateral gene transfer greatly increase the portion of falsely identified repetitive genomic regions. despite these unique challenges, assemblers designed for single genomes are being applied to metagenome data without being significantly modified to systematically address errors introduced in this way . several tools have been developed to detect errors in single genome assemblies. if a reference genome for the targeted organism is available, or one is available from a closely related species, erroneous insertions, deletions or large gaps can be detected by to whom correspondence should be addressed. the author 2013. published by oxford university press. all rights reserved. for permissions, please e-mail: journals.permissions@oup.com comparative analysis of the reference and the genome assembly in question . if a reference is unavailable, the alignment of the raw reads with their assembly provides indirect measures of assembly quality such as coverage depth and mate pair consistency. this information can then be used to detect single-base changes, repeat condensation or expansion, false segmental duplications and other misassemblies . despite this progress, researchers still lack a method that integrates indirect measures of read alignment quality in a quantitative, comprehensive and statistically well-founded manner to systematically detect errors in single genome assemblies. moreover, metrics suitable for evaluating metagenome assembly accuracy, and associated quantitative methods for detecting errors in metagenome assemblies, have yet to be developed. in this work, we develop a novel statistical model for evaluating assembly accuracy in a reference-independent manner. using bayesian statistics, we give an expression for the probability that an assembly is correct, and provide an automated software tool assembly likelihood evaluation (ale) based on this expression. the provided tool may be used in three ways. first, it allows examining the contribution to this probability of correctness from each base in the assembly, which can be used to identify specific errors and their locations. this is particularly useful for genome finishing. second, it provides an overall score for different assemblies of the same genome or metagenome, thereby enabling comparison of these assemblies and optimization of the assembly process. third, when applying re-sequencing data to a reference genome, ale can detect structural variations.ale facilitates the rapid discovery of many types of errors in genome assemblies including metagenomes. it does this by applying a rigorous statistical model, calculating the likelihood of observing a specific assembly, given the reads that were used to generate it, and calculating the contribution to this likelihood from each position in the assembly. this allows ale to determine specific regions within a proposed assembly that are poorly supported by the reads. by integrating several aspects of the assembly and the reads, including k-mer composition, sequence depth, insert length and how well individual bases map, ale is able to find errors as small as a single substitution error or indel, as well as large copy number errors and chimeric metagenome assemblies. this framework can serve as a guide in optimizing genome assemblies in the following two ways. first, total ale scores can be used to identify the best assembly from those generated by different assembly protocols. second, by modifying the regions in which ale reports low sub-scores, more accurate genomes can be constructed. the space of possible corrections to an input genome is too large to allow the current implementation of ale to be used as an independent assembler, but it could be used to compare and combine the results from different assemblers and produce an assembly that is most likely to be correct. ale could also be used to present an alternative method for ale calculating assembly accuracy in local assembly algorithms such as genovo . when used with a reference genome and resequencing data, ale can discover structural variations. as shown in the cases of spirochaeta smaragdinae and r. sphaeroides, ale readily detects structural variations whose sizes vary from a single base to several hundred kilobases. ale currently does not classify the type of assembly errors. future work is needed to determine the profile of each type of assembly errors in a dataset-specific manner. once ale has this capability, it could guide an auto-correction algorithm to automatically fix problematic regions. the effectiveness of ale is influenced by the quality of its input: the read data and the alignments of those reads onto the a b. ale identifies regions with potential assembly errors. (a) cumulative plots showing the percentage of assembly errors detected by ale at different sensitivity thresholds. detected assembly break points (break sensitivity), and novel calls (novel) at different ale insert or placement thresholds (ale top scores) for six assemblies of staphylococcus using six different assemblers are shown. (b) a snapshot from integrative genomics viewer for a scaffold from the velvet assembly of staphlococcus. in the track coverage, the height represents sequencing depth, and vertical colored bars represent potential snps. in the track raw reads, each gray horizontal bar represents a high quality aligned read, whereas horizontal color bars represent reads that may indicate problems (e.g. insert size is too big or too small). vertical color bars are bases different from the reference sequence. more detailed description can be found at: http://www.broadinstitute.org/igv/alignmentdata  
