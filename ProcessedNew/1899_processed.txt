funcish: learning a functional representation of neural ish images motivation: high-spatial resolution imaging datasets of mammalian brains have recently become available in unprecedented amounts. images now reveal highly complex patterns of gene expression varying on multiple scales. the challenge in analyzing these images is both in extracting the patterns that are most relevant functionally and in providing a meaningful representation that allows neuroscien-tists to interpret the extracted patterns. results: here, we present funcisha method to learn functional representations of neural in situ hybridization (ish) images. we represent images using a histogram of local descriptors in several scales, and we use this representation to learn detectors of functional (go) categories for every image. as a result, each image is represented as a point in a low-dimensional space whose axes correspond to meaningful functional annotations. the resulting representations define similarities between ish images that can be easily explained by functional categories. we applied our method to the genomic set of mouse neural ish images available at the allen brain atlas, finding that most neural biological processes can be inferred from spatial expression patterns with high accuracy. using functional representations, we predict several gene interaction properties, such as proteinprotein interactions and cell-type specificity, more accurately than competing methods based on global correlations. we used funcish to identify similar expression patterns of gabaergic neuronal markers that were not previously identified and to infer new gene function based on imageimage similarities.in recent years, high-resolution expression data measured in mammalian brains became available in quantities and qualities never witnessed before , calling for new ways to analyze neural gene expression images. most existing methods for bio-imaging analysis were developed to handle data with different characteristics, like drosophila embryos or cellular imagery . the mammalian brain, composed of billions of neurons and glia, is organized in highly complex anatomical structures and poses new challenges for analysis. current approaches for analyzing brain images are based on smooth non-linear transformations to a reference atlas and may be insensitive to fine local patterns like those emerging from the layered structure of the cerebellum or the spatial distribution of cortical interneurons. another challenge for automatic analysis of biological images lies in providing human interpretable analysis. most machinevision approaches are developed for tasks in analysis of natural images, like object recognition. in such tasks, humans can understand the scene effortlessly and infer complex relations between objects easily. in bio-imaging, however, the goal of image analysis is often to reveal features and structures that are hardly seen even by experts. it is, therefore, important that an image analysis approach provides meaningful interpretation to any patterns or structures that it detects. here, we develop a method to learn functional representations of expression images by using predefined functional ontologies. this approach has two main advantages, accuracy and interpretability, and it builds on a growing body of work in object recognition in natural images, showing how images can be represented using the activations of a large set of detectors . for object recognition, the detectors may include common objects, like a detector for the presence of a chair, a mug or a door. here, we show how to adapt this idea to represent gene expression images, by training a large set of detectors, each corresponding to a known functional category, like axon guidance or glutamatergic receptors. once this representation is trained, every gene is represented as a point in a low-dimensional space whose axes correspond to functional meaningful categories. we describe in section 2.2 how to learn functional representations in a discriminative way and demonstrate the effectiveness of the approach on in situ hybridization (ish) gene expression images of the adult mouse brain collected by the allen institute for brain science . ish image analysis has been used in the past to infer gene biological functions from spatial co-expression in non-neural tissues . however, inferring functions based on gene expression patterns in the brain is believed to be hard, as several studies found very low variability between transcriptomic patterns of different brain regions, sometimes even lower than between-subject variability for the same area . neural expression patterns are usually studied using methods that average expression values over a brain region, and this averaging removes fine-resolution spatial information that may differentiate between brain regions. here, we analyze high-resolution ish images at several scales, taking into account subtle, even cellular resolution, information for functional inference. to whom correspondence should be addressed. y the authors wish it to be known that, in their opinion, the first two authors should be regarded as joint first authors. the author 2013. published by oxford university press. this is an open access article distributed under the terms of the creative commons attribution non-commercial license (http://creativecommons.org/licenses/ by-nc/3.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. for commercial re-use, please contact journals.permissions@oup.comwe find that gene function can indeed be inferred from neural ish images, particularly in biological processes that are related to neural activities. our approach detects related genes with better accuracy based on the similarity of their functional representations. furthermore, these similarities can be explained and interpreted using semantic terms.we start with evaluating the quality of the low-dimensional semantic representation that we learned in two aspects: the classification accuracy for individual semantic terms and the precision of our genegene similarity measure compared with a spatial correlation-based method. we then take a closer look at discriminative spatial patterns, mapping them back onto raw images. finally, we use the geometry of the low-dimensional semantic space to infer new gene functions via gene similarities and their interpretations.  
