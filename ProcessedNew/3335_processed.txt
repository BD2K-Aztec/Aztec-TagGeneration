on genomic repeats and reproducibility results: here, we present a comprehensive analysis on the reproducibility of computational characterization of genomic variants using high throughput sequencing data. we reanalyzed the same datasets twice, using the same tools with the same parameters, where we only altered the order of reads in the input (i.e. fastq file). reshuffling caused the reads from repetitive regions being mapped to different locations in the second alignment, and we observed similar results when we only applied a scatter/gather approach for read mappingwithout prior shuffling. our results show that, some of the most common variation discovery algorithms do not handle the ambiguous read mappings accurately when random locations are selected. in addition, we also observed that even when the exact same alignment is used, the gatk haplotypecaller generates slightly different call sets, which we pinpoint to the variant filtration step. we conclude that, algorithms at each step of genomic variation discovery and characterization need to treat ambiguous mappings in a deterministic fashion to ensure full replication of results. availability and implementation: code, scripts and the generated vcf files are available atthe advancements in high throughput sequencing (hts) technologies have increased the demand on producing genome sequence data for many research questions and prompted pilot projects to test its power in clinical settings . any medical test to be reliably used in the clinic has to be proven to be both accurate and reproducible. however, the fast-evolving nature of hts technologies make it difficult to achieve full reproducibility. we recently showed that resequencing the same dna library with the same model hts instrument twice and analyzing the data with the same algorithms may lead to different variation call sets . aside from the potential problems in the wet lab side, there may be additional complications in the dry lab analysis due to alignment errors and ambiguities due to genomic repeats. the repetitive nature of the human genome causes ambiguity in read mapping when the read length is short . a 100 bp read generated by the illumina platform may align to hundreds of genome locations with similar edit distance. the bwa-mem mappers approach to handle such ambiguity is randomly selecting one location and assigning the mapping quality to zero to inform the variant calling algorithms that the alignment may not be accurate. although many algorithms exist for hts data analysis, only a handful of computational pipelines for read mapping and variant calling may considered a standard such as those that are commonly used in large scale genome projects such as the 1000 genomes project . recently, the genome in a bottle project was started to set standards for accurate hts data analysis for both research and clinical uses by addressing the differences in detection performances of different algorithms and different sequencing platforms. in this study, we investigated whether some of the commonly used variant discovery algorithms make use of this mapping quality information, and how they react to genomic repeats. briefly, we aligned two whole genome shotgun (wgs) datasets, one low and one high coverage genome sequenced as part of the) to the human reference genome (grch37) twice using the same parameters. in the second mapping, we shuffled the order of reads to make sure that the same random numbers are not used for the same reads. we then generated two single nucleotide variant (snv) and indel call sets each from each genome. we observed substantial differences in the call sets generated by all of the variant discovery tools we tested except variationhunter/ commonlaw. however, variationhunter explicitly requires a deterministic read mapper, therefore we removed it from further comparisons. gatks haplotypecaller showed discordancies of 1.061.7 in snv/indel call sets, where freebayes showed the most concordancy (up to 99.2). genome strip showed the greatest discrepancy in structural variation calls (up to 25). our results raise questions about reproducibility of callsets generated with several commonly used genomic variation discovery tools.data and tools. we downloaded two wgs datasets, one at low coverage (5x, hg00096) and one at high coverage (44x, hg02107), and 12 whole exome shotgun sequence (wes) datasets with coverage ranging from 120x to 656x from the 1000 genomes project (the 1000 genomes project) (supplementary). we tested the behaviors of three different read mappers, four snv/indel callers and three sv characterization algorithms (supplementary table s2, section 2). small scale test for ambiguous mapping. we first sub sampled 1 million reads from hg00096, and mapped it to the human reference genome (grch37) using bowtie2, razers3, mrfast and bwamem . next, we randomly shuffled the reads in the fastq file (section 2) and remapped the reordered reads to grch37 using the same tools. the read order randomization simulates the random nature of dna hybridization on the flow cell. we confirmed that mrfast and bowtie2 generated the same alignments, as described in their respective documentations, where bwamem mapped several reads to different locations due to placing such reads to random locations (supplementary). however, although bowtie2 was not affected by read order, it reported different locations when the read names are changed (heng li, personal communication). read mapping in parallel. due to the large number of reads generated by hts platforms, it is a common practice to use scatter/ gather operations (or, its implementation using the mapreduce framework) to distribute the work load to large number of cpus in a cluster. this approach leverages the embarrassingly parallel nature of read mapping, where the fastq files that typically contain 50 million reads are divided into chunks with just 12 million reads per file, the reads in each chunk are mapped separately, and the resulting bam files are combined. reasoning from our observation of different random placements of ambiguous reads when the reads are shuffled, we employed the scatter/gather method to map 1 million reads twice, using different chunk sizes. in this experiment, we divided the reads into chunks of 50 000 and 100 000 read pairs, mapped them using bwa-mem and observed mapping discordance ratios similar to that of random shuffling (2.1, supplementary). we also observed less pronounced differences in read mapping when different number of threads are used for the same fastq file (0.05, supplementary). wgs analysis. we then repeated the same mapping strategy to the full versions of all datasets we downloaded, but we mapped using only bwa-mem, since we observed the other mappers to be deterministic based on the small scale test. we also investigated bwa-mems behavior of random placements using the hg00096 genome, and interestingly, although bwa-mem reported zero mapping qualities for most of the discrepant read mappings (97), it also assigned high mapq values (30) for a fraction of them (0.75; supplementary). single nucleotide variants and indels. we used gatks haplotypecaller, freebayes, platypus and samtools to characterize snvs and indels within the hg00096 and hg02107 genomes using recommended parameters for each tool (section 2). we did not evaluate gatk unifiedgenotyper since it is deprecated by its developers. we then compared each call set generated by the same tools using the reads in original versus shuffled order using bedtools , and found up to 1.70 of variants to be called in one alignment of the same data but not in the other . next, we investigated the underlying sequence context of the snvs and indels differently detected using the same tools with two different alignments (i.e. original versus shuffled order). as expected, 7280 of the discrepant calls were found within common repeats and segmental duplications (supplementary tables s7s10). in most genomic analysis studies duplications and repeats are removed from analyses; however, in this study we observed discrepancies in functionally important regions (i.e. coding exons). for example, 2531249 snvs that were called from one alignment but not another map to coding exons (supplementary). furthermore, 1543 of the 1884 (81.9) discordant exonic snvs predicted by gatk haplotypecaller (either original or shuffled order, non-reduntant total) did not intersect with any common repeats or segmental duplications. freebayes, platypus and samtools predictions were more reproducible, as 98.5 of the calls were identical, and the number of exonic discrepant snv calls were substantially lower than that of gatks (supplementarys10). structural variation. next, we analyzed the deletion calls predicted using delly, lumpy and genome strip. all three sv detection tools we tested showed 3.525.01 difference in call sets using the original versus shuffled order read datasets . similarly, the discrepancies were mostly found within repeats and duplications, however, only a couple of deletion calls intersected with coding exons (supplementary tables s11, s15 and s16). using delly, we predicted 3 of deletion, 4 of tandem duplication, 6 of inversion and 3.6 of translocation calls to be specific to a single alignment, and 91 of these differences intersected with common repeats. owing to the difficulties in predicting these types of svs, more discrepant calls intersected with functionally important regions (i.e. genes and coding exons; supplementary tables s12s14). reusing the same alignments. more interestingly, when we ran gatks haplotypecaller on the same bam file twice we observed discrepant calls similar to using two different bam files generated from original versus shuffled read order (supplementary). other tools produced no discrepancies (supplementary tables s18 s26). detailed analysis of these discordancies revealed that 21 497 of the 21 510 (99.9) second-run specific haplotypecaller calls were initially found in the first run, however, filtered in the varianton genomic repeats and reproducibilityquality score recalibration (vqsr) step. similarly, 10 631 of the 10 646 first-run specific haplotypecaller calls were eliminated by vqsr in the second run. we then performed a line-by-line analysis in such calls and found that the vqslod score was calculated differently, although the training data were the same in both runs. we speculate that this is due to the random sampling of the training data to reduce computational burden (this random subsampling can be seen in the gatk code variantdatamanager.java at https:// github.com/broadgsa/gatk-protected/(commit id: 8ea4dcab8d78e7a7d573fcdc519bd0947a875c06, line 255).). we then confirmed our observation by rerunning the vqsr filter on one of the vcf files five times. each iteration of the vqsr filtering generated a different set of vqslod values, causing different variants to be filtered. however this effect seems to be diminished when multiple samples are used simultaneously. exome analysis. finally, we tested the effect of discordant call sets generated by gatk even with the same alignment files using 12 wes datasets from the 1000 genomes project (supplementary). we followed the same alignment, post-processing for the wes datasets. we then generated two call sets each using haplotypecaller on the same bam files, followed with vqsr filtering. in this experiment, we used the multisample calling options. haplotypecaller produced discordant calls at 13 rate (supplementary tables s17 and s27).in this article, we documented the effects of different approaches to handle ambiguities in read mapping due to genomic repeats. we focused on more widely used computational tools for read mapping and variant calling and observed that random placement of ambiguously mapping reads have an effect on called variants. although discordancies within repeats are less of a concern due to their relatively negligible effects to phenotype, we also discovered hundreds to thousands variants differently detected within coding exons. haplotypecaller showed the most discrepancies, where the discordant calls were less pronounced in freebayes and platypus results. using the same alignments twice, we found that the callers themselves are deterministic, however, they return different call sets when the same data is remapped. interestingly, we observed differences in call sets generated using haplotypecaller even when the same alignments and variant filtration training datasets were provided. although we could not fully characterize the reasons of this observation with gatk, since haplotypecaller algorithm is yet unpublished, we observed that the differences were mainly due to differences in calculation of the vqslod score by the vqsr filter (section 3). therefore, a second source of randomness we observed is within the training step of the vqsr filter, which is specific to gatk. recommendations. we, point out that randomized algorithms may achieve better accuracy in practice, albeit without 100 reproducibility. full reproducibility could only be achieved through using deterministic methods. therefore, for full reproducibility, we recommend to opt for a deterministic read mapper, such as razers3 mrfast, etc., and a deterministic variant caller, such as platypus or freebayes for snv and indels. we note that all sv calling algorithms we surveyed in this article are deterministic algorithms; therefore, the sv call sets can be fully reproducible when they are used together with a deterministic mapper. another approach may be more strict filtering of variants that map to repeats and duplications, however, this may result in lower detection power in functionally important duplicated genes such as the mhc and kir loci. it may be possible to work around the gatks vqslod calculation problem outlined above either by analyzing multiple samples simultaneously, or by setting the maxnumtrainingdata parameter and other downsampling parameters to high values, however, we recommend disabling these randomizations by default to be a better practice for uninformed users. in our tests, changing only the maxnumtrainingdata parameter did not fully resolve the variant filtration problem, which points that there may be other downsampling and/or randomization step within the vqsr filter. conclusion. mapping short reads to repetitive regions accurately still remains an open problem . razers3 and mrfast use edit distance and paired-end span distance to deterministically assign a single best map location to ambiguously mapping reads, where bwa-mem selects a random map location all mapping properties are calculated the same. bwa-mem assigns a zero mapping quality to such randomly selected alignments. this approach is still valid since it informs the downstream analysis tools for problematic alignments, however, as we have documented in this article, several variant discovery tools do not fully utilize this information. complete analysis of the reasons for these discrepancies may warrant code inspection and full disclosure of every algorithmic detail. the differences in call sets we observed in this study have similar accuracy when compared to 1000 genomes data (supplementary tables s28 and s29). in addition a recent study did not find any significant difference between deterministic and non-deterministic mappers in terms of accuracy . it is still expected to have differences between different algorithms and/or parameters but obtaining different results should not be due to the order of independently generated reads in the input file. we may simply count these discordancies as false positives and negatives, and such discordancies may not have any adverse effects in practice, however, we argue that computational predictions should not be affected by luck, and inaccuracies in computational results should be deterministic so they can be better understood and characterized. we are in exciting times in biological research thanks to the development of hts technologies. however, under the shining lights of the discoveries we make in this big biology revolution, it can be easy to overlook that the methods matter. no genomic variant characterization algorithm achieves 100 accuracy yet, even with simulation data, but it is only possible to analyze and understand the shortcomings of deterministic algorithms, and impossible to fully understand how an algorithm performs if it makes random choices.  
