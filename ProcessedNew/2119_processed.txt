graphical pan-genome analysis with compressed suffix trees and the burrowsâ€“wheeler transform motivation: low-cost genome sequencing gives unprecedented complete information about the genetic structure of populations, and a population graph captures the variations between many individuals of a population. recently, marcus et al. proposed to use a compressed de bruijn graph for representing an entire population of genomes. they devised an on log g time algorithm called splitmem that constructs this graph directly (i.e. without using the uncompressed de bruijn graph) based on a suffix tree, where n is the total length of the genomes and g is the length of the longest genome. since the applicability of their algorithm is limited to rather small datasets, there is a strong need for space-efficient construction algorithms. results: we present two algorithms that outperform splitmem in theory and in practice. the first implements a novel linear-time suffix tree algorithm by means of a compressed suffix tree. the second algorithm uses the burrowswheeler transform to build the compressed de bruijn graph in on log r time, where r is the size of the alphabet. to demonstrate the scalability of the algorithms , we applied it to seven human genomes. availability and implementation:we implemented our new algorithms in c, using the library sdsl of. software and test data are available at http:// www.uni-ulm.de/in/theo/research/seqana.html. both algorithms use a variant of the semi-external algorithm described into construct the cst and the bwt, respectively. the experiments were conducted on a 64 bit ubuntu 14.04.1 lts (kernel 3.13) system equipped with two ten-core intel xeon processors e52680v2 with 2.8 ghz and 128 gb of ram (but no parallelism was used). all programs were compiled with g (version 4.8.2) using the provided makefile. with the cst-based and the bwt-based algorithm, respectively, we built compressed de bruijn graphs for the 62 e.coli genomes (containing 310 million base pairs) listed in the supplementary material of, using the k-mer lengths 50, 100 and 1000.lists the results of our experiments. the run-times include the construction of the index, but similar to splitmem it is unnecessary to rebuild the index for a fixed dataset and varying values of k. the peak memory usage reported inincludes the size of the index and the size of the compressed de bruijn graph. because of its large memory requirements, splitmem was not able to build a compressed de bruijn graph for all 62 strains of e.coli on our machine equipped with 128 gb of ram. that is why we included a comparison based on the first 40 e.coli genomes (containing 199 million base pairs) of the dataset. the experimental results show that both of our algorithms use significantly less space (two orders of magnitude) than splitmem. the cst-based algorithm is five times faster than splitmem, while the bwt-based algorithm is more than an order of magnitude faster. it is worth mentioning that our two algorithms compute isomorphicbut not necessarily identicalcompressed de bruijn graphs because the node identifiers may differ. to show the scalability of our new algorithms, we applied them to five different assemblies of the human reference genome (ucsc genome browser assembly ids: hg16, hg17, hg18, hg19 and hg38) as well as the maternal and paternal haplotype of individual na12878 (utah female) of the 1000 genomes project; see. the compressed de bruijn graphs of their first chromosomes (7xchr1, containing 1736 million base pairs) and the complete seven genomes (7xhg, containing 21 201 million base pairs) were built for the k-mer lengths 50, 100 and 1000. the experimental results inshow that the bwt-based algorithm clearly outperforms the cst-based algorithm. it took slightly over 6 h (22 000 s) to construct the index of the seven human genomes and less than 2 h (60007000 s) to build the graph with the our cst-based algorithm mimics splitmem in this respect, whereas the bwt-based algorithm treats the different occurrences of as if they were different characters. assuming that is the second smallest character, this can be achieved as follows. as explained in the supplementary material, all right-maximal k-mers can be determined without the entire lcp-array if the algorithm inis used. if there are m 1 occurrences of in total and this algorithm starts with m 1 singleton intervals i::i; 2 i m, instead of the -interval 2::m, then the different occurrences of are treated as if they were different characters.we have presented two space-efficient methods to build the compressed de bruijn graph from scratch. an experimental comparison with splitmem showed that our algorithms are more than an order of magnitude faster than splitmem while using significantly less space (two orders of magnitude). to demonstrate their scalability, we successfully applied them to seven complete human genomes. consequently, it is now possible to use the compressed de bruijn graph for much larger pan-genomes than before (consisting, e.g. of hundreds or even thousands of different strains of bacteria). although the bwt-based algorithm is the clear winner of the comparison, cstbased algorithms are still important. this is because sts play a central role in sequence analysis and most bioinformatics curricula comprise courses that cover this important data structure. it is therefore conceivable that a bioinformatician might be able to come up with a suffix tree algorithm that solves his/her problem at hand, but not with an algorithm that is based on the bwt and/or related data structures. if the space requirement of the st is the bottleneck in the application, one can use a cst instead. csts with full functionality are, e.g. implemented in the succinct data structure library (sdsl) of. on the downside, extra features such as suffix skips are not implemented in those libraries so that a direct implementation of a suffix tree algorithm by means of a cst might not be possible. future work includes parallel implementations of the algorithms. moreover, it should be worthwhile to investigate the time-space tradeoff if one uses data structures that are optimized for highly repetitive texts, see navarro and ord n ez (2014) and the references therein. most important, however, is to address the problem of compressing the compressed de bruijn graph itself. (our experiments show that for smaller k, the size of the graph can be larger than the size of the index, e.g. the graph for the seven human genomes and k 50 takes 1.65 bytes per base pair, whereas the bwt-index requires only 1.13 bytes per base pair.) very recently, two bloom filter methods were presented that can be used for this purpose. solomon and kingsford (2015) introduced the sequence bloom tree to support sequence-based querying of large-scale collections of thousands of short-read sequencing experiments and applied it to the problem of finding conditions under which query transcripts are expressed. the second approach byis closer to the splitmem approach. their data structurethe bloom filter trie (bft)allows to efficiently store and traverse the uncompressed de bruijn graph. in the section conclusion of their article,write future work concerns the possibility to compress non-branching paths. .. this is exactly what splitmem and our new algorithms do, so maybe the combination of both approaches will yield the ideal pan-genome representation.the first row in a block specifies the experiment. the second row shows the graph size in bytes per base pair. rows 36 contain the numbers of edges, nodes, uniquenodes and repeatnodes, respectively. rows 710 show the average out-degree of the nodes as well as the average string length of the nodes, uniquenodes and repeatnodes. the remaining rows (if applicable) contain the percentage of the nodes that are shared by x sequences.  
