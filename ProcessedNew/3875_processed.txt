genetics and population analysis rapid detection of geneâ€“gene interactions in genome-wide association studies motivation: in complex disorders, independently evolving locus pairs might interact to confer disease susceptibility, with only a modest effect at each locus. with genome-wide association studies on large cohorts, testing all pairs for interaction confers a heavy computational burden, and a loss of power due to large bonferroni-like corrections. correspondingly, limiting the tests to pairs that show marginal effect at either locus, also has reduced power. here, we describe an algorithm that discovers interacting locus pairs without explicitly testing all pairs, or requiring a marginal effect at each locus. the central idea is a mathematical transformation that maps statistical correlation between locus pairs to distance between two points in a euclidean space. this enables the use of geometric properties to identify proximal points (correlated locus pairs), without testing each pair explicitly. for large datasets ( 10 6 snps), this reduces the number of tests from 10 12 to 10 6 , significantly reducing the computational burden, without loss of power. the speed of the test allows for correction using permutation-based tests. the algorithm is encoded in a tool called rapid (rapid pair identification) for identifying paired interactions in casecontrol gwas. results: we validated rapid with extensive tests on simulated and real datasets. on simulated models of interaction, rapid easily identified pairs with small marginal effects. on the benchmark disease, datasets from the wellcome trust case control consortium, rapid ran in about 1 cpu-hour per dataset, and identified many significant interactions. in many cases, the interacting loci were known to be important for the disease, but were not individually associated in the genome-wide scan.recent technological developments in sequencing and genotyping have made it feasible to conduct genome-wide scans of large population cohorts to find genetic markers for common diseases (the wellcome). nevertheless, significant challenges remain. many genome-wide association to whom correspondence should be addressed.studies (gwass) seek to associate each marker with the disease phenotype. as multiple hypotheses are generated, individual associations must have large effect to show up as significant. in complex disorders, many independently evolving loci might interact to confer disease susceptibility, with only a modest effect at each locus. here, we focus on detecting such interactions. detecting k-locus interactions in gwas on large populations is computationally and statistically challenging, even when k = 2. a test involving all pairs of m markers, with a casecontrol population of n individuals, involves o(nm 2 ) computations. for gwas, it is not atypical to have n 10 3 , m 10 6 making these computations, especially with permutation-based tests of significance, intractable. a straightforward (bonferroni-like) correction for the multiple tests would result in significant loss of sensitivity. therefore, many strategies for two-locus interaction testing are based on a two-stage, filtering approach. in the first stage (the filter stage), the objective is to discard the vast majority of locus pairs, while retaining the truly interacting pairs. if the filtering stage is fast and efficient (only a small fraction of all pairs are retained), then computationally intensive tests of association can be performed on the few remaining candidate pairs in a second, scoring, stage. for a filtering algorithm to be effective, it must have (a) speed, in that the number of computations scale linearly with the size of the data; (b) sensitivity/power (truly interacting pairs are retained); and, (c) efficiency (most pairs are discarded). fast and efficient filters allow non-parametric permutation tests to be employed to assess significance. with the advent of deep sequencing, the number of variants considered will grow far beyond 10 6 markers, and designs of filters will be critical to gwas analysis of interactions. while many approaches to detecting interactions have been proposed (see, for an excellent review), the design of filters has not been investigated explicitly. a recent approach, both pragmatic and effective for filtering, is based on the assumption that interacting pairs of loci should also show a marginal effect at each locus . here, the filtering stage consists of single marker tests at each locus. the scoring stage is then limited to pairs in which either one, or both loci, are individually associated. in either strategy, the filter speed is high, as single-marker analysis scales linearly with the number of loci and individuals. empirical results show that only a small fraction of the loci show a marginal effect, leading to high efficiency. however, as marchini et al. point out, there is some loss of power in employing these filters, particularly in interaction models where the marginal effects of the individual loci are small.provides a cartooninto the same bin with higher probability, relative to non-interacting pairs x,z. (d) pairs that fall in the same bin k consecutive times in one of l trials are selected. illustration of such confounding interactions. here, compensating mutations in coding snps (t and g, or a and a) allow the encoded proteins to interact, but individual mutations destroy the lock and key mechanism. therefore, the locus pair (x,y) will show strong association, but there is no marginal effect at either locus. we tackle this case. in this article, we describe a filtering strategy, rapid (rapid pair identification). under certain assumptions, the algorithm provides explicit guarantees on speed, efficiency and sensitivity. to formalize the argument, we parametrize the total computation for n individuals and m markers. let input parameter denote the desired false negative rate of detecting interactions. rapid performs at most 1 m 1.07 tests, and allows no more than 2 m 1.07 ln(1/) pairs by chance, while capturing a fraction 1 of the truly interacting pairs. the surviving pairs can be tested for interaction using a total of o(nm 1.07 ln(1/)) computations. this can be compared with the time of o(nm 2 ) when no filtering is employed. for gwas, where m 10 6 , this results in several orders of magnitude speed up. additionally, increasing desired sensitivity 1 incurs only modest increases in running time. extensive power simulations demonstrate the power of our approach. we also used rapid to reanalyze data from the wellcome trust case control consortium (wtccc) dataset, a benchmark gwas. the filtering using rapid on either dataset only took about 45 min on a 1.8 ghz, 16 gb ram computer and identified many significant interactions.rapid has two key parameters, and . the user decides the minimum strength of interactions (measured by the 2 statistic), and uses it to specify a bound on the euclidean distance between the transformed vectors. the parameter describes the acceptable type ii error rate among the pairs that satisfy the threshold. the parameters l,k also influence speed and sensitivity, but can be computed given n,m,,, as described in equation (3).we tested the speed versus sensitivity of rapid on the wtccc control dataset of 3000 individuals, using a different choice of ,. for each choice of , define the false negatives (fn) as the number of pairs that exceed the threshold , but were rejected by rapid. true positives (tp) is the number of pairs exceeding the threshold that were accepted. likewise, for each choice of ,, we define speed up as the drop in number of computations, compared with the naive approach (o(nm 2 ) computations).describes the speed versus sensitivity [tp/(tp + fn)] trade-off for = 0.1 and 0.4. for low values of , we can show 23 orders of magnitude speed up without sacrificing sensitivity. we next explored the speed-up, and actual runtimes for increasingly large datasets (c), and different thresholds after fixing the = 0.05 (or 5). even for large datasets (1m snps and 3000 genotypes), strongly interacting pairs can be identified with 95 sensitivity in a few hours on a commodity pc. in practice, we work with low values for large datasets as only the most significant interactions are required. we compared rapid against two strategies widely used to measure interactions . strategy i can be thought of as a filtering strategy. only a subset of the possible pairs are tested, those in which one of the snps (strategy ia), or both (strategy ib) show a marginal effect. in strategy ii, all pairs of snps are tested for interaction. on the face of it, strategy ii should demonstrate the highest power.argue that as the scoring stage is limited to the filtered pairs, the correction factor is based on the number of pairs being considered at the scoring stage. to ensure an overall type i error of at most , the significance level of the test for each pair is set to / 2 where 2 is the number of filtered pairs. for strategy i, 2 m, but for the full interaction model, 2 = m 2 . due to the larger number of tests in strategy ii, strategy i often outperforms strategy ii . as rapid is only a filtering strategy, it cannot be directly compared. here, we took only the top in the first model, the case odds increase multiplicatively upon addition of minor alleles at either loci. in the second (threshold) model, the odds increase only if both locus have at least one minor allele, and do not improve with addition of minor alleles. the model parameters in both cases are derived numerically using the single locus heterozygous odds ratio 1+ ( 0.2,0.5,1.0), and disease incidence p d = 0.01. model 1 (top panels) shows marginal effects, as do models with higher values of (= 1). rapid outperforms other methods, and shows a clear improvement when the marginal effects are low. multiplicatively with genotype both within and between loci. model 2 (corresponding to), has threshold effects so that the odds of disease increase only if both loci have at least one disease-associated allele, but additional minor alleles do not further increase the odds. for each model, we simulated genotypes at two interacting loci in n = 2000 cases and n = 2000 controls. the distribution of genotypes was governed by the parameter , where 1+ is the heterozygote odds ratio. for each choice of parameters, we simulated 1000 pairs, and corrected using m = 300 000 snps.shows power of each strategy for different simulation parameters. low values of present the higher challenge, as association exists with low marginal effects. in all tests, the performance of rapid shows greatly improved power over previous approaches. our analysis reveals that many significant pairs do not show individual effects and might be missed by strategy i, but are identified by rapid without the overhead of multiple tests.  
