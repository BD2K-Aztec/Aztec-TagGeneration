genome analysis adacgh2: parallelized analysis of (big) cna data motivation: studies of genomic dna copy number alteration can deal with datasets with several million probes and thousands of subjects. analyzing these data with currently available software (e.g. as available from bioconductor) can be extremely slow and may not be feasible because of memory requirements. results: we have developed a bioconductor package, adacgh2, that parallelizes the main segmentation algorithms (using forking on multicore computers or parallelization via message passing interface, etc., in clusters of computers) and uses ff objects for reading and data storage. we show examples of data with 6 million probes per array; we can analyze data that would otherwise not fit in memory, and compared with the non-parallelized versions we can achieve speed-ups of 2540 times on a 64-cores machine. availability and implementation: adacgh2 is an r package available from bioconductor. version 2.3.11 or higher is available from the development branchcurrent studies of genomic copy number alterations (cna) are using platforms with several million probes per array and several thousand subjects (e.g.), but the canonical implementations of the widely used open-source packages for the analysis of cna data did not allow for parallelized execution of the analysis. this makes it difficult to use clusters of servers and does not take advantage of the trends in parallel computing toward multicore machines (servers with 16124 cores or laptops with 2 or 4 cores are nowadays common). moreover, especially for r/bioconductor software, the available packages will not be able to analyze big datasets if these are larger than about a quarter to a half of the available memory (unless one uses time-consuming, and ad hoc, manual partition of the input and subsequent recombination of the outputsee discussion in section why adacgh2 instead of a manual solution in the vignette of the package). here i describe adacgh2, a bioconductor package designed to address the above deficiencies. i leverage on two r packages, parallel, part of the standard set of r packages, and ff , and combine them, to provide the following: parallelized analysis. i have parallelized the most widely used segmentation approaches that can be applied to cna data, including both comparative genomic hybridization (cgh) and snp arrays , and also covering sequencing data, when these have been appropriately processed, but seethe ability to analyze data that cannot fit in memory. using ff, we only access the section of the data currently being analyzed, keeping in ram and moving between processes only a pointer to the rest of the data on disk. parallelization of data input and output and plotting. input from, and output to, other bioconductor packages.here i present the main functions of the package, the differences with former version and some benchmarks. a full set of examples, further benchmarks and detailed suggestions for usage are included in the package vignettes. the code has been rewritten to use forking, data handling and reading of input data has been completely modified so that data much larger than available memory can be read and analyzed and missing value handling has been changed to use all available data per array. the vignette benchmarks.pdf provides extensive comparisons between the new (2.3.5) and latest previous running versions (version 1.10), but the main differences between these two versions are as follows:reading and analysis of large datasets. the new version can read datasets much larger than the old one and datasets much larger than available memory (see details in section 3). as a consequence of being able to read much larger datasets, the new version can analyze datasets much larger than the old one. missing value handling. the old version used row-wise deletion of missing values when reading data (i.e. a probe would be deleted from the data if it had one missing value in any array/column). the new version deals with missing values array by array, so for each array (or column) all available data (or probes) are used in the segmentation. forking and clusters. the new version of adacgh2 allows for the usage of forking or an explicit cluster (e.g. mpi, sockets) to parallelize reading and analysis. in posix operating systems (including unix, gnu/linux and mac os), forking can be faster, less memory consuming and much easier to use than a cluster. flexibility of reading data and compatibility with former version. the new version of adacgh2 has not removed the mechanisms of reading data available in the old version (when data are small or memory is plentiful, reading data from a single rdata is an available option) and accepts data read by the former version. however, the old version cannot accept data read by the new version because it assumes that data that have been read contain no missing values. these differences in implementation, however, do not affect the underlying core code for the algorithms, which is the same as in the previous version. there have been, however, changes in some defaults to adapt the package to really large data (e.g. using mad as merging default or using haarseg as the smoothfunc for daglad, following recommendations in the package vignette for glad).shows benchmarks of reading and analyzing data with 6 067 433 probes per array/column. those figures compare memory usage and wall time of the old and new versions and of the non-parallelized (np) versions in two different machines (data for the figures, as well as benchmarks for a third machine, and with mpi over two machines, are available from the vignette benchmarks.pdf). to give an idea of sizes, the rdata file for the 1000 arrays data is of 41 gb, and the directory with the data for 2000 columns/arrays occupies 198 gb. compared with the np version, in the analysis of data, adacgh2 leads to speed increases by factors of 2540 times in the 64 cores machines and 710 times in the 12 cores machines, and allows us to analyze data that would not fit in memory. compared with the former version, the new version uses less memory for analysis. more importantly, the new version allows us to read and analyze much larger datasets. in the 256 and. wall time and memory use (summed over all spawned processes) of reading and analysis as a function of number of arrays. reading: comparison between new and old versions. analysis: new and old versions with four segmentation methods and np for two methods. no benchmark allowed to run for 436 h. without parallelization, in the amd machine no runs of cbs with 1000 arrays or haarseg with 2000 can be done (r runs out of memory); in the intel machine no runs for 1000 arrays with any method can be done (r runs out of memory). work flow from input data to figures. r functions are shown with courier font inside boxes. in italics are the names of other packages, which can provide input/accept output. data frames are stored in memory, in contrast to ff objects. data input and conversion to ff objects are done with inputtoadacgh (maybe after using cutfile for parallelized reading of single-column files). segmentation is performed with psegment, and results can then be plotted (pchromplot) or used by other packages (outputtocghregions). when using ff objects, after data input (in a single machine) the remaining analyses can be conducted in a cluster  
