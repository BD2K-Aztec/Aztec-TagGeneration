correcting errors in short reads by multiple alignments motivation: current sequencing technologies produce a large number of erroneous reads. the sequencing errors present a major challenge in utilizing the data in de novo sequencing projects as assemblers have difficulties in dealing with errors. results: we present coral which corrects sequencing errors by forming multiple alignments. unlike previous tools for error correction, coral can utilize also bases distant from the error in the correction process because the whole read is present in the alignment. coral is easily adjustable to reads produced by different sequencing technologies like illumina genome analyzer and roche/454 life sciences sequencing platforms because the sequencing error model can be defined by the user. we show that our method is able to reduce the error rate of reads more than previous methods. availability: the source code of coral is freely available atnext-generation sequencing technologies, such as illumina genome analyzer, applied biosystems solid and roche/454 life sciences dna sequencing platforms, produce a vast amount of reads in a single run. vagaries of the reads produced by each sequencing machine are still being discovered. correction of errors in short reads is a critical task in bioinformatics. the variety of errors and biases of the current sequencing platforms must be addressed if the data is to be used to maximum effect. error correction aims to revert these mistakes made by a sequencing platform by exploiting the redundancy of the data and judging each base in a read as correct or incorrect (and then ideally correcting it). error correction helps to achieve high data use in de novo assembly. furthermore, the computational demands of assembly algorithms are reduced significantly if reads are first corrected. although we evaluate here the impact of error correction on de novo assembly, the technique could also be useful in other applications because error correction can potentially increase the mappability of reads in resequencing as well as in other applications of high-throughput sequencing. to whom correspondence should be addressed.error characteristics of the different platforms are complex, making error correction a difficult task. for instance, the roche/454 sequencing platform produces reads with indel errors, due mainly to homopolymers, whereas the solid and illumina platforms are prone to substitution errors.investigate quality score evolvement, error characteristics and biases of short sequencing reads. the first error correction method that is aimed at short read datasets is built into the assembly tool euler sr . it uses the spectral alignment method, which first establishes a spectrum of trusted k-mers from the input data and then corrects each read so that it contains only sequences from the spectrum. shrec byfollowed, a stand-alone error correction method. shrec is based on a parallelized suffix-trie data structure that holds a set of reads and corrects errors with a majority voting scheme. shrec was extended by salmela (2010) to accommodate hybrid sets of reads from various sequencing technologies, with different read lengths and error characteristics. hitec byuses a suffix array of the reads to count how many times short sequences are present in the read set and use these counts to correct the reads. the approach byrevisits the idea of chaisson and pevzner by overlaying reads with trustworthy tiles (pairs of k-mers), and correcting differences between the reads and the tiles to obtain error corrected read sets. quake byis another recent method that relies on spectral alignments to correct reads. in this article, we present coral (=correction with alignments), a novel approach, which relies on multiple alignments of short reads to correct errors in the data. the idea of using multiple alignments for correcting sequencing reads is not new. for example, the preprocessing in the arachne assembler and the mised error correction tool use multiple alignments to correct reads from the older sanger technology . our new tool is the first to apply this approach to short read data. most of the recent error correction tools are aimed at reads from the illumina genome analyzer platform and therefore they are limited to correcting substitutions which is the dominant error type in illumina reads. coral is easily adjustable to different error models of the various sequencing platforms. furthermore, adjusting the error model is easily accessible to the end user who only needs to set the familiar parameters of multiple alignments, gap penalty and mismatch penalty, to appropriate values according to the error model. for example, for illumina reads one needs to set the gap penalty to a high value effectively disallowing indels, whereas onethe aims of the experiments were 2-fold. first, we measured the quality of correction, and its effect on subsequent assembly. secondly, the computational resources required for the new method were compared to alternative approaches (shrec, quake and reptile). 1experimental setup: for testing we used the datasets listed in. unlike in other publications on the topic, we consider only real sequencing data and no simulated reads. we believe that none of the available read simulators can grasp the true characteristics of next-generation sequencing technologies, and thus observations on simulated data may be invalid. all tests were conducted on an otherwise idle amd opteron machine with 4 2.6 ghz cpus, 32 gb main memory and 1024k l2 cache. the operating system was ubuntu linux version 8.04.4 lts. the compiler was g++ (gcc version 4.2.4) executed with the-o3 option. times given are the average of two runs and were recorded with the linux/unix time command. to test the performance of the short read error correction tools under investigation, we first have to distinguish correct from erroneous bases in the experimental data. we accomplish this by mapping the reads to their respective references and defining mismatches and indels as errors in the sequence reads. this is common practise, as can be seen in the publications by . however, this method bears risks, since genomic variants such as snps can be defined as errors, and ambiguously mapping reads can lead to false classifications of bases as well. this is a general problem with short read data for applications like error correction, assembly or mapping, since the actual genomic sequence is hardly ever known, as that is the target of discovery. to minimize the risk of false classification, we only consider uniquely mapping reads for our experiments. also, this disadvantage is the same for all of the tested methods. we used soap byfor mapping the illumina reads and shrimp byto map the roche/454 reads. we can then assess the performance of an error correction method by identifying how many of the alleged errors in the data it can correct. from these numbers, other statistics like specificity, sensitivity or gain can be inferred, which will be explained below. such statistics, however, are not entirely satisfactory to assess the quality of corrections of a method, because it is unclear which statistic (when optimized) will indeed yield the best performance for other applications depending on the data. since error correction of short read data really is a preprocessing step for other applications like assembly, we assess performance on the impact on this key page: 1459 14551461the runtime is given as total runtime and cpu time (where applicable). application for short read data. for this purpose, we choose edena by , a well-established short read assembler, to run on the corrected read sets.@bullet coral: standard parameters (with the appropriate configurations with regards to the sequencing platforms):-illumina/-454. note, that we did not explore the parameter space to obtain optimal results for any of the error correction methods. in reality, when working on a read set fresh off a sequencing platform, there is no immediate feedback for the user, to identify good or bad error correction, which makes parameter choices hard. for this reason, we ran the tools with a best guess kind of configuration, to make it more indicative of a real application. for shrec, this meant adjusting the cutoff value c, for coral standard parameters and for reptile standard configuration as well, since it estimates all the important statistics by itself. statistical error correction performance: to assess the accuracy of the different methods by numbers, we identify the above four categories of error classification and then deduct the following statistics: @bullet sensitivity = tp/(tp + fn), the sensitivity towards erroneous bases. @bullet gain = (tp fp)/(tp + fn), as introduced by, a statistic to combine the two intuitions of removing errors without introducing additional ones.  
