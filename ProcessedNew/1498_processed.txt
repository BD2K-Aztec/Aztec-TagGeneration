sequence analysis dsrc 2â€”industry-oriented compression of fastq files modern sequencing platforms produce huge amounts of data. archiving them raises major problems but is crucial for reprodu-cibility of results, one of the most fundamental principles of science. the widely used gzip compressor, used for reduction of storage and transfer costs, is not a perfect solution, so a few specialized fastq compressors were proposed recently. unfortunately, they are often impractical because of slow processing, lack of support for some variants of fastq files or instability. we propose dsrc 2 that offers compression ratios comparable with the best existing solutions, while being a few times faster and more flexible. availability and implementation: dsrc 2 is freely available at http:// sun.aei.polsl.pl/dsrc. the package contains command-line compres-sor, c and python libraries for easy integration with existing software and technical documentation with examples of usage.genome sequencing has growing impact on medicine. there are emerging projects like the personal genome project or the million veteran program , in which hundreds of thousands of human genomes are to be sequenced. illumina company offers whole genome sequencing for clinical purposes for a few thousand us dollars. the companies like ion torrent promise the whole human genome sequencing in hours for51000 dollars to be available soon. it seems that personalized medicine for the masses will be available in the near future. the low cost of pure sequencing is not, however, everything, as the data must be stored and transferred. the it costs were not treated seriously in the past, when the sequencing was expensive and slow. nowadays, the costs of storage and transfers counted in hundreds of dollars for a single genome per year are no longer negligible. moreover, the improvements in this field are far behind what is present in the sequencing . an obvious solution to the data deluge is data compression and many specialized compressors appeared in the recent years (see the survey,). these tools are, however, rather experimental and tend to suffer from one or more of the following drawbacks: (i) they focus mainly on the compression ratio, and as a consequence (de)compression is slow (sometimes even comparable with the speed of sequencing), (ii) they are available as external tools, so the compressed formats cannot be directly used by other software, (iii) they have no support for some types of fastq files, e.g. in color space or variable-length reads and (iv) they are unstable and crash frequently. the focus on the compression ratio can sometimes be justified, especially, when the goal is just storage for archival purposes. in many situations the data are, however, stored locally and decompressed many times (for various analyses), so the decompression speed could be a significant factor of the processing speed of a whole pipeline. thus, in practice the well-known but rather inefficient gzip program is still in wide use. we think that it is time for industry-oriented solutions. thus, we introduce dsrc 2, supporting any variant of fastq files. its compression ratios are much better than gzip/bzip2 and only moderately worse than the best existing programs, but the speed of (de)compression is high. dsrc 2 also supports illuminas plan of quality resolution reduction (http://res.illumina.com/ documents/products/whitepapers/whitepaper_datacompression. pdf, 2012) and can read/write to pipes, for easy integration with pipelines. with context being the position in the read, or the order-1 huffman coder of the run-length-encoded quality stream. in the second method, the quality values are compressed arithmetically with context lengths up to 6.to evaluate the proposed compressor, we collected datasets for three different technologies: illumina (fixed-length reads, base space), abi solid (fixed-length reads, color space), ls454/ iontorrent (variable-length reads, base space). majority of experiments were performed on a four 8-core amd opteron tm 6136 2.4 ghz cpus server with raid-5 disk matrix containing 6 hdds. in one test, we also used the pc machine containing 4-core (with hyperthreading) i7 4770 3.4 ghz cpu and ssd disk. for the comparison, we used two popular universal tools, pigz (parallel gzip) and p-bzip2 (parallel bzip2), and the best existing fastq compressors, quip , fqzcomp , seqdb and dsrc 1 . the compressors were run in two modes: the best ratio and fast compression, not necessarily the fastest possible, but with a reasonable ratio . dsrc 2 consumes 5400 mb of main memory in the fast mode and 56.5 gb in best mode. these values are much higher than of gzip (510 mb in parallel variant), but we think they are still acceptable. in the lossless mode, the best ratios were obtained by fqzcomp, but its low speed makes it rather impractical. the compression ratio of dsrc 2 is 1015 smaller, but its speed is an order of magnitude (or more) higher. in the fast mode, the speed of dsrc 2 is sometimes i/o-limited, while the compression ratio is still much better than of the de facto standards gzip/ bzip2. what is important is that dsrc 2 is similarly fast in both compression and decompression. this allows the application in storage of the intermediary results in the processing pipelines, potentially with total improvement of the complete processing speed because of i/o transfer reduction. the relative results for the illuminas quality-reduced data are presented inof the supplementary file s1.shows how dsrc 2 speed scales up for growing number of threads.  
