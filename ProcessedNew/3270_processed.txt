genome analysis noise reduction in genome-wide perturbation screens using linear mixed-effect models motivation: high-throughput perturbation screens measure the phenotypes of thousands of biological samples under various conditions. the phenotypes measured in the screens are subject to substantial biological and technical variation. at the same time, in order to enable high throughput, it is often impossible to include a large number of replicates, and to randomize their order throughout the screens. distinguishing true changes in the phenotype from stochastic variation in such experimental designs is extremely challenging, and requires adequate statistical methodology. results: we propose a statistical modeling framework that is based on experimental designs with at least two controls profiled throughout the experiment, and a normalization and variance estimation procedure with linear mixed-effects models. we evaluate the framework using three comprehensive screens of saccharomyces cerevisiae, which involve 4940 single-gene knockout haploid mutants, 1127 single-gene knockout diploid mutants and 5798 single-gene overexpression haploid strains. we show that the proposed approach (i) can be used in conjunction with practical experimental designs; (ii) allows extensions to alternative experimental workflows; (iii) enables a sensitive discovery of biologically meaningful changes; and (iv) strongly outperforms the existing noise reduction procedures. availability: all experimental datasets are publicly available at www.ionomicshub.org. the r package htsmix is available atperturbation screens subject model organisms to stresses that are external (e.g. heat shock or chemical treatments) or genetic (e.g. disruption or deletion of to whom correspondence should be addressed. genes). a variety of phenotypes can be measured in association with the stresses. these can be univariate phenotypes such as cell growth rate or activity of a reporter gene, low-dimensional phenotypes such as cellular morphology or high-dimensional phenotypes such as gene expression or protein abundance. when conducted on a genome-wide scale, perturbation screens provide invaluable insight into the function of living organisms . they are increasingly used in functional biology , and in biomedical and biopharmaceutical research . the throughput of genome-wide screens is a primary concern in these investigations. since it can take weeks and sometimes months to measure the phenotypes, it is often impossible to fully implement the fundamental principles of statistical experimental design. in particular, the screens can incorporate little replication, and a full randomization of the order of the replicates is often impractical. at the same time, the measured phenotypes are subject to large variation, which is due to both natural between-sample variation, and technical variation in the sample handling and measurement procedures. the problem is compounded by changes in experimental characteristics (e.g. instruments, labor, reagents) that are unavoidable in large-scale screens. interpretation of the screens is, therefore, a key and non-trivial step, which must take the specifics of the experiments into account. in this article, we propose a statistical modeling framework for accurate interpretation of high-throughput screens, most specifically in cases of low-dimensional phenotypes. we focus on screens which have a limited number of replicate samples and a sensitive phenotype (i.e. the phenotype that is affected in a non-negligible proportion of the samples). distinguishing the systematic signal from noise is particularly challenging in such situations.the requirements of high throughput impose constraints on the design and implementation of perturbation screens, and introduce challenges in their interpretation. work in this article was motivated by the insights that (i) control-based normalization is most appropriate for the screens where a large proportion of samples show changes in the phenotypes, and (ii) residual non-additive effects of batch and plate variation are important components of the stochastic variation in the screens, and should be accounted for the optimal detection of hits. we proposed an experimental design that involves at least two control samples, and a normalization and variance estimation procedure based on linear mixed-effects models. evaluations on three comprehensive ionomic screens showed that the proposed method: @bullet can be used in conjunction with a practical experimental design; @bullet allows extensions to alternative structures of data; @bullet enables a specific discovery of biologically meaningful hits; and @bullet strongly outperforms the existing approaches.we therefore recommend this approach as a useful tool in highthroughput functional investigations.  
