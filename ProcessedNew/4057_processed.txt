robust data-driven incorporation of prior knowledge into the inference of dynamic regulatory networks motivation: inferring global regulatory networks (grns) from genome-wide data is a computational challenge central to the field of systems biology. although the primary data currently used to infer grns consist of gene expression and proteomics measurements, there is a growing abundance of alternate data types that can reveal regulatory interactions, e.g. chip-chip, literature-derived interactions, proteinprotein interactions. grn inference requires the development of integrative methods capable of using these alternate data as priors on the grn structure. each source of structure priors has its unique biases and inherent potential errors; thus, grn methods using these data must be robust to noisy inputs. results: we developed two methods for incorporating structure priors into grn inference. both methods [modified elastic net (men) and bayesian best subset regression (bbsr)] extend the previously described inferelator framework, enabling the use of prior information. we test our methods on one synthetic and two bacterial datasets, and show that both men and bbsr infer accurate grns even when the structure prior used has significant amounts of error (490 erroneous interactions). we find that bbsr outperforms men at inferring grns from expression data and noisy structure priors. availability and implementation: code, datasets and networks presented in this article are available at http://bonneaulab.bio.nyu.edu/ software.html.understanding how global regulatory networks (grns) coordinate systems-level response of a cell or organism to a new environmental state or perturbation is a key problem in systems biology, with applications spanning biofuels , novel therapeutic targets and the discovery of novel pathways involved in cellular differentiation . the cellular response is governed by multiple regulatory mechanisms that can be encapsulated by large network models. recent advances in the quality and availability of high-throughput technologies enable measurement of different components of the grn including mrna transcript levels, protein levels, post-translational modifications, as well as dna characteristics such as transcription factor-binding regions and open chromatin locations (encode project). these multi-level and multi-scale datasets have made the inference of integrative grns possible. as high-throughput data capturing the abundance of mrna transcripts are the most mature and readily available, many methods focus only on this single level of regulation, learning transcriptional regulatory networks. in transcriptional grns, the regulators are transcription factors (tfs, either previously known or predicted), and the targets are genes. time-series data, capturing the temporal changes in transcript abundance, allow for the inference of the strength and direction of regulatory interactions, which can be used to predict how the system will behave under previously unmeasured conditions . here, we are primarily interested in methods for learning regulatory networks from compendia of expression data, and combining this data with complementary data sources that provide priors on network structure. importantly, the priors we use in this work provide information about connectivity but do not provide any information about the relative strength, importance or dynamic properties of each known regulatory edge (these we atempt to learn from the data). learning networks from single data types has severe limitations, as grns operate on multiple levels in addition to the transcriptome; thus, alternate data types are needed to form a complete picture of cellular circuits. even if one is interested in learning the purely transcriptional layer of a cells regulatory network, many tfs are post-transcriptionally modified in ways that confound single data-type network inference (the transcript abundance of a tf is not necessarily correlated with its protein abundance nor activity), and some regulatory sub circuits produce transcriptional output that is consistent with multiple models. one way to mitigate these pitfalls is to use publicly available sources of complementary data with bearing on regulation. we term any data that contains direct tf-target information (either predicted, or experimentally validated) as structure priors. one source of such prior information is an ever-growing collection of experimentally validated and manually curated databases of regulatory interactions. these databases are especially rich for to whom correspondence should be addressed. y the authors wish it to be known that, in their opinion, the first two authors should be regarded as joint first authors. the author 2013. published by oxford university press. this is an open access article distributed under the terms of the creative commons attribution license (http://creativecommons.org/licenses/by/3.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited. model organisms , and the sets of known regulatory interactions are considered to be accurate and precise (though not complete). additionally, the encode project consortium (2012) (a high-profile effort to build an encyclopedia of coding dna elements) has generated a wealth of dna-binding information that can be used to generate priors on mammalian regulatory network structure. these are only a few examples of an ever growing number of sources of grn structure priors, and it can be seen that they differ substantially from organism to organism. each source of prior information on grn structure is an incomplete recapitulation of the underlying network, and may contain many incorrect or irrelevant interactions. thus, incorporating structure priors into expression-based grn inference poses several interesting algorithmic challenges. successful methods for integrative grn inference must possess the following key properties: (i) the method must only include the part of the prior with support from the data. this is important, as the prior information typically is a collection of possible regulatory interactions, of which only a subset might be relevant in a given dataset. also, this implies robustness to erroneous interactions in the prior, which can have various sources, such as non-functional tf binding reported by chip-seq. (ii) using a structure prior must not limit the ability to learn the part of the network for which no prior information exists. (iii) the user must be able to control the weight given to the prior. this feature allows the user to tune the method based on the believed completeness and accuracy of the prior, while respecting the first two properties over a wide range of parameters. in this work, we introduce two methods for incorporating structure priors that possess all three criteria.we have conducted systematic thorough testing of the ability of both men and bbsr to accurately reconstruct grns using prior information in biologically relevant settings. we tested both methods with respect to the number and accuracy of prior known interactions (pkis), and the effect of the weight of the pkis. performance is validated against the set of gold standard interactions (gsis).we developed two methods for incorporating prior knowledge into grn inference. both methods use the same underlying ode model of regulation (see section 2), but use different model selection approaches. men uses an adaptive weight on the penalty function to incorporate prior knowledge. bbsr uses the bayesian formulation of linear regression, together with zellners g-prior to incorporate prior information, and best subset regression with the bic for sparse model selection. a key difference between men and bbsr is how the choice of weight (how much influence to give to the prior) effects performance. results presented inshow that for bbsr higher values of g result in overall higher confidence in pkis, and reduced confidence in all unknown interactions. as such, g can be interpreted as a confidence measure in the accuracy and completeness of pkis, and be chosen accordingly. it is also possible to introduce multiple sources of prior information, each with a different weight (value of g). for men,. performance change on the leave-out set. pkis were sampled randomly from 20, 40, 60 and 80 of the gsis in five repetitions. we define the leave-out set as the set of gsis that are not pkis. here, we compare the aupr of the leave-out set when using pkis (y-axis) to the aupr when not using pkis (x-axis). points above the line indicate a performance increase when pkis are used the prior weight parameter exhibits a less predictable behaviour. lower values of generally lead to higher confidence in pkis. however, for all datasets, we observed a performance peak around 0:01. this non-linear property could be the result of cross-validation model selection procedure. we tested the performance of both methods on different subsets of the gsis. we see that increasing the number of pkis increases performance in a linear manner for all datasets and both methods (supplementary). this is in concordance with the results on the leave-out set (the set of gsis that are not pkis), where both methods showed only minor performance change in the presence of pkis, regardless of dataset or number of pkis used . finally, and most importantly for application to biological systems where only incomplete and noisy sets of pkis are available, we assessed the robustness of both methods to fpis. both methods are robust to fpis, and outperform the naive ranking scheme, which assigns high confidence to all pkis . more specifically, for both large real datasets (e.coli and b.subtilis), both methods perform better than various baselines (no pkis), with up to 10 fpis for each true prior interaction. this means that both methods, given sufficient genomic data, are able to act as filters to distinguish between true and false prior interactions. however, bbsr is slightly more robust to the presence of fpis. a key consideration for any practical application of network inference methods with prior information is the trade-off between recapitulating the prior, and discovering novel biology. intuitively, as the degree of belief in the prior is increased (by increasing the weight of the prior information), more of the interactions in the prior will be ranked highly by the inference method. thus, high weights can lead to the incorporation of false interactions in the case of inaccurate pkis (men more prone than bbsr), and impair performance on the leave-out set (as seen in bbsr). we suggest to the reader to set the weight parameter for incorporating prior knowledge based on the expected completeness and accuracy of the pkis, and, when in doubt, to choose a low weight.  
