prediction of human functional genetic networks from heterogeneous data using rvm-based ensemble learning motivation: three major problems confront the construction of a human genetic network from heterogeneous genomics data using kernel-based approaches: definition of a robust gold-standard negative set, large-scale learning and massive missing data values. results: the proposed graph-based approach generates a robust gsn for the training process of genetic network construction. the rvm-based ensemble model that combines adaboost and reduced-feature yields improved performance on large-scale learning problems with massive missing values in comparison to nave bayes.biological pathways that organize functional associations between different genes, proteins and small molecules are central to understanding cellular function. a variety of high-throughput experimental data, such as dna microarray, chip-chip technology and systematic two-hybrid analysis , have the potential to provide a systemlevel perspective of cellular processes and may contribute to systematic drug discovery . moreover, the broad availability of indirect biological data sources, such as gene ontology and protein localization information, also contain information that can be used to understand cellular processes . understanding biological pathways at the whole-genome level, however, remains a major challenge. several computational approaches have been applied to construct biological networks using different individual data sources . however, the results are often contradictory and not super imposable in any obvious way due to the intrinsic error rate of each data set and limited coverage . this limitation has motivated more recent work addressing the problems of integrating heterogeneous functional genomic and proteomic data to construct biological network. results from these studies suggest that the combination of multiple sources can provide a more unified view of prediction with large coverage and high reliability. several rigorous statistical models and machine to whom correspondence should be addressed. learning approaches have been applied to generate reliable integrated predictions, such as bayesian modeling, decision tree and random forest . bayesian modeling (nave bayes and fully connected bayes) is the most popular method used to predict proteinprotein and genetic interactions . correlation among data sets, however, can cause prediction bias in nave bayes models. fully connected bayes models , in contrast, can capture the interdependence among data sources by directly calculating joint probabilities; however, it results in higher computational costs and requires bin size adjustment of each data dimension to obtain reasonable results, especially for high-dimension data. moreover, the model prior is generally arbitrarily set to be the proportion of total number of positive and negative examples in the chosen benchmarks . kernel-based models have demonstrated very competitive computational performance due to their ability to model non-linear systems and high-dimension data. the support vector machine (svm) has recently been successfully applied to predict protein protein interactions and protein complex relationships in yeast and escherichia coli using heterogeneous data (ben). the relevance vector machine (rvm) approach , another powerful kernel-based model, uses a bayesian learning framework to produce sparse decision models. rvm is similar to svm in many respects and has been reported to yield nearly identical performance, but surpasses svm in several aspects, including automatic prevention of over fitting and generation of much sparser models . the rvm has been applied to several biological tasks including the classification and diagnosis of cancers and the identification of non-coding regions in genomes . thus, rvm may be a useful approach for integrating multiple heterogeneous data for constructing genetic networks. three major problems, however, confront the use of rvm in constructing a human genetic network from diverse genomic data. first, a robust gold-standard negative (gsn) set is needed for training. a noisy gold-standard will impair training and cause prediction bias. major methods reported in previous protein interaction studies to define gsn (ben;) are not suitable for defining gsn for construction of a functional genetic network, which is not only composed of physical interactions butpage: 808 807813in this work, a graph-based approach is first presented to construct a more robust gsn than previous methods. through validations using old and new kegg pathways as well as the gene ontology, it has been shown that a robust gsn can be constructed by choosing the n most distant kegg pathway relationships. the high values of f-measure and g-mean (supplementary material s5) in all our results also indicate that our models can yield good classification performance on both positive and negative examples. this suggests that the proposed graph-based gsn is sufficiently robust that the overlap between gsp and gsn is small. with moderate sampling size, the rvm-based model with only a few vectors is able to significantly reduce both training and prediction time. it will be of interest to compare the performance of rvm-adaboost with svm-adaboost in future applications, especially with respect to prediction time that is dominated by the number of vectors in the final assembled model. this can clarify the advantage of rvmbased ensemble models on sparseness. the kc1 kernel combination approach in section 2.2 has been shown to be an effective kernel integration approach in rvm-based model, which can retain the semantic association within each dataset and subsequently sum up kernel values of each dataset to improve the performance progressively. through this method, it is observed that the model performance increases progressively as more datasets are integrated (supplementary data s5), thus allowing the model to predict complementary pathway information. we have also addressed the ability of the rvm-based models to classify the biological dataset with a large number of missing values. we find that the rvm-based model can yield significant performance even with massive missing data values, as shown by comparison with the nave bayes baseline model. among the three model scenarios, the double ensemble model (m3) can generate a much lower generalization error than the others because it includes base-models corresponding to training data with different patterns page: 813 807813  
