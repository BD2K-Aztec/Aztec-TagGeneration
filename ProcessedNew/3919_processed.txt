realizing privacy preserving genome-wide association studies motivation: as genomics moves into the clinic, there has been much interest in using this medical data for research. at the same time the use of such data raises many privacy concerns. these circumstances have led to the development of various methods to perform genome-wide association studies (gwas) on patient records while ensuring privacy. in particular, there has been growing interest in applying differentially private techniques to this challenge. unfortunately, up until now all methods for finding high scoring snps in a differentially private manner have had major drawbacks in terms of either accuracy or computational efficiency. results: here we overcome these limitations with a substantially modified version of the neighbor distance method for performing differentially private gwas, and thus are able to produce a more viable mechanism. specifically, we use input perturbation and an adaptive boundary method to overcome accuracy issues. we also design and implement a convex analysis based algorithm to calculate the neighbor distance for each snp in constant time, overcoming the major computational bottleneck in the neighbor distance method. it is our hope that methods such as ours will pave the way for more widespread use of patient data in biomedical research. availability and implementation: a python implementation is available atgenome-wide association studies (gwas) are a cornerstone of genotypephenotype association in humans. these studies use various statistical tests to measure which polymorphisms in the genome are important for a given phenotype and which are not. with the increasing collection of genomic data in the clinic, there has been a push towards using this information to validate classical gwas findings and generate new ones . unfortunately, there is growing concern that the results of these studies might lead to loss of privacy for those who participate in them . these privacy concerns have led some to suggest using statistical tests that are differentially private . on the bright side, such methods, properly used, can help ensure a high degree of privacy. moreover, recent work has suggested that differentially private methods can be used to help avoid overfitting and related problems that plague much of biomedical science . these gains, however, have traditionally come at a high cost in utility and efficiency. moreover, since the genome is extremely high dimensional, this cost is especially pronounced, as was noted in previous works . in order to help balance utility and privacy, new methods are needed that provide greater utility than current methods while achieving equal or greater privacy. here we improve upon the state of the art in differentially private gwas. we build on previous work , which applied the ideas of differential privacy to common v c the author 2016. published by oxford university press.the above work shows how to make differentially private gwas much more realistic, both in terms of accuracy and run time. though the tools of differential privacy have been around for years, the biomedical community has been slow to adopt them . though this delay is partially due to the limited knowledge about such approaches in the biomedical field, perhaps a bigger reason is that current techniques greatly reduce the utility of data and their analysis. in a field whose main concern is human health there is extra incentive to give the most accurate analysis possiblelives could be on the line. despite this concern, there are a few important areas where accurate differentially private methods might play a role. the most obvious one is when institutional or legal concerns prevent data from being published . when such limitations exist, it might be possible to release differentially private versions of the data under consideration instead. the other application where differential privacy might be useful is when untrusted users query a database. it is this situation that has motivated many of the previous works on differential privacy , and some of the only applications of data perturbation that have been implemented in real world systems . in a nutshell, the idea is that users who might want to use a large medical database to help design a study (e.g. to come up with hypothesis to test, find participants with certain traits for a study) or validate results can do so by asking queries about the database and getting differentially private answers to those queries. this approach allows researchers access to the database while minimizing privacy concerns. as an added bonus, since the queries are being used as a preliminary step, as opposed to being part of a rigorous analysis, there may be less worry about the ethical implications of returning inaccurate results. it is even possible that being able to make such queries will actually lead to more accurate results downstream.. we demonstrate the runtime of our exact method as well as the approximate method for various numbers of snps as well as the average error per snp that comes from using the approximate methodwe see that in all cases the exact method is much faster than the approximate method. in addition, its runtime is fairly steady for all choices of m ret. these results are averaged over 20 trials.. we compare the accuracy of output perturbation (blue) and input perturbation (green), tested on the 10 highest scoring snps. we see that the input perturbation approach greatly outperforms the standard output perturbation approach. this graph was averaged over 1000 runs, and the error is plotted on a log scale  
