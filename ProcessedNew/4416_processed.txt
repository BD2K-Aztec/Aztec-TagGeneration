genome analysis statistical confidence measures for genome maps: application to the validation of genome assemblies motivation: genome maps are imperative to address the genetic basis of the biology of an organism. while a growing number of genomes are being sequenced providing the ultimate genome mapsthis being done at an even faster pace now using new generation sequencersthe process of constructing intermediate maps to build and validate a genome assembly remains an important component for producing complete genome sequences. however, current mapping approach lack statistical confidence measures necessary to identify precisely relevant inconsistencies between a genome map and an assembly. results: we propose new methods to derive statistical measures of confidence on genome maps using a comparative model for radiation hybrid data. we describe algorithms allowing to (i) sample from a distribution of maps and (ii) exploit this distribution to construct robust maps. we provide an example of application of these methods on a dog dataset that demonstrates the interest of our approach. availability: methods are implemented in two freely available softwares: carthagenegenome maps are imperative to address the genetic basis of an organism biology. while a growing number of genomes are being completely sequenced providing the ultimate genome maps, the process of constructing intermediate mapsgenetic maps, rh maps to name only a fewremains certainly an important task . indeed, the current whole-genome shotgun approach for genome sequencing produce a large number of contigs and scaffolds of limited length. the n50 scaffold size of the recent panda genome assembly, for example, reaches 1.3 mb compared with the 50 mb of the smallest human chromosome, providing a limited picture of the genome architecture for this species. dense chromosomal maps remain invaluable for organizing the scaffolds along the chromosomes and to whom correspondence should be addressed. can be of great help for checking the order of markers within assemblies . radiation hybrid (rh) maps, for example, have played an important role in facilitating the process of whole-genome sequencing and assembly . they provide an independent source of information for the validation of genome assemblies because the comparison of maps produced by independent protocols (genetic, rh, sequence based) gives clues about map accuracies. one of the most sensitive aspect of comparing maps howeverfor example, the comparison of a map to a genome assemblylies in the interpretation of inconsistencies. indeed, as a result of the limited nature of experimental data used in the mapping construction process, the resulting maps are not exempt of errors. perhaps more importantly, because of the difference in marker informativeness and also in the density of markers along a map, the experimental data support for the local order of markers at different locations of the map may vary considerably. the usual output of a mapping experiment consists, however, in a single map representing the optimal solution of the optimization problem associated with the mapping experiment, e.g. minimum obligate breaks or maximum likelihood order in genetic or rh mapping. while lod scores between pairs of markers in genetic or rh maps measure the degree of linkage between adjacent markers, genome maps lack statistical confidence measure to reflect middle to long range order accuracy in contrast, for example, to the long-standing practice of support values in phylogenetic analysis, i.e. the bootstrap values or the bayesian posterior probabilities for the internal nodes of phylogenetic trees . the aforementioned difficulties are particularly relevant when addressing the quality of genome assembly. indeed, having in hand a single map resulting from a mapping process and a single genome assembly, there is no straightforward rules that enable to select assembly regions, inconsistent with the map, that deserve further investigations. here, we propose to address this difficulty by constructing statistical confidence measures for maps that reflect locally the confidence or support we have for a particular map order. this enables to rank the inconsistencies with respect to these measures and help in the validation of whole-genome assemblies. previous work has been done on the modeling of map uncertainty using bayesian models, for rh data and genetic data . they were, however, limited to a small number of markers. in this article, we propose a new model that (i) exploit the availability of prior information on marker ordering (on a closely related species or on a draft assembly) and (ii) aims at analyzing large datasets such as provided by high-throughput genotyping platforms (snp chips).radiation hybrid mapping is a powerful tool to facilitate the localization of genes of interest on animal genomes. integrating comparative genomics into rh mapping allows to further improve the mapping process by exploiting the important colinearity (conserved synteny) between genomes of (closely) related species. in this work, we present methods that exploit this model to help in the process of producing robust whole-genome assemblies. we exploit a comparative model which has the key property that only when the rh data is informative enough with respect to a different ordering than that of the reference order will an alternative order be accepted. as a consequence, our approach allows to pinpoint regions where the assembly order disagree with an rh map order that is strongly supported by the rh data.as was previously explained by, we found that the main impact of the presence of genotyping errors was to increase the uncertainty in the marker ordering. this can be explained by the resulting inflation of markers distances, corresponding to higher estimates of breakage probability. the main consequence is that robust maps tend to have a smaller number of markers. however, the quality of the robust maps, which we measured by the lis criterion, is only marginally impacted. this shows how estimating the map uncertainty allows to take into account and to some extent overcome the problems created by genotyping errors. to further reduce the uncertainty in the maps when errors are present, we propose to combine an error model with the map distribution. we observed, however, that for high error rates (10 in our simulations), using imputations was not enough to produce good-quality robust maps. indeed, it tended to produce robust maps with a higher number of markers but low lis, i.e. a biased inference. our explanation for these results is that the initial map distribution, which we use for imputation, is too far from the true distribution to provide accurate imputation of the genotypes, and consequently good robust maps. in particular, we observed that some of the markers tend to have a very large number of imputations, most of them being erroneous (see supplementary). this is in great contrast with imputation on datasets with a 5 error rate and explains the differences in performance in these two cases. more generally, our results stress the fact that the estimation of the map distribution is greatly impacted by markers with a large number of errors. for real data, care as to be taken for including only markers for which genotyping is a priori of good quality. the criteria to identify good-quality marker will depend on the genotyping method used. for snp chips, our experience is that genotyping controls (markers and non-irradiated genome) and using conservative thresholds for genotype calling from the raw data are quite important. considering that today the density of markers provided by snp chips is larger than the one that the resolution of rh panels allows to separate, working with a subset of high-quality markers is not problematic. this being said, it is reassuring to note that even large error rates can be estimated confidently with the error model (supplementary). this has the practical consequence of providing a mean to quantify the level of confidence that can be placed in the data to produce good rh maps. the robust maps presented here correspond to a subset of markers with an order common to all the maps in the distribution. we can note that a search for the longest common subsequence of all the maps would lead to the same subset of markers. the notion of robust maps, however, can easily be extended, using the inclusion tree as a guideline, to a subset of markers with preserved order in a controlled proportion of the distribution (e.g. 99.9). this last notion is very close to the notion of framework maps well known in the context of rh mapping . the metamap representation of the distribution of maps could therefore eventually lead to new approaches for the construction of framework maps. a classical problem when using mcmc is to make sure that the chain has converged and provides samples from the target distribution. our main argument to show that the mcmc chains have converged in our simulation is the good calibration of the posterior distributions of the probability of adjacency. we obtained this result while performing a relatively modest number of iterations but in the same time using proposal distributions that tend to propose moves with high probability of acceptance (see details in appendix 1 provided in supplementary material). on the dog data, we checked that our results were consistent across several mcmc runs, indicating that we have performed a sufficient number of iterations. in previous bayesian approaches to rh mapping, the authors were dealing with much smaller datasets, and incorporated the estimation of breakage probabilities and retention fraction into the model. with large datasets, this becomes computationally impractical and so we relied on simple points estimates for these quantities. although trying to incorporate an update of these parameters without increasing too much of the computation time could be interesting, our results show that good robust maps can be obtained with our more simple approach. an important aspect of our model is the incorporation of a reference order as a prior. for the sampling of maps via the mcmc algorithm, we found that this was particularly true. when running the algorithm on the rh data without a reference order (which corresponds to specifying a uniform prior on all possible orders), the number of maps visited becomes huge after very few iterations. using comparative information allows to reduce the space of orders visited to those that are compatible with the mechanisms of chromosome evolution known to preserve large conserved segments between genomes of related species. in our example of application in the dog, we used the human genome as a reference. this was possible in large part because the markers used were gene coding sequences page: 3042 30353042  
