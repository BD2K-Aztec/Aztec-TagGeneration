data and text mining capri: efficient inference of cancer progression models from cross-sectional data downloaded from we devise a novel inference algorithm to effectively solve the cancer progression model reconstruction problem. our empirical analysis of the accuracy and convergence rate of our algorithm , cancer progression inference (capri), shows that it outperforms the state-of-the-art algorithms addressing similar problems. motivation: several cancer-related genomic data have become available (e.g. the cancer genome atlas, tcga) typically involving hundreds of patients. at present, most of these data are aggre-gated in a cross-sectional fashion providing all measurements at the time of diagnosis. our goal is to infer cancer progression models from such data. these models are represented as directed acyclic graphs (dags) of collections of selectivity relations, where a mutation in a gene a selects for a later mutation in a gene b. gaining insight into the structure of such progressions has the potential to improve both the stratification of patients and personalized therapy choices. results: the capri algorithm relies on a scoring method based on a probabilistic theory developed by suppes, coupled with bootstrap and maximum likelihood inference. the resulting algorithm is efficient, achieves high accuracy and has good complexity, also, in terms of convergence properties. capri performs especially well in the presence of noise in the data, and with limited sample sizes. moreover capri, in contrast to other approaches, robustly reconstructs different types of confluent trajectories despite irregularities in the data. we also report on an ongoing investigation using capri to study atypical chronic myeloid leukemia, in which we uncovered non trivial select-ivity relations and exclusivity patterns among key genomic events. availability and implementation: capri is part of the translational oncology r package and is freely available on the web at:analysis and interpretation of the fast-growing biological data sets that are currently being curated from laboratories all over the world require sophisticated computational and statistical methods. motivated by the availability of genetic patient data, we focus on the problem of reconstructing progression models of cancer. in particular, we aim to infer the plausible sequences of genomic alterations that, by a process of accumulation, selectively make a tumor fitter to survive, expand and diffuse (i.e. metastasize). along the trajectories of progression, a tumor (monotonically) acquires or activates mutations in the genome, which, in turn, produce progressively more viable clonal subpopulations over the so-called cancer evolutionary landscape (cf.,). knowledge of such progression models is very important for drug development and in therapeutic decisions. for example, it has been known that for the same cancer type, patients in different stages of different progressions respond differently to different treatments. several datasets are currently available that aggregate diverse cancer-patient data and report in-depth mutational profiles, including e.g. structural changes (e.g. inversions, translocations, copynumber variations) or somatic mutations (e.g. point mutations, insertions, deletions, etc.). an example of such a dataset is the cancer genome atlas (tcga) (cf., nci and the nhgri, 2005). these data, by their very nature, only give a snapshot of a given tumor sample, mostly from biopsies of untreated tumor samples at the time of diagnoses. it still remains impractical to track the tumor progression in any single patient over time, thus limiting most analysis methods to work with cross-sectional data. (unlike longitudinal studies, these cross-sectional data are derived from samples that are collected at unknown time points, and can be considered as static.) to rephrase, we focus on the problem of cancer progression models reconstruction from cross-sectional data. the problem is not new and, to the best of our knowledge, two threads of research starting in the late 90s have addressed it. the first category of works examined mostly gene-expression data to reconstruct the temporal ordering of samples (cf.,). the second category of works looked at inferring cancer progression models of increasing model-complexity, starting from the simplest tree models (cf.) to more complex graph models (cf.,); see the next subsection for an overview of the state of the art. building on our previous work described in oldewe present a novel and comprehensive algorithm of the second category that addresses this problem. the new algorithm proposed here is called cancer progression inference (capri) and is part of the translational oncology (tronco) package (cf.,). starting from cross-sectional genomic data, capri reconstructs a probabilistic progression model by inferring selectivity relations, where a mutation in a gene a selects for a later mutation in a gene b. these relations are depicted in a combinatorial graph and resemble the way a mutation exploits its selective advantage to allow its host cells to expand clonally. among other things, a selectivity relation implies a putatively invariant temporal structure among the genomic alterations (i.e. events) in a specific cancer type. in addition, these relations are expected to also imply probability raising for a pair of events in the following sense: namely, a selectivity relation between a pair of events here signifies that the presence of the earlier genomic alteration (i.e. the upstream event) that is advantageous in a darwinian competition scenario increases the probability with which a subsequent advantageous genomic alteration (i.e. the downstream event) appears in the clonal evolution of the tumor. thus the selectivity relation captures the effects of the evolutionary processes, and not just correlations among the events and imputed clocks associated with them. as an example, we show in the selectivity relation connecting a mutation of egfr to the mutation of cdk. consequently, an inferred selectivity relation suggests mutational profiles in which certain samples (early-stage patients) display specific alterations only (e.g. the alteration characterizing the beginning of the progression), while certain other samples (e.g. late-stage patients) display a superset subsuming the early mutations (as well as alterations that occur subsequently in the progression). various kinds of genomic aberrations are suitable as input data, and include somatic point/indel mutations, copy-number alterations, etc., provided that they are persistent, i.e. once an alteration is acquired no other genomic event can restore the cell to the nonmutated (i.e. wild type) condition. (for instance, epigenetic alterations such as methylation and alterations in gene expression are not directly usable as input data for the algorithm. notice that the selection of the relevant events is beyond the scope of this work and requires a further upstream pipeline, such as that provided, for instance, inthe selectivity relations that capri reconstructs are ranked and subsequently further refined by means of a hybrid algorithm, which reasons over time, mechanism and chance, as follows. capris overall scoring methods combine topological constraints grounded on patrick suppes conditions of probabilistic causation (see e.g.), with a maximum likelihood-fit procedure (cf.,) and derives much of its statistical power from the application of bootstrap procedures (see e.g.). capri returns a graphical model of a complex selectivity relation among events which captures the essential aspects of cancer evolution: branches, confluences and independent progressions. in the specific case of confluences, capris ability to infer them is related to the complexity of the patterns they exhibit, expressed in a logical fashion. as pointed out by other approaches (cf.,), this strategy requires trading off complexity for expressivity of the inferred models, and results in two execution modes for the algorithm: supervised and unsupervised, which we discuss in detail in sections 2 and 3. in section 3 we show that capri enjoys a set of attractive properties in terms of its complexity, soundness and expressivity, even in the presence of uniform noise in the input datae.g. due to genetic heterogeneity and experimental errors. although many other approaches enjoy similar asymptotic properties, we show that capri can compute accurate results with surprisingly small sample sizes (cf., section 4). moreover, to the best of our knowledge, based on extensive synthetic data simulations, capri outperforms all the competing procedures with respect to all desirable performance metrics. we conclude by showing an application of capri to reconstruct a progression model for atypical chronic myeloid leukemia (acml) using a recent exome sequencing dataset, first presented in).  
