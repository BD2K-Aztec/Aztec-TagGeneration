genome analysis the masurca genome assembler motivation: second-generation sequencing technologies produce high coverage of the genome by short reads at a low cost, which has prompted development of new assembly methods. in particular, multiple algorithms based on de bruijn graphs have been shown to be effective for the assembly problem. in this article, we describe a new hybrid approach that has the computational efficiency of de bruijn graph methods and the flexibility of overlap-based assembly strategies , and which allows variable read lengths while tolerating a significant level of sequencing error. our method transforms large numbers of paired-end reads into a much smaller number of longer super-reads. the use of super-reads allows us to assemble combinations of illumina reads of differing lengths together with longer reads from 454 and sanger sequencing technologies, making it one of the few assemblers capable of handling such mixtures. we call our system the maryland super-read celera assembler (abbreviated masurca and pronounced mazurka). results: we evaluate the performance of masurca against two of the most widely used assemblers for illumina data, allpaths-lg and soapdenovo2, on two datasets from organisms for which high-quality assemblies are available: the bacterium rhodobacter sphaeroides and chromosome 16 of the mouse genome. we show that masurca performs on par or better than allpaths-lg and significantly better than soapdenovo on these data, when evaluated against the finished sequence. we then show that masurca can significantly improve its assemblies when the original data are augmented with long reads.following the creation of draft versions of the human genome in 2001, many small and large genomes were sequenced using first-generation (i.e. sanger) sequencing technology, with read lengths exceeding 800 bp. more recently, a variety of types of second-generation sequencing (sgs) technologies have appeared with read lengths ranging from 50400 bp. the lowest-cost sequencers today produce 100-bp reads at a cost many thousands of times lower than sanger sequencing. new assembly methods have been developed in response to the challenge of short-read assembly, and they have steadily improved in recent years. despite this progress, though, the problem of determining the sequence of a genome is far from a solved problem. virtually all assemblies published today are draft genomes with varying levels of quality, containing many gaps and assembly errors that present significant problems for scientists who rely on these genomes for downstream analysis. this article reports progress in assembling genomes facilitated by a new approach to genome assembly. first, we briefly describe the two general approaches that have been used for assembly of whole-genome shotgun sequencing data. overlaplayoutconsensus (olc) assembly. briefly, the olc paradigm first attempts to compute all pairwise overlaps between reads, using sequence similarity to determine overlap. then an olc algorithm creates a layout, which is an alignment of all overlapping reads. from this layout, the algorithm extracts a consensus sequence by scanning the multiread alignment, column by column. most assemblers for sanger sequencing data, including celera assembler , pcap , arachne and phusion , are based on the olc approach. two of the main benefits of the olc approach are flexibility with respect to read lengths and robustness to sequencing errors. to improve the likelihood that apparent overlaps are real (and not repeat-induced), olc algorithms typically require them to exceed some minimum length, e.g. the celera assembler requires overlaps of 40 bp or longer, allowing for a small error rate (12) in the overlapping region. to compensate for shorter read length and lack of uniformity in coverage, sgs de novo assembly projects typically generate 100 times as many reads as sanger-sequencing projects; e.g. the original human and mouse projects generated $35 million reads each, whereas recent human sequencing projects generated 34 billion reads. the de bruijn graph approach avoids the pairwise overlap computation entirely, which is one reason why it has become the leading method for sgs assembly. to whom correspondence should be addressed.the de bruijn graph approach. the de bruijn graph assembly algorithm was pioneered by), who first implemented these ideas in the euler assembler . although euler was designed for sanger reads, the same general framework has been adopted recently by programs for assembling sgs data, and for illumina read data in particular. recently developed assemblers that use the de bruijn strategy include allpaths-lg , soapdenovo , velvet , euler-sr and abyss . this approach begins by creating a de bruijn graph from the read data, as follows. for a fixed value k, every substring of length k (a k-mer) from every read is assigned to a directed edge in a graph connecting nodes a and b. nodes a and b correspond to the first and last k-1 nucleotides of the original k-mer. any path through the graph that visits every edge exactly once, formally known as an eulerian path, forms a draft assembly of the reads. in practice, these graphs are complex with many intersecting cycles, and many alternative eulerian paths, and therefore creating the graph is merely the first small step in creating a good draft assembly. complete assembly requires incorporating mate pair information into the graph and attempting to disentangle the many complex cycles created by repetitive sequences. because the k-mers are shorter than reads, the graph contains less information than the reads, so the reads need to be retained for later use in disambiguating paths in the graph. the main benefit of this approach is its computational efficiency, which it gains from the fact that the immense number of overlaps is not computed. the main drawbacks are loss of k-mer adjacency information in the graph and spurious branching caused by errors in the data. super-reads, a new alternative. in this article, we propose a third paradigm for assembly of short-read data, based on the creation of what we call super-reads. the aim is to create a set of super-reads that contains all of the sequence information present in the original reads despite the fact that there are far fewer super-reads than original reads. for the ideal error-free case, see the theorem below. the basic concept of super-reads is to extend each original read forwards and backwards, base by base, as long as the extension is unique. the concept can be explained as follows. we create a k-mer count look-up table (using an efficient hash table) to determine quickly how many times each k-mer occurs in our reads. given a k-mer found at the end of a read, there are four possible k-mers that could be the next k-mer in a genomes sequence: these are the strings formed by appending a, c, g or t to the last k-1 bases in the read. our algorithm looks up, which of these k-mers occur in the table. if only one of the four possible k-mers occurs, we say the read has a unique following k-mer and we append that base to the read. we continue until the read can no longer be extended uniquely; i.e. there is more than one possible continuing base, or we have reached a dead end and no base is permissible. we perform this extension on both the 3 0 and 5 0 ends of the read. the new longer string is called a superread. many reads extend to the same super-read as shown in. notice that if two reads have an interior difference by even one baseas, for example, would occur if they derived from two non-identical repeats or from two divergent haplotypesthen they will generate distinct super-reads. of course super-reads can easily be computed using a de bruijn graph. the point is that once the super-reads are created, theytogether with mate pairs that connect super-readscollectively replace the de bruijn graph. incorporation of mate-pair information is carried out using the olc assembly step described below. the two most important properties of the super-read data computation are as follows: each of the original reads is contained in a super-read (so no information has been lost); and many of the original reads yield the same super-read, so using super-reads leads to vastly reduced dataset. hundreds of times fewer super-reads than reads. masurca uses a modified version of the cabog assembler , for the overlap-based assembly following superread construction. in creating its fundamental unit of unitigs, cabog uses only maximal reads, i.e. reads that are not proper substrings of other larger reads. in principle, this could cause assembly errors but in practice they seem to be rare. because of this practice, we carry out one extra step: the only super-reads we use are maximal super-reads, i.e. those that are not exact substrings of another super-read. we then assemble the maximal super-reads along with other available data including mate pairs with the modified cabog assembler. the other data include jumping libraries and possibly 454 read data and sanger read data and mate pairs. we observe that the coverage of the genome by maximal super-reads typically varies from $23, independent of whether the raw read coverage is 50, 100 or even higher. note that each heterozygous single nucleotide polymorphism increases the number of super-reads. for a haploid genome, super-reads will tend towards 2 coverage, whereas for highly heterozygous diploid genomes the super-read coverage may be closer to 4. in the two example genomes described in the results section, rhodobacter sphaeroides and mus musculus, the reads outnumber the maximal super-reads by factors of $400 and 300, respectively. the n50 lengths for the super-reads themselves are 3314 and 2241 bp, respectively. masurca automatically chooses the k-mer size for creating super-reads, and in these two cases, k is 33 and 69, respectively. the following theorem lays the theoretical foundation of equivalence of assemblies made from the original reads and the super-reads for the case of perfect error-free reads.the super-reads theorem for the ideal case of perfect (error-free) reads. to understand the underpinnings of the super-reads approach, we consider the simplest case. here we ignore mate pairs. the above construction of super-reads is based on a fixed k-mer size, so for clarity we can call them k-super-reads. the genome is a collection of strings (chromosomes) and loops (plasmids or organelles) with a four-letter alphabet. to avoid end effects, we assume that all dna in the genome is circular, as is often the case for bacteria, but we shall still speak of their substrings. a string (read or super-read) is called perfect if it is identical to a substring of the genome. such a substring of the genome together with its coordinates is called a placement. a string may have multiple placements. we say that a set of strings r is k-perfect with respect to a genome g if (i) every base of the genome g is covered by some placement, and (ii) adjacent placements overlap by at least k bases. when a set of reads is k-perfect, we can distill the information in the reads by the usually much smaller set of k-super-reads. the following result says that k-super-reads contain all of the information in the reads. theorem. assume a set of reads is k-perfect for some genome g. then the corresponding set of k-super-reads has the same property.in other words, the set of super-reads contains all of the information in the reads, and they have introduced no errors. the proof follows from the construction of super-reads. because each read is contained in a super-read, no data are lost. at the same time, if the original read data are inadequate for deducing what the genome is, then so are the super-read data. if both flanks of some copy of the repeat were not covered in the read set, there would be no maximal k-super-read that could be placed at that copy of the repeat. in practice reads are not perfect, and because the super-reads can only represent the information in the original reads, there will always be some super-reads that contain errors that were in the original reads. the task of the assembly algorithm used downstream of super-reads is to detect and correct most of the errors and create a mostly correct assembly. assemblers have long been designed to do exactly that, because reads used in assembly projects were never assumed to be perfect. the masurca assembler benefits from the advanced assembly techniques in the cabog assembler for creating contigs and scaffolds from super-reads.velvet the best performers in gage were allpaths-lg and soapdenovo. hence, we have included those two programs for comparison with masurca 2.0. for a more recent comparison one should see the gage-b competition . it reports on assemblies of 12 bacterial genomes by abyss, cabog, masurca 1.8.3, mira v3.4.0 , soapdenovo, spades v2.3.0 and velvet. masurca 1.8.3 produced the best assemblies for the majority of the 12 species. spades did well, especially on 250-bp reads, but is not designed for larger genomes. allpathslg was not used in that competition because it requires two libraries, whereas this test had only one library per species. evaluating the assemblies. we evaluated the performance of the assemblers using two separate techniques. we evaluated the contigs using the recently published quast 2.1 software . in the tables below, we report the contig sizes in terms of nga50 reported by quast. the nga50 size is defined as the value n such that 50 of the finished sequence is contained in contigs whose alignments to the finished sequence are of size n or larger. note that nga50 differs from n50 in that n50 is defined by the total size of the assembled contigs, whereas nga50 is defined by the actual size of the genome itself. if the assembly size is close to the true genome size, then n50 and nga50 are roughly equivalent. quast does not report the scaffold statistics in the way we would prefer to look at them. in evaluating the scaffolding, we look for the correct order and orientation of the contigs and contiguity of the coverage allowing for reasonable (shorter than a longest mate pair) gaps. thus we evaluated the scaffolds separately by mapping them to the finished sequence using nucmer . we then clustered the matches of each scaffold to the finished sequence based on proximity of the matches in terms of finished sequence coordinates. within each cluster of the matches of the scaffold to the finished sequence, we required that the matches are in the same order in terms of finished sequence and scaffold match coordinates (no rearrangements), same orientation and the distance between the consecutive matches is smaller than 40 kb (the size of the longest library) for the mouse genome and 3.5 kb for the bacteria. then we counted the number of clusters and the number of the scaffolds. the number of scaffold misassemblies is the difference between these two numbers. we defined nga50 for the set of scaffolds as the value n such that 50 of the finished sequence is spanned by clusters where the span of each individual cluster is of size n or larger. bacteria genome assembly. for the first comparison, we chose two illumina datasets: (i) a paired-end library (i.e. pe), in which reads were generated from both ends of 180-bp dna fragments (sra accession srr081522), and (ii) a jumping library in which paired ends were sequenced from 3600-bp fragments, (sra accession srr034528). we randomly down-sampled both libraries to 45 genome coverage. for lr we used 59 211 sanger reads, with average length 772 bp, from the national center for biotechnology information (ncbi) trace archive entry for r.sphaeroides str. 2.4.1 . the sanger reads provided $10 genome coverage. for our experiments, we used randomly down-sampled lr datasets of 1, 2 and 4 coverage. the data are summarized in supplementary table s1. the parameters used for the allpaths-lg, masurca and soapdenovo2 assemblies are described in the supplementary material. because the creation of super-reads is critical in the masurca design, we first present the analysis of the number and correctness of the super-reads. for this dataset, masurca reduced the original 2 050 868 paired-end reads to 5168 super-reads, a reduction by a factor of almost 400. in addition to those, the masurca submits tobp, the minimum size was 33 bp, and the longest super-read was 13 283 bp. the total amount of sequence in super-reads was 9 138 989 bp, $2 coverage of the genome. to determine how well the (maximal) super-reads agreed with the genome, we mapped the super-reads to the finished sequence by nucmer using a k-mer seed size of 15 (parameters:-l 15-c 32 maxmatch). the total number of bases in the super-reads that matched the finished sequence was 9 106 770 in 4845 super-reads. a total of 99.2 of the matching bases were in at least one of 4673 super-reads that matched with at least 99 identity over at least 99 of their length. the remaining 323 super-reads that did not match the finished sequence contained 32 219 bp of sequence, and their maximum size was 150 bp. we examined the reads that were used to produce the non-matching super-reads and could not find a match to the genome of length !32 bp in any of these reads. it is likely that these reads primarily contained adapter sequences with errors or other contaminantsshows the comparison of the performance of the masurca assembler with the others on the r.sphaeroides dataset. the masurca assembler using only illumina data performs on par with allpaths-lg, with nearly identical nga50 sizes, two fewer contig errors and two more scaffold errors. all scaffold errors were in small scaffolds whose sizes were well below the n50 scaffold size and this did not influence the nga50 scaffold size. moreover, the performance of masurca on illumina data alone is comparable with performance of cabog on only the sanger (long-read) data. although soapdenovo2 had the smallest number of contig errors (5), its contigs were significantly smaller than those produced by the other assemblers. as we introduced additional coverage by lr into the mix, the assemblies produced by masurca assembler become superior in contiguity to all other assemblers (bottom three rows of). in particular, the contig n50 value increased from 41.4 to 52.7 kb with just 1 sanger data, and to 228 kb with deeper 4 sanger data. we note that neither soapdenovo2 nor allpaths-lg allows for mixed datasets of this type. mouse genome assembly. to save time and to allow for more detailed examination of the results, we created a restricted dataset for a single chromosome of the mouse genome, chromosome 16 (mmu16). we downloaded the same data for the mouse genome as was used in the evaluation of allpaths-lg , which are available from the ncbi sra under the study mouse_b6_genome_on_illumina. these sequences were generated from mouse strain c57bl/6j, the same strain used for the finished mouse sequence (mouse genome). we mapped the reads to the finished sequence for the entire mouse genome using bowtie2 , allowing up to five best hits of identical quality for each read. we then extracted the reads whose best hit either for the read or for its mate was in chromosome 16. we also downloaded the original sanger reads from ncbi trace archive (mouse genome), and mapped them against the finished sequence. masurca does not require the lr to be mated, and we excluded mate-pair information for these reads during assembly. supplementarylists the mouse datasets used in our experiments. from the paired-end dataset containing 50 million reads, the super-reads module of masurca produced 297 279 super-reads containing 210 839 005 bp, with an n50 size of 2241 bases. the reads outnumber the (maximal) super-reads by a factor of over 300. the original $45 coverage by the 101-bp paired-end reads reduced to just over 2 coverage by super-reads. in addition, the super-reads module output 940 390 linking mates from the pe library; these are paired reads that link together two super-reads. thus we reduced 50 m reads to $1.24 m super-reads and linking mates, a 40-fold reduction. after mapping the super-read sequences to the finished sequence using nucmer, we found that 209 017 737 bp in 284 179 super-reads matched mmu16. of these matching bases, 98 were contained in at least one of the 258 927 super-reads that had at least 99 identity to mmu16 over at least 99 of the super-reads length. results for the mouse assemblies are provided in. not unexpectedly, the mmu16 dataset was more challenging than the bacterial genome. for assembly with illumina-only data, the nga50 contig size for masurca assembly was twice as big compared with the allpaths-lg assembly, whereas the number of errors was 62 larger. soapdenovo2 produced small contigs with a large number of errors. the masurca assembler produced the largest scaffolds, with nga50 more than an order of magnitude larger than the allpaths-lg scaffolds and almost twice bigger than the soapdenovo2 scaffolds. masurca produced progressively larger and more accurate contigs as lr were added into the mix. additional 4 lr coverage almost doubled the n50 contig size while reducing the number of contig misassemblies by 13. the lr data did not have any mate pairs by design; thus we did not expect a significant improvement in scaffolding, however, the scaffolds improved as well. we note that for each run the same set of super-reads, jumping library reads and linking mates went into the cabog assembler; the only difference between runs was in the number of lr. as we introduced more lr, the number of assembly errors decreased, whereas the contig n50 size increased significantly.we began this project when we were faced with the prospect of assembling a 20 gbp pine tree genome with perhaps 15 billion illumina reads. that was far larger than anything that had been assembled. along the way, we have found our philosophy of reducing illumina reads to super-reads is useful. we discuss possible shortcomings and problems of our approach, as well as data problems that can result in a poor assembly if the user does not address them. we have mentioned the gage b study of bacterial genomes, in which masurca was declared highly effective. at the end of this section, we list larger genomes that have been assembled by masurca and are publicly available. overall evaluation. in tables 1 and 2, the quast nga50 contig size and the nga50 scaffold size can be viewed loosely as n50 sizes after the contigs and scaffolds have been broken at each major misassembly. when comparing two assemblies, if after breaking at errors the n50 contig or scaffold size is doubled in one assembly compared with the other while introducing fewer than twice as many errors, we believe the doubling is justified. inon illumina data only, we view allpaths as doing slightly better than masurca on scaffolds and both did significantly better than soapdenovo. note that the scaffold nga50 for allpaths and masurca are about three-fouth of the size of the genome, indicating that unlike soapdenovo, they both got the biggest chromosome in a correct scaffold. the fact that masurca has long scaffolds $3 mb after breaking at errors, and the errors occur at roughly $1 mb in spacing indicates that the errors lie near the ends of the big scaffold or in small scaffolds (in this case they all were in small scaffolds), so that the overall size of the scaffolds is not severely impacted by breaking at errors. when significant amounts of long read data are available, masurca makes use of that resource and does better. its contig sizes rise dramatically and the scaffold error rates drop. for r.sphaeroides the high gc content of the genome results in greater variability in the read coverage because of biases present in illumina sequencing technology. this case shows that good assemblies are still possible even for high (or low) gc genomes.is a better test of scaffolding, as the scaffolds are not approaching the size of the genome. masurcas scaffolds are roughly 13 times larger than allpaths while introducing only about 6 times as many errors. errors seem inevitable unless contigs and scaffolds are built conservatively and remain small. soapdenovos assembly suffers from small contigs. again, adding lr improves the assembly significantly. it is clear that even if assembler a is significantly better than assembler b on a collection of genome datasets, a may do worse than b on some datasets . here we have chosen datasets for which the pe mate pairs overlap each other, as is required by allpaths. our limited experience masurca assemblies are better if multiple pe libraries are used, varying the fragment length. generally a jumping library should also be available such as one built from 3 kb (or longer) fragments. error correction. error correction greatly simplifies the de bruijn graph and typically results in larger k-unitigs and thus larger super-reads. our algorithm works best on error-corrected reads, but is not tied to a particular error correction technique. in the masurca software package, we use the quorum error correction algorithm (marcais et al., in preparation). however, one can substitute other techniques, such as quake or hammer . data problems. a variety of problems with the input reads and libraries can reduce the quality of an assembly. one of the most common issues is mislabeled or poorly size-selected fragment libraries. for example, we have encountered jumping libraries identified as 8 kb (made from 8 kb fragments), but later found that the sequences include a mixture of pairs created from 2 to 8 kb fragments. similar problems often arise with long-distance paired reads. various explanations have been offered for this type of error, but regardless of the source, the misidentified mate pairs create difficulties when the assembler tries to place them 8 kb apart in the assembly. an examination of the assembly may reveal the problem, at which point it can be corrected and the assembly can be restarted. we have observed libraries that were designed to be longer than 5 kb but were entirely comprised of 2 kb fragments. another problem that arises with current technology is that the forward reads might be of excellent quality, but their mates (which are created in a separate run) are of far lower quality. we encountered one dataset where some of the libraries had so many errors that the assembly was better when made without those libraries. for example, when using 454 paired-end data, if the wrong linker sequence is provided to the assembler, the assembly will be severely fragmented. in general, severe fragmentation of an assembly is an indication of some kind of data error, which in turn requires a form of data debugging to fix the errors and restart the assembly. no list of possible data errors will be complete. a data diagnostic, u/k. before running an assembler, one should evaluate the quality of the input data with any tools available. one strategy that we have found useful is to count the number of unique k-mers in the reads. given a project with deep coverage, e.g. 30 or higher, any k-mers that occurs just once in the set of reads almost certainly contains at least one error. [this is the insight used by the quake error corrector (. we can compare the number of unique k-mers in forward and reverse reads as a means of evaluating the quality of the reverse reads. we can also use k-mer counts to estimate the real error rate in the read data, as follows. a sequencing error in the middle of a read is likely to result in k unique k-mers, because every k-mer containing the error will be unique. if the average number of unique k-mers per read is u, then u/k is a lower bound estimate of the average number of sequencing errors per read in the data. this estimate ignores the fact that an error near the end of a read will result in fewer erroneous k-mers, and it does not take into account cases when there are two or more errors per k-mer. the u/k value should be used as a minimum fitness criterion for the input read data: if the estimated number of errors is 423 for 100-bp reads, then it is likely that there was a problem in the sequencing run (current illumina technology usual has an error rate below 1). it may be more effective to ignore or redo a run with a high error rate than to use it for assembly. polymorphic genomes. differences between the two copies of homologous chromosomes in a diploid genome can increase the number of super-reads $2-fold. this does not usually constitute a problem as long as subsequent assembly steps handle the polymorphic super-reads. the celera assembler (cabog) will attempt to combine polymorphic regions that differ by up to 6. if the haplotype divergence rate is higher, it will result in a fragmented assembly, where many scaffolds will terminate in regions of haplotype difference. this occurs because, even though the mate pairs may suggest that two scaffolds representing two haplotypes should be merged, the contigs within those scaffolds will not align sufficiently well, and therefore the scaffolder will not make the merge. in this case, the assembly can be post-processed to split the haplotypes and create scaffolds representing both heterozygous chromosomes. available genomes assembled by masurca. masurca has been used to assemble de novo a variety of genomes, sometimes improving on published genomes using added data, sometimes creating the first publicly available draft genome for the species. below is a partial list of genomes that were recently assembled with masurca, including the types of read data used for each project:loblolly pine, pinus taeda, a 22 gbp genome, draft assembly using illumina data only, in collaboration with the pinerefseq consortium. indian cow, bos indicus, 454/illumina mixed data, in collaboration with usda/ars. rhesus macaque, macaca mulatta, sanger/illumina mixed data, in collaboration with university of nebraska.water buffalo, bubalus bubalus, 454/illumina mixed data, in collaboration with usda-ars and caspur, italy. domestic cat, felis felis, sanger/454/illumina mixed data, in collaboration with washington university. philippine tarsier, tarsier syrichta, sanger/illumina mixed data, in collaboration with washington university. fire ant, wasmannia auropunctata, 454/illumina mixed data, in collaboration with oist, japan. stalk-eyed fly, teleopsis dalmanni, 454/illumina mixed data, in collaboration with university of maryland.  
