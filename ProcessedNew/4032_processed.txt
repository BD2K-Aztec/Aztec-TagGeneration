rnaquast: a quality assessment tool for de novo transcriptome assemblies ability to generate large rna-seq datasets created a demand for both de novo and reference based transcriptome assemblers. however, while many transcriptome assemblers are now available, there is still no unified quality assessment tool for rna-seq assemblies. we present rnaquasta tool for evaluating rna-seq assembly quality and benchmarking transcriptome as-semblers using reference genome and gene database. rnaquast calculates various metrics that demonstrate completeness and correctness levels of the assembled transcripts, and outputs them in a user-friendly report. availability and implementation: rnaquast is implemented in python and is freely available atnext-generation sequencing technologies have raised a challenging problems of de novo genome and transcriptome assembly from short reads. as a result, multiple assembly tools were developed in the last decade. even though most papers describing novel assembly approaches provide benchmarking of various tools, no unified methods for assessing assembly quality were developed until recently. while multiple tools for both reference-based and reference-free genome assembly evaluation were developed and later used in various genomic studies , no tool have set a standard for assessing quality of transcriptome assemblies. although several studies provided evaluation methods or performed independent benchmarks of rna-seq assemblers , in papers describing novel transcriptome assembly software the resulting transcripts were evaluated using different in-house methods , therefore making it difficult to compare the results across various publications. we present rnaquasta quality assessment tool for transcriptome assemblies, which utilizes reference genome and gene database. rnaquast takes assembled transcripts as an input and maps them to the reference genome using either blat or gmap . by comparing the resulting alignments with the gene database, rnaquast calculates various statistics and generates a summary report. below we describe methods implemented in rnaquast, present an example of summary report and compare rnaquast with detonate software .in this section we demonstrate assembly quality metrics calculated by rnaquast and compare them with scores computed by refeval and rsem-eval from detonate software package version 1.10 . to perform the comparison we assembled m. musculus rna-seq paired-end library using the following transcriptome assemblers: trans-abyss 1.5.3 , idba-tran 1.1.1 , soapdenovo-trans 1.03 and trinity 2.1.1 . idbatran and trinity were run with the default parameters (k 20; 30; 40; 50; 60 for idba-tran and k 25 for trinity). as for trans-abyss and soapdenovo-trans, we ran both tools using various k-mer lengths and selected the best assemblies for the comparison. we used the number of 95-assembled isoforms, number of misassemblies and database coverage reported by rnaquast as the main criteria for selecting optimal assemblies. we also included contigs produced by spades 3.6.1 genome assembler , which was run in single-cell mode (due to uneven coverage of rna-seq data) with the default k-mer lengths (k 21, 33, 55). although spades was not designed as a transcriptome assembler, it turned out to show decent results on rna-seq data. we included the most important metrics from the reports produced by rnaquast and detonate and presented them in. rnaquast was launched with the default parameters; ref-eval and rsem-eval were run as recommended in the user manual (http://deweylab.biostat.wisc.edu/detonate/vignette.html). command lines that were used to run all tools are provided in the supplementary material. although there is no direct connection between rnaquast metrics and scores reported by the detonate software (seefor the details),shows that they mostly have a good correlation. to ease the comparison with detonate, we also added the number of 99-assembled isoforms, since ref-eval uses the 99 threshold for calculating contig scores.demonstrates that trans-abyss assembly has the largest number of 50-assembled isoforms and the highest database per nucleotide coverage, and at the same the highest contig recall value. on the other hand, trans-abyss has the largest fraction of unaligned (10) and unannotated (25) transcripts, which correlates with the lowest contig precision reported by ref-eval. idba-tran assembly, conversely, has the highest fraction of 50/95-matched transcripts (76 and 82 respectively), but the lowest database coverage, which correlates with the highest contig and nucleotide precision, and rather low contig, nucleotide and k-mer recall values. soapdenovo-trans generates an accurate assembly in terms of number of misassemblies, mismatch rate and nucleotide precision, but its assembly appears to be rather fragmented (almost 77 of transcripts are shorter than 500 bp, the smallest number of 50/ 95/99-assembled isoforms). similarly, trans-abyss assembly also contains a lot of short sequencesabout 83 of assembled transcripts are shorter than 500 bp. trinity and, surprisingly, spades have relatively high database coverage and recall metrics, and the same time assemble the largest number of 95/99-assembled isoforms. however, both tools generate rather high number of misassembled contigs with spades having approximately twice more misassemblies than trinity. elevated number of misassembled contigs in spades assembly can be explained by the fact that spades is a genome assembler and has no specific algorithm for detecting transcripts in the de bruijn graph during assembly.  
