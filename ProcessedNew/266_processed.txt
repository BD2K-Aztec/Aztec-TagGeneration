an accurate paired sample test for count data motivation: recent technology platforms in proteomics and genomics produce count data for quantitative analysis. previous works on statistical significance analysis for count data have mainly focused on the independent sample setting, which does not cover the case where pairs of measurements are taken from individual patients before and after treatment. this experimental setting requires paired sample testing such as the paired t-test often used for continuous measurements. a state-of-the-art method uses a negative binomial distribution in a generalized linear model framework for paired sample testing. a paired sample design assumes that the relative change within each pair is constant across biological samples. this model can be used as an approximation to the true model in cases of heterogeneity of response in complex biological systems. we aim to specify the variation in response explicitly in combination with the inherent technical variation. results: we formulate the problem of paired sample test for count data in a framework of statistical combination of multiple contingency tables. in particular, we specify explicitly a random distribution for the effect with an inverted beta model. the technical variation can be modeled by either a standard poisson distribution or an exponentiated poisson distribution, depending on the reproducibility of the acquisition workflow. the new statistical test is evaluated on both proteomics and genomics datasets, showing a comparable performance to the state-of-the-art method in general, and in several cases where the two methods differ, the proposed test returns more reasonable p-values. availability: available for download at http://www.oncoproteomics.nl/.recent technology platforms in proteomics and genomics produce count data for quantitative analysis. in proteomics, the number of ms/ms events observed for a protein in the mass spectrometer has been shown to correlate strongly with the proteins abundance in a complex mixture . in genomics, next-generation sequencing technologies use read count as a reliable measure of the abundance of the target transcript . statistical analysis of count data is therefore becoming increasingly important. previous works using a beta-binomial model or a negative binomial model have focused on an independent sample setting. nevertheless, consider a study where data are measured from each patient before and after treatment. the measurements are no longer independent. another frequently used design is to compare the gene/protein expression levels between matched pairs of cancer and to whom correspondence should be addressed. normal tissues. these experimental designs require paired sample testing such as the paired t-test used for continuous measurements. due to the lack of a proper statistical test, recent efforts in proteomics (van) and genomics have resorted to calculating fold changes within each sample and subsequently using a rule-based system to identify differential markers. the rules have to take into account such issues as difference in variation at regions of low and high abundance. while this approach might be applicable for a discovery study with a small sample size (e.g. n = 3 pairs), it possesses no concept of statistical significance for generalized inference. in this article, we aim to develop a statistical method for analysis of paired samples for count data. for ease of presentation, we consider an experiment in which each sample pair consists of a pre-treatment measurement and a post-treatment measurement. one is interested in the relative change in abundance due to the treatment for each protein across biological samples. to this end, we derive from each protein in each sample pair a 22 contingency table containing a pre-treatment count and a post-treatment count as well as total sample counts for normalization. the treatment effect and statistical significance can be computed using the fishers exact test or the g-test for each contingency table. however, combining information from multiple tables to obtain a common effect and a confidence estimate is non-trivial, and has been a central problem in the field of meta-analysis. this article proposes a new technique to estimate a common effect and significance analysis for multiple contingency tables. the method uses ratio of two poisson distributions, leading to a binomial distribution parameterized by a single random effect variable. the random effect is subsequently modeled with an inverted beta distribution, resulting in an inverted beta binomial model for the observed count data. the new statistical test is therefore called the inverted beta binomial test. the article is organized as follows. section 2 presents mathematical notations, the concept of common treatment effect and previous approaches to the problem. section 3 presents the new statistical test and its implementation. experimental results are presented in section 4. section 5 concludes this article.this article addresses the problem of significance analysis for paired samples with count data. this type of statistical testing arises, for example, in studies where one is interested in a treatment effect or when one plans to correct for differences in genetic background by using matched cancer/normal tissues. by formulating the problem in the framework of combining contingency tables, we can use a large body of literature in statistical meta-analysis. for instance, the forest plot, a frequently used visualization method in meta-analysis, offers a dedicated visualization tool for paired sample tests. we have proposed a novel statistical test using an inverted betabinomial distribution, explicitly separating technical variation from biological variation. this is in contrast to a state-of-the-art technique, an extension of the edger method, which models total variation with a negative binomial distribution. experimental results on a proteomics dataset and a genomics dataset demonstrate that ibb is a considerable alternative to the extension of edger as it tends to favor unidirectional regulation. technical variation modeled by the ibb test can be adapted to account for over or under dispersion using an exponentiated poisson distribution. in theory, one should examine the acquisition platform from independent studies to accurately capture the technical variation. this is, however, not always possible in practice since typically data acquisition comprises of several steps in a complex workflow, in which technology platforms such as a mass spectrometer or a sequencer play a part only. hence, one needs to make assumptions about the data generative mechanism, for which the standard poisson distribution provides a reasonable approximation and is a common practice. deviating from the standard poisson distribution should be treated with special care. a generalized linear mixed model (glmm) is a natural statistical framework to account for random effect . the main difficulty with model fitting in glmm is that the likelihood function does not have a closed form and thus one has to resort to complicated numerical methods for optimization , similar to the challenge we face with ibb. we have shown that for one-dimensional integration, approximation by a numerical quadrature is efficient and accurate. in addition, when i601  
