automated detection and tracking of many cells by using 4d live-cell imaging data motivation: automated fluorescence microscopes produce massive amounts of images observing cells, often in four dimensions of space and time. this study addresses two tasks of time-lapse imaging analyses ; detection and tracking of the many imaged cells, and it is especially intended for 4d live-cell imaging of neuronal nuclei of caenorhabditis elegans. the cells of interest appear as slightly deformed ellipsoidal forms. they are densely distributed, and move rapidly in a series of 3d images. thus, existing tracking methods often fail because more than one tracker will follow the same target or a tracker transits from one to other of different targets during rapid moves. results: the present method begins by performing the kernel density estimation in order to convert each 3d image into a smooth, continuous function. the cell bodies in the image are assumed to lie in the regions near the multiple local maxima of the density function. the tasks of detecting and tracking the cells are then addressed with two hill-climbing algorithms. the positions of the trackers are initialized by applying the cell-detection method to an image in the first frame. the tracking method keeps attacking them to near the local maxima in each subsequent image. to prevent the tracker from following multiple cells, we use a markov random field (mrf) to model the spatial and temporal covariation of the cells and to maximize the image forces and the mrf-induced constraint on the trackers. the tracking procedure is demonstrated with dynamic 3d images that each contain 4100 neurons of c.elegans.fluorescence microscopy imaging of live cells has been a powerful tool for studying cellular and molecular dynamics in many applications . automated microscopes generate vast numbers of images of the observed cells, and the images are often in four dimensions of space and time. the cells in these images are densely distributed, move rapidly and are often similar in appearance. it is thus impossible in practice to manually track hundreds of such cells as their movement is captured in a sequence of images. this has led to growing interest in computational methods that can automatically detect and track multiple moving cells . the appearance of imaged cells can vary from globular to more complicated forms. they move independently, or sometimes their movement is coordinated. cell tracking methods have been developed for particular cases of interest. in general, tracking procedures consist of two steps: (i) relevant objects are segmented from the background in each frame by using, for example, the watershed algorithm , and (ii) each of the segmented objects is then linked to the nearest object in the subsequent frame . to reduce the number of failures in the process of matching nearest neighbors, closeness is defined not only on the spatial distance between the objects, but also on other available information, such as variations in volume, morphology, intensity and other features . the integration of such information is essential when the imaged cells move in a complex manner. however, in several studies, such information is limited or even unavailable. for instance, when fluorescent cells are much smaller than the optical resolution of microscopes, it is difficult to evaluate morphological features because most objects have similar appearances. this is especially true when the objects have inherently similar shapes, are closely spaced, and are barely distinguishable from the background. in such cases, tracking must be done using only the central coordinates of the cells. this study tackles the problem of tracking many cells while relying only on the central coordinates. the cells of interest appear as slightly deformed ellipsoidal forms. in addition, they move rapidly in coordination with one another. widely used tracking methods, such as nearest matching methods , particle filters and graph-based optimization , often fail because trackers change from the followed target to a different one (turnover) or because two or more trackers coalesce on the same target during rapid moves. one way to overcome such difficulties is to utilize a spatiotemporal pattern to whom correspondence should be addressed. the author 2014. published by oxford university press. this is an open access article distributed under the terms of the creative commons attribution non-commercial license (http://creativecommons.org/licenses/ by-nc/3.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. for commercial re-use, please contact journals.permissions@oup.com of covariation for the moving cells. in conventional methods, in which the trackers follow each object individually, many such turnovers and coalescences occur in the transition of objects. in particular, when using nearest neighbor matching of segmented objects, the occurrence of only a few turnovers can trigger a series of many tracking failures. however, when cells are known to move in a coordinated way and the transition pattern is modeled, such errors can be corrected by successful trackers, which can return the failed trackers to their correct positions. in other words, unlike the independent tracking of multiple cells, the performance is enhanced by allowing the trackers to interact cooperatively by sharing the direction and distance of the moves. the present method aims to improve the tracking performance by utilizing the spatiotemporal covariation of the moving cells. the proposed method relies on the kernel density estimation (kde) and several optimization modules. it begins by using kde to convert each image to a smooth, continuous density function in 3d space. the cells in the image are assumed to appear as slightly deformed ellipsoidal forms and to lie in the regions around the local maxima of the density functions. the tasks of detecting and tracking the cells are addressed by using hill-climbing algorithms for the continuous functions. for detecting the cells, we introduce a new optimization method, the repulsive parallel hill-climbing (rphc) algorithm, which detects all of the existing local maxima and thus reduces the chances of failing to detect the darker and smaller objects. the trackers are initialized at the detected positions in the first frame. the tracking algorithm keeps them near the local maxima, which change with time. to prevent the trackers from turnovers and coalescences, we used a markov random field (mrf) prior to model the spatial and temporal covariation of the moving cells. by using the mrf-induced cooperation, the present method tries to keep the trackers near to the varying local maxima of the density functions by optimizing the image forces under a constraint on the covariation of the objects. the present method is an extension of, which proposed similar tracking methods based on the particle filter and mrf priors. they aimed to track the movements of several tens of targets interacting with each other. this study differs from their works in the prior construction as shown in later. in addition, this study is conducted for a much larger number of targets, e.g. several hundreds of cells, while the motions of targets are more strongly correlated than those considered by the previous studies. the tracking procedure will be demonstrated below with data that we acquired from live imaging of neuronal nuclei of caenorhabditis elegans.  
