bioimage informatics app2: automatic tracing of 3d neuron morphology based on hierarchical pruning of a gray-weighted image distance-tree motivation: tracing of neuron morphology is an essential technique in computational neuroscience. however, despite a number of existing methods, few open-source techniques are completely or sufficiently automated and at the same time are able to generate robust results for real 3d microscopy images. results: we developed all-path-pruning 2.0 (app2) for 3d neuron tracing. the most important idea is to prune an initial reconstruction tree of a neurons morphology using a long-segment-first hierarchical procedure instead of the original termini-first-search process in app. to further enhance the robustness of app2, we compute the distance transform of all image voxels directly for a gray-scale image, without the need to binarize the image before invoking the conventional distance transform. we also design a fast-marching algorithm-based method to compute the initial reconstruction trees without pre-computing a large graph. this method allows us to trace large images. we bench-tested app2 on $700 3d microscopic images and found that app2 can generate more satisfactory results in most cases than several previous methods. availability: the software has been implemented as an open-source vaa3d plugin. the source code is available in the vaa3d code repository http://vaa3d.org.3d reconstruction of complex neuron morphology from lightmicroscopic images is an important technique for computational neuroscience. it has received considerable attention in recent years, such as in the diadem competition that involved $100 teams worldwide and many related studies (e.g.). however, despite a number of developed algorithms of neuron reconstruction (also called neuron tracing), it remains a significant problem how to trace neurons in a robust and precise way from real 3d microscopic images. automation of neuron tracing for complex neuron morphology and low quality image data has been previously discussed in the all-path-pruning (app) method . the key idea of app is to generate an initial reconstruction that covers all the potential signal of a neuron in a 3d image, followed by a linear-time pruning of unneeded branches until a least compact representation is produced while the coverage of all neuronal signal is maintained. in this study, we present a new version of the app algorithm, called app2 , with the goal to generate a more accurate and robust reconstruction within a shorter amount of time. to attain this goal, we develop new algorithms in three components:(i) a method to generate distance transform of the neuron signal from gray-scale image directly, without thresholding-based binarization ;(ii) a method to generate the initial reconstruction ; (iii) a hierarchical pruning method to produce the final reconstruction . compared with app, all three components of app2 are novel, especially the pruning process for where app2 is much more efficient than app. the distance-transform step and the initial reconstruction step of app2 are useful enhancement and can also be used for app essentially. therefore, to evaluate the efficiency of our algorithms, we compared the tracing results with the gray-weighted distance transform (gwdt) or without gwdt. we also compared the result of app2 and app methods. to examine the robustness of our algorithm, we used signal deletion tests. we also tested our algorithms on many datasets from different sources, including a diadem dataset and many other more challenging datasets of fruit fly and dragonfly neurons that have heavy noise. in our experiments, we have found that in most cases, app2 is able to produce a reasonable tracing result within a short amount of time, usually within seconds for a large 3d image. our new results are often better than those generated using several other existing competitive methods. to whom correspondence should be addressed. y the authors wish it to be known that, in their opinion, the first two authors should be regarded as joint first authors.  
