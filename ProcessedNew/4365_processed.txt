sphinxâ€”an algorithm for taxonomic binning of metagenomic sequences motivation: compared with composition-based binning algorithms, the binning accuracy and specificity of alignment-based binning algorithms is significantly higher. however, being alignment-based, the latter class of algorithms require enormous amount of time and computing resources for binning huge metagenomic datasets. the motivation was to develop a binning approach that can analyze metagenomic datasets as rapidly as composition-based approaches, but nevertheless has the accuracy and specificity of alignment-based algorithms. this article describes a hybrid binning approach (sphinx) that achieves high binning efficiency by utilizing the principles of both composition-and alignment-based binning algorithms. results: validation results with simulated sequence datasets indicate that sphinx is able to analyze metagenomic sequences as rapidly as composition-based algorithms. furthermore, the binning efficiency (in terms of accuracy and specificity of assignments) of sphinx is observed to be comparable with results obtained using alignment-based algorithms. availability: a web server for the sphinx algorithm is available atthe enormous microbial diversity prevalent in natural ecosystems represents a rich resource for discovery of hitherto unknown microbes and the novel genes/proteins they encompass. estimates reveal that 99 of these microbes cannot be easily cultured in the laboratory . the rapidly growing field of metagenomics directly investigates this microbial diversity by obtaining and sequencing the entire genomic content present in any given environmental sample . since majority of these organisms in environmental samples belong to hitherto unknown taxonomic groups, one of the biggest challenges for computational biologists is not only just to catalog the known organisms, but also to identify to whom correspondence should be addressed. and characterize new organisms belonging to known or unknown taxonomic groups. these organisms could belong to an entirely new species or genus or family or order or class or even a new phylum. researchers typically catalog taxonomic diversity (a process referred to as binning) by using computational methods that identify the taxonomic affiliation of all the sequences obtained from a given environmental sample. sequences sharing the same taxonomic label are subsequently grouped (binned) together. accurate binning of metagenomic sequences is a crucial step in any metagenomics project since wrongly binned sequences will affect/hinder in the downstream analysis of many subsequent steps, such as sequence assembly, gene prediction and functional annotation, etc. existing binning algorithms assign a sequence to a particular taxon/clade if features of the sequence are similar to sequence(s) belonging to that taxon/clade. the extent to which these features are similar determines not only the accuracy, but also the specificity of assignment (the taxonomic level at which the sequence is assigned). besides, binning methods are challenged by sequences generated by current sequencing technologies, such as 454 and illumina. the short lengths of sequences (35100 bp) produced using these sequencing technologies make it difficult to identify features which are similar between sequences from closely related organisms and are distinct from those from distant organisms. one class of features used by binning algorithms is based on the similarity of the compositional characteristics of the query and the target sequences. a few examples of compositionbased binning algorithms published in recent years include phylopythia , tacoa and phymmbl . phylopythia utilizes support vector machines and uses oligonucleotide frequencies as training features to initially build organism/clade-specific classifiers. these classifiers are subsequently used for assigning a query sequence to an organism/clade whose genome(s) is/are most similar to the query (with respect to oligonucleotide usage). however, svm-based classifiers used by phylopythia are not robust enough to predict the taxonomic labels of short query sequences having lengths 1000 bp. as a result, in addition to most of the short sequences remaining unclassified, this method has a high misclassification rate. another composition-based binning algorithm, namely tacoa, also uses oligonucleotide frequencies as features for building organism-specific models . based on the gc content of a genome, tacoa builds a genome model, represented in the form of a vector. the elements of these vectors contain the ratiothe summarized binning results obtained with sphinx, sortitems, megan and tacoa (for all four validation datasets) are given in supplementary table 3. a graphical representation of these results is illustrated in. as mentioned previously, these results were generated using the ffn database in clustered (sphinx) and unclustered formats (sort-items, megan and tacoa). the results of sphinx, sort-items and megan obtained with ffn database are referred to as results with sphinx-ffn, sort-items-ffn and megan-ffn, respectively. results of sphinx obtained using a reference database containing both coding and non-coding regions are referred to as results with sphinx-fna.current alignment-based binning methods depend on exhaustive database searches. performing such exhaustive database searches for millions of sequences (present in typical metagenomic samples) would take enormous amounts of time. this hinders research groups having modest computational resources from using similarity-based binning methods. the hybrid approachsphinx presented in this article addresses this issue by adopting a reduced search-space approach. using this approach, sphinx achieves a 15-to 20-fold reduction in the time taken for binning, compared with other binning approaches which depend on exhaustive database searches . on a single desktop with modest specifications (intel xeon quad core, 4 gb ram), sphinx-fna takes just about 88 h for binning 1.6 million sequences of the mouse gut metagenome. binning the same set of sequences using sphinx-ffn would have further reduced the time to an estimated 2024 h without significant loss in accuracy and specificity. in contrast, exhaustive search approaches (against the same database) would require an estimated 6 weeks for completing the same task. furthermore, validation results of sphinx obtained with simulated datasets indicate that the binning efficiency of sphinx matches those obtained with alignment-based binning algorithms, which depend on the output of exhaustive database searches (e.g. sort-items). an examination of the results obtained for the same set of sequences with different variants of databases indicate highest binning efficiency (in terms of accuracy and specificity) with the sphinx-fna database variant since it contains fragments originating from both coding and non-coding regions (including fragments spanning both these regions) of completely sequenced genomes. however, results of sphinx obtained with a databasevariant devoid of fragments spanning coding and non-coding regions (referred to as sphinx-c-nc in supplementary) indicate that using such a database variant results in an increase in taxonomic assignments at non-specific levels, as well as, an increase in the percentage of wrong assignments (as compared with the sphinxfna variant). these results show that the most optimal results are obtained using the sphinx-fna database variant. since our observations with clustered and non-clustered variants of the ffn database indicate no significant loss in binning efficiency using a reduced search-space strategy, it will be beneficial to adopt the latter strategy even for the nr database (which is more comprehensive in terms of having sequences even from partially characterized genomes in addition to sequences from completely sequenced genomes). this will help in significantly reducing the overall time taken by alignment-based binning approaches. the quality of reference database clusters is an important factor that determines the binning specificity and accuracy of the sphinx algorithm. though this study adopted the k-means clustering approach, in principle, any other clustering method that can efficiently segregate dna sequences (of varying oligonucleotide composition) in feature vector space can be applied to the current workflow of sphinx. the k-means clustering approach adopted in the present study takes only about 4 h on a simple desktop to cluster approximately 1.9 million vectors corresponding to coding sequences of 952 prokaryotic genomes. this includes the time taken for generating all the vectors, as well as, for obtaining the vectors corresponding to the cluster centroids. the quality of the clustered reference database is also dependent on the kmer size. a typical metagenomic sequence (obtained using existing sequencing technologies) has a length 8001000 bp. for such short sequences, the taxonomic discrimination capability achieved using lower kmer sizes is expected to be poor. on the other hand, the frequencies of various oligonucleotides obtained using large kmer sizes will be extremely low and statistically insignificant. a kmer size of 4 was used in the current study since an earlier study had demonstrated that tetra-nucleotide frequencies carry an inherent taxonomic signal . however, using kmer size of 4 limits the applicability of the current method for obtaining reliable taxonomic assignments for very short sequences, especially those obtained from sequencing technologies such as solexa and illumina. the binning efficiency of sphinx also depends on the taxonomic coverage of the clustered reference database. the clustered database used in the current study contained sequences originating from 952 completely sequenced prokaryotic genomes. as more and more genomes are being sequenced, updating the clustered database with sequences from these genomes will help in improving the quality of taxonomic assignments. updating the clustered reference database with sequences from these new genomes takes only a few minutes, since the process only involves mapping the new sequences to existing cluster centroids, and subsequently recomputing the cluster centroids. the clustered reference database used in the current study contained sequences originating from prokaryotic genomes. in principle, this database can be constructed using sequences from other taxonomic domains, such as viruses or eukaryotes. however, given that the information content in sequences originating from non-coding regions (which form major portions of eukaryotic genomes) does not conform to known patterns of taxonomic hierarchy, extending the sphinx approach to such sequences will be a challenging task. it is also difficult to bin sequencesalignment-based binning algorithms are observed to have greater binning accuracy and specificity as compared with existing composition-based methods. in this article, we demonstrate that adopting a reduced search space strategy enables one to drastically reduce the overall time taken for alignment-based binning approaches, with no significant loss of binning efficiency. this indicates the immense applicability of the proposed algorithm in rapidly mapping the taxonomic diversity of large metagenomic samples with high accuracy and specificity.  
