a new approach to bias correction in rna-seq motivation: quantification of sequence abundance in rna-seq experiments is often conflated by protocol-specific sequence bias. the exact sources of the bias are unknown, but may be influenced by polymerase chain reaction amplification, or differing primer affinities and mixtures, for example. the result is decreased accuracy in many applications, such as de novo gene annotation and transcript quantification. results: we present a new method to measure and correct for these influences using a simple graphical model. our model does not rely on existing gene annotations, and model selection is performed automatically making it applicable with few assumptions. we evaluate our method on several datasets, and by multiple criteria, demonstrating that it effectively decreases bias and increases uniformity. additionally, we provide theoretical and empirical results showing that the method is unlikely to have any effect on unbiased data, suggesting it can be applied with little risk of spurious adjustment. availability: the method is implemented in the seqbias r/bioconductor package, available freely under the lgpl license fromin the last few years, rna-seq has emerged as a promising alternative to microarrays in quantifying rna abundance. but, as microarray technology has brought with it technical challenges ranging from developing robust normalization to accounting for cross-hybridization, rna-seq presents a new set of challenges. as first noted by, a particular challenge is the often complex and protocol-specific influence of nucleotide sequence on quantification. in an ideal experiment, the number of rna-seq reads mapping to a particular position in the genome is a function of rna abundance and should not be additionally dependent on the sequence at that position. yet, this is not the case. as illustration,plots this non-uniformity in nucleotide frequencies on five datasets , each using a different protocol. to whom correspondence should be addressed.these biases may adversely effect transcript discovery, as low level noise may be overreported in some regions, and in others, active transcription may be underreported. they render untrustworthy comparisons of relative abundance between genes or isoforms, and any test of differential expression hangs on the assumption that these biases are identical between replicates, an undesirable assumption given that the causes of the bias are not well understood. additionally, in many tests of differential expression higher read count will result in higher statistical confidence. it follows that the sensitivity of such a test will also be biased by sequence, affecting downstream analysis such as gene ontology enrichment tests. this bias, though observed primarily in the 5 end of a read, is not resolved by trimming the reads prior to mapping (section 1 in supplementary material), suggesting it is not a result of erroneous base calling, and that a more sophisticated means of correction is needed.propose two models. the first is a poisson linear model, in which read counts across a transcript follow an inhomogeneous poisson process. the read count at position i within the transcript is poisson distributed with parameter i , where, log( i ) is the sum of independent weights determined by the nucleotide at each position surrounding the read start, in addition to a term capturing the abundance of the transcript. the second model is based on multiple additive regression trees, or mart . in their tests, the mart model shows a moderate improvement over the poisson linear model. both models are fit to a number of abundant test genes, requiring existing gene annotations for the reference genome. another model, proposed by, directly estimates the distribution of initial heptamers within reads, then estimates a presumed background heptamer distribution, sampled from the ends of reads. the read count at a given position is then adjusted by the ratio of the foreground and background heptamer probabilities. specifying two distributions over heptamers (i.e. foreground and background distributions) requires 2(4 7 1) = 32766 parameters, so while no gene annotations are needed to train such a model, a significant number of reads are required, and a number that increases exponentially with k, if it were desirable to model k-mers for k 7. lastly,have recently published a description of another approach, in which sequence probabilities are modeled by variable-order markov chains. the structure of these markov chains are hard-coded, chosen in advance using a hill-climbing algorithm on a representative dataset. this method is implemented in the latest. nucleotide frequencies are plotted relative to the start (labeled position 0) of each mapped read, respecting strand, and grouped by platform (illumina or abi solid). the datasets plotted here are those used for evaluation, listed in. the sequence is taken from the genomic context surrounding the read, so that 40 to 1, for example, fall outside the read sequence itself. the symmetrized kullbackleibler divergence is used to summarize the difference in nucleotide frequency compared with a fixed estimate of background nucleotide frequencies made by sampling many positions near mapped reads. under the assumption that reads are sampled uniformly from transcripts, each of the plots should be essentially flat.the protocol column lists whether a poly-a priming step to select for polyadenylated transcripts was used (mrna), or depletion of ribosomal rna with no step to select for polyadenylated transcripts (wt). version of cufflinks , and tightly incorporated into its estimation of transcript abundance, requiring either predicted or existing gene annotations. here we propose a new approach, using bayesian networks to model sequence probabilities. unlike the methods of roberts or li, our model requires no gene annotations, nor even the assumption that the short reads are derived from rna. in this sense, we build on the work done by, generalizing their approach in a way we find to be more robust and effective at correcting for bias in a variety of protocols. due to the weak assumptions required by our model, it is applicable and potentially useful in any setting in which short reads are aligned to a reference sequence.since we cannot observe directly the underlying rna abundance, our evaluation strategy relies on testing three assumptions we make of an ideal, unbiased rna-seq experiment.(1) positional nucleotide frequencies (as in), measured from reads within exons, should not differ greatly from frequencies measured by sampling uniformly within the same exons.(2) read counts across a single exon should follow, approximately, a poisson process.(3) adjusting for bias in rna-seq should increase the agreement between rna-seq and another method of quantification.evident from, the assumption of uniform read coverage often does not hold in typical rna-seq datasets. although the bias corrected read counts across the exon pictured in this example are visibly more uniform, we sought a simple, objective tests that could be applied genome-wide. to this end, we used crossvalidation tests (i.e. methods were trained and tested on disjoint subsets of the same rna-seq datasets) of a quantitative measure of the increase in uniformity of nucleotide frequencies (kullback leibler divergence in section 3.1) and increase in uniformity of read coverage (poisson regression in section 3.2). additionally, we compare rna-seq-based estimate of gene expression to quantitative real-time pcr (qrt-pcr) based estimates for the same genes, showing increased correlation between the two methods after bias correction (section 3.3). to evaluate the first two assumption, we applied our procedure (labeled bn) as well as those of) and, which are implemented in the r packages mseq and genominator, respectively, to four publicly available datasets , as well as an unpublished dataset of our own . each method was trained on data taken from chromosomes 18 of the genome from which the reads were mapped (including chromosomes 2a and 2b of the chimpanzee genome). for evaluation, we drew a set of long, highly expressed exons from the remaining chromosomes. in particular, for each reference sequence, beginning with the set of exons annotated by ensembl release 60 , we removed any exons with known alternate splice sites, then chose the top 1000 exons by read count, restricting ourselves to those at least 100 nt long. the differences in the methods being tested necessitated training procedures unique to each. the total number of reads used to train each method is listed in section 3 in supplementary material, and below we describe the procedure used for each.recommends that their mart and glm models be trained using the 100 most abundant genes. we used 1000 exons from chromosomes 18, otherwise chosen in a manner identical to that which was used to select the test exons. both the glm and mart models were trained considering the initial read position and 20 nt upstream and downstream, and otherwise using default parameters.recommends using all the reads to estimate heptamer frequencies used by their model. the training procedure works by simple tallying of frequencies. the implementation of this model in the genominator package uses a great deal of memory, and we were unable to train with the volume of data we wished, so we reimplemented the model and trained it on all of the reads aligned to chromosomes 18. we evaluated several variations of the heptamer model. the suggested method involved averaging the frequencies of the first two heptamers of each read. yet, we found that in every case, this performed worse than simply counting the frequencies of the initial heptamer, and thus we report only the latter. the background frequencies are estimated from positions 1823 in each read. our own method was trained on the 100 000 randomly selected reads from chromosomes 18, considering the initial read position and 20 nt upstream and downstream. all datasets were mapped using bowtie using default parameters against, respectively, the hg19, mm9, rhemac2 and pantro2 genome assemblies obtained from the ucsc genome browser .we have demonstrated that sequence bias can confound, sometimes severely, quantification in rna-seq experiments, and we have introduced an effective method to account for this bias without the need of existing gene annotations. the analysis provided demonstrates that our method shows significant improvement in three aspects: uniformity of read coverage, consistency of nucleotide frequencies and agreement with qrt-pcr. in our results, estimating initial heptamer frequencies was not seen to be as effective as the other models, even when data generated using random hexamer priming was used. a possible explanation is, given the large number of parameters needed to estimate heptamer frequencies (4 7 = 16383), these parameters are estimated with less accuracy than in models requiring fewer parameters. yet, we trained the 7mer model on a minimum of 1.9 million reads (section 3 in supplementary material), a number that based on theoretical results, following from work byand included in section 10 in supplementary material for completeness, suggests should lead to accurate estimates a perhaps more significant factor is that this method does not capture bias outside of the initial heptamer, though many datasets clearly are affected by bias in other positions. thus to improve the performance, it seems necessary to increase the size of the k-mers being considered. however, exponentially more reads would be required for an accurate estimate since the accuracy of the model, as quantified by its kl divergence from the true distribution, is (r 1)/2n, where r = 4 k is the number of parameters that must be estimated (section 10 in supplementary material). our method generalizes this approach, attempting to overcome this problem by using an estimation of sequence probability that requires fewer parameters and can account for bias outside of the initial heptamer. in all our tests, this approach was at least as effective as those of, despite not requiring gene annotations or manual selection of training examples. we have not performed any direct comparison to the method described byand implemented in cufflinks . though this method is superficially similar to our own, a proper comparison is difficult, as the software cannot be applied independently of estimating transcript abundance in fpkm (fragments per exonic kilobase, per million mapped reads) using cufflinks. fairness would dictate that competing methods be substituted in fpkm estimation, or that a separate interface be written to the cufflinks bias correction methodboth comparisons requiring significant effort. though the cufflinks method and our own both use graphical models to estimate sequence probabilities, we make no restriction on the graph other than acyclicity. we go to considerable effort to efficiently approximate the optimal structure for each dataset rather than using a fixed structure, as in cufflinks. a one size fits all approach likely works quite well in many cases, yet the observed specificity of the bias to protocol and platform argues against it. for example, the structures learned by our method are considerably different between those sequenced on an illumina platform versus an abi platform, and even vary within platform. during the review of this article, another method addressing sequence bias in rna-seq was published by. rather than fitting a model of the specific base-level sequence bias surrounding read start, they propose making adjustments according to summary statistics at the gene level. such an approach is disadvantaged in its inability to model the very specific pattern of sequence bias we have observed. yet, such an approach is efficient, and though we have not yet evaluated it, claimed to be effective. because we do not require annotations, chip-seq, and other high-throughput sequencing experiments, may also benefit from our model. in a preliminary investigation, we found the sequence bias in one chip-seq experiment was less than that observed in any of the rna-seq data we evaluated; however, our method is still able to effectively correct for the bias that was observed (section 7 in supplementary material). protocol differences, as we have seen, can result in significant differences in observed nucleotide frequencies, so we cannot safely assert that bias in chip-seq data is always low. given the weak assumptions made by our model, our estimation of bias could easily be incorporated into chip-seq peak-calling algorithms, and potentially improve accuracy. to determine the extent to which polymerase chain reaction amplification is responsible for the observed bias, we evaluated data from the frt-seq method proposed by. frt-seq avoids the pcr amplification step during library preparation with reverse transcription occurring on the flowcell surface. we observed that this data is not free from sequence bias, yet unlike other data generated on the illumina platform, it appears to be effected only by relatively few positions adjacent to the read start (section 8 in supplementary material). other protocol improvements might further reduce sequence bias. notably, promising work byproposes a pooled adapter strategy to deal with this issue in small rna sequencing experiments. rna-seq is most often used to compare levels of expression, and so a natural concern is the consistency of the bias between samples. in the data we examined, the bias appears to be largely, but not entirely consistent (section 9 in supplementary material). similarly, in, the three datasets sequenced on the illumina platform display similar patterns of non-uniformity, yet differ in magnitude, suggesting that batch effects in rna-seq remain a legitimate concern that should not be dismissed without evaluation. in summary, we have demonstrated a relatively simple graphical model that effectively corrects for sequence bias pervasive in rnaseq, and to a lesser extent, chip-seq experiments. in our tests, this model performs at least as well, and often better than existing methods, and involves fewer requirements or assumptions. our model leads to more accurate quantification, and would likely provide a positive benefit when incorporated into downstream analysis.  
