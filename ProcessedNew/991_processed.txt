sequence analysis classification of dna sequences using bloom filters motivation: new generation sequencing technologies producing increasingly complex datasets demand new efficient and specialized sequence analysis algorithms. often, it is only the novel sequences in a complex dataset that are of interest and the superfluous sequences need to be removed. results: a novel algorithm, fast and accurate classification of sequences (facss), is introduced that can accurately and rapidly classify sequences as belonging or not belonging to a reference sequence. facs was first optimized and validated using a synthetic metagenome dataset. an experimental metagenome dataset was then used to show that facs achieves comparable accuracy as blat and ssaha2 but is at least 21 times faster in classifying sequences. availability: source code for facs, bloom filters and metasim dataset used is available at http://facs.biotech.kth.se. the bloom::faster 1.6 perl module can be downloaded from cpan at http://search.cpan.org/palvaro/bloom-faster-1.6/ contacts:the era of personal genomics is fast approaching, as a result of which whole human genomes will be obtained on a routine basis. currently, only a fraction of such sequences contain relevant soughtafter information and the remaining sequences need to be removed. more complex datasets are also becoming increasingly available, derived from: metagenome studies that contain a mixture of genetic material from different organisms present in environmental or patient samples ; studies of dynamic methylation pattern profiles ; and sequencing of re-arranged and mutated genomes . to handle and analyse this vast amount of data requires fast, accurate and specialized methods that can align a large number of sequences onto genomes or reference sequences. the increasing need for to whom correspondence should be addressed. faster algorithms has led to the development of software such as megablast , ssaha and blast-like alignment tool for longer dna sequence reads. more recently, soap , maq , shrimp , bwa and bowtie have been developed for shorter dna sequence reads. many of these algorithms can detect single nucleotide changes. for most of these existing methods a hash-table must be built containing either the query (blast, maq and shrimp) or reference (ssaha, blat and soap) sequences; this hash-table must then be searched to align reads. one important issue in metagenomic studies is the classification of sequences as novel, or belonging to a known genome, i.e. filtering out data that has been seen before. there is a need for a fast preprocessing step that reduces the complexity of the data before more careful analysis is performed. often, it is the novel reads that are of interest and the location of other reads in their originating genomes is irrelevant. this means that alignment tools, such as those mentioned above, actually perform more computations than necessary. a bloom filter is a space-efficient data structure with fast lookup times and a manageable risk of producing false positives. it was originally developed by burton bloom in the 1970s to reduce the amount of space required to contain hash-coded information . in this article, an algorithm is described, fast and accurate classification of sequence (facss), which uses a novel scheme to classify sequence reads as belonging to one of many reference sequences or being novel. the algorithm transforms the reference sequence into bloom filters, and then the bloom filters can be queried for exact matches. this method allows rapid classification of sequences using references as large as the human genome. in this study, the facs algorithm was evaluated using a synthetic long-read metagenomic dataset and was compared to conventional methods [blat and sequence search and alignment by hashing algorithm 2 (ssaha2)] with respect to speed, sensitivity and specificity. facs was then used to analyse and remove human sequences from an experimental metagenomic dataset containing 177 184 sequences generated using a roche 454-flx sequencer. this was done in an effort to show that facs can be used to classify sequences to known genomes while reducing the complexity of the dataset and retain novel reads. for this task, facs was 21 timespage: 1596 15951600this study used a novel algorithm called facs, which utilizes the compact hash-based data structure of bloom filters for fast and accurate classification of sequences. the algorithm was optimized using a synthetic metagenome dataset generated by metasim, which consisted of 100 000 reads sampled from 19 microbial genomes, 3 viruses and 2 human chromosomes. facs was then put to the test in removing all human and mitochondrial sequences from a real metagenome dataset containing 177 184 reads generated using massive parallel pyrosequencing. the sample was derived from a molecular exploration of the human respiratory tract, searching for previously unknown viral species [data to be published elsewhere and see. of the experimental metagenome dataset, 30.9 of the sequences could be classified as belonging to either human or mitochondrial references with facs. the performance of facs was evaluated by comparing it to blat and ssaha2. the facs method was 21 and 31 times faster than blat and ssaha2, respectively, in classifying sequences in the experimental dataset while achieving comparable accuracy. this makes the facs method ideal for quickly classifying reads to genomes or large references from a complex dataset. as the number of sequences to be analysed increases the advantage of using facs compared to blat or ssaha2, in terms of speed, should be even more pronounced. the sensitivity and specificity of the filter is very dependent on the reference filter size, the k-mer size, the match cut-off and the bloom filter false positive frequency. this study has shown that a k-mer of 1721 bases and match criterion of 4055 sequence identity is adequate for analysing genomes ranging from microbial to human. however, the optimal use of the facs method should not use a constant k-mer size, but adapt it according to the size of the reference, as was the case for the experimental metagenome dataset in this study. ultimately, the choice of match criterion will depend on the desired k-mer size, reference size and the application for which the method is being used. furthermore, it was also demonstrated that the facs cut-off, although low in strict sequence similarity, is stringent and performs equally well as the match cut-off used with blat and ssaha2. this is an outcome of the different algorithms that make up each method. the match cut-offs were chosen based on their effect on the sensitivity and specificity of each method when trained on the synthetic metagenome dataset. this was conducted in an effort to find the best match cut-off possible for each method and reduce the risk of bias. the results for both the synthetic metasim dataset and the experimental metagenome dataset, when using the human mitochondrial reference, showed relatively few unique reads for each method. this is due to the reasonably well-behaved simulated reads and small reference genomes making it relatively easy to analyse. conversely, when using the human genome as a reference for the experimental metagenome dataset, the number of unique reads classified by each method increased substantially. this change reflects the complexity of the human genome and a certain bias of each method. of the reads unique to blat/11occ and ssaha2/skip2, 49 were shorter than 61 bases. this explains some of the differences between the facs, blat and ssaha2 methods, since facs did not consider reads shorter than 61 bases in this study. some low-complexity reads will not be considered by blat or ssaha2, while facs does not have any low-complexity filter. however, both ssaha2 and blat classifies more lowcomplexity reads than facs. it was interesting that facs was so insensitive to low-complexity reads even though it does not have any low-complexity filter. furthermore, classifying low-complexity reads with facs does not take any additional time compared to an ordinary sequence, unlike blat that uses a binary help file 11occ to avoid analysing low-complexity reads and ssaha2 which ignores k-mers that are abundant in the genome, in order to increase speed. since the reference genomes in the synthetic metagenome dataset were not repeat-masked before metasim sampled them, 6000 sequences consisted mostly of n:s (uncalled bases) from the genome assemblies. facs will try to classify these sequences but they were excluded from the analysis for blat and ssaha2 since neither method will try to align them. that so many unique reads are found using each method leads to further questions: how many methods are needed for complete classification? how stringent must match criteria be to make certain that the classified reads belong to the reference sequence, while keeping the fraction of false negatives low? a sequence similarity of 45 with an alignment spanning over at least 45 of the query was chosen as a match criterion when using page: 1600 15951600  
