a new statistical framework to assess structural alignment quality using information compression motivation: progress in protein biology depends on the reliability of results from a handful of computational techniques, structural alignments being one. recent reviews have highlighted substantial inconsistencies and differences between alignment results generated by the ever-growing stock of structural alignment programs. the lack of consensus on how the quality of structural alignments must be assessed has been identified as the main cause for the observed differences. current methods assess structural alignment quality by constructing a scoring function that attempts to balance conflicting criteria, mainly alignment coverage and fidelity of structures under superposition. this traditional approach to measuring alignment quality, the subject of considerable literature, has failed to solve the problem. further development along the same lines is unlikely to rectify the current deficiencies in the field. results: this paper proposes a new statistical framework to assess structural alignment quality and significance based on lossless information compression. this is a radical departure from the traditional approach of formulating scoring functions. it links the structural alignment problem to the general class of statistical inductive inference problems, solved using the information-theoretic criterion of minimum message length. based on this, we developed an efficient and reliable measure of structural alignment quality, i-value. the performance of i-value is demonstrated in comparison with a number of popular scoring functions , on a large collection of competing alignments. our analysis shows that i-value provides a rigorous and reliable quantification of structural alignment quality, addressing a major gap in the field.a protein structural alignment is an assignment of residueresidue correspondences between the amino acids of two or more proteins, based on their 3d structure. protein structural alignments support basic and applied research in molecular biology. for example, they reveal how protein families evolve, identify patterns of conservation in amino acid sequences that fold into similar structures, facilitate comparative modelling of structures from sequence and guide experimental solutions to structures using crystallographic molecular replacement . the last four decades have seen the development of many methods aimed at generating biologically meaningful structural alignments. while the number of new methods is estimated to be doubling roughly every five years , several comparative studies have observed many inconsistencies and paradoxes when comparing the alignments generated by existing methods. noteworthy among these studies are those by michael levitt , liisa holm and manfred sippl and colleagues. a common theme emerging from all these studies is the need for a systematic framework to asses the quality of structural alignments. while a handful of quantitatively rigorous statistical models for structure comparison have been proposed for this, there is no consensus regarding their usefulness. this is in stark contrast to the state-of-the-art in the closely related problem of aligning protein sequences, where many rigorous statistical models have been proposed to quantitatively assess sequence alignment quality . this has, in turn, helped standardize the task of measuring sequence alignment quality and, thus, the task of generating meaningful sequence alignments. in this work, we begin by examining the foundations of how structural alignments are currently assessed. guided by good biological insights, current structural aligners use a scoring function to quantify the structural alignment quality. this has traditionally been achieved by combining the contributions of a small number of important criteria into an easy-to-compute scoring function. [for a comprehensive list of commonly used scoring functions, see. overwhelmingly, the two key criteria that various current measures use are coverage and fidelity. typically, coverage measures the number of correspondences (or equivalences) in an alignment and, in some cases, also considers the number of gaps. fidelity, measures how similarly positioned the aligned residues are. this is commonly (but not always) based on the root-mean-square deviation (rmsd) computed after the best rigid-body transformation of corresponding residues is found. to search for the best structural alignment, the goal of the aligners is to simultaneously maximize coverage and fidelity. however, these two objectives are in direct conflict with each other. we observe that most of the current proliferation of structural alignment scoring functions arise from attempts to reconcile this conflict, that is, existing scoring functions differ mainly in how they combine these two criteria. as the reviews show, existing scoring functions do not generate consistent results, even when aligning structures that have only moderately diverged in evolution . to whom correspondence should be addressed. the author 2014. published by oxford university press. this is an open access article distributed under the terms of the creative commons attribution non-commercial license (http://creativecommons.org/licenses/by-nc/3.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. for commercial re-use, please contact journals.permissions@oup.combecause this traditional approach of formulating a scoring function has been explored extensively over the last four decades, further development along the same lines is unlikely to provide any major breakthrough. therefore, this field will stand to benefit by departing from the traditional approaches and exploring radically new ones. this paper is a step in this direction. structural alignment as an inductive inference problem. the goal of inductive inference is to propose a theory (or hypothesis) that is able to best explain the observed data. structural alignment can thus be seen an instance of the general class of inference problems. in this context, an alignment (i.e. residueresidue correspondence) is a hypothesis that attempts to explain the residue residue relationships between two protein structures, whose observed data is the (x, y, z) coordinates of the structures. in general, any hypothesis has a certain (descriptive) complexity. a complex hypothesis with more free parameters can predict (or fit, explain) a greater variety of observed data than a simpler hypothesis. therefore, in order to choose the best hypothesis for any inference problem, one is confronted with a trade-off between hypothesis complexity and its fit with the observations. for structural alignments, this trade-off is related to the conflict between coverage and fidelity. coverage (in various forms handled in the current scoring functions) is a crude approximation of the (alignment) hypothesis complexity. similarly, the fidelity (or goodness of fit with the observed data) of a structural alignment is approximated using rmsd of superposition or using some distance measure. these rudimentary approximations cause the existing scoring functions to introduce several tunable parameters in an attempt to balance the contributions between coverage and fidelity of structural alignments. this has been a major source of the inconsistencies observed in alignments. the field of statistical learning and inference provides rigorous approaches to address this trade-off systematically. in the early 1960s, several landmark papers proposed links between inductive inference and information theory . the minimum message length (mml) principle provided the first practical information-theoretic criterion for hypothesis selection based on observations. it is used here to rigorously assess structural alignment quality and reliably differentiate between competing alignments. structural alignment quality and lossless information compression. the pioneering work of claude e. shannon provides the means to quantify information: the length of the shortest code required to transmit, losslessly, an observed event. this can be understood as the length of the shortest message needed to communicate the event losslessly between an imaginary sender (alice) and receiver (bob). in this context, the structural alignment problem can be rationalized as a communication process between alice and bob, where alice has access to the (x, y, z) coordinates of two protein structures and she wants to encode and transmit this information to bob losslessly. two possible scenarios then arise: (i) if the two are unrelated to each other structurally, alice cannot do better than to encode and transmit the information of the two structures independently, one after another. that is, knowledge of one structure (called reference, or s) does not provide information about the other (called target, or t) and, thus, knowledge of s cannot be used to compress t. this form of independent transmission is termed here as the null model message. (ii) on the other hand, if the two structures are structurally related (i.e. there is a meaningful alignment between the two), knowledge of s reveals information about t. the more similar the structures, the more information one reveals about the other. alice can use this similarity to compress and transmit the information of the target structure using the information of the reference. for bob to decode the information of the target losslessly (i.e. to the precision with which alice sees it), he will require the structural information of the reference structure plus the information of its proposed relationship (i.e. the structural alignment) with the target. this will allow alice to encode the target more concisely than stating the target structure using a null model. we call this form of transmission, the alignment model message (to contrast it with the null model message, where the structures are transmitted independently). we note that this information-theoretic framework for structural alignment is intuitive. if the proposed alignment relationship is a poor one, then the encoded alignment model message will be inefficient (i.e. long). alternatively, if the alignment relationship is a good one, then the transmission of the target becomes efficient (i.e. short). therefore, the total message length of the lossless transmission of coordinate information (using an alignment hypothesis) forms an excellent measure to assess structural alignment quality. it follows that the best alignment is the one with the shortest total message length of lossless transmission. while we have intuitively rationalized this framework as a communication process, this message paradigm is also backed by mathematical rigour. formally, let a denote some alignment between structural coordinates s and t. using the product rule of probability over three events a, s and t we have: pa&s&t=pa psja ptjs&a =pa ps ptjs&a 1 where pa&s&t gives the joint probability of alignment a for structures s and t, pa the prior probability of the alignment, ptjs&a the likelihood of t given s and a. note, psja is p(s) because s and a are assumed to be independent. shannons mathematical theory of communication gives the relationship between the shortest message length i(e) to communicate losslessly any observation e, and its probability p(e) as ie= log pe. technically, i(e) denotes the shannon information content of e. restating equation 1 in terms of information content, we obtain:  
