gene expression a turing test for artificial expression data motivation: the lack of reliable, comprehensive gold standards complicates the development of many bioinformatics tools, particularly for the analysis of expression data and biological networks. simulation approaches can provide provisional gold standards, such as regulatory networks, for the assessment of network inference methods. however, this just defers the problem, as it is difficult to assess how closely simulators emulate the properties of real data. results: in analogy to turings test discriminating humans and computers based on responses to questions, we systematically compare real and artificial systems based on their gene expression output. different expression data analysis techniques such as clustering are applied to both types of datasets. we define and extract distributions of properties from the results, for instance, distributions of cluster quality measures or transcription factor activity patterns. distributions of properties are represented as histograms to enable the comparison of artificial and real datasets. we examine three frequently used simu-lators that generate expression data from parameterized regulatory networks. we identify features distinguishing real from artificial data-sets that suggest how simulators could be adapted to better emulate real datasets and, thus, become more suitable for the evaluation of data analysis tools. availability: see http://www2.bio.ifi.lmu.de/$kueffner/attfad/ and the supplement for precomputed analyses; other compendia can be analyzed via the cran package attfad. the full datasets can be obtained fromthe analysis of expression data involves a range of bioinformatics tools. they are used for outlier removal and normalization , for clustering , for finding relevant biological processes as well as for the inference and modeling of gene regulatory interactions (gris) . the improvement of such tools frequently depends on insights into properties of transcriptional regulation. to better understand such properties and to facilitate further tool development, several simulators have been developed for various areas of expression analysis. another reason for conducting simulation studies is to provide gold standards that are not available for real data. in case of clustering, the number of gene clusters and the clustergene associations are usually not known for real data but can be defined easily within an in silico framework . for the assessment of tools, it is important that simulators generate realistic expression patterns. similar techniques are applied to analyze whether gene sets associated with biological processes exhibit a significant enrichment of differential expression. the assessment of enrichment tests on real data is difficult, as the genes or processes that exhibit differential activity between experimental conditions are usually not known before the actual experiment . as a remedy, enrichment tests can be assessed based on simulations of gene sets and their differential expression patterns . furthermore,generated realistic data and noise distributions to examine data normalization approaches for two-dye arrays. simulators are also used to examine specific theoretical assumptions [e.g. expression data distributions , single-cell data and theoretical properties of gris (. simulators devised for studying gri inference approaches are again motivated by the need for complete gold standard networks. unlike the specific simulators, network simulators claim to more generally satisfy the mentioned requirements. they imitate experimentally determined gris and their dynamical properties and emulate other properties of real data such as data and noise distributions . network simulators have been applied successfully to assess algorithms that reconstruct gris from expression data, e.g. via community-wide blind assessments . therefore, simulators implement elaborate experimental settings, for instance, by dealing with biological and technical replicates and by generating data for gene knockouts, various perturbations and time series data . some simulators also take into account sequence variations in promoter regions and coding sequences . instead of random topologies, many simulators use realistic topologies, such as scale-free networks or networks of experimentally determined gris . algorithms can be benchmarked using simulators in a meaningful way if generated, and real data are sufficiently similar . as this is difficult to show, in silico models are sometimes considered insufficient evidence for method enhancements. this is owing to our lack of a good understanding of the distribution of expression levels across the to whom correspondence should be addressed. various biological states and the correlation between biological replicates . the present study evaluates to which extent current state-ofthe-art simulators are able to generate realistic datasets and gold standards. we propose characteristic histograms to compare artificial and real expression compendia. the histograms are derived by applying a range of expression data analysis approaches. we provide data on our web site and r software to apply the suggested analyses on the compendia examined in this article or defined by the user. the properties of real and artificial datasets thus become amenable to a mutual pairwise comparison. for the generation of artificial datasets, we focus on network simulators, as they are most frequently used in practice and most general in their scope.we compare various properties between real and artificial datasets and find strong deviations (, heatmap). properties and their deviations are discussed below in detail. each subsection presents one type of property histogram and is exemplified in detail based on the data from one of the three simulators . results on the other simulators are briefly summarized at the end of each section (see availability for additional figures).simulated datasets aim to bridge the gap to dependable gold standards that are required for the development and validation of tools across many expression data analysis steps. for the application to algorithm benchmarks, simulators should be able to emulate the properties of real data. to test this ability, we applied several important steps in gene expression data analysis ranging from clustering to the inference of gris. the results of these analyses were represented as property histograms for the comparison of real and artificial datasets. data generated by three gene network simulators were compared with four expression compendia measured in e.coli and s.cerevisiae. we showed that property histograms facilitate the characterization and comparison of expression compendia. most importantly, histograms were highly consistent across different real expression compendia and even between different organisms. in contrast, simulated data exhibited markedly different ranges of values and shapes. the captured properties thus clearly separated real and simulated data in analogy to turings test. we observed strong deviations even in basic intensity and noise histograms. these are likely due to simplified simulation models omitting steps that play a role in real measurements such as the modeling of mrna concentrations and their quantification by optical detectors. we constructed further histograms from clustering approaches to compare resulting clusters of genes and experimental conditions. artificial co-regulation patterns as detected by clustering are exclusively generated by transcriptional regulation, as this is typically the only regulatory mechanism implemented in current simulators. however, the most striking and reproducible (i.e. found in all examined simulators) deviations were observed for properties derived from gene regulatory networks. this is surprising, as the examined simulators were particularly devised for the assessment of network inference approaches. many simulators aim to use realistic gene regulatory network topologies, e.g. sampled from experimentally derived gris, instead of random networks. however, other important layers of regulation such as different cellular states or signal transduction are neglected that in real data contribute to the complexity of expression patterns. furthermore, executable models are constructed by arbitrarily selecting model parameters for the dynamic simulation of gris. datasets generated in such a setup will differ substantially from real measurements even if realistic gri topologies are used. indeed, none of the different topologies(b), we examine to what extent tftg interactions and pairs of tgs regulated by the same tfs, respectively, can be identified based on correlation. positive or negative differences in density [ordinate, non-continuous in (a)] indicate that the chances to detect true tftg or tg tg relationships in the given correlation intervals are increased or decreased, respectively. interactions were also analyzed for a yeast and an alternative e.coli dataset. in (c), the activity of tfs is inferred from the levels of differential expression exhibited by their tgs. shown is the density (ordinate) of tfs active in a given fraction of the available chips. the leftmost histogram bin corresponds to a fraction of 0 and thus denotes tfs that are never found active implemented by the three simulators substantially reduced the observed differences to real data. realistic data simulation requires a careful analysis of properties of network topologies, dynamic parameters and their relationship to the generated expression data. our results suggest several improvements: (i) the expression model should be improved to produce normally distributed data in the range of typical expression measurement platforms, so that, for instance, fold changes have a similar meaning as in real datasets. the simulation of noise is important, but excessive noise levels should be avoided. (ii) the generation of realistic co-regulation patterns requires the emulation of groups of tfs, their combinatorial effects and the conditions for becoming active. (iii) as a related topic, we note that random parameterization (gnw, grendel) or random mapping of experimentally determined parameters onto the network (syntren) is not adequate. instead, an iterative optimization of model parameters could preserve dataset properties such as those that we described here. (iv) simulators should implement regulation on the protein level. currently, the simulation of just transcriptional regulation over-simplifies network inference, as all regulatory events become visible at the level of gene expression. (v) finally, simulators should account for the diversity of genes, for instance, regarding the number of regulatory states, instead of assuming that one model is sufficient to generate all data. this would help to reproduce the broader distributions of properties derived from real data. our approach (see availability for web site and software) offers a detailed comparative analysis of expression data generated by real and artificial gene regulatory networks. our assessment is based on typical data processing and analysis pipelines. we thereby provided an important layer of assessment on top of data simulators that are essential tools for both data analysis and network inference when no reliable gold standards are available. the analysis suggested several ways for improving current simulators to generate more realistic datasets.  
