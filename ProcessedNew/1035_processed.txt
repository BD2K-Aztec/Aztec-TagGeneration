sequence analysis codoc: efficient access, analysis and compression of depth of coverage signals current data formats for the representation of depth of coverage data (doc), a central resource for interpreting, filtering or detecting novel features in high-throughput sequencing datasets, were primarily designed for visualization purposes. this limits their applicability in stand-alone analyses of these data, mainly owing to inaccurate representation or mediocre data compression. codoc is a novel data format and comprehensive application programming interface for efficient representation, access and analysis of doc data. codoc compresses these data $432 better than the best current comparable method by exploiting specific data characteristics while at the same time enabling more-exact signal recovery for lossy compression and very fast query answering times. availability and implementation: java source code and binaries are freely available for non-commercial use at http://purl.org/bgraph/codoc.depth of coverage (doc) data are one-dimensional discrete genomic signals describing the number of reads from a highthroughput sequencing (hts) experiment covering each position in a reference genome. doc is determined by traversing shortread alignments column-wise and counting the number of mapped reads overlapping with each individual position (i.e. its coverage). doc is a primary source of information for the detection of structural variants where it is assumed that a gain/loss of genetic material results in increased/decreased coverage. the same fundamental assumption is exploited in rna sequencing where estimated expression rates are calculated from normalized coverage signals. doc also plays a central role in, e.g. identifying novel transcripts, characterizing the alternative splicing landscape of a sample or comparing multiple snp-calling datasets where it is required to determine what genomic regions are sufficiently covered in all considered datasets to be comparable among each other . current data formatsbroads tiled data file format, tdf, and ucscs bigwig format were optimized for efficient display of doc in genomic browsers but not for their stand-alone analysis. coverages) can be read from these external lists at decompression time . this further reduces the number of required codewords while at the same time preserving (near-) exact doc values at/close to variant positions. blocked encoding and compression. codewords are converted to byte representations using different encoders: chromosome identifiers are stored by standard rle, position offsets by differential golomb/rice encoding , and coverage values are stored unencoded. eventually, all encoded bytes are additionally compressed by a general-purpose compression algorithm (gzip or bzip2). the data are then split into blocks (bits) that contain a configurable maximum of codewords (100 000 by default), which enables efficient random access at decompression time. decompression. signal reconstruction is done by linear interpolation at neighboring key positions. decompression starts by constructing an in-memory interval tree of bits and their byte offsets. when a particular genomic position is queried, codoc consults this index and loads the bit containing the queried position from disk, finds the key positions and their coverage values by binary search and reports the interpolated result. codoc caches accessed bits using a leastrecently used strategy to exploit spatial locality of queries to close genomic positions.  
