sequence analysis comparative analysis of algorithms for next-generation sequencing read alignment motivation: the advent of next-generation sequencing (ngs) techniques presents many novel opportunities for many applications in life sciences. the vast number of short reads produced by these techniques, however, pose significant computational challenges. the first step in many types of genomic analysis is the mapping of short reads to a reference genome, and several groups have developed dedicated algorithms and software packages to perform this function. as the developers of these packages optimize their algorithms with respect to various considerations, the relative merits of different software packages remain unclear. however, for scientists who generate and use ngs data for their specific research projects, an important consideration is choosing the software that is most suitable for their application. results: with a view to comparing existing short read alignment software, we develop a simulation and evaluation suite, seal, which simulates ngs runs for different configurations of various factors, including sequencing error, indels and coverage. we also develop criteria to compare the performances of software with disparate output structure (e.g.some packages return a single alignment while some return multiple possible alignments). using these criteria, we comprehensively evaluate the performances of bowtie, bwa, mr-and mrsfast, novoalign, shrimp and soapv2, with regard to accuracy and runtime. conclusion: we expect that the results presented here will be useful to investigators in choosing the alignment software that is most suitable for their specific research aims. our results also provide insights into the factors that should be considered to use alignment results effectively. seal can also be used to evaluate the performance of algorithms that use deep sequencing data for various purposes (e.g.identification of genomic variants). availability: seal is available as open source at http://compbio.case .edu/seal/.next-generation sequencing techniques are demonstrating promise in transforming research in life sciences . these techniques support many applications including metagenomics , detection of snps and genomic structural variants in a population, dna methylation studies , analysis of mrna expression , cancer genomics and personalized medicine . some applications (e.g. metagenomics) require de novo sequencing of a sample , while many others (e.g. variant detection, cancer genomics) require resequencing. for all of these applications, the vast amount of data produced by sequencing runs poses many computational challenges . in resequencing, a reference genome is already available for the species (e.g. the human genome) and one is interested in comparing short reads obtained from the genome of one or more donors (individual members of the species) to the reference genome. therefore, the first step in any kind of analysis is the mapping of short reads to a reference genome. this task is complicated by many factors, including genetic variation in the population, sequencing error, short read length and the huge volume of short reads to be mapped. so far, many algorithms have been developed to overcome these challenges and these algorithms have been made available to the scientific community as software packages . currently available software packages for short read alignment include bowtie , soap , bwa , mrfast , mrsfast , novoalign and shrimp . in this article, we assess the performance of currently available alignment algorithms, with a view to (i) understanding the effect of various factors on accuracy and runtime performance and (ii) comparing existing algorithms in terms of their performance in various settings. for this purpose, we develop a simulation and evaluation suite, seal, that simulates short read sequencing runs for a given set of configurations and evaluates the output of each software using novel performance criteria that are specifically designed for the current application. our results show significant differences in performance and accuracy as quality of the reads and the characteristics of the genome vary. in the next section, we briefly describe the alignment algorithms that are evaluated in this article. subsequently, in section 3, we describe the simulation suite implemented in seal and our performance criteria in detail.page: 2791 27902796as expected, these alignment tools are designed with different approaches to trading off speed and accuracy to optimize detection of different types of variations in donor genomes. this trade-off is evident in the performance of bwa and soap on the human genome : without a threshold value to eliminate unreliable reads, bwa is not as accurate even at low error rates ( 0.9 at a base pair substitution rate of 10 3 and falling sharply to 0.37 at an error rate of 10 1 ). soap has a consistently high accuracy ( 0.95) even with no threshold and high error rates. based on these observations, we can conclude that bwa is specifically designed not to miss any potential mappings, at the cost of reporting many incorrect mappings. the evaluation of mrfast, mrsfast and shrimp shows some expected trends; since each fragment is potentially mapped to many locations in the genome, we expect their strict accuracy value to be much lower than that of other tools. as the error rate increases from 0.001 to 0.1, however, we see the strict accuracy measure increase for all three of these tools. intuitively, this seemingly surprising trend makes sense since we expect the number of potential genome mappings to decrease as the reads become less reliable, thus reducing the number of incorrect mappings in relation to the single potential correct mapping. these tools relaxed accuracy values (as defined in section 3.2) also show some expected trends; since mrfast and mrsfast can report many genome locations for each fragment, we expect their relaxed accuracy to be quite high for low error rates and to decline as the error rate increases. we must emphasize the large difference between our relaxed and strict accuracy measures in our evaluation of mrfast, mrsfast and shrimp. the relative usefulness of these two measures depends on the users specific research aims; one may be more interested in tools with good relaxed accuracy if studying structural variants,while strict accuracy may be of more use in genotyping snps. we must also note that our analysis may not be fair to shrimpthis tool is designed for mapping color-space reads and our simulation does not generate this type of data. as expected, the tools show an overall linear relationship between coverage (number of reads) and the total runtime. for most alignment tools, we can further separate the total runtime into separate measurements for indexing and alignment; if the index can be reused across multiple alignment runs, a high indexing time can be affordable. we believe that our results will be useful to a wide variety of genomic researchers, though we must recognize that we cannot precisely simulate all experimental scenarios or sequencing hardware characteristics. as the state of the art advances, data from new sequencing hardware may challenge the assumptions that todays high-performing algorithms depend on. similarly, algorithms with unfavorable accuracy or speed on todays data sets may find renewed use in the future.  
