structural bioinformatics secstant: secondary structure analysis tool for data selection, statistics and models building motivation: atomistic or coarse grained (cg) potentials derived from statistical distributions of internal variables have recently become popular due to the need of simplified interactions for reaching larger scales in simulations or more efficient conformational space sampling. however, the process of parameterization of accurate and predictive statistics-based force fields requires a huge amount of work and is prone to the introduction of bias and errors. results: this article introduces secstant, a software for the creation and analysis of protein structural datasets with user-defined pri-mary/secondary structure composition, with a particular focus on the cg representation. in addition, the possibility of managing different resolutions and the primary/secondary structure selectivity allow addressing the mapping-backmapping of atomistic to cg representation and study the secondary to primary structure relations. sample data-sets and distributions are reported, including interpretation of structural features.molecular dynamics (md) computer simulations, and more specifically force field (ff)-based atomistic md , are considered invaluable tools to get insight in the structure and function of biological matter. within this approach, the inter-atomic interactions are represented by means of a sum of analytical terms, whose parameters were optimized in the course of the past decades, based on quantum chemistry calculations or experimental data. this approach is implemented in a number of widely used software packages (van). despite its undoubted utility, the atomistic md presents some weaknesses. single proteins simulations can now reach the sub-s scale with ordinary computational resources. however, most biologically interesting phenomena occur on wider time and space scales, needing large parallelism. this problem is not likely to be simply resolved by the increase of the processors power and of parallelism, becoming increasingly harder as the system complexity grows. recent efforts have focused on the development of dedicated hardware. an example is the supercomputer anton , which implements specialized hardware for protein dynamics, leading to simulation time scales into the range of hundreds of micro seconds to milliseconds. however, such systems are not broadly available to the scientific community. a second problem of the atomistic approach is related to the model itself. as longer time scales are explored in the simulations, the traditional ffs show inaccuracies especially in the evaluation of the relative energies of different secondary structures . a great effort is currently in the course to produce a new generation of ffs to fix these problems, although this task appears hard without the introduction of more complex interactions with larger number of parameters . this, in turn, worsens a problem already existing in the traditional ffs, i.e. the complexity of the optimization procedure. apparently paradoxically, the reductionist approach has recently been considered as a possible alternative. minimizing the number of parameters of the model allows applying more efficient parameters optimization strategies to accurately reproduce given properties. direct emanations of this approach are the coarse grained (cg) models, representing group of atoms with single interacting centers (beads) and the so called knowledge based or statistical potentials (sp) , i.e. potentials with a relatively small number of parameters, derived by the statistical analysis of the increasingly larger experimental structures databases. cg models solve directly the first class of problems, as they immediately reduce the computational cost of orders of magnitude. on the other hand, sps, though bearing many limitations specifically residing in the difficulty of combining transferability and predictive power with structural accuracy , have shown better performance than traditional atomistic ffs for docking or homology modeling applications . the combination of cg with sps has been used in models for md simulations, such as martini , to whom correspondence should be addressed. representing the amino acid at an intermediate resolution level (with 26 beads), embedded in cg explicit water, or the one by bahar and jernigan, with a similar resolution but with implicit water, or the one developed by us , based on a single bead per amino acid (placed on ca) in implicit water. this resolution level can be considered the minimal where internal variables can still explicitly describe secondary structures, and therefore called minimalist. specifically referring to minimalist models , different algorithms were considered to produce sps, such as direct or iterative boltzmann inversion (bi) , relative entropy minimization and reverse monte carlo . they all rely on the statistical distributions of the internal variables, either used as direct input or as target quantity for the potential optimization. this implies that the quality of statistical distribution determines the accuracy of the model . in turn, the quality of the statistical distribution is determined by the statistical relevance of the dataset (i.e. number and diversity of included structures) and its composition in terms of sequence or secondary structures. the latter in particular is relevant for the parameterization of potentials capable of accurately reproducing the secondary structure tendency of different amino acids. the rscb protein data bank (pdb) , the most comprehensive database of biomolecularand specifically proteinsstructures, is the natural source of data for building statistical sets and corresponding probability distributions. biomolecules coordinates are stored in a format that is a widely used, internationally referred representation for macromolecular data, including experimental and structural information. these, however, are integrated within the coordinates file, and not of immediate use to the aim of building, e.g. primary or secondary structure-dependent dataset. in this article, we describe and validate secstant, a tool with an intuitive and sleek interface able to automatically create from pdb user-defined datasets of protein structural composition or primary sequence motives at different levels of resolution (atomistic or cg). furthermore, a large number of internal variable distributions can be evaluated together with two and three body correlation functions. the latter point is particularly innovative and useful for the parameterization and validation of the cg models. in fact, the correlation map between the internal variables describing the backbone conformation within the cg representation has the same role of the well-known ramachandran plot . although there are a number of tools to evaluate the latter [for instance (, to our knowledge, none are freely available to evaluate the corresponding correlation maps within the minimalist representations. the ability to evaluate the sp by means of bi facilitates the parameterization process of cg models. in addition, the possibility to consider both atomistic and cg resolutions allows in principle to directly make connections between the two levels. this is particularly important in view of generating cg models fully compatible with atomistic ffs to be included in a coherent multiscale representation, which are often considered as possible solutions to combine the advantages of cg and atomistic representation and eliminate their disadvantages . we illustrate secstant and its potentialities reporting sample datasets distributions and correlations. interesting novel features emerge from this statistical analysis to which we give a physicalchemical interpretation.  
