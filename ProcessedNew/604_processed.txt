automated gene-model curation using global discriminative learning motivation: gene-model curation creates consensus gene models by combining multiple sources of protein-coding evidence that may be incomplete or inconsistent. to date, manual curation still produces the highest quality models. however, manual curation is too slow and costly to be completed even for the most important organisms. in recent years, machine-learned ensemble gene predictors have become a viable alternative to manual curation. current approaches make use of signal and genomic region consistency among sources and some voting scheme to resolve conflicts in the evidence. as a further step in that direction, we have developed ecraig (ensemble craig), an automated curation tool that combines multiple sources of evidence using global discriminative training. this allows efficient integration of different types of genomic evidence with complex statistical dependencies to maximize directly annotation accuracy. our method goes beyond previous work in integrating novel non-linear annotation agreement features, as well as combinations of intrinsic features of the target sequence and extrinsic annotation features. results: we achieved significant improvements over the best ensemble predictors available for homo sapiens, caenorhabditis elegans and arabidopsis thaliana. in particular, ecraig achieved a relative mean improvement of 5.1 over jigsaw, the best published ensemble predictor in all our experiments. availability: the source code and datasets are both available atensemble predictors are automated gene-model curation tools that build gene models by combining conflicting and incomplete information provided by multiple sources of coding evidence. to date, manual curation still produces the highest-quality annotations as it benefits from problem-domain knowledge of expert human curators that is difficult to build into gene predictors. however, manual curation is slow and costly, and has been unable to complete to whom correspondence should be addressed. the annotation even for the most important organisms . several methods of semi-automatic curation try to speed up manual methods by automating the selection of good combinations of manually-tuned evidence integration rules. such methods include exonhunter , eugene , gaze and more recently augustus+hints . semi-automated gene annotation pipelines also belong in this category. ensembl and pairagon+nscan_est for example, use expressed sequence tags (ests), complementary dnas (cdnas) and automated predictions to find a consensus gene model. in recent years, ensemble predictors based on machine learning have become a viable alternative to manual or semi-automated methods. these methods measure signal and genomic region consistency among sources encoded as feature vectors and use voting schemes to resolve evidence conflicts. fully automated, learningbased ensemble predictors include the work of and jigsaw . in particular, jigsaw has performed favorably in multiple benchmark datasets in comparison with the best semi-automated annotation pipelines. some learning-based ensemble predictors require annotated sequences for training (supervised methods); others learn combination parameters to maximize agreement without needing annotated training data beyond what was used for individual sources of evidence (unsupervised methods). unsupervised methods such as glean and evigan are advantageous in cases where no manually-curated gene annotations are available. however, they tend to perform less well than supervised ensemble predictors. among supervised ensemble predictors, the work of uses maximum-likelihood estimation to learn the parameters of an inputoutput hidden markov model (hmm) that combines multiple gene predictions. jigsaw is an improved version of combiner that uses a semi-markov structure model and a learning procedure that implicitly models dependencies of evidence sources given the input sequence. the main idea in combiner and jigsaw is to classify feature vectors of the input sources as either accurate or inaccurate using decision trees. an accurate (inaccurate) vector is one that led to predictions that match the annotation in at least (most) half of the training set. the learned decision trees partition the feature space into accurate and inaccurate regions, allowing the combiner to decide  
