'sciencenet'â€”towards a global search and share engine for all scientific knowledge modern biological experiments create vast amounts of data which are geographically distributed. these datasets consist of petabytes of raw data and billions of documents. yet to the best of our knowledge, a search engine technology that searches and cross-links all different data types in life sciences does not exist. we have developed a prototype distributed scientific search engine technology, sciencenet, which facilitates rapid searching over this large data space. by bringing the search engine to the data, we do not require server farms. this platform also allows users to contribute to the search index and publish their large-scale data to support e-science. furthermore, a community-driven method guarantees that only scientific content is crawled and presented. our peer-to-peer approach is sufficiently scalable for the science web without performance or capacity tradeoff. availability and implementation: the free to use search portal web page and the downloadable client are accessible at: http://sciencenet.kit.edu. the web portal for index administration is implemented in asp.net, the askme experiment publisher is written in python 2.7, and the backend yacy search engine is based on java 1.6.most commonly known search engine technologies (bing, google) are based on popularity ranking algorithms. however, scientific research has special requirements for search engines that cannot be addressed by popularity ranking in all cases. special search engines (for example, scirus , pubmed, google scholar, web of science, scopus) concentrate more on providing content from scientific journals and literature . other meta search engines cross-link several centralized databases via a single search interface [for example bioinformatic harvester , eb-eye , entrez , ensembl , string (. todays scientific search queries require searching across different data sources that are geographically distributed. often different data types, like high content screening (hcs) image data or sequence based data , require special databases that present a challenge to the global search methods mentioned above. the latest developments in high content/high-throughput screening microscopy and nextgeneration sequencing technologies routinely produce experimental datasets in the terabyte (tb) range resulting in millions of data files. to the best of our knowledge, there is no central database to encompass all experiment datasets due to the fact that large-scale data handling is a challenge for any known data publication platform. uploading all this data to a centralized database is currently too time consuming and expensive . also, maintaining a centralized infrastructure over the years is costly . consequently, it is likely that no single library alone will be able to index the entire science web . research strongly benefits from accessible data that provides a valuable resource for comparative and novel studies . thus, a decentralized search and publishing network that can handle multiple data types at different locations will significantly improve the scientific research process.  
