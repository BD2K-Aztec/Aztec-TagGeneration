gene expression discriminative local subspaces in gene expression data for effective gene function prediction motivation: massive amounts of genome-wide gene expression data have become available, motivating the development of computational approaches that leverage this information to predict gene function. among successful approaches, supervised machine learning methods , such as support vector machines (svms), have shown superior prediction accuracy. however, these methods lack the simple biological intuition provided by co-expression networks (cns), limiting their practical usefulness. results: in this work, we present discriminative local subspaces (dls), a novel method that combines supervised machine learning and co-expression techniques with the goal of systematically predict genes involved in specific biological processes of interest. unlike traditional cns, dls uses the knowledge available in gene ontology (go) to generate informative training sets that guide the discovery of expression signatures: expression patterns that are discriminative for genes involved in the biological process of interest. by linking genes co-expressed with these signatures, dls is able to construct a dis-criminative cn that links both, known and previously uncharacterized genes, for the selected biological process. this article focuses on the algorithm behind dls and shows its predictive power using an arabidopsis thaliana dataset and a representative set of 101 go terms from the biological process ontology. our results show that dls has a superior average accuracy than both svms and cns. thus, dls is able to provide the prediction accuracy of supervised learning methods while maintaining the intuitive understanding of cns. availability: a matlab implementation of dls is available atdiscovering the biological processes that genes carry out inside the cell is a major challenge to understand gene function at a genome-wide scale. unfortunately, many organisms lack in-depth understanding about the genes involved in specific biological processes. as an example, in the favorite model in plant biology, arabidopsis thaliana, 16 319 (52) of its genes lack annotations about their biological processes in the gene ontology (go) database (go annotations date: november 9, 2010) (; http://www.geneontology.org). machine learning has emerged as one of the key technologies to support gene function discovery. in particular, many methods have been proposed to take advantage of the massive amounts of microarray expression data available (seefor reviews). these prediction methods can be classified into two broad groups: supervised and semi-supervised approaches. on one hand, supervised techniques use a labeled training set of genes to learn how to discriminate the genes of each label or function. on the other hand, semi-supervised approaches first group genes in an unsupervised manner, without using any functional information, and then a prediction is performed, usually by propagating the overrepresented functions among the genes of each group (guiltby-association rule,). among supervised machine learning techniques, support vector machines (svms) have been one of the most successful approaches to predict gene function, as has been shown by several works . however, despite their theoretical advantage in terms of classification accuracy, in practice, svms present the mayor inconvenience of operating as a black-box . although additional techniques can be applied to extract comprehensible semantic information from svm models, their application is not straightforward and is usually restricted to linear-svm models . in the general case of non-linear svms, the transformation of the data to high-dimensional spaces complicates any interpretation of the svm solution. in our experience, this is a major limitation for gene function discovery as understanding the predictions is a key aspect to evaluate their biological soundness and guide research. this aspect is even more critical considering the incomplete nature of annotations and the capability of genes to have multiple functions, which prevents obtaining an error-free gold standard, and thus evaluating the absolute accuracy of the methods (false-negative problem;). in contrast to supervised methods, many semi-supervised approaches have emerged based on simpler, but biologically sound concepts, such as co-expression and the guilt-by-association rule (to whom correspondence should be addressed. the author 2012. published by oxford university press. this is an open access article distributed under the terms of the creative commons attribution license (http://creativecommons.org/licenses/by/3.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.). the basic assumption in these methods is that if a group of genes shows synchronized (correlated) expression patterns, then there is a high chance for them to participate in a common biological process. common techniques used to group genes are clustering , biclustering (seefor reviews) and co-expression networks (cns;). unfortunately, current methods based on cns do not offer the accuracy of supervised methods to predict gene function, as we show in this work by comparing the performances of cns and svms. furthermore, their classification strategy poses some relevant inconveniences. in particular, the selection of a suitable correlation threshold to define co-expressed genes is often difficult and arbitrary. furthermore, both cns and clustering rely on global co-expression patterns, meaning that genes need to be co-expressed in a large proportion of the data in order to be grouped together. usually, these data involve hundreds or thousands of microarray experiments, each measured under a wide range of experimental conditions, such as different time points, tissues, environmental conditions, genetic backgrounds and mutations. in this scenario, expecting global co-expression becomes a strong imposition and limitation. the previous observation has motivated the development of biclustering algorithms . the main idea behind biclustering is to find clusters of genes that co-express in subsets of experimental conditions. after the seminal work by, an extensive list of biclustering approaches has been developed (seefor reviews). however, besides their theoretical advantages, these approaches have not been extensively used in practice. based on our experience, the unsupervised local search of experimental conditions often leads to clusters with genes from a broad range of functions, thus, limiting their discriminative properties. this problem is even worse considering the noisy nature of microarray data, which often leads to the discovery of biologically meaningless biclusters. selecting datasets in a condition-dependent fashion should more precisely identify gene interactions relevant to a specific biological question at hand . however, given the amount of expression data available today, manual selection of the relevant conditions is not a practical solution in most cases. to overcome the state of the art limitations exposed above and aid gene functional research, we present discriminative local subspaces (dls), a novel machine learning method that discriminatively predicts new genes involved in a biological process of interest by building a discriminative cn. dls takes advantage of the discriminative nature of supervised learning while maintaining the expressiveness of cn approaches. unlike other co-expression-based methods, dls exploits the existing knowledge available in go to construct informative training sets. these training sets guide the search of suitable subsets of experimental conditions containing expression signatures. an expression signature corresponds to a discriminative expression pattern with two key properties: (i) it is defined in a local subspace of the data (i.e. a particular gene and a subset of experimental conditions) and (ii) it is highly discriminative (exclusive) for the positive training genes associated to a biological process of interest. as a further feature and to tackle the inherent noise of negative training sets (genes not related to a biological process), dls incorporates a procedure that iteratively predicts false-negative (fn) genes and refines the training set in order to improve its prediction performance. the discriminative nature of expression signatures allows dls to reveal novel co-expression associations for the selected process. in contrast to discriminative black-box models, such as svms, these predicted associations can be exposed in the context of a discriminative cn, giving the scientist the possibility to visualize, evaluate and interpret the predicted associations. unlike traditional cn, dls does not rely on a predefined and fixed correlation threshold to construct the networks. instead, dls uses a bayesian probabilistic approach that adaptively derives a confidence score for each predicted association. a network is then constructed based on a desired minimum confidence, which is translated into different correlation thresholds depending on the discriminative level of each signature. in order to test the prediction power of our method, we use an a. thaliana expression dataset containing 2017 microarray hybridizations. we compare dls performance with respect to cn and two versions of svm, linear-svm and radial basis kernel (rbf)-svm. the accuracy and predictive power of the methods are tested using cross-validation and also testing the enrichment of year 2008 predictions with respect to new 2010 annotations, using 101 representative go terms from the biological process ontology. our results reveal that dls attains superior average accuracy and similar predictive power than rbf-svm. furthermore, they show a clear advantage for dls over linear-svm and cn in both tests. remarkably, they show that unlike svm and cn, dls is able to systematically improve its predictive power when increasing the number of available experimental conditions. the rest of the article presents the details behind dls method (section 2), our experimental setup (section 3), the main results (section 4) and our principal conclusions of this work (section 5).in this work, we described dls, a novel method that combines supervised machine learning and co-expression approaches to effectively predict new genes involved in a biological process of interest. we introduced four key concepts that allow dls to effectively predict gene function: the derivation of informative training sets of genes by discovering fn training genes, the supervised search of discriminative expression patterns in subsets of experimental conditions (expression signatures), a bayesian probabilistic approach to derive the confidence for each prediction and the construction of discriminative cns to represent predictions. by using an a. thaliana expression dataset and 101 go biological processes, our experiments showed that dls is able to provide effective gene functional predictions, with accuracies comparable to the highly discriminative svms, while maintaining the expressiveness of cns. interestingly, they also show that, unlike svms and cns, dls systematically improves its prediction performance as more experimental conditions are added to the dataset. thus, we believe that the supervised use of co-expression proposed in this work opens new opportunities to extract meaningful biological hypothesis from the increasing amounts of expression data, and therefore, to cope with the need to understand gene functions and biological processes.  
