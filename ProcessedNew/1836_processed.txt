genetics and population analysis fish: fast and accurate diploid genotype imputation via segmental hidden markov model motivation: fast and accurate genotype imputation is necessary for facilitating gene-mapping studies, especially with the ever increasing numbers of both common and rare variants generated by high-throughput-sequencing experiments. however, most of the existing imputation approaches suffer from either inaccurate results or heavy computational demand. results: in this article, aiming to perform fast and accurate genotype-imputation analysis, we propose a novel, fast and yet accurate method to impute diploid genotypes. specifically, we extend a hidden markov model that is widely used to describe haplotype structures. but we model hidden states onto single reference haplotypes rather than onto pairs of haplotypes. consequently the computational complexity is linear to size of reference haplotypes. we further develop an algorithm merge-and-recover (mar) to speed up the calculation. working on compact representation of segmental reference haplotypes, the mar algorithm always calculates an exact form of transition probabilities regardless of partition of segments. both simulation studies and real-data analyses demonstrated that our proposed method was comparable to most of the existing popular methods in terms of imputation accuracy, but was much more efficient in terms of computation. the mar algorithm can further speed up the calculation by several folds without loss of accuracy. the proposed method will be useful in large-scale imputation studies with a large number of reference subjects. availability: the implemented multi-threading software fish is freely available for academic use at https://sites.google.com/site/lzhangho-mepage/fish. contact:genotype imputation refers to a process in which missing genotypes at un-typed markers in a test sample are statistically inferred by knowledge of genotypes observed at the same markers in a reference sample . the principle underlying genotype imputation is that modern human genomes share segments of haplotypes with each other, as reflected by linkage disequilibrium (ld) patterns . imputed genotypes have been widely used to fill sporadic missing genotypes, to integrate multiple studies with different genotyping platforms into meta-analysis, and to finemap causal, but un-typed, disease loci. genotype imputation has significant potential to greatly enhance our capacity to integrate and extend the scope of current existing datasets at no additional expense. consequently, it has become a standard toolkit in largescale genetic-association studies, and this has facilitated the discovery of a remarkable number of genetic loci responsible for a variety of complex traits and diseases . a variety of statistical methods, including mach , impute (versions 1 and 2) , beagle and others , have been developed and used widely for genotype imputation. these methods provide excellent accuracy for imputing common variants (minor allele frequency (maf)45) derived from genomewide association studies . however, as next-generation sequencing technology is getting mature and more widely applied, an increasing number of less common (15maf55) and rare variants (maf51) have been uncovered. it has been hypothesized that these less common and rare genetic variants represent another potential mechanism by which variations in the human genome influence complex diseases. consequently, it has become increasingly important to be able to impute fast and accurately this increasing number of these variants in existing genome-wide association studies in order to facilitate gene-mapping studies and to study a variety of genomic structures. the accuracy of genotype imputation is influenced greatly by the size of reference panel ; larger reference samples increase imputation accuracy. when imputing common variants, reference panels of small to moderate size (e.g. 200) may be sufficient to attain an acceptable level of imputation accuracy. when imputing less common or rare variants, however, the accuracy of imputation will be considerably lower than that for common variants with reference panels of small to moderate size. consequently, it is critical to use an expanded reference panel when imputing less common or rare variants in order to attain an acceptable level of accuracy. fortunately, a continuously increasing resource of reference datasets based on next generation sequencing, e.g. 1000 genomes project , is becoming publicly available. eventually, these well-validated datasets will provide a comprehensive set of reference samples that can support accurate genotype imputation of an extensive range of genetic variants, from common to rare ones. one practical limitation of existing imputation methods is that they can be computationally intensive when operating with large reference samples. for example, both mach and impute have quadratic computational complexity to the number of reference haplotypes used in the hidden markov model (hmm), a level of complexity which actually prohibits them from making full use of all available reference haplotypes. in practice, both mach and impute (version 2) compensate for this limitation by selecting only a subset of reference haplotypes to use for imputation. obviously, this approach may cause a potential loss of accuracy under certain conditions, and this loss of accuracy may become particularly severe when imputing less common and particularly rare variants. alternatively, they both have a haploid model implementation with linear complexity, which is achieved by imputing on pre-phased haplotypes rather than diplotypes . nonetheless, phasing diplotypes into haplotypes introduces additional computation demanding as well as phasing uncertainty . in the context of a growing number of large sequencing datasets, it is becoming critically important to develop computationally efficient imputation methods that can use large reference datasets in order to retain imputation accuracy, particularly for rare variants, at a reasonably high level. though a variety of alternative solutions have been proposed , they fall short regard to either accuracy or extensive computational demand. both mach and impute are based on li and stephens haploid hmm . their heavy computational demand in imputing diplotypes is attributable to modeling hidden states on pairs of reference haplotypes rather than on single haplotypes. in the present article, we propose an alternative and efficient model to impute diplotypes with linear complexity. basically, we extend the same hmm, but we model hidden states on single haplotypes so that the computational complexity is linear to the size of reference haplotypes. we take into account unphased genotypes through marginalization and decomposition. in addition, we develop an efficient computing algorithm to further speed up the execution of the proposed method. through simulation as well as real data analyses, we show convincingly that the proposed method is much faster than existing methods, and yet is comparable in terms of imputation accuracy. a typical genome-wide imputation analysis for thousands of individuals, using the largest reference panel derived from the 1000 genomes project and routine computing devices can be accomplished within only a few hours with the method we developed.in this section, we investigated the performance of the proposed method, namely fish, as well as compared it with several existing popular methods, through simulated and real datasets.in this article, we have proposed a new method for performing diploid genotype imputation based on the hmm. we have also developed an algorithm mar for efficient execution of the proposed method. our method is comparable to most of the existing popular methods in terms of imputation accuracy and gdr, and is much preferable in terms of computational efficiency. we model hidden states on single reference haplotypes rather than on pairs of haplotypes. consequently, the computational complexity reduces from quadratic to linear to the number of reference haplotypes. to achieve the linear complexity, we define the equation (9), which assumes the independence ofthe random mating assumption, this independence equation holds as long as the total reference haploytypes serve as the entire population from which the test subject is sampled. in practice, it will hold approximately under large reference sample size, a condition for which our method was proposed. the computational improvement is qualitatively and quantitatively dramatic. we take into account haploid genotype uncertainty at each marker by weighted sum of both possible configurations. our simulation studies, as well as real data analyses, showed no significant loss of accuracy compared to conventional methods modeled on pairs of reference haplotypes. in the context of high-throughput sequencing datasets, an urgent priority for genotype imputation is to improve computational efficiency. several alternative solutions have been proposed, one of which is to pre-phase genotypes in the test sample into haplotypes, then to impute on the inferred haplotypes . this reduces the computational complexity so that it is linear to the number of reference haplotypes. however, haplotype phasing itself is a computation-demanding process in large-scale settings. moreover, the success of imputation on phased haplotypes relies largely on the availability and accuracy of statistical inference of haplotypes and may lose accuracy in certain conditions , though recent developments on haplotype phasing may ease this limitation . compared to the pre-phasing approach, our proposed method does not require haplotypes to be known. it has another potential to impute on data types that could not be pre-phased, though we did not consider that situation in the current study. another recent development includes imputing via matrix operation . however this method may cause some potential loss of accuracy, though it may lead to increased speed of computation. equation (14) provides an approximation of between-segmental transition probability calculation. when operating on long segments in which recombination events dominate probability calculations, such approximations may provide reasonable accuracy because individual haplotypes within a block receive the same probabilities regarding recombination. when operating on short segments in which initial haplotype probability dominates probability calculations, however, the loss of accuracy may become severe. an ideal requirement would be that the way to split segments will influence only computational efficiency, but not the imputation accuracy. the developed mar algorithm meets this requirement, which allows us to optimize the minimal computation without concerns on accuracy. the improvement of computation by compact representation depends on how reference haplotypes could be merged, and essentially, on maf and ld patterns. suppose that the total l markers are partitioned into l s segments, and there are on average n s blocks within segments. the computational complexity without compact representation is c 1 l r (for a single individual), and that with compact representation isthat the improvement in computation was highly correlated with this ratio. in summary, we have proposed a new statistical model and method for fast and accurate genotype imputation. our method is suitable for large-scale dataset analyses. the implemented software fish is publicly available for academic use.  
