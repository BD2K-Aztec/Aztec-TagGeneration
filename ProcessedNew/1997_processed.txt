genevalidator: identify problems with protein-coding gene predictions genomes of emerging model organisms are now being sequenced at very low cost. however, obtaining accurate gene predictions remains challenging: even the best gene prediction algorithms make substantial errors and can jeopardize subsequent analyses. therefore, many predicted genes must be time-consumingly visually inspected and manually curated. we developed genevalidator (gv) to automatically identify problematic gene predictions and to aid manual curation. for each gene, gv performs multiple analyses based on comparisons to gene sequences from large databases. the resulting report identifies problematic gene predictions and includes extensive statistics and graphs for each prediction to guide manual curation efforts. gv thus accelerates and enhances the work of biocura-tors and researchers who need accurate gene predictions from newly sequenced genomes. availability and implementation: gv can be used through a web interface or in the command-line. gv is open-source (agpl), available at https://wurmlab.github.io/tools/genevalidator.the plummeting costs of dna sequencing have made de novo genome sequencing accessible to individual laboratories and even researchers . however, identifying genes in a newly assembled genome remains challenging. traditional gene prediction approaches involve either ab initio prediction via modelling of coding versus non-coding sequence or similaritybased prediction using independent sources. relevant sources include protein-coding sequences from other organisms, or peptide or transcriptome sequences from the organism being studied. modern algorithms combine both approaches . the recent ability of obtaining large amounts of rna sequences at low cost has led to a dramatic improvement in the performance of similarity-based algorithms and thus gene prediction quality albeit only for expressed genes. despite this, the accuracy of gene prediction tools (e.g.) remains disappointing . typical errors include missing exons, noncoding sequence retention in exons, fragmenting genes and merging neighboring genes. automated gene prediction quality evaluation tools analyze exon boundaries or focus on subsets of highly conserved genes . unfortunately, such tools ignore most of the information present in frequently updated databases such as swissprot or genbank nr. visual analysis is thus required to identify errors and manual curation is needed to fix them. this requires tens of minutes to days for one gene a daunting task when considering analyses of dozens of species each with thousands of genes .gvs power comes from leveraging large, frequently-updated databases, using multiple metrics, input/output format flexibility and importantly its multiple data visualization approaches. indeed, visualization is crucial for understanding genomic comparisons . the code underlying gv respects best practices in scientific software development . however, gvs analyses depend, (h) conserved regions. graphs (ad) were produced with a sequence for which gv detected no problems. the other graphs show typical problems: (e) query is short; (f), (g) query sequence is a fusion of unrelated genes; (h): query includes sequence absent from first 10 hits on blast-identification of homologs in databases which include low-quality sequences, on expecting similar gene sequence and structure among homologs, and on empirically chosen cutoffs. binary results of individual tests are thus indicative rather than infallible. similarly, gvs overall quality evaluations are not ground truths but indicate consistencies with database sequences. we used two approaches to determine the appropriateness of gvs scoring system. gv scores for 10 000 randomly selected swissprot genes were significantly higher than gv scores for 10 000 randomly selected trembl genes (supplementary). similarly, 7390 of recently updated gene models from four eukaryotic genomes had higher gv scores than older versions (supplementary; supplementary). both results are consistent with gv appropriately quantifying gene prediction improvements due to manual curation or improved gene prediction technologies. lower gv scores for some gene predictions could be due the reference databases containing sequences of low-quality, new automated predictions introducing new errors and scores being noisy for queries with few blast hits.  
