sequence analysis pe-assembler: de novo assembler using short paired-end reads motivation: many de novo genome assemblers have been proposed recently. the basis for most existing methods relies on the de bruijn graph: a complex graph structure that attempts to encompass the entire genome. such graphs can be prohibitively large, may fail to capture subtle information and is difficult to be parallelized. result: we present a method that eschews the traditional graph-based approach in favor of a simple 3 extension approach that has potential to be massively parallelized. our results show that it is able to obtain assemblies that are more contiguous, complete and less error prone compared with existing methods. availability: the software package can be found atde novo genome assembly has been a fundamental problem in bioinformatics since the advent of dna sequencing. the secondgeneration sequencing technologies such as illumina solexa and abi solid have introduced a new sense of vigor to the field. the short length of the sequences coupled with high coverage and high level of noise has transformed de novo assembly to a tractable yet challenging proposition. the ease at which paired-end read libraries can be generated on these platforms is an added advantage. a number of works have been proposed to assemble short reads. the first few de novo assemblers developed to handle highthroughput short reads were based on base-by-base 3 extension. ssake, vcake and sharcgs are examples using this principle. to resolve ambiguities, these methods adapted trivial heuristics such as selecting the base with maximum overlap or selecting the base with the highest consensus. such arbitrary criteria results in substandard assemblies that were often a compromise between contiguity and error rate. furthermore, the approaches were not scalable to handle medium or large genomes; therefore, their use is restricted to assembling bac clones or small bacteria genomes. they were also not designed to make use of paired-end reads, thus greatly limiting their usefulness in assembling high-throughput data. to whom correspondence should be addressed.the more practical approaches for assembling high-throughput short reads have spawned based on de bruijn graph approach. velvet is perhaps the most widely used method for de novo genome assembly today. it is very fast in execution, fairly memory efficient and produces reasonably accurate assemblies. similar to all other methods based on de bruijn graph, velvet requires the entire genome to be stored in a graph structure. in the presence of noise, the graph may be too large to be stored on system memory. furthermore, resulting assembly generated from velvet tends to contain many errors at small repeat regions. another approach, euler-usr is very similar in concept to velvet, but employs more sophisticated error detection and correction steps. however, in practice, we noted velvet produces more contiguous and complete assemblies in comparison with eulerusr. both velvet and euler-usr take full advantage of paired-end read libraries. one of the major shortcomings of de bruijn graph approaches is the inability to parallelize the assembly process. this is a critical requirement as many powerful computers utilize multiple processors where numerous threads can be run seamlessly in parallel. introduction of abyss tackled this issue. the core assembly algorithm of abyss is very similar to that of velvet, but it allows de bruijn graph to be distributed across multiple cores/nodes, and each core/node can operate on the graph independently to a certain extent. the assembly result of abyss is similar to that of velvet. however, we noticed that when executed in parallel in a multi-core single computer, abyss does not offer any advantage over velvet in term of execution time or memory usage. to utilize abyss efficiently, it requires a multi-node computing cluster that may seem a disadvantage in an era where computers are increasingly made faster by adding more cores within a single cpu. soapdenovo addressed many of these issues by introducing a de bruijn graph-based method that can seamlessly takes advantage of multi-core systems. allpaths/allpaths2 appears to be the most accurate method at present. it introduces an interesting hybrid approach where the genome is still stored as a large graph; however, the graph is separated into different segments and assembly of these segments can be carried independently. this makes it possible to run some stages of allpaths algorithm in parallel. the high accuracy of allpaths is contributed by the fact that it tries all possible ways to assemble every segments; however, this comes at a tremendous cost in terms of time and memory usage, and therefore it will not augment well for larger genomes. we propose the method pe-assembler that is capable of handling large datasets and produces highly contiguous and accurate assemblies within reasonable time. our approach is based on simple 3 extension approach and does not involve representing the entire genome in the form of a graph. fundamentally, it is similar to other 3 extension approaches such as ssake, vcake and sharcgs. however, it improves upon such early approaches in multiple ways. the extensive use of paired-end reads ensures that the dataset is localized within the region. hence, our method can be run in parallel to greatly speedup the execution while staying within reasonable system requirements. ambiguities are resolved using a multiple path extension approach, which takes into account sequence coverage, support from multiple paired libraries and more subtle information such as the span distribution of the paired-end reads.pe-assembler has demonstrated that it is possible to obtain complete and highly accurate de novo genome assemblies using high-throughput sequencing data within reasonable time and memory constraints. the highlight of pe-assembler is that it eschews the traditional graph-based approach in favor of a simple extension approach. the advantages of this approach are numerous. memory requirements of graph-based approaches seem to increase exponentially as genome and data size increase. this was highlighted by the inability of velvet and allpaths2 to cope with simulated hg18 chr10 dataset. in contrast, pe-assembler produced a very usable assembly within a realistic memory limit. our approach is fundamentally similar to other 3 extension approaches such as ssake, sharcgs and vcake, but distinguishes itself due to its extensive use of paired-end reads. not only does it make such approach scalable to larger genomes datasets by localizing data, it also contributes to its high accuracy. as evident from both simulated and experimental data results, pe-assembler is the least prone of all algorithms to misassemble different regions of the genome in a continuous segment.perhaps the most important aspect of pe-assembler is its ability to seamlessly parallelize the assembly process. multiple threads can simultaneously assemble the genome at various positions across the genome, while a simple detection mechanism will ensure that multiple assemblies of the same region are highly unlikely. also noteworthy is that parallel assembly in pe-assembler does not come at an extra cost in memory as in other methods such as allpaths2 or abyss. being able to massively parallelize the assembly process at no extra overhead, it will prove valuable in assembling mammalian genomes as well as in larger metagenomics projects. with minor modifications, this approach can be extended to be run in a computer cluster across multiple nodes to further decrease the running time.  
