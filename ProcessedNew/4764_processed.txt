data and text mining two effective methods for correcting experimental high-throughput screening data motivation: rapid advances in biomedical sciences and genetics have increased the pressure on drug development companies to promptly translate new knowledge into treatments for disease. impelled by the demand and facilitated by technological progress, the number of compounds evaluated during the initial high-throughput screening (hts) step of drug discovery process has steadily increased. as a highly automated large-scale process, hts is prone to systematic error caused by various technological and environmental factors. a number of error correction methods have been designed to reduce the effect of systematic error in experimental hts (brideau et al., 2003; carralot et al., 2012; kevorkov and makarenkov, 2005; makarenkov et al., 2007; malo et al., 2010). despite their power to correct systematic error when it is present, the applicability of those methods in practice is limited by the fact that they can potentially introduce a bias when applied to unbiased data. we describe two new methods for eliminating systematic error from hts data based on a prior knowledge of the error location. this information can be obtained using a specific version of the t-test or of the 2 goodness-of-fit test as discussed in dragiev et al. (2011). we will show that both new methods constitute an important improvement over the standard practice of not correcting for systematic error at all as well as over the b-score correction procedure (brideau et al., 2003) which is widely used in the modern hts. we will also suggest a more general data preprocessing framework where the new methods can be applied in combination with the well correction procedure (makarenkov et al., 2007). such a framework will allow for removing systematic biases affecting all plates of a given screen as well as those relative to some of its individual plates.a typical drug development project starts with a candidate identification phase in which a large chemical compound library is tested against a given biological target . complex high-throughput screening equipment is employed at this to whom correspondence should be addressed. stage to obtain precise estimates of compound activity levels. the collected data are then used to identify the compounds that show the most promising drug-like activity behavior . the selected compounds, called hits, typically undergo further testing to confirm their reproducibility and suitability for drug development. depending on the nature of the study, the hits may be compounds with the highest activation capacity (i.e. activation assays), inhibition capacity (i.e. inhibition assays) or both. the hit selection process assumes that the measurements taken by hts equipment accurately represent the activity levels of the tested compounds. an important consideration for this to be true is that experimental conditions are the same for all compounds of the screen. biases in the measurements can nonetheless appear, due to inconsistencies in the environmental factors, such as electricity, temperature, humidity or lighting changes . organizational factors can also have a significant systematic impact on the results of an hts campaign. for example, differences in the incubation time allow the solvent evaporation to cause unintended variations in the solution concentrations. highly sensitive readers in particular can detect subtle differences among the tested molecules which misdirect follow-up efforts when they are due to bias rather than to biology. as a result of systematic bias causing under-or over-estimation of biological activity, inactive compounds may be incorrectly selected as hits (false positives), whereas promising (active) compounds may remain undetected (false negatives). in hts, systematic error is usually column or row dependent . it is important to note that systematic error can either affect compounds placed in the same well, column or row location in all plates of the screen (i.e. screen-specific error) or affect a column or row of a specific single plate of the screen (i.e. plate-specific error).illustrates the presence of positional effects in two publicly available experimental hts datasets: mcmaster test dataset, used as a benchmark for the mcmaster data mining and docking competition (; it contained the compounds intended to inhibit the escherichia coli dihydrofolate reductase, dhfr) and a dataset provided by the chemistry department of princeton university and consisting of a screen of compounds meant to inhibit the glycosyltransferase murg function of e. coli .examples demonstrate that systematic biases in hts may have different screen-specific and plate-specific systematic deviations. for instance, in the mcmaster dataset, the measurements in the column 10 are globally over-estimated , but in plate 1036 they are rather under-estimated . similarly,reveals apparent edge effects in the princeton dataset with the values of the outer rows and columns being below the screen average. this effect was not observed, however, for all plates of the princeton screen, with an evident over-estimation of the first column measurements detected in plate 144 . thus, systematic error correction methods should be able first to recognize the character of systematic error affecting the data at hand and then remove it either from the whole assay and/or only from the specific plates where it was detected. in this article, we describe two new methods for eliminating plate-specific systematic error and show how these methods can be applied in a more general correction framework that also includes the well correction procedure which allows for removing screen-specific systematic biases.we described two new methods, called mea and pmp, allowing for elimination of plate-specific systematic error from experimental hts data. both methods rely on the prior information concerning the location of the rows and columns of the given plate affected by systematic bias. such information can be obtained by using the methodology described in. we conducted a simulation study with different hts plate sizes, hit percentages and systematic error magnitudes. in this study, the mea and pmp methods were compared with the b-score and no-correction strategies. both new methods always outperformed the b-score and no-correction procedures when the number of the plates rows and columns affected by systematic error was low (4). in the simulations where the number of rows and columns affected by systematic error could reach 50 of the plates total number of rows and columns (3s), the mea and pmp methods generally yielded better results than bscore when the hit percentage was under 3 (in a typical hts campaign the hit percentage is usually under 1) or when the level of systematic error was under 1.8sd. the b-score method showed a more stable behavior than mea and pmp only when the number of rows and columns affected by systematic error, hit percentage and systematic error variance were high (mainly due to a mediocre performance of the t-test in this case). mea was generally the best method for correcting systematic error within 96well plates, whereas pmp performed better for 384 and 1536-well plates. the analysis of the mcmaster data mining and docking competition test assay showed that the new methods can be also applied in the combination with the well correction technique aiming to remove screen-specific systematic error. hence, a general data correction phase in hts, permitting for the elimination of both screen-and plate-specific systematic biases, can be conducted in the following way:(1) normalize the raw measurements using percent of control, normalized percent inhibition or z-score transformation. this normalization step can be carried out either on a plate-byplate basis or for all assay measurements together (i.e. when all plates have been processed under the same experimental conditions);(2) perform the t-test or 2 goodness-of-fit test on the hit distribution surface for the selected hit selection threshold; if systematic error is detected then carry out the well correction method;(3) perform the t-test or 2 goodness-of-fit test on each individual plate of the assay to identify its rows and columns affected by systematic error as well as the error locations;(4) for all plates where systematic error is detected: correct the plate measurements by carrying out the pmp or mea method (or, alternatively, the b-score procedure).in this study, we addressed the issue of the commonly considered additive systematic artifact that can be described using equation (17). it is worth noting that the multiplicative type of systematic bias affecting well (i,j) of plate p and defined by  
