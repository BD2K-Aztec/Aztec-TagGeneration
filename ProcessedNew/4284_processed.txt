sequence analysis slamem: efficient retrieval of maximal exact matches using a sampled lcp array motivation: maximal exact matches, or just mems, are a powerful tool in the context of multiple sequence alignment and approximate string matching. the most efficient algorithms to collect them are based on compressed indexes that rely on longest common prefix array-centered data structures. however, their space-efficient representations make use of encoding techniques that are expensive from a computational point of view. with the deluge of data generated by high-throughput sequencing, new approaches need to be developed to deal with larger genomic sequences. results: in this work, we have developed a new longest common prefix array-sampled representation, optimized to work with the backward search method inherently used by the fm-index. unlike previous implementations that sacrifice running time to have smaller space, ours lead to both a fast and a space-efficient approach. this implementation was used by the new software slamem, developed to efficiently retrieve mems. the results show that the new algorithm is competitive against existing state-of-the-art approaches. availability and implementation: the software is implemented in c and is operating system independent. the source code is freely available for download atwith the new high-throughput sequencing technologies becoming faster, cheaper and more accurate, the number of available genomes is growing fast. metagenomics is also pushing forward the need to align new sequences to those already known to compare different strains or assemblies, build phylogenetic trees, identify new genes, identify mutations or polymorphisms, observe structural variations and perform other relevant operations. it is well known that dynamic programming approaches are prohibitive, both in terms of required memory and processing time, when aligning large genomes or a number of different genomes. to approach these problems, strategies using seeded alignments with shared segments, which are identical among the sequences and act as anchor points for the alignment, have been developed. these anchors can be fixed-length exact matches, or k-mers, as those used in the blast tool. however, this type of match is inefficient because it can lead to an oversized number of hits, and these still have to be extended in both directions using pairwise comparisons, implying a significant processing time. much more efficient is the identification of maximal unique matches (mums) that have been introduced first by). mums are identical substrings that occur exactly once in each sequence and whose occurrences cannot be extended to either side without producing a mismatch. the second version of mummer introduced a new more compact suffix tree (st) representation, and the third and last one added the ability to output maximal exact matches (mems). these are similar to mums but can occur any number of times, which is useful when the number of mums is insufficient to produce enough anchors for a solid alignment, e.g. when many repeated regions exist. also, using mems instead of mums multiplies the regions covered by anchors, reducing considerably the areas requiring further processing. however, the bottleneck of mummer is the memory requirements of its st index structure, which can become problematic when it does not fit into the main memory. other closedsource tools based on enhanced suffix arrays (esas) such as vmatch and coconut have also been released, but they share the same problem. for this reason, and to deal with larger sequences, other approaches to find mems have been developed. the sparsemem approach makes use of a sparse sa as an index, which trades memory space for extra computational time. later, backwardmem used a backward search method over a compressed esa. more recently, essamem improved sparsemem by enhancing it with a sparse child array that reduces computational time maintaining the same memory footprint. this method currently shows the best tradeoff between time and memory consumption for mem identification. in this work, we propose another approach as an alternative to these previous tools. we have developed a new sampled representation of the longest common prefix (lcp) array, optimized to work with the backward search method inherent from the to whom correspondence should be addressed. fm-index. results show the effectiveness of the new method for a number of different genomes.  
