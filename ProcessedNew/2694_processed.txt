learning transcriptional networks from the integration of chipâ€“chip and expression data in a non-parametric model results: we have developed letice (learning t ranscriptional networks from the integration of chipchip and expression data), an algorithm for learning a transcriptional network from chipchip and expression data. the network is specified by a binary matrix of transcription factor (tf)gene interactions partitioning genes into modules and a background of genes that are not involved in the transcriptional regulation. we define a likelihood of a network, and then search for the network optimizing the likelihood. we applied letice to the location and expression data from yeast cells grown in rich media to learn the transcriptional network specific to the yeast cell cycle. it found 12 condition-specific tfs and 15 modules each of which is highly represented with functions related to particular phases of cell-cycle regulation. availability: our algorithm is available at http://linus.nci.nih.gov/data/youna/letice.zip contact:the process of transcription, whereby an rna product is produced from the dna, is an important control point for regulating the activity of genes and their protein products in particular cell types or in response to a particular signal. the circuit diagram of this transcriptional control process in which many transcription factors (tfs) act simultaneously and interactively to control the transcription of many genes is called a transcriptional regulatory network (trn). learning a trn from data is intrinsically difficult since most of the available data are highly condition dependent. therefore, using data obtained from a specific condition or experiment can reveal only limited parts of the network which are active in that specific condition. as a way of inferring and understanding aspects of a transcriptional network, previous researchers introduced the concept of modules. though the exact definition of a module varies between papers; in general, a module is a set of genes sharing a common set of regulating tfs. to whom correspondence should be addressed.the earliest attempts to learn a trn began with an introduction of expression data since these data provide a global view of expression levels of thousands of genes at a time.tried to learn a trn using the assumption that the expression levels of genes depend on the expression levels of the tfs regulating those genes. a fundamental limitation of this approach is that expression data only measure the mrna abundances, while it is the tf proteins that are directly involved in the regulation of genes. therefore, the mrna levels of the tfs may not be highly correlated with those of the genes they regulate. second, high correlation of expression levels only provides indirect evidence for the transcriptional hierarchy of the corresponding gene regulation. for example, two genes, a and b, may be highly correlated because (i) a regulates b or (ii) b regulates a, or (iii) both are regulated by a third gene c. these three cases may not be easily distinguished using microarray data alone. due to these intrinsic limitations of expression data for learning trns, it is important to integrate other available information, such as chipchip location data or dna motif data. location data often are presented as a matrix of p-values, with rows corresponding to genes and columns corresponding to tfs. for each tf j and gene i, the corresponding element of the matrix is the p-value for the hypothesis that there exists no interaction between tf j and the promoter region of gene i. therefore, location data provide direct evidence for the relation between tfs and the genes they regulate by identifying physical interactions between tfs and dna regions. however, location data also have limitations since this physical interaction may indicate binding but not function . also, location data are highly condition dependent and difficult to obtain. another widely used data type are motif data that provide information about which potential tf binding sites exist in the promoter region of a gene. motif data provide less direct evidence for the relation between tfs and genes than location data because motifs are merely potential binding sites which may not be bound by tfs. for this reason, we do not use motif data in our algorithm. because location, motif and expression data provide complementary information, many researchers have proposed methods for modeling a trn by integrating these data types. in general, they have taken either a regression approach or a clustering approach. the regression approach taken byis based on the rather strong assumption that the expression levels of tfs are correlated with the expression levels of the genes they regulate. the clustering approach followed byis based on the weaker assumption that expression levels of genes regulated by the same tfs are correlated. of the algorithms that use the clustering approach, the most widely cited are the gram algorithm and the remodiscovery algorithm . gram integrates location and expression data, whereas remodiscovery integrates location, expression and motif data to learn transcriptional modules. however, they share a common structure. they threshold p-value matrices representing location data and (for remodiscovery) score matrices representing motif data with single cutoffs t c and t m , respectively. then they seed the procedure by detecting modules of tightly coexpressed genes that share common subsets of tfs and motifs that exceed these thresholds. finally, they relax the thresholds and add additional genes whose expression patterns are similar to the core expression profile of the modules. we have developed an algorithm, which we call letice (learning t ranscriptional networks from the integration of chip chip and expression data). it follows the clustering approach like gram and remodiscovery. however, it differs from these algorithms in significant ways. first, letice defines a probabilistic model that integrates the location and expression data and fits this model by maximizing its likelihood. as a result, it simultaneously generates all modules using the entire set of tfs, and thus can identify combinatorial interactions between tfs. most other algorithms use subsets of tfs and a p-value cutoff to build modules sequentially and then use expression data to measure the quality of each module and to adjust it. thus, there is an asymmetry in integrating the two sources of data for those algorithms. second, letice uses a non-parametric probabilistic model for the expression data, and therefore does not impose any assumptions about the distribution such as the often violated normality assumption. finally, letice identifies condition specific tfs, i.e. tfs that are active in regulating genes in a given condition. finding such condition-specific tfs is important, but it is hard to do so simply by analyzing expression data or location data separately. many tfs actively regulating genes show constant expression profiles, and therefore identifying condition-specific tfs by variation in expression levels can result in many false negatives. finding condition-specific tfs using only location data is not effective either. if a tf does not regulate any genes then the p-values for the tf are uniformly distributed between 0 and 1. therefore, choosing condition-specific tfs using a p-value threshold can result in many false positives. by properly integrating expression and location data, letice is able to model tf bindings and identify the genes regulated by these tfs on a condition-specific basis.we developed letice, an algorithm for building a trn by integrating expression and location data. the trn is defined by a binding matrix b, which partitions genes into modules and a page: 1885 18791886  
