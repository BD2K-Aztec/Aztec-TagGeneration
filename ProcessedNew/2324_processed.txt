data and text mining identifying duplicate content using statistically improbable phrases motivation: document similarity metrics such as pubmeds find related articles feature, which have been primarily used to identify studies with similar topics, can now also be used to detect duplicated or potentially plagiarized papers within literature reference databases. however, the cpu-intensive nature of document comparison has limited medline text similarity studies to the comparison of abstracts, which constitute only a small fraction of a publications total text. extending searches to include text archived by online search engines would drastically increase comparison ability. for large-scale studies, submitting short phrases encased in direct quotes to search engines for exact matches would be optimal for both individual queries and programmatic interfaces. we have derived a method of analyzing statistically improbable phrases (sips) for assistance in identifying duplicate content. results: when applied to medline citations, this method substantially improves upon previous algorithms in the detection of duplication citations, yielding a precision and recall of 78.9 (versus 50.3 for etblast) and 99.6 (versus 99.8 for etblast), respectively. availability: similar citations identified by this work are freely accessible in the dj vu database, under the sip discovery method category atmost scientists today face intense competition in the race for peer recognition, visibility and international acclaim. academic distinction is gained based on the number of peer-reviewed publications in highly circulated journals. this intense pressure to publish, not only to advance, but also simply to sustain ones career, is summarized in the adage, publish or perish. because substantial amounts of time and resources are needed to complete scientific studies, there is often a natural desire to seek maximumsips have been shown to provide a more sensitive method of duplicate identification than etblast, the only tool currently used to identify duplicate citations. we have demonstrated that the sip method performs well in areas where etblast operates with low sensitivity. indeed, etblast has been shown to underperform in abstracts whose text similarity is low and whose size is small, i.e. below four sentences (data not shown). sips also outperform etblast in computation power. whereas etblast runs on a 40 cpu cluster and typically compares one abstract to all others in pubmed in 40 s to 1 min, the sips of an abstract are searched through pubmed in 69 s on average and the process can be run on a single cpu. although the parallelization of the sip code has not been performed on a cluster of 40 cpus, it would likely result in a substantial gain of speed when compared with etblast.in spite of this enhanced performance, the false positive rate of sip analysis is roughly equivalent to that of etblast. false positives are highly similar citations not otherwise considered to be duplicates. for these cases, the use of a text similarity tool (using a bag of word approach like etblast or short similar sentences with sips) would fail because text similarity does not account for natural syntactic inconsistencies such as synonym use or grammatical variations. when using an appropriate threshold for the sip score ratio 0.1 in this analysisfew false negatives were found. although we cannot measure the exact number without visually inspecting thousands of pairs, we estimate the false negative rate of sip analysis to be 18 when calculated using duplicates tagged in pubmed. both etblast and sip analysis use exceedingly simple text comparison techniques compared to advanced natural language processing algorithms, yet these tools have proven effective at identifying the majority of duplicate citations. the exhaustive identification of all duplicates in medline will necessitate the development of more sophisticated tools to analyze grammar and extract meaning from sentences rather than rely on word comparisons only. unfortunately, increased awareness of such technology could lead to an arms race, whereby authors wishing to plagiarize seek to exploit these areas of weakness in order to avoid detection. however, since most publications are now stored electronically, these authors will have to contend with the possibility that although the technology needed to detect these exploitations is not available now, it may be in the near futureat which point any hidden indiscretions may quickly rise to the surface.  
