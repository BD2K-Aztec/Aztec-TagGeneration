component-wise gradient boosting and false discovery control in survival analysis with high-dimensional covariates downloaded from motivation: technological advances that allow routine identification of high-dimensional risk factors have led to high demand for statistical techniques that enable full utilization of these rich sources of information for genetics studies. variable selection for censored outcome data as well as control of false discoveries (i.e. inclusion of irrelevant variables) in the presence of high-dimensional predictors present serious challenges. this article develops a computationally feasible method based on boosting and stability selection. specifically, we modified the component-wise gradient boosting to improve the computational feasibility and introduced random permutation in stability selection for controlling false discoveries. results: we have proposed a high-dimensional variable selection method by incorporating stability selection to control false discovery. comparisons between the proposed method and the commonly used univariate and lasso approaches for variable selection reveal that the proposed method yields fewer false discoveries. the proposed method is applied to study the associations of 2339 common single-nucleotide polymorphisms (snps) with overall survival among cutaneous melanoma (cm) patients. the results have confirmed that brca2 pathway snps are likely to be associated with overall survival, as reported by previous literature. moreover, we have identified several new fanconi anemia (fa) pathway snps that are likely to modulate survival of cm patients. availability and implementation: the related source code and documents are freely available atrapid advances in technology that have generated vast amounts of data from genetic or genome studies have led to a high demand for developing powerful statistical learning methods for extracting information effectively. for instance, understanding clinical and pathophysiologic heterogeneities among subjects at risk and designing effective treatment for appropriate subgroups is one of the most active areas in genetic studies. wide heterogeneities present in patients response to treatments or therapies. understanding such heterogeneities is crucial in personalized medicine, and discovery of genetic variants offers a feasible approach. however, serious statistical challenges arise when identifying real predictors among hundreds of thousands of candidates, and an urgent need has emerged for the development of effective algorithms for model building and variable selection. the last three decades have given rise to many new statistical learning methods, including cart , random forest , neural networks , svms and high dimensional regression . boosting has emerged as a powerful framework for statistical learning. it was originally introduced in the field of machine learning for classifying binary outcomes , and later its connection with statistical estimation was established byproposed a gradient boosting framework for regression settings. b hlmann andproposed a component-wise boosting procedure based on cubic smoothing splines for l2 loss functions. b hlmann (2006) demonstrated that the boosting procedure works well in high-dimensional settings. for censored outcome data, ridgeway (1999) applied boosting to fit proportional hazards models, and li and luan (2005) developed a boosting procedure for modeling potentially non-linear functional forms in proportional hazards models. despite the popularity of aforementioned methods, issues such as false discovery (e.g. seletion of irrelevant snps) and difficulty in identifying weak signals present further barriers. simultaneous inference procedure, including the bonferroni correction, has been widely used in large-scale testing literature. however, in many highdimensional settings, such as in genetic studies, variable selection is serving as a screening tool to identify a set of genetic variants for further investigation. hence, a small number of false discoveries would be tolerable and simultaneous inference would be too conservative. in contrast, the false discovery rate (fdr), defined as the expected proportion of false positives among significant tests , is a more relevant metric for false discovery control under the framework of variable selection. however, few existing variable selection algorithms control false discoveries. this has brought an urgent need of developing computationally feasible methods that tackle both variable selection and false discovery control. we propose a novel high-dimensional variable selection method for survival analysis by improving the existing variable selection methods in several aspects. first, we have developed a computationally feasible variable selection approach for high-dimensional survival analysis. second, we have designed a random sampling scheme to improve the control of the false discovery rate. finally, the proposed framework is flexible to accommodate complex data structures. the rest of the article is organized as follows. in section 2 we introduce notation and briefly review the l 1 penalized estimation and gradient boosting method that are of direct relevance to our proposal. in section 3 we develop the proposed approach, and in section 4 we evaluate the practical utility of the proposal via intensive simulation studies. in section 5 we apply the proposal to analyze a genome-wide association study of cutaneous melanoma. we conclude the article with a brief discussion in section 6.  
