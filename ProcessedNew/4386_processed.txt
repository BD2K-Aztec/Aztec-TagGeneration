sprites: detection of deletions from sequencing data by re-aligning split reads motivation: advances of next generation sequencing technologies and availability of short read data enable the detection of structural variations (svs). deletions, an important type of svs, have been suggested in association with genetic diseases. there are three types of deletions: blunt deletions , deletions with microhomologies and deletions with microsinsertions. the last two types are very common in the human genome, but they pose difficulty for the detection. furthermore, finding deletions from sequencing data remains challenging. it is highly appealing to develop sensitive and accurate methods to detect deletions from sequencing data, especially deletions with microho-mology and deletions with microinsertion. results: we present a novel method called sprites (split read realignment to detect structural variants) which finds deletions from sequencing data. it aligns a whole soft-clipping read rather than its clipped part to the target sequence, a segment of the reference which is determined by spanning reads, in order to find the longest prefix or suffix of the read that has a match in the target sequence. this alignment aims to solve the problem of deletions with microhomologies and deletions with microinsertions. using both simulated and real data we show that sprites performs better on detecting deletions compared with other current methods in terms of f-score. availability and implementation: sprites is open source software and freely available at https:// github.com/zhangzhen/sprites. contact:structural variation (sv) was originally defined as insertions, deletions and inversions larger than 1k bp in size , and now has been extended to include much smaller variants (e.g. those 50 bp in length) and more types of variants, such as translocation and tandem duplication. these variants are prevalent in human populations and are associated with human diseases, complex traits and evolution . thus, finding svs is an important task. recent advances in high throughput sequencing make it possible to reveal more variants than ever before. many efforts have been made to detect variants from high throughput sequencing data. for example, the 1000 genomes project v c the author 2016. published by oxford university press. all rights reserved. for permissions, please e-mail: journals.permissions@oup.comconsortium has released sv data of 1092 individuals from 14 populations . some methods are specially designed for detecting a specific type of svs: svseq for deletion and mindthegap for insertion. a deletion indicates a dna segment missing in an individual genome, also known as a donor/sample genome, compared with the reference genome. eighty percent of genetic disorders in the disease database, database chromosomal imbalance and phenotype in humans using ensembl resources (decipher), are caused by deletions . deletions are such an important type of svs that almost every sv discovery tool has developed a module to find deletions. we focus on the discovery of deletions in this article. read pairs are the most common form of current sequencing data. dna libraries are generally constructed by shearing a genome into fragments, cloning and size-selecting the fragments. a library is a collection of fragments with a roughly equal size. the length of a fragment excluding adapters at two ends is commonly referred to as the insert size. the insert size varies from fragment-to-fragment. the exact value of insert size for each fragment cannot be determined but its approximate value can be estimated by sampling. the normal range of insert sizes is specified through the library mean and standard deviation . two reads of a read pair are generated by sequencing two ends of a fragment. before calling variants are performed, these read pairs need to be mapped to a reference genome using read mappers such as bwa and bowtie2 . if two reads of a read pair are successfully mapped, its insert size is then given as the distance between two corresponding locations on the reference genome. an anomalous insert size indicates a value beyond the normal range. the corresponding read pairs are called discordant read pairs. analyzing discordant read pairs to reveal variants, such as read pair method, is one of the most common approaches. many tools adopt such approach, such as breakdancer , pemer , variationhunter , and gasv . although read pair methods can improve the resolution of calling with high-coverage data, they uncover variants by giving only inexact positions of breakpoints. the read depth method is another approach that gives approximate breakpoints. read depth refers to the number of reads mapped to a particular part of the genome and can indicate how many copies of a region are present, but it cannot indicate where the copies occur . segseq , ewt and cnvnator are some examples of algorithms that apply this approach. assembly and split read methods are two types of approaches that are able to detect variants with base-pair breakpoint resolution. assembly methods exploit aberrations from the reference genome to identify locations where variants might be, and then assemble reads just for that area . comparing the assembled contigs to the area on the reference genome can detect variants with exact breakpoints. however, assembly methods have limitations. although only local assembly is performed, all reads of the library are processed in order to construct the k-mer spectrum that is required for assembly. the step requires a large amount of time and memory to run. it also tends not to deal well with heterozygous variants, which occur on only one of a pair of homologous chromosomes . split reads refer to those that cover breakpoints of variants whether they are single-end or paired-end. split read methods, as their name implies, derive variants from these split reads. read aligners can help identify split reads. given a pair of reads r i ; r 0 i , if r i is mapped and r 0 i is either unmapped or soft-clipped at the 5 0-or 3 0-end, r 0 i may be a split read. in some cases it may not be a split read due to either sequencing error or mapping error. there are two ways to use split reads to detect variants: via split read mapping and via soft-clipped mapping. split read mapping focuses on unmapped reads. an unmapped read was first broken up into two parts. then, these two parts are respectively mapped to the reference sequence, which results in the breakpoint of the corresponding variant being pinpointed. examples of split read mapping-based methods include pindel , age , svseq , prism and delly . soft-clipped mapping focuses on reads with the 5 0-or 3 0-end soft-clipped. these reads are also called soft-clipping reads. one breakpoint of the variant is specified by the mapping location where soft-clipping occurs. the other breakpoint is determined by aligning the soft-clipped segment of the read to the reference sequence. clipcrop , crest , svseq2 and socrates are representatives of soft-clipped mapped-based methods. split read methods have a few disadvantages, such as time and memory inefficiency, and both high false positive and false negative rates. some of them do not perform well on low-coverage data. three deletion types are observed in the human genome: (1) blunt deletions: nothing special happened at the breakpoints, (2) deletions with microhomologies: two small identical sequences at deletion breakpoints, and (3) deletions with microinsertions: deletion breakpoints having a small untemplated sequence inserted.studied the breakpoints of 315 deletions and found that 70 of breakpoints have 130 bp of microhomology, 33 of breakpoints contain 1369 bp of inserted sequence, and 10 of breakpoints have both simultaneously. only a few breakpoints ($7) have blunt ends. the presence of microhomology and microinsertion creates problems for re-aligning the clipped part. microhomology in a soft-clipping read causes the clipped part to be too short for the alignment. the alignment algorithm returns multiple hits for the clipped part. finding the correct one among these hits is challenging. microinsertion in the clipped part causes the alignment to fail because inserted sequence cannot match the reference. however, split read mapping can deal with microhomology and microinsertion. pindel uses the pattern growth approach to report deletions with microinsertions. age aligns the 5 0 and 3 0 ends of two given sequences simultaneously and creates a jumping gap to address their presence. delly follows the age approach and makes changes to age. despite the availability of these tools, methods with high accuracy are required for the detection of deletions with microhomologies and microinsertions. in this article, we present a new method called sprites (split read re-alignment to detect structural variants) for detecting deletions from sequencing data. sprites can solve the problem that microhomologies and microinsertions cause. it re-aligns the whole read rather than the clipped part to the target sequence, a segment of the reference, in order to find the longest prefix or suffix of the read that has a match in the target sequence. in the case of microhomology, the length of the sequence to be matched is extended to the length of clipped part plus the length of microhomology. the longest mapped prefix or suffix of the read can usually cover microhomology. thus, the deletion call is easy to determine. in the case of microinsertion, the longest matched prefix or suffix of the read can avoid the impact of microinsertion on the detection. the comparison of the re-alignments of the soft-clipped segment and the whole read is illustrated in. sprites uses alignments produced by bwa, while it can also use alignments produced by other read aligners that support 5 0-or 3 0-end soft-clipping, like bowtie2 . re-alignment is one of most time-consuming tasks in the detection. a target sequence is a segment of the reference. for a soft-clipping read, sprites relies on its spanning read pairs to determine the size and location of target sequences. given that most of these target sequences have a length of only hundreds of base pairs, re-aligning soft-clipping reads to them saves a large amount of time. the input file has the size on the order of gigabytes. sprites transverses it from start to end only once and only stores information about soft-clipping reads that are useful for deletion detection, which reduces sprites memory footprint. besides its great performance on lowcoverage data, sprites can also be used for the analysis of highcoverage data. we tested it extensively on the simulated data and real sequencing data and compared it with four other detection tools including svseq2, lumpy, delly and pindel. the results show that among these tools sprites is highly sensitive at the relatively low false discovery rates and thus has the greatest f-scores in many cases. the major contributions of this article include: (1) our method can find the longest prefix or suffix of a soft-clipping read that has a match in the target sequence by performing the re-alignment; (2) our method solves the problem of deletions with microhomology and deletions with microinsertion, which are very challenging to be found from the sequencing data; (3) our method limits the alignment length so that time and memory usage are dramatically reduced; (4) a piece of open source software is implemented based on our method and can be freely available.we compared sprites with the four most commonly used sv detection tools, i.e. pindel, svseq2, delly and lumpy . pindel is the first tool that relies on the concept of splitting reads to detect variants. besides deletions, it is able to call other types of variants, such as insertions and inversions. svseq2 is a tool that specializes in finding deletion calls. deletions are called by realigning the soft-clipped sequence of reads, which is similar to our tool. it focuses on analyzing low-coverage data. the latest version of svseq2 can only process one chromosome at a time. when working on whole genome data, we first ran svseq2 for each chromosome (or contig) of the human reference genome and then concatenated the results of individual chromosomes to obtain the final results. lumpy is a probabilistic-based approach for sv discovery, which integrates multiple sv detection signals, such as read pairs, split reads, thereby achieving a substantial improvement in detection as compared with other popular sv tools such as breakdancer, gasvpro . homozygous variants are commonly used for the detection evaluation. however, heterozygous variants are prevalent variants which are often less deleterious but more frequent among genetic disorders compared with homozygous variants. moreover, the detection of heterozygous variants plays a substantial role in the tumor study because that real samples tend to be a mixture of abnormal and normal genomes and tumor samples usually to have more heterogeneous variants than homozygous ones . however, detecting heterozygous variants is problematic. so we use heterozygous variants for the evaluation besides homozygous variants. ryan layer, the author of lumpy, provided us with two artificial genomes: one genome with 2500 randomly generated deletions of size 100 bp to 10 kbp, the other genome with 5516 non-randomly generated deletions. the 5516 deletions were publicly released by the 1000 genomes project. svsim (https://github.com/ gregoryfaust/svsim), an sv simulator, was used to generate these genomes by introducing these deletions into the b37 version of human reference, also known as grch37 version. the fasta file of the b37 version can be found at ftp://ftp.1000genomes.ebi.ac.uk/ vol1/ftp/technical/reference/. the location of these simulated deletions in these genomes was recorded in two bedpe files. we used the first genome for homozygous deletion detection and the second genome for heterozygous deletion detection. the first genome was intended for homozygous deletion detection. we used wgsim (https://github.com/lh3/wgsim), a read simulator, to sequence this genome with 2, 5, 10, 20 and 50 haploid coverage, respectively, to generate paired-end reads of length 150 bp. the insert size of paired-end reads was centered at 500 bp with the standard deviation equal to 50 bp. generated reads contained sequencing errors (the overall error rate of 0.5). the second genome was intended for heterozygous deletion detection. in order to generate heterozygous deletions, a normal genome and an abnormal genome were required. we used the b37 version of the human reference genome as the normal genome and the genome with 5516 deletions as the abnormal genome. pairedend reads were generated by using wgsim to sequence the two genomes with 0.05, 0.1, 0.2 and 0.5 sv allele frequencies at 10, 20 and 40, respectively. for example, we generated reads with 0.05 sv allele frequency at 10 coverage like this: we used wgsim to sequence the normal genome at 9.5 haploid coverage and sequence the abnormal genome at 0.5 haploid coverage, then the two sets of reads were combined to form pair-end reads with 0.05 sv allele frequency at 10 coverage. reads for heterozygous deletions have the same properties with reads for homozygous deletions. whether reads are for homozygous deletions or for heterozygous deletions, they need to be mapped to the reference for use with detection tools. bwa aln was used to map reads. then, alignment files were sorted and indexed by samtools . lumpy required as input two bam files: a file that was the original bam file and a file that represented split read alignment. the split read alignment file was generated as follows: split reads were first extracted from the original bam file using a custom script provided along with the lumpy program; these split reads were then realigned by yaha . furthermore, we used the data of the na12878 individual released by the illumina platinum genomes project and the data of the five other individuals (na19311, na19312, na19313, na19316 and na19317) provided by the 1000 genomes project, as the real data for the evaluation. sprites uses two micro-intervals to represent the two breakpoints of a deletion. micro-intervals reflect the fact that microhomologies and microinsertions occur at deletion breakpoints. lumpy also uses two intervals to represent breakpoints. however, for each deletion svseq2 and pindel predicted, two breakpoints were converted to two breakpoint intervals with a length 100 bp. for each known deletion, the same conversion was performed. since delly provides the confidence interval of deletion breakpoints, we used them as breakpoint intervals and no conversion was performed. a deletion call is represented by two breakpoint intervals a and b. a known deletion is represented by two breakpoint intervals a 0 and b 0. the deletion calls overlaps the known deletion if and only if a overlaps a 0 and b overlaps b 0. bedtools was used for checking such overlaps. a call is a true positive (tp) if the call overlaps a known deletion, otherwise it is a false positive (fp). false negatives (fn) refer to the known deletions that sv detection tools failed to report. a comprehensive measure, called f-score, is mainly used to evaluate the methods. the f-score is defined as the harmonic mean of the sensitivity and the precision (1 fdr). the sensitivity is defined as tp tpfn while the false discovery rate (fdr) is defined as fp tpfp .sprites is a new deletion detection method based upon re-aligning soft-clipping reads. results of tests on both simulated and real data show that sprites is more sensitive in low-coverage data. the false discovery rate of sprites is also low. as a result, sprites performs the best overall in terms of the f-score in low-coverage data. furthermore, there is also evidence that realigning soft-clipping reads is more effective than realigning their soft-clipped segments. tests on simulated data show that sprites is able to detect deletions with microhomologies and microinsertions at breakpoints in addition to blunt deletions. we have only used reads with soft-clipping at the 5 0-end because 5 0-end has generally higher quality than 3 0end. the reason why sprites does not work well in high-coverage data may be that sprites does not directly use paired-end information for the detection. since there is plenty of paired-end information in high-coverage data, such information could play a more important role in the detection in high-coverage data than in low-coverage data. utilizing paired-end information in order to improve its performance in high-coverage data is one of directions of our future work. the development of next generation sequencing technologies has increased read length from 36 to 100200 bp. as a result, sv detection methods have shifted from pure pe methods to sr and to hybrid methods such pe sr methods. as the trend continues, we believe that re-aligning split reads-based methodology will play an important role in sv detection in population-scale and cancergenome studies, because such methods are applicable to these types of data.  
