genetics and population analysis an integrated approach to reduce the impact of minor allele frequency and linkage disequilibrium on variable importance measures for genome-wide data motivation: there is growing momentum to develop statistical learning (sl) methods as an alternative to conventional genome-wide association studies (gwas). methods such as random forests (rf) and gradient boosting machine (gbm) result in variable importance measures that indicate how well each single-nucleotide polymorphism (snp) predicts the phenotype. for rf, it has been shown that variable importance measures are systematically affected by minor allele frequency (maf) and linkage disequilibrium (ld). to establish rf and gbm as viable alternatives for analyzing genome-wide data, it is necessary to address this potential bias and show that sl methods do not significantly under-perform conventional gwas methods. results: both ld and maf have a significant impact on the variable importance measures commonly used in rf and gbm. dividing snps into overlapping subsets with approximate linkage equilibrium and applying sl methods to each subset successfully reduces the impact of ld. a welcome side effect of this approach is a dramatic reduction in parallel computing time, increasing the feasibility of applying sl methods to large datasets. the created subsets also facilitate a potential correction for the effect of maf using pseudocovariates. simulations using simulated snps embedded in empirical data assessing varying effect sizes, minor allele frequencies and ld pat-ternssuggest that the sensitivity to detect effects is often improved by subsetting and does not significantly under-perform the armitage trend test, even under ideal conditions for the trend test.genome-wide association studies (gwas) have successfully detected numerous single-nucleotide polymorphisms (snps) associated with a variety of phenotypes, but the identified loci at best explain a modest proportion of the heritable variance estimated by twin and family studies . recent estimates of the heritable variance explained by all snps, however, indicate that genome-wide snp data does offer substantial explanatory power . this gap of missing heritability between heritability estimates and the snps detected by gwas has led to increasing concern over the performance of gwas, with attention focused on low power due to the multiple testing burden and small effect sizes, as well as the omission of rare disease alleles and epistatic effects, among other issues . these shortcomings of gwas have encouraged the application of statistical learning (sl) methods as an alternative for analyzing genome-wide data . sl methods are designed specifically for the task of identifying meaningful predictors in high-dimensional data, relying on data-driven algorithms rather than conventional parametric modeling. numerous sl methods have been proposed for use with snp dataincluding random forests (rf;), multifactor dimensionality reduction and the lasso generally with encouraging results. rf has received significant attention in the genetics literature with surprisingly less attention given to gradient boosting machine (gbm;) despite its similarity to rf. both rf and gbm build an ensemble of non-parametric prediction models, with each model constructed iteratively using all available snps. gbm additionally applies boosting to build each model with a focus of improving model fit for cases fit poorly in the previous iteration. importantly, the iterative tree-building approach of rf and gbm accounts for conditional relationships and complex causal mechanisms, including epistasis and covariate effects, without a priori specification. individual snps are then evaluated using variable importance measures, which quantify each snps total contribution to the prediction of the phenotype . such variable importance measures can be used to rank-order snps by importance, identifying potentially informative snps among genome-wide data. studies of rf with snp data have yielded promising results. simulations suggest that rfs power to detect causal snps exceeds fishers exact test when epistasis is present and is still comparable with fishers exact test when detecting main effects only to whom correspondence should be addressed.. rf maintains this advantage even if many noise snps are present . applying rf to genome-wide data is feasible, though computationally burdensome. with empirical genome-wide data, rf is capable of replicating gwas results and identifying additional candidate snps . although these results are encouraging, further study is necessary to establish rf and gbm as viable alternatives to gwas methods. few studies of sl methods account for linkage disequilibrium (ld), utilize realistic effect sizes or compare the sensitivity of the sl method to gwas.considered more realistic ld and effect sizes but only focused on rf as a second-stage analysis. meanwhile, gbm merits further consideration based on its strong performance relative to rf. studies show gbm performs even better than rf for many data types but evaluation of its performance with genome-wide snp data is still needed. in addition, concerns have been raised about the impact of minor allele frequency (maf) and ld on the variable importance measures used by rf and gbm to rank-order snps. with respect to ld, importance scores for correlated functional snps are inflated when using variable importance measures based on the gini criterion , whereas importance scores for functional snps correlated with uninformative predictors are deflated . correlated predictors do not induce bias in permutation-based importance measures, though the variability of importance scores is decreased . maf may also influence importance scores, with higher maf being associated with higher gini importance values for all snps, and higher permutation importance values for functional snps . the influence of maf may be attributed, at least in part, to the tendency of the rf algorithm to prefer predictors with higher variability . taken together, such effects may increase the difficulty of detecting disease-causing variants located in ld blocks or with low maf, especially when using gini-based importance measures. methods for controlling the impact of maf and ld on variable importance have been proposed. to address the effect of ld,introduced a modified rf algorithm and accompanying importance measure that account for the competition between correlated snps for inclusion in rf models.developed a conditional permutation scheme for the variable importance that successfully addresses the impact of correlated predictors. alternatively, pseudocovariates (pcvs) may be added to the data to simultaneously address the effect of all structure in the data that are unrelated to the phenotype . although each of these methods have been demonstrated to potentially reduce the impact of ld and maf, all three increase the computational burden beyond what is feasible for genome-wide data.specifically note that their method does not scale to be feasible with genome-wide data. the current implementation of the conditional methods proposed byalso have substantially larger memory requirements than conventional rf. correction with pcvs is similarly infeasible, effectively doubling the size of the data and requiring a number of replications of the analysis to establish stable estimates. in sum, to establish rf and gbm as viable methods for genome-wide snp data, it will be necessary (i) to address concerns over the impact of ld and maf while maintaining computational feasibility and (ii) to provide a direct comparison with conventional gwas methods under realistic conditions. in this study, we propose and evaluate a procedure designed to reduce the impact of ld on rf, gbm or related sl methods for genome-wide data. the proposed method creates overlapping subsets of snps from a genome-wide dataset under the constraints that snps within a set are not in ld, and that each snps is represented in at least a user-specified number of subsets (see methods). the sl method of choice can then be performed on the subsets without concern for ld, followed by an aggregation of results over subsets. next, we show that the proposed subsetting procedure is computationally feasible for genomewide data. dividing the data into subsets makes analysis of each piece more manageable and facilitates parallel computation across multiple cores or on a high-performance grid for a drastic reduction of computing time. third, we evaluate a correction for the impact of maf adapted from the methods proposed by), which is computationally feasible in combination with the subsetting procedure. specifically, in each subset, we generate a small set of independent pcvs with zero association with the phenotype, coded as snps with maf ranging from 0.01 to 0.50. variable importance estimates for the pcvs in each subset are aggregated to provide a stable estimate of variable importance attributable to maf. this estimate can then be used to correct the importances of the empirical snps. finally, we provide a rigorous direct comparison of the sensitivity of rf and gbm to the armitage trend test (att;), the test utilized most frequently in conventional gwas analyses , under realistic data conditions. using simulated snps embedded in empirical genetic data, we show that the sensitivity of rf and gbm is broadly consistent with the att for snps explaining as little as 1 of the phenotypic variance even under conditions that do not leverage the advantages of rf and gbm (i.e. a linear additive model without dominance or epistatic effects;).sl methods such as rf and gbm are a viable alternative to conventional parametric testing of individual snps in a gwas. however, there are valid concerns over the impact of ld and maf on variable importance measures that must be addressed. in response, this study presents an integrated approach to meaningfully reduce the effect of ld and maf on variable importance in rf and gbm. the results of this study show that the proposed subsetting algorithm can successfully reduce or eliminate the effect of ld on the variable importance measures of rf and gbm. the process of aggregating results over the subsets is not biased by the number of subsets containing a given snp and, in many cases, may aid the detection of effect snps. in particular, the use of ld subsetting can be expected to aid rf and gbm is identifying effect snps within ld blocks. since ld subsets are constructed prior to analysis, the procedure could also be applied to other sl methods. importantly, gbm provides detection rates for the functional snps within sampling variation of detection rates for the att. this result for gbm is especially encouraging given that this study uses an additive genetic model that precisely matches the type of effect anticipated by the att. sl methods may be expected to provide substantial improvement over the att for detecting correlated effect snps and snps with non-additive and epistatic effects . alternatively, rf and gbm may act as an initial screen to reduce genome-wide data to a set of candidate snps small enough to make thorough modeling of their complex relationships feasible using penalized regression or other appropriate methods . the ld subsetting approach also facilitates the introduction of pcvs, as proposed by, which may potentially be used to correct for the effect of maf on variable importance measures. the proposed pcv correction evaluated in this study provides a marked reduction in the effect of maf on non-effect snps. caution is necessary in applying pcvs, however, given a moderate effect of maf remains and the effect of maf on the importance of functional snps may be magnified, with uncertain implications (supplementary information). still, pcvs at minimum provide the option of emphasizing sensitivity to snps with low maf, which may contain the majority of heritable variance for some phenotypes, such as high-density lipoprotein (hdl) cholesterol , and can be difficult to detect with conventional methods . finally, in addition to pcvs numerous covariates for comorbid disorders, environmental factors and other influential variables may be included in the analysis with a much lower computational cost than for popular gwas software . a number of factors may be considered in seeking to improve the approaches evaluated by this study. more careful tuning of the metaparameters for the ld subsetting algorithm, including the selection of k, b and t, may enhance the effectiveness of the correction. alternative methods to improve the use of pcvs to correct for the effect of maf may also be explored. the correction proposed here is only one possible application of pcvs; other versions may improve the effectiveness of pcvs or carry different advantages tailored to the preferences of the researcher. finally, these results show strong results for gbm that are consistent with the more widely known rf; additional work should be performed to evaluate gbm as a viable tool for analyzing genome-wide data, especially given its lighter computational burden. although our approach does not fully eliminate the impact of ld and maf on variable importance measures, the proposed corrections provide a satisfying improvement. importantly, ld subsetting also facilitates analysis in a parallel environment, improving the computational feasibility of these methods for genome-wide data. continuing efforts to establish the validity, reliability and feasibility of sl methods such as rf and gbm with genome-wide data will be crucial to establishing these methods as viable alternatives to conventional gwas analyses.  
