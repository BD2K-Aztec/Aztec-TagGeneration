gene expression normalization of metabolomics data with applications to correlation maps motivation: in metabolomics, the goal is to identify and measure the concentrations of different metabolites (small molecules) in a cell or a biological system. the metabolites form an important layer in the complex metabolic network, and the interactions between different metab-olites are often of interest. it is crucial to perform proper normalization of metabolomics data, but current methods may not be applicable when estimating interactions in the form of correlations between me-tabolites. we propose a normalization approach based on a mixed model, with simultaneous estimation of a correlation matrix. we also investigate how the common use of a calibration standard in nuclear magnetic resonance (nmr) experiments affects the estimation of correlations. results: we show with both real and simulated data that our proposed normalization method is robust and has good performance when discovering true correlations between metabolites. the standardization of nmr data is shown in simulation studies to affect our ability to discover true correlations to a small extent. however, comparing standardized and non-standardized real data does not result in any large differences in correlation estimates. availability and implementation: source code is freely available at https://sourceforge.net/projects/metabnorm/in metabolomics, the ultimate goal is to determine quantitatively the levels of all metabolites (small molecules) in a biological sample. at present, it is not possible to measure the complete metabolome, and, depending on the purpose of the experiment, the number of features measured can range from a handful to a couple of thousands. usually, in targeted experiments, a small number of features are measured, and the metabolites are completely identified. in untargeted experiments, many more features are quantified, but a majority of them cannot be identified as a specific metabolite. subsets of the metabolome are sometimes referred to as metabolic profiles . several methods are at our disposal for metabolomic analyses, e.g. nuclear magnetic resonance (nmr) spectroscopy or gas chromatography coupled to mass spectrometry. in this article, we focus on metabolomics data from nmr experiments. when quantifying metabolite levels by using proton nmr, the protons in a molecule give rise to a signal that appears as one or several peaks in a spectrum. because of spin-quantum effects, peaks split in different ways and may overlap, but it is often possible to assign and quantify peaks that belong to a single metabolite or group of metabolites. usually, the signal from a metabolite is quantified by calculating the area of a peak that can be uniquely assigned to it, although peak heights are also sometimes used. to quantify the concentrations of the metabolites, it is common practice to add a known amount of a certain compound to each sample. when the compound is dissolved in the sample itself, it is called an internal standard. in contrast, an external standard would be either a solution of the compound in a capillary or the compound run as a separate sample but with the same experimental setup. the added calibration compound then gives rise to a control peak in the spectrum of the sample. compounds commonly used as (internal) calibration standards in proton nmr are trimethylsilyl propionate (tsp) and tetramethylsilane. the following formula is used to calculate the concentration of the metabolites using the calibration standard. let c i be the concentration of metabolite i, and c 0 the (known) concentration of the control compound. setwhere n 0 is the (known) number of protons in the control molecule, n i is the (known) number of protons in metabolite i, a i is the measured peak area of metabolite i and a 0 is the peak area of the standard. besides helping with quantification, a calibration standard is useful for chemical shift calibration, which helps in identifying the metabolites by using the chemical shift values in the literature. however, the use of the standard can be troublesome in some scenarios, as we show in appendix a in the supplementary information. the fact that the standardization is done as a ratio will induce apparent correlations between metabolites, even if none exists in the first place. to whom correspondence should be addressed.metabolites in the cell participate in enzyme-catalyzed reactions that form complex biochemical networks. there are often interactions between metabolites (affecting their concentrations) when they appear in the same biochemical sub-network, or pathway. if, for instance, there is a rise in the cellular concentration of a metabolite that is the substrate of an enzyme, then the catalyzed reaction will usually proceed more rapidly so that the product of the reaction will also tend to increase in concentration. thus, the concentrations of substrate and product would tend to be positively correlated. in the same way, negative correlations may occur when an increase in concentration of one metabolite leads to the depletion of the second metabolite. an example might be an enzyme that is subject to allosteric inhibition: a rise in the cellular concentration of the inhibitor metabolite would then tend to reduce the cellular concentration of the enzymes product. thus, the inhibitor and the product would be negatively correlated. analysis of the positive and negative correlations between metabolites can be performed by preparing a large number (typically 3050) of apparently identical samples of, for instance, cultured cells. although the measured concentrations of cellular metabolites in the individual samples will be identical within biological variation, that uniformity is achieved by numerous homeostatic mechanisms that will give rise to positive and negative correlations between metabolite concentrations. this type of analysis is often referred to as metabolitemetabolite correlation analysis (mmca) . the terms mmca, correlation analysis and estimation of correlation maps will be used interchangeably in this article. commonly, pearson correlations are used to estimate the interactions between metabolites. the use of mutual information has also been suggested as a dependency measure, as it captures more than linear relationships between metabolites . however, as metabolomics data generally are quite skewed, even after transformation with a standard as in equation 1, the pearson coefficient may not be a good estimate of the correlations (see further discussion below). a transformation of the data may therefore be needed before further analysis. estimating interactions with mutual information can also benefit from such transformations . the need for normalization for metabolomics data is crucial, just as with other types of omics data. nmr samples are affected by technical artifacts and may exhibit inflated between-sample variation owing to batch effects. for correlation analysis, these batch effects, together with effects from standardization, will result in large positive correlations, as illustrated in. a few normalization methods for metabolomics data have been suggested in the literature. the nomis method is based on the presence of multiple internal standards in each sample. the optimal combination of standards is selected and used to remove systematic error. also dependent on multiple internal standards is the ccmn method , which is mainly aimed at mass spectrometry-based metabolomics data. a recent addition to the field is the ruv-2 method, which is shown to be powerful for removal of unwanted variability while not being dependent on internal standards . however, ruv-2 is not a global normalization method in the sense that it does not produce a complete normalized dataset, but rather a compressed set suitable for detecting differentially abundant metabolites. hence, ruv-2 is not recommended in connection to classification, clustering problems or mmca. in situations when these metabolomics normalization methods are not appropriate, normalization methods adapted from the single-channel microarray literature are commonly used. however, the nature of some common single-channel methods, e.g. quantile normalization , renders them inappropriate to use on the smaller datasets that are usually produced in metabolomics. in quantile normalization, the idea is to give each sample the same distribution over features (e.g. metabolites). this is achieved by sorting the values in each sample, calculating a mean quantile over the samples and substituting the value of the data item in the original dataset with the mean (followed by a re-sort of each sample). this can be problematic for features in the tails of the distribution, as it is possible that a feature could receive the same value across all samples. the result of this is that, as happens with our dataset described in section 2, some correlations between metabolites cannot be calculated. the median centering normalization also proves to be relatively non-robust if the number of metabolites is small (see discussion below). in this article, we investigate how the use of a calibration standard for quantitation affects the reliable estimation of correlation maps. we argue that log transformations are reasonable for metabolomics data, and we suggest a global normalization method, suitable for smaller (targeted) metabolomics datasets, that is robust in connection to mmca. the purpose of this normalization is to remove variation due to sources other than homeostatic changes. the proposed global normalization method is intended to be a complement to existing methods dependent on multiple internal standards and methods that only function in differential expression settings.the purpose of this article is two-fold; first we propose a global normalization method intended for use with smaller metabolomics datasets, and second, we investigate how well correlations can be discovered when we have the option of using nmr data calibrated using a standard, or not. when comparing raw and standardized metabolite levels (peak areas/concentration) for the real hdf dataset, we observed large positive correlations in the non-normalized data. such large correlations are not biologically reasonable, as we expect both negative and positive correlations to be present, and we argue that they are caused by batch effects and the calibration standard . the positive correlations were more pronounced for the standardized data, which is a cause for concern. however, after normalization, both the raw and standardized data exhibited better correspondence, and large differences in estimated correlations could not be found. most likely, the influence of the calibration standard is (at least partly) removed by the inclusion of a random sample effect in our normalization model. our simulation study on the discovery of true metabolitemetabolite correlations included cohort, batch and sample effects in the simulated data, as well as a simulated calibration compound. although true nmr data are more complex, and the calibration standard affects the data in a more intricate way than by simple scaling, we think the study gives some pointers concerning performance of different normalization methods, and how the power is affected when we use either raw or standardized data. in summary, our simulations show that using raw data compared with standardized data has a slight edge when it comes to performance (measured as average auc). however, the loss in power using standardized data compared with raw data is small and the added advantages of better metabolite quantitation and chemical shift calibration render standardized data a feasible choice when estimating correlations. in our correlation-robustness study (based on real data), we investigate how stable the correlations are when removing one or several metabolites from the set, and re-normalizing without the removed metabolites. the study shows that methods developed for high-dimensional datasets, like the loess smoother, perform poorly for smaller datasets, if at all applicable. the commonly. raw nmr data compared with the standardized counterpart. the inter-metabolite correlations for five metabolites (alanine, choline, glutamate, glycine and valine) are compared in raw and standardized data for three normalization methods and non-normalized data in the hdf datasetnote: the columns represent the different methods used; mixed model, quantile normalization (qn) and variance stabilizing normalization (vsn). the average auc value of 50 repeats of each scenario is given, with the standard deviation in parenthesis. a graphical representation of the results is provided in appendix e (supplementary). used median normalization is also problematic when removing certain sets of metabolites, and the same trend can be seen for the sum scaling method. the mixed model we propose is a robust choice. in this article, we focus on low-dimensional metabolomics datasets for two main reasons. first, the normalization methods adopted from the microarray community (e.g. quantile normalization) are usually not applicable to these sets, and as current methods for metabolomics data have restrictions (either demanding presence of multiple standards or intended for differential analysis), customized methods are needed. second, in mmca, the focus is usually to unravel metabolitemetabolite correlations for a smaller set of metabolites, and targeted datasets are mainly used for this. when evaluating our mixed model for larger datasets (varying size between 20640 features), contrasting it with quantile and variance stabilizing normalization (vsn), we conclude that a model-based approach is to prefer for datasets with less than $100 features. for larger sets, the variance stabilizing approach performs equally well as a mixed model and better than quantile normalization. as mixed models are hard to adapt for large-scale sets, vsn is a good alternative. the real data we use in this article have a complex structure with cohorts, batches and samples. the normalization method based on the mixed model can also be applied to simpler designs, e.g. when the nesting consists of samples within batches, making it applicable to many scenarios. the estimation of the fixed and random effects in the mixed model is coupled to an iterative procedure to estimate the correlation matrix of the metabolites simultaneously. however, it is also possible to apply the method for just one iteration, and ignore the estimation of the correlation matrix in the first step, as we do in one of the simulation studies. this is a feasible option when the purpose is only to normalize the data, in e.g. a p 4 n (more metabolites than samples) setting.we present a mixed model approach to normalization of lowdimensional metabolomics datasets. we show that this method performs well compared with competing methods with respect to robustness and discovery of true correlations. we also use real and simulated data to infer how standardization with a calibration compound affects the estimation of correlations. although the performance for non-standardized data is slightly better than for standardized data, the benefits of chemical shift calibration in identifying metabolites as well as in quantitation of metabolite concentrations motivate the use of a calibration standard in nmr experiments.  
